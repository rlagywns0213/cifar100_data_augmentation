{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cutout.ipynb","provenance":[{"file_id":"1pSPNcOLDPSKONSeGALl1Jplu9ET9z-1q","timestamp":1619081668342}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0cc36555109249c1b4b47b51069dd24a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bd4bb92ab8c941838e879518b38a4cd0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4d34bbaa63b4a19b4b7cf611e756283","IPY_MODEL_9ddbbc922612429dab1107e2c26bf039"]}},"bd4bb92ab8c941838e879518b38a4cd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4d34bbaa63b4a19b4b7cf611e756283":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_baed98cd9e7b4576834fba188584da9d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c103e67a9dec419e8f0c7434192bfc6c"}},"9ddbbc922612429dab1107e2c26bf039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71df241ab1614356ac3533cf2cd22686","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [00:18&lt;00:00, 8904825.08it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9ea147c20aa4eda8a3cab047cfd2031"}},"baed98cd9e7b4576834fba188584da9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c103e67a9dec419e8f0c7434192bfc6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71df241ab1614356ac3533cf2cd22686":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b9ea147c20aa4eda8a3cab047cfd2031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OSFGYaIDG6f0"},"source":["Cutout Data Augmentation.\n","\n","This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"]},{"cell_type":"markdown","metadata":{"id":"vCVSE5-UboYl"},"source":["##**Import all neceassary packages**\n","\n"]},{"cell_type":"code","metadata":{"id":"5YBMwPsubsbX"},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L88afYXKMSdL"},"source":["##**Model - Define ResNet Model**"]},{"cell_type":"code","metadata":{"id":"eMFSLTnkMQdq"},"source":["'''ResNet18/34/50/101/152 in Pytorch.'''\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18(num_classes=10):\n","    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n","\n","def ResNet34(num_classes=10):\n","    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n","\n","def ResNet50(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n","\n","def ResNet101(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n","\n","def ResNet152(num_classes=10):\n","    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n","\n","def test_resnet():\n","    net = ResNet50()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test_resnet()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjM3cl279Lvg"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"gIvuSgE49Kvu"},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6y3zhSfMbdC"},"source":["##**Cutout: Main Code for Applying Cutout data augmentation**"]},{"cell_type":"code","metadata":{"id":"iMQI2K4AMopg"},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s8oXpzdMvol"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"Pjeqawi9cNK6"},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'resnet34' # resnet18, resnet50, resnet101\n","batch_size = 128  # Input batch size for training (default: 128)\n","epochs = 150 # Number of epochs to train (default: 200)\n","learning_rate = 0.1 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","cutout = True # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","seed = 0 # Random seed (default: 0)\n","print_freq = 30\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXL_PBj6cVoe"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["0cc36555109249c1b4b47b51069dd24a","bd4bb92ab8c941838e879518b38a4cd0","b4d34bbaa63b4a19b4b7cf611e756283","9ddbbc922612429dab1107e2c26bf039","baed98cd9e7b4576834fba188584da9d","c103e67a9dec419e8f0c7434192bfc6c","71df241ab1614356ac3533cf2cd22686","b9ea147c20aa4eda8a3cab047cfd2031"]},"id":"dvQjH3T9caYs","executionInfo":{"status":"ok","timestamp":1620709407862,"user_tz":-540,"elapsed":11008,"user":{"displayName":"‍강정흠[학생](대학원 컴퓨터공학과)","photoUrl":"","userId":"06099435212534282294"}},"outputId":"2ccf4b8c-97e4-40f9-ed73-7fde8c3ea2dc"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","train_transform = transforms.Compose([])\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","if cutout:\n","    train_transform.transforms.append(Cutout(n_holes=n_holes, length=length))\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cc36555109249c1b4b47b51069dd24a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gITLQIAr9lAZ"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"s0-lYvAp9oHA","executionInfo":{"status":"error","timestamp":1620710284354,"user_tz":-540,"elapsed":28610,"user":{"displayName":"‍강정흠[학생](대학원 컴퓨터공학과)","photoUrl":"","userId":"06099435212534282294"}},"outputId":"c6af480a-c830-4e20-d257-f4e710d098d3"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","model = ResNet34(num_classes=num_classes).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n","\n","scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","###########################################################\n","best_acc = 0\n","for epoch in range(epochs):\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), 'model_best.pt')\n","\n","torch.save(model.state_dict(),'model_latest.pt')\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","----- epoch: 0, lr: 0.1 -----\n","torch.Size([128, 100]) torch.Size([128])\n","Epoch: [0][  0/391]\tTime  0.277 ( 0.277)\tLoss 4.7767e+00 (4.7767e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   5.47 (  5.47)\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","Epoch: [0][ 30/391]\tTime  0.169 ( 0.175)\tLoss 5.1212e+00 (5.7276e+00)\tAcc@1   0.78 (  1.21)\tAcc@5   5.47 (  5.75)\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","Epoch: [0][ 60/391]\tTime  0.171 ( 0.172)\tLoss 4.5906e+00 (5.1996e+00)\tAcc@1   1.56 (  1.59)\tAcc@5  12.50 (  6.99)\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","Epoch: [0][ 90/391]\tTime  0.171 ( 0.172)\tLoss 4.4746e+00 (4.9647e+00)\tAcc@1   1.56 (  1.84)\tAcc@5  10.16 (  8.28)\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","Epoch: [0][120/391]\tTime  0.172 ( 0.172)\tLoss 4.3439e+00 (4.8137e+00)\tAcc@1   3.12 (  2.28)\tAcc@5  11.72 (  9.95)\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","Epoch: [0][150/391]\tTime  0.176 ( 0.172)\tLoss 4.3614e+00 (4.7032e+00)\tAcc@1   5.47 (  2.67)\tAcc@5  21.09 ( 11.49)\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n","torch.Size([128, 100]) torch.Size([128])\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-eb965a66af7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-eb965a66af7e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, epoch, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"IDzDv3_FyInA"},"source":["import torch\n","import pandas as pd\n","import argparse\n","import time\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","def eval():\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    test_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        normalize\n","    ])\n","\n","    test_dataset = torchvision.datasets.ImageFolder('./test', transform=test_transform)\n","    test_loader = DataLoader(test_dataset, batch_size=2, num_workers=4, shuffle=False)\n","\n","    model = ReXNetV1(width_mult=0.6, depth_mult=1.0)\n","    model = model.cuda()\n","    model.load_state_dict(torch.load(SAVEPATH+'model_weight.pth'))\n","\n","    print('Make an evaluation csv file for kaggle submission...')\n","    model.eval()\n","    \n","    Category = []\n","    for input, _ in test_loader:\n","        input = input.cuda()\n","        output = model(input)\n","        output = torch.argmax(output, dim=1)\n","        Category = Category + output.tolist()\n","\n","    Id = list(range(0, 8000))\n","    samples = {\n","       'Id': Id,\n","       'Category': Category \n","    }\n","    df = pd.DataFrame(samples, columns=['Id', 'Category'])\n","\n","    df.to_csv(SAVEPATH+'submission.csv', index=False)\n","    print('Done!!')\n","\n","\n","if __name__ == \"__main__\":\n","    eval()"],"execution_count":null,"outputs":[]}]}