{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"random_erase+cutout.ipynb","provenance":[{"file_id":"18b80wpeQD1Wj6NjwZFFhZGDuMWWW1TIZ","timestamp":1619872182172},{"file_id":"1pSPNcOLDPSKONSeGALl1Jplu9ET9z-1q","timestamp":1619081668342}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9154d7f68a064149a5c9ecbb1891a0f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_baa9fa802d5b4f208d6b2316786e83bd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6e329d91a3c2406695311ce3d06d3a5e","IPY_MODEL_143500376faa43c8accbf5a554d0f9bd"]}},"baa9fa802d5b4f208d6b2316786e83bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e329d91a3c2406695311ce3d06d3a5e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5cc24daea5a04c1688ceab35e0256431","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_373c4cf78ac440aca27e63a20bc4c706"}},"143500376faa43c8accbf5a554d0f9bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5b45531fa8845bea51939a05bd52f6c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [00:24&lt;00:00, 6827432.69it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3428c339d4ab4a69b5f3bd1541c5f5ae"}},"5cc24daea5a04c1688ceab35e0256431":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"373c4cf78ac440aca27e63a20bc4c706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5b45531fa8845bea51939a05bd52f6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3428c339d4ab4a69b5f3bd1541c5f5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OSFGYaIDG6f0"},"source":["Cutout Data Augmentation. + Random Erase\n","\n","This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n","\n","+ \n","\n","https://github.com/zhunzhong07/Random-Erasing\n"]},{"cell_type":"markdown","metadata":{"id":"vCVSE5-UboYl"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"id":"5YBMwPsubsbX"},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import math\n","import random\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR\n","\n","from torchvision import datasets, transforms\n","\n","from tqdm.notebook import tqdm as tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L88afYXKMSdL"},"source":["##**Model - Define ResNet Model**"]},{"cell_type":"code","metadata":{"id":"eMFSLTnkMQdq"},"source":["'''ResNet18/34/50/101/152 in Pytorch.'''\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18(num_classes=10):\n","    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n","\n","def ResNet34(num_classes=10):\n","    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n","\n","def ResNet50(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n","\n","def ResNet101(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n","\n","def ResNet152(num_classes=10):\n","    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n","\n","def test_resnet():\n","    net = ResNet50()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test_resnet()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjM3cl279Lvg"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"gIvuSgE49Kvu"},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s8oXpzdMvol"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"Pjeqawi9cNK6"},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'resnet34' # resnet18, resnet50, resnet101\n","batch_size = 128  # Input batch size for training (default: 128)\n","epochs = 150 # Number of epochs to train (default: 200)\n","learning_rate = 0.1 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","cutout = True # Apply Cutout?\n","n_holes = 1 # Number of holes to cut out from image\n","length = 16 # Length of the holes\n","seed = 0 # Random seed (default: 0)\n","print_freq = 30\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","\n","# Random Erasing\n","p=0\n","sh=0.4\n","r1=0.3\n","\n","\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXL_PBj6cVoe"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"id":"kxLzEbnrb0h5"},"source":["'''\n","p: probability that the random erasing operation will be performed.\n","scale: range of proportion of erased area against input image.\n","ratio: range of aspect ratio of erased area.\n","value: erasing value. Default is 0. If a single int, it is used to\n","'''\n","# Random Erasing\n","p = 0 #default 'Random Erasing probability' ==> p\n","sh = 0.4 #default 'max erasing area'  ==>  ratio\n","r1 = 0.3 #default 'aspect of erasing area' ==> ratio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_32isPMccu4"},"source":["class RandomErasing(object):\n","    '''\n","    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n","    -------------------------------------------------------------------------------------\n","    probability: The probability that the operation will be performed.\n","    sl: min erasing area\n","    sh: max erasing area\n","    r1: min aspect ratio\n","    mean: erasing value\n","    -------------------------------------------------------------------------------------\n","    '''\n","    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n","        self.probability = probability\n","        self.mean = mean\n","        self.sl = sl\n","        self.sh = sh\n","        self.r1 = r1\n","       \n","    def __call__(self, img):\n","\n","        if random.uniform(0, 1) > self.probability:\n","            return img\n","\n","        for attempt in range(100):\n","            area = img.size()[1] * img.size()[2]\n","       \n","            target_area = random.uniform(self.sl, self.sh) * area\n","            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n","\n","            h = int(round(math.sqrt(target_area * aspect_ratio)))\n","            w = int(round(math.sqrt(target_area / aspect_ratio)))\n","\n","            if w < img.size()[2] and h < img.size()[1]:\n","                x1 = random.randint(0, img.size()[1] - h)\n","                y1 = random.randint(0, img.size()[2] - w)\n","                if img.size()[0] == 3:\n","                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n","                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n","                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n","                else:\n","                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n","                return img\n","\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Z0Tg_7ACQ36"},"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119,"referenced_widgets":["9154d7f68a064149a5c9ecbb1891a0f0","baa9fa802d5b4f208d6b2316786e83bd","6e329d91a3c2406695311ce3d06d3a5e","143500376faa43c8accbf5a554d0f9bd","5cc24daea5a04c1688ceab35e0256431","373c4cf78ac440aca27e63a20bc4c706","b5b45531fa8845bea51939a05bd52f6c","3428c339d4ab4a69b5f3bd1541c5f5ae"]},"id":"9pNFGOTZbs7z","executionInfo":{"status":"ok","timestamp":1620142827552,"user_tz":-540,"elapsed":16630,"user":{"displayName":"ê¹€íš¨ì¤€","photoUrl":"","userId":"12098101409760390036"}},"outputId":"20b22b8c-e35e-4039-b814-b66c2baf4300"},"source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    RandomErasing(probability = 0.5, sh = sh, r1 = r1 ),\n","    Cutout(n_holes=n_holes, length=length)\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","\n","num_classes = 100\n","train_dataset = datasets.CIFAR100(root='data/',\n","                                    train=True,\n","                                    transform=transform_train,\n","                                    download=True)\n","\n","test_dataset = datasets.CIFAR100(root='data/',\n","                                    train=False,\n","                                    transform=transform_test,\n","                                    download=True)\n","\n","\n","train_loader =torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9154d7f68a064149a5c9ecbb1891a0f0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Weeu3YVYwZ5T","executionInfo":{"status":"ok","timestamp":1620142836818,"user_tz":-540,"elapsed":8217,"user":{"displayName":"ê¹€íš¨ì¤€","photoUrl":"","userId":"12098101409760390036"}},"outputId":"d0b57ce6-be0d-4e19-ca99-5ef364cb98ef"},"source":["import math\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","len(labels)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"T5jt2VAIwc_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620142836819,"user_tz":-540,"elapsed":6933,"user":{"displayName":"ê¹€íš¨ì¤€","photoUrl":"","userId":"12098101409760390036"}},"outputId":"1c78129b-96c3-447d-a5a1-6581e60a585d"},"source":["print(images.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([128, 3, 32, 32])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gITLQIAr9lAZ"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0-lYvAp9oHA","executionInfo":{"status":"ok","timestamp":1620147363501,"user_tz":-540,"elapsed":146814,"user":{"displayName":"ê¹€íš¨ì¤€","photoUrl":"","userId":"12098101409760390036"}},"outputId":"7f460963-a481-4280-d2ca-913b32262491"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg\n","\n","model = ResNet34(num_classes=num_classes).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n","\n","scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","###########################################################\n","best_acc = 0\n","for epoch in range(epochs):\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    start_time = time.time()\n","    train(train_loader, epoch, model, optimizer, criterion)\n","    test_acc = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    if best_acc < test_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), 'model_best.pt')\n","\n","torch.save(model.state_dict(),'model_latest.pt')\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","----- epoch: 0, lr: 0.1 -----\n","Epoch: [0][  0/391]\tTime  0.704 ( 0.704)\tLoss 4.7744e+00 (4.7744e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   3.91 (  3.91)\n","Epoch: [0][ 30/391]\tTime  0.066 ( 0.088)\tLoss 4.5024e+00 (4.9716e+00)\tAcc@1   3.91 (  1.39)\tAcc@5  10.16 (  6.30)\n","Epoch: [0][ 60/391]\tTime  0.086 ( 0.080)\tLoss 4.5341e+00 (4.7440e+00)\tAcc@1   3.12 (  1.83)\tAcc@5  10.94 (  8.38)\n","Epoch: [0][ 90/391]\tTime  0.067 ( 0.076)\tLoss 4.3004e+00 (4.6123e+00)\tAcc@1   3.12 (  2.38)\tAcc@5  14.06 ( 10.47)\n","Epoch: [0][120/391]\tTime  0.056 ( 0.074)\tLoss 4.0429e+00 (4.5269e+00)\tAcc@1   3.91 (  2.74)\tAcc@5  23.44 ( 12.13)\n","Epoch: [0][150/391]\tTime  0.053 ( 0.074)\tLoss 4.2394e+00 (4.4603e+00)\tAcc@1   3.12 (  3.00)\tAcc@5  14.84 ( 13.47)\n","Epoch: [0][180/391]\tTime  0.062 ( 0.073)\tLoss 4.1357e+00 (4.4100e+00)\tAcc@1   3.91 (  3.41)\tAcc@5  20.31 ( 14.69)\n","Epoch: [0][210/391]\tTime  0.048 ( 0.073)\tLoss 4.0691e+00 (4.3639e+00)\tAcc@1   7.81 (  3.84)\tAcc@5  24.22 ( 15.84)\n","Epoch: [0][240/391]\tTime  0.074 ( 0.072)\tLoss 4.0083e+00 (4.3268e+00)\tAcc@1   8.59 (  4.10)\tAcc@5  23.44 ( 16.84)\n","Epoch: [0][270/391]\tTime  0.061 ( 0.072)\tLoss 4.0684e+00 (4.2926e+00)\tAcc@1   9.38 (  4.43)\tAcc@5  21.88 ( 17.84)\n","Epoch: [0][300/391]\tTime  0.076 ( 0.071)\tLoss 4.0425e+00 (4.2664e+00)\tAcc@1   6.25 (  4.64)\tAcc@5  20.31 ( 18.53)\n","Epoch: [0][330/391]\tTime  0.061 ( 0.071)\tLoss 4.3039e+00 (4.2388e+00)\tAcc@1   5.47 (  4.90)\tAcc@5  17.19 ( 19.26)\n","Epoch: [0][360/391]\tTime  0.093 ( 0.071)\tLoss 3.8119e+00 (4.2133e+00)\tAcc@1  10.94 (  5.12)\tAcc@5  31.25 ( 19.96)\n","Epoch: [0][390/391]\tTime  0.273 ( 0.071)\tLoss 3.5716e+00 (4.1900e+00)\tAcc@1  13.75 (  5.37)\tAcc@5  42.50 ( 20.60)\n","==> Train Accuracy: Acc@1 5.370 || Acc@5 20.604\n","==> Test Accuracy:  Acc@1 10.220 || Acc@5 31.190\n","==> 30.03 seconds to train this epoch\n","\n","\n","----- epoch: 1, lr: 0.1 -----\n","Epoch: [1][  0/391]\tTime  0.245 ( 0.245)\tLoss 3.8943e+00 (3.8943e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  24.22 ( 24.22)\n","Epoch: [1][ 30/391]\tTime  0.074 ( 0.074)\tLoss 3.9273e+00 (3.8773e+00)\tAcc@1   9.38 (  8.74)\tAcc@5  27.34 ( 29.59)\n","Epoch: [1][ 60/391]\tTime  0.064 ( 0.072)\tLoss 3.9249e+00 (3.8507e+00)\tAcc@1  12.50 (  9.07)\tAcc@5  30.47 ( 30.56)\n","Epoch: [1][ 90/391]\tTime  0.073 ( 0.071)\tLoss 3.7067e+00 (3.8372e+00)\tAcc@1  13.28 (  9.49)\tAcc@5  31.25 ( 31.15)\n","Epoch: [1][120/391]\tTime  0.101 ( 0.071)\tLoss 3.6249e+00 (3.8260e+00)\tAcc@1  14.84 (  9.76)\tAcc@5  36.72 ( 31.53)\n","Epoch: [1][150/391]\tTime  0.054 ( 0.071)\tLoss 3.8322e+00 (3.8099e+00)\tAcc@1   9.38 (  9.96)\tAcc@5  32.81 ( 31.99)\n","Epoch: [1][180/391]\tTime  0.067 ( 0.071)\tLoss 3.7510e+00 (3.8015e+00)\tAcc@1   7.81 ( 10.10)\tAcc@5  32.03 ( 32.29)\n","Epoch: [1][210/391]\tTime  0.065 ( 0.071)\tLoss 3.6924e+00 (3.7911e+00)\tAcc@1   9.38 ( 10.23)\tAcc@5  34.38 ( 32.63)\n","Epoch: [1][240/391]\tTime  0.076 ( 0.070)\tLoss 3.6565e+00 (3.7749e+00)\tAcc@1  14.06 ( 10.50)\tAcc@5  36.72 ( 33.08)\n","Epoch: [1][270/391]\tTime  0.072 ( 0.070)\tLoss 3.5551e+00 (3.7657e+00)\tAcc@1  16.41 ( 10.70)\tAcc@5  39.84 ( 33.39)\n","Epoch: [1][300/391]\tTime  0.085 ( 0.070)\tLoss 3.5722e+00 (3.7526e+00)\tAcc@1  16.41 ( 10.95)\tAcc@5  39.06 ( 33.86)\n","Epoch: [1][330/391]\tTime  0.060 ( 0.070)\tLoss 3.6105e+00 (3.7415e+00)\tAcc@1  14.06 ( 11.14)\tAcc@5  34.38 ( 34.09)\n","Epoch: [1][360/391]\tTime  0.093 ( 0.070)\tLoss 3.8666e+00 (3.7308e+00)\tAcc@1  13.28 ( 11.34)\tAcc@5  33.59 ( 34.38)\n","Epoch: [1][390/391]\tTime  0.047 ( 0.070)\tLoss 3.3479e+00 (3.7170e+00)\tAcc@1  11.25 ( 11.52)\tAcc@5  42.50 ( 34.83)\n","==> Train Accuracy: Acc@1 11.520 || Acc@5 34.832\n","==> Test Accuracy:  Acc@1 16.890 || Acc@5 43.800\n","==> 29.40 seconds to train this epoch\n","\n","\n","----- epoch: 2, lr: 0.1 -----\n","Epoch: [2][  0/391]\tTime  0.256 ( 0.256)\tLoss 3.5573e+00 (3.5573e+00)\tAcc@1  11.72 ( 11.72)\tAcc@5  38.28 ( 38.28)\n","Epoch: [2][ 30/391]\tTime  0.053 ( 0.076)\tLoss 3.2219e+00 (3.5037e+00)\tAcc@1  21.09 ( 14.74)\tAcc@5  47.66 ( 41.23)\n","Epoch: [2][ 60/391]\tTime  0.090 ( 0.074)\tLoss 3.6335e+00 (3.5081e+00)\tAcc@1  17.19 ( 14.64)\tAcc@5  37.50 ( 41.43)\n","Epoch: [2][ 90/391]\tTime  0.063 ( 0.072)\tLoss 3.4194e+00 (3.4983e+00)\tAcc@1  19.53 ( 15.07)\tAcc@5  44.53 ( 41.62)\n","Epoch: [2][120/391]\tTime  0.078 ( 0.072)\tLoss 3.6590e+00 (3.4954e+00)\tAcc@1  10.16 ( 15.32)\tAcc@5  35.16 ( 41.85)\n","Epoch: [2][150/391]\tTime  0.086 ( 0.071)\tLoss 3.3523e+00 (3.4859e+00)\tAcc@1  19.53 ( 15.56)\tAcc@5  50.00 ( 42.07)\n","Epoch: [2][180/391]\tTime  0.093 ( 0.071)\tLoss 3.4264e+00 (3.4779e+00)\tAcc@1  22.66 ( 15.81)\tAcc@5  44.53 ( 42.37)\n","Epoch: [2][210/391]\tTime  0.080 ( 0.071)\tLoss 3.3104e+00 (3.4669e+00)\tAcc@1  15.62 ( 15.92)\tAcc@5  46.09 ( 42.69)\n","Epoch: [2][240/391]\tTime  0.067 ( 0.070)\tLoss 3.4593e+00 (3.4529e+00)\tAcc@1  16.41 ( 16.25)\tAcc@5  46.88 ( 43.10)\n","Epoch: [2][270/391]\tTime  0.072 ( 0.070)\tLoss 3.4368e+00 (3.4394e+00)\tAcc@1  14.84 ( 16.50)\tAcc@5  42.97 ( 43.60)\n","Epoch: [2][300/391]\tTime  0.098 ( 0.070)\tLoss 3.0242e+00 (3.4263e+00)\tAcc@1  19.53 ( 16.65)\tAcc@5  58.59 ( 44.05)\n","Epoch: [2][330/391]\tTime  0.069 ( 0.070)\tLoss 3.2737e+00 (3.4144e+00)\tAcc@1  16.41 ( 16.86)\tAcc@5  46.88 ( 44.33)\n","Epoch: [2][360/391]\tTime  0.052 ( 0.070)\tLoss 3.1542e+00 (3.4026e+00)\tAcc@1  25.00 ( 17.12)\tAcc@5  50.00 ( 44.76)\n","Epoch: [2][390/391]\tTime  0.048 ( 0.070)\tLoss 3.4272e+00 (3.3909e+00)\tAcc@1  21.25 ( 17.40)\tAcc@5  43.75 ( 45.11)\n","==> Train Accuracy: Acc@1 17.404 || Acc@5 45.112\n","==> Test Accuracy:  Acc@1 23.350 || Acc@5 54.350\n","==> 29.50 seconds to train this epoch\n","\n","\n","----- epoch: 3, lr: 0.1 -----\n","Epoch: [3][  0/391]\tTime  0.274 ( 0.274)\tLoss 3.3828e+00 (3.3828e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  47.66 ( 47.66)\n","Epoch: [3][ 30/391]\tTime  0.064 ( 0.075)\tLoss 3.4885e+00 (3.2520e+00)\tAcc@1  17.19 ( 20.06)\tAcc@5  39.84 ( 49.65)\n","Epoch: [3][ 60/391]\tTime  0.082 ( 0.073)\tLoss 3.2528e+00 (3.2327e+00)\tAcc@1  17.19 ( 20.71)\tAcc@5  52.34 ( 49.53)\n","Epoch: [3][ 90/391]\tTime  0.064 ( 0.072)\tLoss 3.2174e+00 (3.2098e+00)\tAcc@1  17.97 ( 21.21)\tAcc@5  50.00 ( 50.23)\n","Epoch: [3][120/391]\tTime  0.083 ( 0.071)\tLoss 3.2152e+00 (3.1954e+00)\tAcc@1  17.19 ( 21.55)\tAcc@5  53.91 ( 50.72)\n","Epoch: [3][150/391]\tTime  0.082 ( 0.070)\tLoss 3.1959e+00 (3.1860e+00)\tAcc@1  19.53 ( 21.69)\tAcc@5  50.78 ( 51.05)\n","Epoch: [3][180/391]\tTime  0.052 ( 0.070)\tLoss 3.2263e+00 (3.1895e+00)\tAcc@1  21.88 ( 21.51)\tAcc@5  46.88 ( 50.83)\n","Epoch: [3][210/391]\tTime  0.066 ( 0.070)\tLoss 3.2730e+00 (3.1800e+00)\tAcc@1  18.75 ( 21.70)\tAcc@5  41.41 ( 50.99)\n","Epoch: [3][240/391]\tTime  0.099 ( 0.070)\tLoss 3.0602e+00 (3.1709e+00)\tAcc@1  22.66 ( 21.78)\tAcc@5  53.91 ( 51.21)\n","Epoch: [3][270/391]\tTime  0.076 ( 0.070)\tLoss 2.9645e+00 (3.1629e+00)\tAcc@1  25.78 ( 21.83)\tAcc@5  57.81 ( 51.43)\n","Epoch: [3][300/391]\tTime  0.096 ( 0.070)\tLoss 2.8562e+00 (3.1537e+00)\tAcc@1  29.69 ( 22.01)\tAcc@5  64.84 ( 51.57)\n","Epoch: [3][330/391]\tTime  0.067 ( 0.070)\tLoss 3.0499e+00 (3.1464e+00)\tAcc@1  25.00 ( 22.16)\tAcc@5  57.03 ( 51.74)\n","Epoch: [3][360/391]\tTime  0.073 ( 0.070)\tLoss 2.9270e+00 (3.1389e+00)\tAcc@1  28.91 ( 22.33)\tAcc@5  61.72 ( 51.95)\n","Epoch: [3][390/391]\tTime  0.047 ( 0.070)\tLoss 2.9988e+00 (3.1313e+00)\tAcc@1  27.50 ( 22.47)\tAcc@5  53.75 ( 52.12)\n","==> Train Accuracy: Acc@1 22.470 || Acc@5 52.118\n","==> Test Accuracy:  Acc@1 27.910 || Acc@5 59.370\n","==> 29.44 seconds to train this epoch\n","\n","\n","----- epoch: 4, lr: 0.1 -----\n","Epoch: [4][  0/391]\tTime  0.250 ( 0.250)\tLoss 2.8450e+00 (2.8450e+00)\tAcc@1  28.12 ( 28.12)\tAcc@5  57.81 ( 57.81)\n","Epoch: [4][ 30/391]\tTime  0.046 ( 0.075)\tLoss 3.0241e+00 (2.9693e+00)\tAcc@1  21.09 ( 24.65)\tAcc@5  54.69 ( 57.21)\n","Epoch: [4][ 60/391]\tTime  0.086 ( 0.073)\tLoss 2.9009e+00 (2.9528e+00)\tAcc@1  30.47 ( 25.09)\tAcc@5  59.38 ( 57.48)\n","Epoch: [4][ 90/391]\tTime  0.055 ( 0.072)\tLoss 2.9410e+00 (2.9456e+00)\tAcc@1  22.66 ( 25.73)\tAcc@5  60.94 ( 57.49)\n","Epoch: [4][120/391]\tTime  0.055 ( 0.071)\tLoss 2.8600e+00 (2.9402e+00)\tAcc@1  26.56 ( 26.01)\tAcc@5  57.81 ( 57.40)\n","Epoch: [4][150/391]\tTime  0.053 ( 0.071)\tLoss 2.7582e+00 (2.9332e+00)\tAcc@1  31.25 ( 26.22)\tAcc@5  61.72 ( 57.39)\n","Epoch: [4][180/391]\tTime  0.057 ( 0.070)\tLoss 2.9054e+00 (2.9321e+00)\tAcc@1  27.34 ( 26.23)\tAcc@5  58.59 ( 57.46)\n","Epoch: [4][210/391]\tTime  0.056 ( 0.070)\tLoss 3.0539e+00 (2.9301e+00)\tAcc@1  25.78 ( 26.27)\tAcc@5  51.56 ( 57.41)\n","Epoch: [4][240/391]\tTime  0.057 ( 0.070)\tLoss 2.9951e+00 (2.9227e+00)\tAcc@1  21.88 ( 26.27)\tAcc@5  65.62 ( 57.61)\n","Epoch: [4][270/391]\tTime  0.088 ( 0.070)\tLoss 2.8835e+00 (2.9240e+00)\tAcc@1  34.38 ( 26.37)\tAcc@5  58.59 ( 57.54)\n","Epoch: [4][300/391]\tTime  0.060 ( 0.070)\tLoss 2.8683e+00 (2.9166e+00)\tAcc@1  28.91 ( 26.54)\tAcc@5  59.38 ( 57.68)\n","Epoch: [4][330/391]\tTime  0.087 ( 0.070)\tLoss 2.7674e+00 (2.9082e+00)\tAcc@1  26.56 ( 26.71)\tAcc@5  62.50 ( 57.90)\n","Epoch: [4][360/391]\tTime  0.083 ( 0.070)\tLoss 2.7489e+00 (2.9022e+00)\tAcc@1  29.69 ( 26.87)\tAcc@5  64.06 ( 58.09)\n","Epoch: [4][390/391]\tTime  0.047 ( 0.070)\tLoss 2.9079e+00 (2.8948e+00)\tAcc@1  26.25 ( 26.95)\tAcc@5  61.25 ( 58.24)\n","==> Train Accuracy: Acc@1 26.954 || Acc@5 58.238\n","==> Test Accuracy:  Acc@1 24.970 || Acc@5 56.450\n","==> 29.37 seconds to train this epoch\n","\n","\n","----- epoch: 5, lr: 0.1 -----\n","Epoch: [5][  0/391]\tTime  0.236 ( 0.236)\tLoss 2.6184e+00 (2.6184e+00)\tAcc@1  32.81 ( 32.81)\tAcc@5  66.41 ( 66.41)\n","Epoch: [5][ 30/391]\tTime  0.061 ( 0.073)\tLoss 2.7132e+00 (2.7311e+00)\tAcc@1  25.78 ( 29.66)\tAcc@5  67.19 ( 62.25)\n","Epoch: [5][ 60/391]\tTime  0.057 ( 0.070)\tLoss 2.5937e+00 (2.7404e+00)\tAcc@1  31.25 ( 29.21)\tAcc@5  64.06 ( 61.78)\n","Epoch: [5][ 90/391]\tTime  0.071 ( 0.070)\tLoss 2.5801e+00 (2.7387e+00)\tAcc@1  35.16 ( 29.43)\tAcc@5  64.06 ( 61.68)\n","Epoch: [5][120/391]\tTime  0.065 ( 0.070)\tLoss 2.8752e+00 (2.7467e+00)\tAcc@1  30.47 ( 29.49)\tAcc@5  58.59 ( 61.36)\n","Epoch: [5][150/391]\tTime  0.063 ( 0.069)\tLoss 2.9197e+00 (2.7394e+00)\tAcc@1  25.00 ( 29.66)\tAcc@5  54.69 ( 61.72)\n","Epoch: [5][180/391]\tTime  0.052 ( 0.069)\tLoss 2.3840e+00 (2.7344e+00)\tAcc@1  37.50 ( 29.83)\tAcc@5  75.00 ( 61.89)\n","Epoch: [5][210/391]\tTime  0.059 ( 0.069)\tLoss 2.5904e+00 (2.7423e+00)\tAcc@1  28.91 ( 29.62)\tAcc@5  66.41 ( 61.69)\n","Epoch: [5][240/391]\tTime  0.084 ( 0.069)\tLoss 2.7175e+00 (2.7443e+00)\tAcc@1  30.47 ( 29.59)\tAcc@5  60.94 ( 61.66)\n","Epoch: [5][270/391]\tTime  0.063 ( 0.069)\tLoss 2.5723e+00 (2.7375e+00)\tAcc@1  41.41 ( 29.75)\tAcc@5  64.84 ( 61.83)\n","Epoch: [5][300/391]\tTime  0.076 ( 0.069)\tLoss 2.5313e+00 (2.7301e+00)\tAcc@1  28.91 ( 29.93)\tAcc@5  67.19 ( 62.08)\n","Epoch: [5][330/391]\tTime  0.075 ( 0.069)\tLoss 2.7576e+00 (2.7293e+00)\tAcc@1  32.03 ( 29.94)\tAcc@5  58.59 ( 62.11)\n","Epoch: [5][360/391]\tTime  0.060 ( 0.070)\tLoss 2.7460e+00 (2.7236e+00)\tAcc@1  30.47 ( 30.12)\tAcc@5  57.81 ( 62.28)\n","Epoch: [5][390/391]\tTime  0.053 ( 0.069)\tLoss 2.3556e+00 (2.7129e+00)\tAcc@1  40.00 ( 30.39)\tAcc@5  72.50 ( 62.54)\n","==> Train Accuracy: Acc@1 30.390 || Acc@5 62.544\n","==> Test Accuracy:  Acc@1 33.680 || Acc@5 66.670\n","==> 29.30 seconds to train this epoch\n","\n","\n","----- epoch: 6, lr: 0.1 -----\n","Epoch: [6][  0/391]\tTime  0.257 ( 0.257)\tLoss 2.9368e+00 (2.9368e+00)\tAcc@1  26.56 ( 26.56)\tAcc@5  55.47 ( 55.47)\n","Epoch: [6][ 30/391]\tTime  0.056 ( 0.074)\tLoss 2.5073e+00 (2.5389e+00)\tAcc@1  34.38 ( 32.96)\tAcc@5  60.94 ( 66.28)\n","Epoch: [6][ 60/391]\tTime  0.079 ( 0.072)\tLoss 2.3050e+00 (2.5497e+00)\tAcc@1  35.94 ( 33.61)\tAcc@5  70.31 ( 65.77)\n","Epoch: [6][ 90/391]\tTime  0.070 ( 0.071)\tLoss 2.7143e+00 (2.5650e+00)\tAcc@1  32.03 ( 32.95)\tAcc@5  58.59 ( 65.55)\n","Epoch: [6][120/391]\tTime  0.059 ( 0.070)\tLoss 2.5583e+00 (2.5711e+00)\tAcc@1  35.94 ( 32.90)\tAcc@5  62.50 ( 65.28)\n","Epoch: [6][150/391]\tTime  0.073 ( 0.070)\tLoss 2.7381e+00 (2.5645e+00)\tAcc@1  29.69 ( 33.17)\tAcc@5  58.59 ( 65.57)\n","Epoch: [6][180/391]\tTime  0.065 ( 0.070)\tLoss 2.7209e+00 (2.5540e+00)\tAcc@1  32.03 ( 33.57)\tAcc@5  64.06 ( 65.73)\n","Epoch: [6][210/391]\tTime  0.076 ( 0.070)\tLoss 2.4676e+00 (2.5596e+00)\tAcc@1  39.06 ( 33.47)\tAcc@5  71.88 ( 65.65)\n","Epoch: [6][240/391]\tTime  0.064 ( 0.069)\tLoss 2.6766e+00 (2.5541e+00)\tAcc@1  29.69 ( 33.64)\tAcc@5  62.50 ( 65.87)\n","Epoch: [6][270/391]\tTime  0.071 ( 0.069)\tLoss 2.6082e+00 (2.5576e+00)\tAcc@1  35.94 ( 33.63)\tAcc@5  62.50 ( 65.86)\n","Epoch: [6][300/391]\tTime  0.069 ( 0.069)\tLoss 2.3853e+00 (2.5561e+00)\tAcc@1  41.41 ( 33.67)\tAcc@5  68.75 ( 65.90)\n","Epoch: [6][330/391]\tTime  0.054 ( 0.069)\tLoss 2.3998e+00 (2.5547e+00)\tAcc@1  35.16 ( 33.64)\tAcc@5  71.09 ( 65.98)\n","Epoch: [6][360/391]\tTime  0.077 ( 0.069)\tLoss 2.4729e+00 (2.5526e+00)\tAcc@1  36.72 ( 33.61)\tAcc@5  66.41 ( 66.04)\n","Epoch: [6][390/391]\tTime  0.050 ( 0.069)\tLoss 2.5160e+00 (2.5462e+00)\tAcc@1  35.00 ( 33.79)\tAcc@5  66.25 ( 66.20)\n","==> Train Accuracy: Acc@1 33.794 || Acc@5 66.198\n","==> Test Accuracy:  Acc@1 33.720 || Acc@5 65.940\n","==> 29.29 seconds to train this epoch\n","\n","\n","----- epoch: 7, lr: 0.1 -----\n","Epoch: [7][  0/391]\tTime  0.255 ( 0.255)\tLoss 2.3932e+00 (2.3932e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  67.19 ( 67.19)\n","Epoch: [7][ 30/391]\tTime  0.064 ( 0.075)\tLoss 2.1908e+00 (2.4816e+00)\tAcc@1  39.06 ( 35.51)\tAcc@5  73.44 ( 67.31)\n","Epoch: [7][ 60/391]\tTime  0.077 ( 0.073)\tLoss 2.3262e+00 (2.4650e+00)\tAcc@1  39.06 ( 35.60)\tAcc@5  71.88 ( 67.75)\n","Epoch: [7][ 90/391]\tTime  0.059 ( 0.071)\tLoss 2.4533e+00 (2.4573e+00)\tAcc@1  35.94 ( 35.83)\tAcc@5  67.19 ( 67.97)\n","Epoch: [7][120/391]\tTime  0.055 ( 0.071)\tLoss 2.3535e+00 (2.4602e+00)\tAcc@1  40.62 ( 35.74)\tAcc@5  70.31 ( 67.95)\n","Epoch: [7][150/391]\tTime  0.091 ( 0.070)\tLoss 2.2808e+00 (2.4548e+00)\tAcc@1  40.62 ( 35.95)\tAcc@5  73.44 ( 68.17)\n","Epoch: [7][180/391]\tTime  0.068 ( 0.070)\tLoss 2.4482e+00 (2.4501e+00)\tAcc@1  40.62 ( 36.14)\tAcc@5  69.53 ( 68.28)\n","Epoch: [7][210/391]\tTime  0.068 ( 0.070)\tLoss 2.3117e+00 (2.4372e+00)\tAcc@1  39.06 ( 36.32)\tAcc@5  71.88 ( 68.48)\n","Epoch: [7][240/391]\tTime  0.057 ( 0.070)\tLoss 2.3804e+00 (2.4361e+00)\tAcc@1  35.16 ( 36.38)\tAcc@5  69.53 ( 68.41)\n","Epoch: [7][270/391]\tTime  0.048 ( 0.069)\tLoss 2.2587e+00 (2.4278e+00)\tAcc@1  39.06 ( 36.58)\tAcc@5  73.44 ( 68.64)\n","Epoch: [7][300/391]\tTime  0.084 ( 0.069)\tLoss 2.4399e+00 (2.4243e+00)\tAcc@1  38.28 ( 36.62)\tAcc@5  67.97 ( 68.80)\n","Epoch: [7][330/391]\tTime  0.099 ( 0.069)\tLoss 2.0876e+00 (2.4238e+00)\tAcc@1  41.41 ( 36.54)\tAcc@5  79.69 ( 68.92)\n","Epoch: [7][360/391]\tTime  0.062 ( 0.069)\tLoss 2.4526e+00 (2.4188e+00)\tAcc@1  35.94 ( 36.56)\tAcc@5  70.31 ( 69.04)\n","Epoch: [7][390/391]\tTime  0.048 ( 0.069)\tLoss 2.3827e+00 (2.4184e+00)\tAcc@1  37.50 ( 36.59)\tAcc@5  67.50 ( 69.07)\n","==> Train Accuracy: Acc@1 36.592 || Acc@5 69.066\n","==> Test Accuracy:  Acc@1 35.950 || Acc@5 68.280\n","==> 29.24 seconds to train this epoch\n","\n","\n","----- epoch: 8, lr: 0.1 -----\n","Epoch: [8][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.3478e+00 (2.3478e+00)\tAcc@1  29.69 ( 29.69)\tAcc@5  70.31 ( 70.31)\n","Epoch: [8][ 30/391]\tTime  0.107 ( 0.077)\tLoss 2.5047e+00 (2.3121e+00)\tAcc@1  32.03 ( 39.24)\tAcc@5  68.75 ( 71.65)\n","Epoch: [8][ 60/391]\tTime  0.063 ( 0.073)\tLoss 1.8801e+00 (2.3247e+00)\tAcc@1  48.44 ( 38.23)\tAcc@5  82.03 ( 71.29)\n","Epoch: [8][ 90/391]\tTime  0.082 ( 0.072)\tLoss 2.0579e+00 (2.3182e+00)\tAcc@1  42.19 ( 38.24)\tAcc@5  76.56 ( 71.41)\n","Epoch: [8][120/391]\tTime  0.068 ( 0.072)\tLoss 2.2613e+00 (2.3139e+00)\tAcc@1  40.62 ( 38.32)\tAcc@5  71.09 ( 71.56)\n","Epoch: [8][150/391]\tTime  0.099 ( 0.071)\tLoss 2.4209e+00 (2.3187e+00)\tAcc@1  35.94 ( 38.42)\tAcc@5  70.31 ( 71.46)\n","Epoch: [8][180/391]\tTime  0.065 ( 0.071)\tLoss 2.3338e+00 (2.3191e+00)\tAcc@1  39.06 ( 38.41)\tAcc@5  67.97 ( 71.42)\n","Epoch: [8][210/391]\tTime  0.066 ( 0.071)\tLoss 2.3175e+00 (2.3154e+00)\tAcc@1  41.41 ( 38.49)\tAcc@5  73.44 ( 71.63)\n","Epoch: [8][240/391]\tTime  0.061 ( 0.070)\tLoss 2.1122e+00 (2.3106e+00)\tAcc@1  42.97 ( 38.65)\tAcc@5  74.22 ( 71.86)\n","Epoch: [8][270/391]\tTime  0.070 ( 0.070)\tLoss 2.2981e+00 (2.3151e+00)\tAcc@1  33.59 ( 38.57)\tAcc@5  71.09 ( 71.75)\n","Epoch: [8][300/391]\tTime  0.083 ( 0.070)\tLoss 2.2582e+00 (2.3092e+00)\tAcc@1  42.19 ( 38.77)\tAcc@5  71.09 ( 71.84)\n","Epoch: [8][330/391]\tTime  0.059 ( 0.070)\tLoss 2.6433e+00 (2.3130e+00)\tAcc@1  35.16 ( 38.77)\tAcc@5  66.41 ( 71.70)\n","Epoch: [8][360/391]\tTime  0.089 ( 0.070)\tLoss 2.4612e+00 (2.3131e+00)\tAcc@1  33.59 ( 38.76)\tAcc@5  71.09 ( 71.66)\n","Epoch: [8][390/391]\tTime  0.046 ( 0.069)\tLoss 2.1312e+00 (2.3115e+00)\tAcc@1  45.00 ( 38.78)\tAcc@5  77.50 ( 71.71)\n","==> Train Accuracy: Acc@1 38.782 || Acc@5 71.708\n","==> Test Accuracy:  Acc@1 42.920 || Acc@5 73.400\n","==> 29.30 seconds to train this epoch\n","\n","\n","----- epoch: 9, lr: 0.1 -----\n","Epoch: [9][  0/391]\tTime  0.249 ( 0.249)\tLoss 2.1522e+00 (2.1522e+00)\tAcc@1  42.97 ( 42.97)\tAcc@5  67.97 ( 67.97)\n","Epoch: [9][ 30/391]\tTime  0.073 ( 0.076)\tLoss 2.0439e+00 (2.1684e+00)\tAcc@1  39.84 ( 41.38)\tAcc@5  75.00 ( 73.44)\n","Epoch: [9][ 60/391]\tTime  0.076 ( 0.073)\tLoss 2.4303e+00 (2.1890e+00)\tAcc@1  32.81 ( 40.98)\tAcc@5  64.84 ( 73.28)\n","Epoch: [9][ 90/391]\tTime  0.062 ( 0.072)\tLoss 2.2967e+00 (2.1858e+00)\tAcc@1  39.84 ( 41.29)\tAcc@5  73.44 ( 73.65)\n","Epoch: [9][120/391]\tTime  0.086 ( 0.071)\tLoss 2.1584e+00 (2.2114e+00)\tAcc@1  42.97 ( 40.82)\tAcc@5  76.56 ( 73.17)\n","Epoch: [9][150/391]\tTime  0.077 ( 0.071)\tLoss 2.5654e+00 (2.2137e+00)\tAcc@1  34.38 ( 40.83)\tAcc@5  72.66 ( 73.25)\n","Epoch: [9][180/391]\tTime  0.082 ( 0.071)\tLoss 2.4395e+00 (2.2141e+00)\tAcc@1  35.16 ( 40.81)\tAcc@5  67.97 ( 73.18)\n","Epoch: [9][210/391]\tTime  0.061 ( 0.070)\tLoss 2.4435e+00 (2.2148e+00)\tAcc@1  35.94 ( 40.87)\tAcc@5  69.53 ( 73.25)\n","Epoch: [9][240/391]\tTime  0.068 ( 0.070)\tLoss 2.2934e+00 (2.2165e+00)\tAcc@1  36.72 ( 40.88)\tAcc@5  75.00 ( 73.22)\n","Epoch: [9][270/391]\tTime  0.062 ( 0.070)\tLoss 2.2324e+00 (2.2192e+00)\tAcc@1  37.50 ( 40.77)\tAcc@5  72.66 ( 73.24)\n","Epoch: [9][300/391]\tTime  0.072 ( 0.070)\tLoss 2.3762e+00 (2.2159e+00)\tAcc@1  42.97 ( 40.88)\tAcc@5  67.97 ( 73.36)\n","Epoch: [9][330/391]\tTime  0.078 ( 0.070)\tLoss 2.0353e+00 (2.2104e+00)\tAcc@1  47.66 ( 40.95)\tAcc@5  74.22 ( 73.52)\n","Epoch: [9][360/391]\tTime  0.087 ( 0.070)\tLoss 2.2344e+00 (2.2121e+00)\tAcc@1  42.19 ( 40.95)\tAcc@5  73.44 ( 73.53)\n","Epoch: [9][390/391]\tTime  0.047 ( 0.069)\tLoss 2.3650e+00 (2.2129e+00)\tAcc@1  37.50 ( 40.95)\tAcc@5  66.25 ( 73.48)\n","==> Train Accuracy: Acc@1 40.954 || Acc@5 73.484\n","==> Test Accuracy:  Acc@1 43.390 || Acc@5 75.160\n","==> 29.24 seconds to train this epoch\n","\n","\n","----- epoch: 10, lr: 0.1 -----\n","Epoch: [10][  0/391]\tTime  0.276 ( 0.276)\tLoss 2.1504e+00 (2.1504e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5  75.00 ( 75.00)\n","Epoch: [10][ 30/391]\tTime  0.068 ( 0.074)\tLoss 1.9068e+00 (2.0334e+00)\tAcc@1  52.34 ( 45.84)\tAcc@5  75.00 ( 76.66)\n","Epoch: [10][ 60/391]\tTime  0.071 ( 0.074)\tLoss 2.3151e+00 (2.0929e+00)\tAcc@1  36.72 ( 44.42)\tAcc@5  66.41 ( 75.79)\n","Epoch: [10][ 90/391]\tTime  0.069 ( 0.072)\tLoss 1.7938e+00 (2.1015e+00)\tAcc@1  46.88 ( 43.96)\tAcc@5  82.81 ( 75.62)\n","Epoch: [10][120/391]\tTime  0.096 ( 0.072)\tLoss 2.0470e+00 (2.1136e+00)\tAcc@1  48.44 ( 43.55)\tAcc@5  77.34 ( 75.29)\n","Epoch: [10][150/391]\tTime  0.085 ( 0.071)\tLoss 2.2851e+00 (2.1185e+00)\tAcc@1  42.97 ( 43.46)\tAcc@5  67.97 ( 75.14)\n","Epoch: [10][180/391]\tTime  0.061 ( 0.071)\tLoss 2.0570e+00 (2.1122e+00)\tAcc@1  46.88 ( 43.64)\tAcc@5  78.12 ( 75.21)\n","Epoch: [10][210/391]\tTime  0.065 ( 0.071)\tLoss 2.3909e+00 (2.1175e+00)\tAcc@1  43.75 ( 43.60)\tAcc@5  68.75 ( 75.11)\n","Epoch: [10][240/391]\tTime  0.062 ( 0.071)\tLoss 2.1509e+00 (2.1187e+00)\tAcc@1  43.75 ( 43.57)\tAcc@5  73.44 ( 75.10)\n","Epoch: [10][270/391]\tTime  0.091 ( 0.071)\tLoss 1.9557e+00 (2.1188e+00)\tAcc@1  46.09 ( 43.53)\tAcc@5  82.03 ( 75.05)\n","Epoch: [10][300/391]\tTime  0.076 ( 0.070)\tLoss 2.0985e+00 (2.1135e+00)\tAcc@1  47.66 ( 43.57)\tAcc@5  75.00 ( 75.18)\n","Epoch: [10][330/391]\tTime  0.053 ( 0.070)\tLoss 2.0317e+00 (2.1117e+00)\tAcc@1  46.88 ( 43.56)\tAcc@5  77.34 ( 75.28)\n","Epoch: [10][360/391]\tTime  0.063 ( 0.070)\tLoss 2.0439e+00 (2.1098e+00)\tAcc@1  47.66 ( 43.66)\tAcc@5  75.00 ( 75.32)\n","Epoch: [10][390/391]\tTime  0.047 ( 0.070)\tLoss 1.9088e+00 (2.1108e+00)\tAcc@1  47.50 ( 43.66)\tAcc@5  83.75 ( 75.30)\n","==> Train Accuracy: Acc@1 43.656 || Acc@5 75.296\n","==> Test Accuracy:  Acc@1 44.690 || Acc@5 76.500\n","==> 29.46 seconds to train this epoch\n","\n","\n","----- epoch: 11, lr: 0.1 -----\n","Epoch: [11][  0/391]\tTime  0.268 ( 0.268)\tLoss 2.2220e+00 (2.2220e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5  71.88 ( 71.88)\n","Epoch: [11][ 30/391]\tTime  0.096 ( 0.078)\tLoss 1.9406e+00 (2.0160e+00)\tAcc@1  44.53 ( 45.04)\tAcc@5  78.12 ( 77.09)\n","Epoch: [11][ 60/391]\tTime  0.054 ( 0.073)\tLoss 1.9125e+00 (1.9889e+00)\tAcc@1  55.47 ( 45.98)\tAcc@5  76.56 ( 77.59)\n","Epoch: [11][ 90/391]\tTime  0.069 ( 0.072)\tLoss 1.8664e+00 (2.0073e+00)\tAcc@1  52.34 ( 45.50)\tAcc@5  77.34 ( 77.43)\n","Epoch: [11][120/391]\tTime  0.081 ( 0.072)\tLoss 2.0501e+00 (2.0180e+00)\tAcc@1  45.31 ( 45.36)\tAcc@5  73.44 ( 77.10)\n","Epoch: [11][150/391]\tTime  0.051 ( 0.071)\tLoss 2.1663e+00 (2.0254e+00)\tAcc@1  35.16 ( 45.20)\tAcc@5  75.00 ( 77.06)\n","Epoch: [11][180/391]\tTime  0.081 ( 0.071)\tLoss 2.2059e+00 (2.0332e+00)\tAcc@1  44.53 ( 45.03)\tAcc@5  74.22 ( 77.04)\n","Epoch: [11][210/391]\tTime  0.076 ( 0.071)\tLoss 2.1917e+00 (2.0343e+00)\tAcc@1  42.97 ( 45.09)\tAcc@5  73.44 ( 76.97)\n","Epoch: [11][240/391]\tTime  0.088 ( 0.071)\tLoss 2.3455e+00 (2.0377e+00)\tAcc@1  35.16 ( 45.03)\tAcc@5  67.97 ( 76.78)\n","Epoch: [11][270/391]\tTime  0.071 ( 0.071)\tLoss 1.9822e+00 (2.0359e+00)\tAcc@1  45.31 ( 45.06)\tAcc@5  71.09 ( 76.78)\n","Epoch: [11][300/391]\tTime  0.060 ( 0.070)\tLoss 2.0975e+00 (2.0294e+00)\tAcc@1  48.44 ( 45.19)\tAcc@5  75.00 ( 76.91)\n","Epoch: [11][330/391]\tTime  0.060 ( 0.070)\tLoss 2.2197e+00 (2.0323e+00)\tAcc@1  40.62 ( 45.08)\tAcc@5  75.78 ( 76.87)\n","Epoch: [11][360/391]\tTime  0.062 ( 0.070)\tLoss 2.1249e+00 (2.0319e+00)\tAcc@1  41.41 ( 45.04)\tAcc@5  75.00 ( 76.92)\n","Epoch: [11][390/391]\tTime  0.047 ( 0.070)\tLoss 2.1660e+00 (2.0349e+00)\tAcc@1  38.75 ( 44.93)\tAcc@5  78.75 ( 76.92)\n","==> Train Accuracy: Acc@1 44.932 || Acc@5 76.916\n","==> Test Accuracy:  Acc@1 44.910 || Acc@5 76.390\n","==> 29.66 seconds to train this epoch\n","\n","\n","----- epoch: 12, lr: 0.1 -----\n","Epoch: [12][  0/391]\tTime  0.252 ( 0.252)\tLoss 2.1030e+00 (2.1030e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  73.44 ( 73.44)\n","Epoch: [12][ 30/391]\tTime  0.078 ( 0.077)\tLoss 1.9232e+00 (1.9884e+00)\tAcc@1  47.66 ( 46.60)\tAcc@5  79.69 ( 77.52)\n","Epoch: [12][ 60/391]\tTime  0.069 ( 0.075)\tLoss 1.9806e+00 (1.9868e+00)\tAcc@1  46.88 ( 46.59)\tAcc@5  75.00 ( 77.46)\n","Epoch: [12][ 90/391]\tTime  0.064 ( 0.074)\tLoss 1.7143e+00 (1.9758e+00)\tAcc@1  50.00 ( 46.94)\tAcc@5  82.03 ( 77.73)\n","Epoch: [12][120/391]\tTime  0.063 ( 0.073)\tLoss 2.0959e+00 (1.9814e+00)\tAcc@1  39.84 ( 46.41)\tAcc@5  75.00 ( 77.98)\n","Epoch: [12][150/391]\tTime  0.088 ( 0.072)\tLoss 1.8799e+00 (1.9812e+00)\tAcc@1  49.22 ( 46.44)\tAcc@5  79.69 ( 78.01)\n","Epoch: [12][180/391]\tTime  0.046 ( 0.072)\tLoss 1.9104e+00 (1.9815e+00)\tAcc@1  49.22 ( 46.43)\tAcc@5  75.78 ( 77.98)\n","Epoch: [12][210/391]\tTime  0.056 ( 0.072)\tLoss 1.9631e+00 (1.9892e+00)\tAcc@1  43.75 ( 46.27)\tAcc@5  80.47 ( 77.86)\n","Epoch: [12][240/391]\tTime  0.053 ( 0.072)\tLoss 2.0504e+00 (1.9866e+00)\tAcc@1  48.44 ( 46.43)\tAcc@5  75.00 ( 77.87)\n","Epoch: [12][270/391]\tTime  0.076 ( 0.073)\tLoss 1.9028e+00 (1.9864e+00)\tAcc@1  52.34 ( 46.39)\tAcc@5  82.81 ( 77.90)\n","Epoch: [12][300/391]\tTime  0.062 ( 0.074)\tLoss 2.0467e+00 (1.9860e+00)\tAcc@1  50.78 ( 46.43)\tAcc@5  76.56 ( 77.92)\n","Epoch: [12][330/391]\tTime  0.121 ( 0.074)\tLoss 1.9677e+00 (1.9835e+00)\tAcc@1  46.09 ( 46.48)\tAcc@5  78.12 ( 77.99)\n","Epoch: [12][360/391]\tTime  0.073 ( 0.074)\tLoss 1.9772e+00 (1.9849e+00)\tAcc@1  48.44 ( 46.44)\tAcc@5  81.25 ( 77.92)\n","Epoch: [12][390/391]\tTime  0.048 ( 0.074)\tLoss 2.1751e+00 (1.9887e+00)\tAcc@1  41.25 ( 46.33)\tAcc@5  66.25 ( 77.84)\n","==> Train Accuracy: Acc@1 46.330 || Acc@5 77.842\n","==> Test Accuracy:  Acc@1 48.840 || Acc@5 80.650\n","==> 31.19 seconds to train this epoch\n","\n","\n","----- epoch: 13, lr: 0.1 -----\n","Epoch: [13][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.9676e+00 (1.9676e+00)\tAcc@1  41.41 ( 41.41)\tAcc@5  80.47 ( 80.47)\n","Epoch: [13][ 30/391]\tTime  0.091 ( 0.080)\tLoss 2.1123e+00 (1.9536e+00)\tAcc@1  38.28 ( 46.90)\tAcc@5  72.66 ( 78.58)\n","Epoch: [13][ 60/391]\tTime  0.090 ( 0.076)\tLoss 1.8367e+00 (1.9156e+00)\tAcc@1  47.66 ( 47.85)\tAcc@5  78.12 ( 78.86)\n","Epoch: [13][ 90/391]\tTime  0.071 ( 0.074)\tLoss 2.1368e+00 (1.9103e+00)\tAcc@1  46.09 ( 47.92)\tAcc@5  71.88 ( 79.04)\n","Epoch: [13][120/391]\tTime  0.096 ( 0.075)\tLoss 1.7139e+00 (1.9139e+00)\tAcc@1  49.22 ( 47.75)\tAcc@5  82.81 ( 78.89)\n","Epoch: [13][150/391]\tTime  0.063 ( 0.075)\tLoss 1.8726e+00 (1.9141e+00)\tAcc@1  49.22 ( 47.64)\tAcc@5  77.34 ( 78.97)\n","Epoch: [13][180/391]\tTime  0.055 ( 0.075)\tLoss 2.0895e+00 (1.9290e+00)\tAcc@1  40.62 ( 47.26)\tAcc@5  79.69 ( 78.81)\n","Epoch: [13][210/391]\tTime  0.072 ( 0.076)\tLoss 1.7948e+00 (1.9331e+00)\tAcc@1  49.22 ( 47.12)\tAcc@5  80.47 ( 78.66)\n","Epoch: [13][240/391]\tTime  0.097 ( 0.076)\tLoss 2.1482e+00 (1.9380e+00)\tAcc@1  42.19 ( 47.02)\tAcc@5  77.34 ( 78.62)\n","Epoch: [13][270/391]\tTime  0.050 ( 0.076)\tLoss 1.8716e+00 (1.9407e+00)\tAcc@1  49.22 ( 46.98)\tAcc@5  83.59 ( 78.61)\n","Epoch: [13][300/391]\tTime  0.065 ( 0.076)\tLoss 1.9683e+00 (1.9402e+00)\tAcc@1  48.44 ( 46.98)\tAcc@5  78.91 ( 78.61)\n","Epoch: [13][330/391]\tTime  0.051 ( 0.076)\tLoss 1.9711e+00 (1.9394e+00)\tAcc@1  48.44 ( 47.02)\tAcc@5  75.78 ( 78.60)\n","Epoch: [13][360/391]\tTime  0.062 ( 0.076)\tLoss 1.9160e+00 (1.9421e+00)\tAcc@1  49.22 ( 46.94)\tAcc@5  77.34 ( 78.59)\n","Epoch: [13][390/391]\tTime  0.048 ( 0.076)\tLoss 2.2623e+00 (1.9422e+00)\tAcc@1  37.50 ( 46.91)\tAcc@5  68.75 ( 78.55)\n","==> Train Accuracy: Acc@1 46.908 || Acc@5 78.550\n","==> Test Accuracy:  Acc@1 47.660 || Acc@5 79.420\n","==> 32.07 seconds to train this epoch\n","\n","\n","----- epoch: 14, lr: 0.1 -----\n","Epoch: [14][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.8580e+00 (1.8580e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  80.47 ( 80.47)\n","Epoch: [14][ 30/391]\tTime  0.058 ( 0.081)\tLoss 1.8964e+00 (1.8594e+00)\tAcc@1  45.31 ( 47.05)\tAcc@5  81.25 ( 80.54)\n","Epoch: [14][ 60/391]\tTime  0.055 ( 0.079)\tLoss 2.0405e+00 (1.8757e+00)\tAcc@1  42.97 ( 48.01)\tAcc@5  74.22 ( 79.67)\n","Epoch: [14][ 90/391]\tTime  0.062 ( 0.077)\tLoss 1.7952e+00 (1.8791e+00)\tAcc@1  51.56 ( 48.09)\tAcc@5  83.59 ( 79.58)\n","Epoch: [14][120/391]\tTime  0.072 ( 0.076)\tLoss 1.7306e+00 (1.8825e+00)\tAcc@1  53.91 ( 48.15)\tAcc@5  83.59 ( 79.56)\n","Epoch: [14][150/391]\tTime  0.074 ( 0.076)\tLoss 1.6474e+00 (1.8838e+00)\tAcc@1  53.12 ( 48.12)\tAcc@5  85.16 ( 79.60)\n","Epoch: [14][180/391]\tTime  0.083 ( 0.075)\tLoss 2.0730e+00 (1.8900e+00)\tAcc@1  42.97 ( 48.28)\tAcc@5  81.25 ( 79.48)\n","Epoch: [14][210/391]\tTime  0.106 ( 0.075)\tLoss 1.7837e+00 (1.8942e+00)\tAcc@1  50.78 ( 48.14)\tAcc@5  82.81 ( 79.45)\n","Epoch: [14][240/391]\tTime  0.076 ( 0.075)\tLoss 2.0246e+00 (1.8944e+00)\tAcc@1  42.97 ( 48.20)\tAcc@5  75.00 ( 79.41)\n","Epoch: [14][270/391]\tTime  0.064 ( 0.075)\tLoss 1.8267e+00 (1.9000e+00)\tAcc@1  51.56 ( 48.08)\tAcc@5  77.34 ( 79.27)\n","Epoch: [14][300/391]\tTime  0.072 ( 0.075)\tLoss 1.8819e+00 (1.9056e+00)\tAcc@1  47.66 ( 47.98)\tAcc@5  79.69 ( 79.18)\n","Epoch: [14][330/391]\tTime  0.057 ( 0.074)\tLoss 1.9495e+00 (1.9028e+00)\tAcc@1  47.66 ( 48.16)\tAcc@5  79.69 ( 79.23)\n","Epoch: [14][360/391]\tTime  0.107 ( 0.075)\tLoss 1.7533e+00 (1.9012e+00)\tAcc@1  52.34 ( 48.18)\tAcc@5  84.38 ( 79.29)\n","Epoch: [14][390/391]\tTime  0.048 ( 0.074)\tLoss 1.9545e+00 (1.8996e+00)\tAcc@1  48.75 ( 48.21)\tAcc@5  82.50 ( 79.27)\n","==> Train Accuracy: Acc@1 48.214 || Acc@5 79.270\n","==> Test Accuracy:  Acc@1 47.560 || Acc@5 80.110\n","==> 31.41 seconds to train this epoch\n","\n","\n","----- epoch: 15, lr: 0.1 -----\n","Epoch: [15][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.8803e+00 (1.8803e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  77.34 ( 77.34)\n","Epoch: [15][ 30/391]\tTime  0.064 ( 0.080)\tLoss 1.8773e+00 (1.8640e+00)\tAcc@1  42.97 ( 48.16)\tAcc@5  78.12 ( 79.76)\n","Epoch: [15][ 60/391]\tTime  0.048 ( 0.077)\tLoss 1.7694e+00 (1.8676e+00)\tAcc@1  53.12 ( 48.71)\tAcc@5  82.03 ( 79.66)\n","Epoch: [15][ 90/391]\tTime  0.074 ( 0.077)\tLoss 1.6104e+00 (1.8515e+00)\tAcc@1  55.47 ( 49.40)\tAcc@5  85.94 ( 80.06)\n","Epoch: [15][120/391]\tTime  0.137 ( 0.076)\tLoss 1.8620e+00 (1.8591e+00)\tAcc@1  46.09 ( 49.21)\tAcc@5  82.81 ( 80.06)\n","Epoch: [15][150/391]\tTime  0.114 ( 0.076)\tLoss 1.8506e+00 (1.8621e+00)\tAcc@1  53.12 ( 49.20)\tAcc@5  77.34 ( 80.01)\n","Epoch: [15][180/391]\tTime  0.095 ( 0.076)\tLoss 1.8071e+00 (1.8615e+00)\tAcc@1  49.22 ( 49.24)\tAcc@5  77.34 ( 80.08)\n","Epoch: [15][210/391]\tTime  0.065 ( 0.076)\tLoss 1.8910e+00 (1.8643e+00)\tAcc@1  54.69 ( 49.09)\tAcc@5  78.12 ( 80.07)\n","Epoch: [15][240/391]\tTime  0.087 ( 0.075)\tLoss 1.8945e+00 (1.8648e+00)\tAcc@1  50.78 ( 49.07)\tAcc@5  79.69 ( 79.97)\n","Epoch: [15][270/391]\tTime  0.107 ( 0.075)\tLoss 1.6323e+00 (1.8581e+00)\tAcc@1  50.00 ( 49.21)\tAcc@5  88.28 ( 80.12)\n","Epoch: [15][300/391]\tTime  0.058 ( 0.075)\tLoss 1.8560e+00 (1.8608e+00)\tAcc@1  52.34 ( 49.15)\tAcc@5  78.91 ( 80.11)\n","Epoch: [15][330/391]\tTime  0.065 ( 0.075)\tLoss 1.8651e+00 (1.8572e+00)\tAcc@1  45.31 ( 49.23)\tAcc@5  80.47 ( 80.19)\n","Epoch: [15][360/391]\tTime  0.074 ( 0.075)\tLoss 1.8970e+00 (1.8569e+00)\tAcc@1  44.53 ( 49.23)\tAcc@5  80.47 ( 80.19)\n","Epoch: [15][390/391]\tTime  0.048 ( 0.074)\tLoss 1.7112e+00 (1.8582e+00)\tAcc@1  52.50 ( 49.19)\tAcc@5  86.25 ( 80.17)\n","==> Train Accuracy: Acc@1 49.186 || Acc@5 80.166\n","==> Test Accuracy:  Acc@1 48.680 || Acc@5 79.400\n","==> 31.24 seconds to train this epoch\n","\n","\n","----- epoch: 16, lr: 0.1 -----\n","Epoch: [16][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.8375e+00 (1.8375e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  81.25 ( 81.25)\n","Epoch: [16][ 30/391]\tTime  0.083 ( 0.079)\tLoss 1.5942e+00 (1.7817e+00)\tAcc@1  56.25 ( 50.93)\tAcc@5  82.81 ( 80.90)\n","Epoch: [16][ 60/391]\tTime  0.066 ( 0.076)\tLoss 1.7515e+00 (1.8231e+00)\tAcc@1  51.56 ( 49.85)\tAcc@5  78.91 ( 80.55)\n","Epoch: [16][ 90/391]\tTime  0.064 ( 0.075)\tLoss 1.9806e+00 (1.8283e+00)\tAcc@1  47.66 ( 50.13)\tAcc@5  80.47 ( 80.60)\n","Epoch: [16][120/391]\tTime  0.058 ( 0.074)\tLoss 1.7494e+00 (1.8189e+00)\tAcc@1  50.00 ( 50.32)\tAcc@5  82.03 ( 80.62)\n","Epoch: [16][150/391]\tTime  0.050 ( 0.073)\tLoss 1.8351e+00 (1.8121e+00)\tAcc@1  53.91 ( 50.56)\tAcc@5  83.59 ( 80.91)\n","Epoch: [16][180/391]\tTime  0.063 ( 0.074)\tLoss 2.0090e+00 (1.8110e+00)\tAcc@1  42.97 ( 50.63)\tAcc@5  79.69 ( 80.95)\n","Epoch: [16][210/391]\tTime  0.084 ( 0.073)\tLoss 1.7618e+00 (1.8105e+00)\tAcc@1  46.88 ( 50.71)\tAcc@5  85.94 ( 80.97)\n","Epoch: [16][240/391]\tTime  0.065 ( 0.073)\tLoss 2.0077e+00 (1.8108e+00)\tAcc@1  44.53 ( 50.69)\tAcc@5  76.56 ( 80.93)\n","Epoch: [16][270/391]\tTime  0.066 ( 0.073)\tLoss 1.5031e+00 (1.8149e+00)\tAcc@1  63.28 ( 50.57)\tAcc@5  81.25 ( 80.82)\n","Epoch: [16][300/391]\tTime  0.056 ( 0.073)\tLoss 2.0352e+00 (1.8198e+00)\tAcc@1  45.31 ( 50.37)\tAcc@5  73.44 ( 80.74)\n","Epoch: [16][330/391]\tTime  0.058 ( 0.073)\tLoss 1.5614e+00 (1.8224e+00)\tAcc@1  57.81 ( 50.39)\tAcc@5  89.84 ( 80.63)\n","Epoch: [16][360/391]\tTime  0.055 ( 0.073)\tLoss 1.8486e+00 (1.8202e+00)\tAcc@1  45.31 ( 50.33)\tAcc@5  81.25 ( 80.70)\n","Epoch: [16][390/391]\tTime  0.048 ( 0.073)\tLoss 1.7288e+00 (1.8257e+00)\tAcc@1  51.25 ( 50.23)\tAcc@5  81.25 ( 80.61)\n","==> Train Accuracy: Acc@1 50.230 || Acc@5 80.614\n","==> Test Accuracy:  Acc@1 52.390 || Acc@5 82.140\n","==> 30.72 seconds to train this epoch\n","\n","\n","----- epoch: 17, lr: 0.1 -----\n","Epoch: [17][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.8320e+00 (1.8320e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  81.25 ( 81.25)\n","Epoch: [17][ 30/391]\tTime  0.100 ( 0.081)\tLoss 1.5305e+00 (1.8010e+00)\tAcc@1  56.25 ( 50.53)\tAcc@5  85.94 ( 81.28)\n","Epoch: [17][ 60/391]\tTime  0.063 ( 0.076)\tLoss 1.9359e+00 (1.7939e+00)\tAcc@1  51.56 ( 50.81)\tAcc@5  73.44 ( 81.45)\n","Epoch: [17][ 90/391]\tTime  0.078 ( 0.075)\tLoss 1.7154e+00 (1.8010e+00)\tAcc@1  53.12 ( 50.52)\tAcc@5  83.59 ( 81.36)\n","Epoch: [17][120/391]\tTime  0.069 ( 0.074)\tLoss 1.6497e+00 (1.8079e+00)\tAcc@1  51.56 ( 50.41)\tAcc@5  84.38 ( 80.93)\n","Epoch: [17][150/391]\tTime  0.072 ( 0.074)\tLoss 1.6640e+00 (1.8117e+00)\tAcc@1  60.16 ( 50.22)\tAcc@5  82.03 ( 80.95)\n","Epoch: [17][180/391]\tTime  0.058 ( 0.073)\tLoss 1.6815e+00 (1.8081e+00)\tAcc@1  50.78 ( 50.35)\tAcc@5  87.50 ( 80.88)\n","Epoch: [17][210/391]\tTime  0.062 ( 0.073)\tLoss 1.6768e+00 (1.8080e+00)\tAcc@1  53.12 ( 50.33)\tAcc@5  79.69 ( 80.83)\n","Epoch: [17][240/391]\tTime  0.071 ( 0.073)\tLoss 2.0711e+00 (1.8068e+00)\tAcc@1  46.88 ( 50.42)\tAcc@5  76.56 ( 80.89)\n","Epoch: [17][270/391]\tTime  0.074 ( 0.073)\tLoss 1.6550e+00 (1.8071e+00)\tAcc@1  57.81 ( 50.43)\tAcc@5  81.25 ( 80.94)\n","Epoch: [17][300/391]\tTime  0.059 ( 0.073)\tLoss 1.7280e+00 (1.8051e+00)\tAcc@1  53.12 ( 50.50)\tAcc@5  83.59 ( 81.03)\n","Epoch: [17][330/391]\tTime  0.067 ( 0.073)\tLoss 2.0914e+00 (1.8066e+00)\tAcc@1  46.88 ( 50.48)\tAcc@5  78.12 ( 80.99)\n","Epoch: [17][360/391]\tTime  0.096 ( 0.073)\tLoss 1.6395e+00 (1.8070e+00)\tAcc@1  56.25 ( 50.46)\tAcc@5  84.38 ( 80.98)\n","Epoch: [17][390/391]\tTime  0.047 ( 0.073)\tLoss 1.8757e+00 (1.8053e+00)\tAcc@1  48.75 ( 50.49)\tAcc@5  80.00 ( 81.05)\n","==> Train Accuracy: Acc@1 50.488 || Acc@5 81.046\n","==> Test Accuracy:  Acc@1 50.080 || Acc@5 80.790\n","==> 30.67 seconds to train this epoch\n","\n","\n","----- epoch: 18, lr: 0.1 -----\n","Epoch: [18][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.9862e+00 (1.9862e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  75.78 ( 75.78)\n","Epoch: [18][ 30/391]\tTime  0.068 ( 0.076)\tLoss 1.6859e+00 (1.7743e+00)\tAcc@1  53.12 ( 51.46)\tAcc@5  82.81 ( 81.45)\n","Epoch: [18][ 60/391]\tTime  0.060 ( 0.074)\tLoss 1.5503e+00 (1.7795e+00)\tAcc@1  60.16 ( 50.95)\tAcc@5  85.16 ( 81.71)\n","Epoch: [18][ 90/391]\tTime  0.062 ( 0.073)\tLoss 1.6510e+00 (1.7845e+00)\tAcc@1  56.25 ( 50.80)\tAcc@5  83.59 ( 81.52)\n","Epoch: [18][120/391]\tTime  0.067 ( 0.072)\tLoss 1.7795e+00 (1.7810e+00)\tAcc@1  50.00 ( 51.10)\tAcc@5  82.03 ( 81.57)\n","Epoch: [18][150/391]\tTime  0.082 ( 0.072)\tLoss 2.1790e+00 (1.7683e+00)\tAcc@1  39.06 ( 51.36)\tAcc@5  73.44 ( 81.73)\n","Epoch: [18][180/391]\tTime  0.084 ( 0.072)\tLoss 1.8755e+00 (1.7726e+00)\tAcc@1  50.00 ( 51.33)\tAcc@5  77.34 ( 81.61)\n","Epoch: [18][210/391]\tTime  0.067 ( 0.071)\tLoss 1.7146e+00 (1.7711e+00)\tAcc@1  52.34 ( 51.37)\tAcc@5  83.59 ( 81.70)\n","Epoch: [18][240/391]\tTime  0.074 ( 0.072)\tLoss 1.7116e+00 (1.7720e+00)\tAcc@1  56.25 ( 51.39)\tAcc@5  81.25 ( 81.64)\n","Epoch: [18][270/391]\tTime  0.068 ( 0.071)\tLoss 1.5630e+00 (1.7680e+00)\tAcc@1  54.69 ( 51.52)\tAcc@5  85.16 ( 81.71)\n","Epoch: [18][300/391]\tTime  0.092 ( 0.071)\tLoss 1.9279e+00 (1.7750e+00)\tAcc@1  46.88 ( 51.30)\tAcc@5  81.25 ( 81.54)\n","Epoch: [18][330/391]\tTime  0.087 ( 0.071)\tLoss 1.7876e+00 (1.7729e+00)\tAcc@1  53.12 ( 51.34)\tAcc@5  80.47 ( 81.56)\n","Epoch: [18][360/391]\tTime  0.067 ( 0.071)\tLoss 1.9294e+00 (1.7732e+00)\tAcc@1  51.56 ( 51.26)\tAcc@5  77.34 ( 81.62)\n","Epoch: [18][390/391]\tTime  0.048 ( 0.071)\tLoss 1.8449e+00 (1.7706e+00)\tAcc@1  48.75 ( 51.35)\tAcc@5  78.75 ( 81.68)\n","==> Train Accuracy: Acc@1 51.352 || Acc@5 81.678\n","==> Test Accuracy:  Acc@1 53.640 || Acc@5 82.490\n","==> 30.05 seconds to train this epoch\n","\n","\n","----- epoch: 19, lr: 0.1 -----\n","Epoch: [19][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.5296e+00 (1.5296e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  84.38 ( 84.38)\n","Epoch: [19][ 30/391]\tTime  0.095 ( 0.078)\tLoss 1.7744e+00 (1.7101e+00)\tAcc@1  43.75 ( 52.14)\tAcc@5  82.03 ( 82.54)\n","Epoch: [19][ 60/391]\tTime  0.058 ( 0.074)\tLoss 1.6798e+00 (1.7608e+00)\tAcc@1  49.22 ( 50.87)\tAcc@5  85.94 ( 81.70)\n","Epoch: [19][ 90/391]\tTime  0.063 ( 0.073)\tLoss 1.9204e+00 (1.7454e+00)\tAcc@1  45.31 ( 51.36)\tAcc@5  80.47 ( 82.25)\n","Epoch: [19][120/391]\tTime  0.065 ( 0.073)\tLoss 1.5830e+00 (1.7502e+00)\tAcc@1  54.69 ( 51.37)\tAcc@5  84.38 ( 82.17)\n","Epoch: [19][150/391]\tTime  0.067 ( 0.072)\tLoss 1.6970e+00 (1.7509e+00)\tAcc@1  57.03 ( 51.52)\tAcc@5  80.47 ( 82.00)\n","Epoch: [19][180/391]\tTime  0.064 ( 0.072)\tLoss 1.5436e+00 (1.7556e+00)\tAcc@1  54.69 ( 51.45)\tAcc@5  85.16 ( 81.97)\n","Epoch: [19][210/391]\tTime  0.066 ( 0.071)\tLoss 1.4375e+00 (1.7542e+00)\tAcc@1  57.03 ( 51.33)\tAcc@5  89.06 ( 82.04)\n","Epoch: [19][240/391]\tTime  0.065 ( 0.072)\tLoss 1.6882e+00 (1.7578e+00)\tAcc@1  49.22 ( 51.27)\tAcc@5  82.81 ( 82.01)\n","Epoch: [19][270/391]\tTime  0.094 ( 0.071)\tLoss 1.5077e+00 (1.7543e+00)\tAcc@1  55.47 ( 51.35)\tAcc@5  88.28 ( 82.07)\n","Epoch: [19][300/391]\tTime  0.058 ( 0.071)\tLoss 1.9252e+00 (1.7555e+00)\tAcc@1  47.66 ( 51.39)\tAcc@5  77.34 ( 82.05)\n","Epoch: [19][330/391]\tTime  0.068 ( 0.071)\tLoss 1.6698e+00 (1.7587e+00)\tAcc@1  50.78 ( 51.36)\tAcc@5  81.25 ( 81.99)\n","Epoch: [19][360/391]\tTime  0.063 ( 0.071)\tLoss 1.7589e+00 (1.7651e+00)\tAcc@1  45.31 ( 51.26)\tAcc@5  81.25 ( 81.85)\n","Epoch: [19][390/391]\tTime  0.048 ( 0.071)\tLoss 2.3770e+00 (1.7637e+00)\tAcc@1  41.25 ( 51.34)\tAcc@5  70.00 ( 81.87)\n","==> Train Accuracy: Acc@1 51.342 || Acc@5 81.866\n","==> Test Accuracy:  Acc@1 52.080 || Acc@5 82.140\n","==> 30.08 seconds to train this epoch\n","\n","\n","----- epoch: 20, lr: 0.1 -----\n","Epoch: [20][  0/391]\tTime  0.254 ( 0.254)\tLoss 1.5924e+00 (1.5924e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  84.38 ( 84.38)\n","Epoch: [20][ 30/391]\tTime  0.077 ( 0.078)\tLoss 1.6715e+00 (1.6981e+00)\tAcc@1  46.88 ( 52.39)\tAcc@5  84.38 ( 82.46)\n","Epoch: [20][ 60/391]\tTime  0.098 ( 0.075)\tLoss 2.1980e+00 (1.6974e+00)\tAcc@1  42.97 ( 52.72)\tAcc@5  68.75 ( 82.43)\n","Epoch: [20][ 90/391]\tTime  0.074 ( 0.074)\tLoss 1.8176e+00 (1.7141e+00)\tAcc@1  52.34 ( 52.53)\tAcc@5  82.81 ( 82.22)\n","Epoch: [20][120/391]\tTime  0.077 ( 0.073)\tLoss 1.8559e+00 (1.7092e+00)\tAcc@1  47.66 ( 52.69)\tAcc@5  82.03 ( 82.55)\n","Epoch: [20][150/391]\tTime  0.069 ( 0.073)\tLoss 1.6981e+00 (1.7088e+00)\tAcc@1  51.56 ( 52.69)\tAcc@5  84.38 ( 82.54)\n","Epoch: [20][180/391]\tTime  0.074 ( 0.072)\tLoss 1.7170e+00 (1.7126e+00)\tAcc@1  55.47 ( 52.49)\tAcc@5  81.25 ( 82.49)\n","Epoch: [20][210/391]\tTime  0.064 ( 0.072)\tLoss 1.8634e+00 (1.7207e+00)\tAcc@1  50.00 ( 52.33)\tAcc@5  81.25 ( 82.49)\n","Epoch: [20][240/391]\tTime  0.110 ( 0.072)\tLoss 1.7832e+00 (1.7192e+00)\tAcc@1  48.44 ( 52.35)\tAcc@5  83.59 ( 82.51)\n","Epoch: [20][270/391]\tTime  0.106 ( 0.072)\tLoss 1.7277e+00 (1.7244e+00)\tAcc@1  52.34 ( 52.28)\tAcc@5  78.91 ( 82.41)\n","Epoch: [20][300/391]\tTime  0.085 ( 0.072)\tLoss 1.6616e+00 (1.7268e+00)\tAcc@1  53.91 ( 52.32)\tAcc@5  85.16 ( 82.37)\n","Epoch: [20][330/391]\tTime  0.056 ( 0.071)\tLoss 1.5754e+00 (1.7324e+00)\tAcc@1  53.12 ( 52.24)\tAcc@5  86.72 ( 82.25)\n","Epoch: [20][360/391]\tTime  0.053 ( 0.072)\tLoss 1.7469e+00 (1.7335e+00)\tAcc@1  51.56 ( 52.21)\tAcc@5  79.69 ( 82.22)\n","Epoch: [20][390/391]\tTime  0.039 ( 0.071)\tLoss 2.1085e+00 (1.7331e+00)\tAcc@1  50.00 ( 52.25)\tAcc@5  77.50 ( 82.21)\n","==> Train Accuracy: Acc@1 52.252 || Acc@5 82.206\n","==> Test Accuracy:  Acc@1 50.830 || Acc@5 81.890\n","==> 30.06 seconds to train this epoch\n","\n","\n","----- epoch: 21, lr: 0.1 -----\n","Epoch: [21][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.7823e+00 (1.7823e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  78.91 ( 78.91)\n","Epoch: [21][ 30/391]\tTime  0.071 ( 0.077)\tLoss 1.7712e+00 (1.6536e+00)\tAcc@1  57.03 ( 54.94)\tAcc@5  82.03 ( 83.74)\n","Epoch: [21][ 60/391]\tTime  0.061 ( 0.073)\tLoss 1.6266e+00 (1.6500e+00)\tAcc@1  57.81 ( 54.55)\tAcc@5  82.81 ( 83.85)\n","Epoch: [21][ 90/391]\tTime  0.073 ( 0.073)\tLoss 1.7370e+00 (1.6571e+00)\tAcc@1  53.12 ( 54.30)\tAcc@5  83.59 ( 83.73)\n","Epoch: [21][120/391]\tTime  0.072 ( 0.073)\tLoss 1.5418e+00 (1.6622e+00)\tAcc@1  60.16 ( 54.20)\tAcc@5  85.16 ( 83.32)\n","Epoch: [21][150/391]\tTime  0.084 ( 0.072)\tLoss 1.7938e+00 (1.6728e+00)\tAcc@1  49.22 ( 53.80)\tAcc@5  81.25 ( 83.05)\n","Epoch: [21][180/391]\tTime  0.049 ( 0.072)\tLoss 1.8194e+00 (1.6803e+00)\tAcc@1  49.22 ( 53.53)\tAcc@5  83.59 ( 82.95)\n","Epoch: [21][210/391]\tTime  0.066 ( 0.072)\tLoss 1.9047e+00 (1.6891e+00)\tAcc@1  50.00 ( 53.26)\tAcc@5  71.88 ( 82.81)\n","Epoch: [21][240/391]\tTime  0.052 ( 0.072)\tLoss 1.6673e+00 (1.6914e+00)\tAcc@1  55.47 ( 53.20)\tAcc@5  78.12 ( 82.85)\n","Epoch: [21][270/391]\tTime  0.051 ( 0.071)\tLoss 1.4978e+00 (1.6976e+00)\tAcc@1  67.19 ( 53.17)\tAcc@5  82.81 ( 82.72)\n","Epoch: [21][300/391]\tTime  0.071 ( 0.072)\tLoss 1.5945e+00 (1.7035e+00)\tAcc@1  56.25 ( 53.07)\tAcc@5  79.69 ( 82.60)\n","Epoch: [21][330/391]\tTime  0.071 ( 0.072)\tLoss 1.7812e+00 (1.7080e+00)\tAcc@1  50.00 ( 52.94)\tAcc@5  84.38 ( 82.50)\n","Epoch: [21][360/391]\tTime  0.081 ( 0.071)\tLoss 1.5891e+00 (1.7108e+00)\tAcc@1  56.25 ( 52.91)\tAcc@5  84.38 ( 82.44)\n","Epoch: [21][390/391]\tTime  0.048 ( 0.071)\tLoss 1.7700e+00 (1.7132e+00)\tAcc@1  50.00 ( 52.94)\tAcc@5  78.75 ( 82.42)\n","==> Train Accuracy: Acc@1 52.936 || Acc@5 82.416\n","==> Test Accuracy:  Acc@1 52.120 || Acc@5 81.640\n","==> 30.09 seconds to train this epoch\n","\n","\n","----- epoch: 22, lr: 0.1 -----\n","Epoch: [22][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.6468e+00 (1.6468e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  77.34 ( 77.34)\n","Epoch: [22][ 30/391]\tTime  0.078 ( 0.077)\tLoss 1.9010e+00 (1.6435e+00)\tAcc@1  54.69 ( 54.11)\tAcc@5  77.34 ( 83.52)\n","Epoch: [22][ 60/391]\tTime  0.075 ( 0.074)\tLoss 1.6469e+00 (1.6416e+00)\tAcc@1  45.31 ( 54.03)\tAcc@5  85.16 ( 83.52)\n","Epoch: [22][ 90/391]\tTime  0.055 ( 0.073)\tLoss 1.6647e+00 (1.6554e+00)\tAcc@1  52.34 ( 53.71)\tAcc@5  84.38 ( 83.44)\n","Epoch: [22][120/391]\tTime  0.052 ( 0.073)\tLoss 1.7281e+00 (1.6626e+00)\tAcc@1  51.56 ( 53.67)\tAcc@5  82.03 ( 83.28)\n","Epoch: [22][150/391]\tTime  0.066 ( 0.072)\tLoss 1.7644e+00 (1.6674e+00)\tAcc@1  55.47 ( 53.62)\tAcc@5  79.69 ( 83.15)\n","Epoch: [22][180/391]\tTime  0.062 ( 0.072)\tLoss 2.0173e+00 (1.6774e+00)\tAcc@1  43.75 ( 53.36)\tAcc@5  75.00 ( 83.11)\n","Epoch: [22][210/391]\tTime  0.067 ( 0.072)\tLoss 1.4433e+00 (1.6765e+00)\tAcc@1  57.81 ( 53.41)\tAcc@5  89.06 ( 83.20)\n","Epoch: [22][240/391]\tTime  0.054 ( 0.072)\tLoss 1.7005e+00 (1.6851e+00)\tAcc@1  53.12 ( 53.29)\tAcc@5  83.59 ( 83.06)\n","Epoch: [22][270/391]\tTime  0.085 ( 0.072)\tLoss 1.5885e+00 (1.6943e+00)\tAcc@1  52.34 ( 53.14)\tAcc@5  89.06 ( 82.97)\n","Epoch: [22][300/391]\tTime  0.064 ( 0.071)\tLoss 1.7203e+00 (1.6962e+00)\tAcc@1  55.47 ( 53.16)\tAcc@5  84.38 ( 82.93)\n","Epoch: [22][330/391]\tTime  0.079 ( 0.071)\tLoss 1.3920e+00 (1.6985e+00)\tAcc@1  61.72 ( 53.13)\tAcc@5  89.84 ( 82.88)\n","Epoch: [22][360/391]\tTime  0.085 ( 0.071)\tLoss 1.7139e+00 (1.7011e+00)\tAcc@1  47.66 ( 53.09)\tAcc@5  81.25 ( 82.90)\n","Epoch: [22][390/391]\tTime  0.047 ( 0.071)\tLoss 2.0933e+00 (1.7081e+00)\tAcc@1  50.00 ( 52.89)\tAcc@5  75.00 ( 82.78)\n","==> Train Accuracy: Acc@1 52.886 || Acc@5 82.782\n","==> Test Accuracy:  Acc@1 55.550 || Acc@5 84.390\n","==> 30.10 seconds to train this epoch\n","\n","\n","----- epoch: 23, lr: 0.1 -----\n","Epoch: [23][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.5776e+00 (1.5776e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  89.06 ( 89.06)\n","Epoch: [23][ 30/391]\tTime  0.061 ( 0.080)\tLoss 1.6888e+00 (1.6641e+00)\tAcc@1  46.88 ( 52.87)\tAcc@5  81.25 ( 83.87)\n","Epoch: [23][ 60/391]\tTime  0.084 ( 0.076)\tLoss 1.6061e+00 (1.6385e+00)\tAcc@1  55.47 ( 53.79)\tAcc@5  83.59 ( 83.93)\n","Epoch: [23][ 90/391]\tTime  0.069 ( 0.074)\tLoss 1.6882e+00 (1.6613e+00)\tAcc@1  50.00 ( 53.44)\tAcc@5  81.25 ( 83.64)\n","Epoch: [23][120/391]\tTime  0.081 ( 0.074)\tLoss 2.0154e+00 (1.6664e+00)\tAcc@1  49.22 ( 53.65)\tAcc@5  77.34 ( 83.34)\n","Epoch: [23][150/391]\tTime  0.057 ( 0.073)\tLoss 1.8800e+00 (1.6677e+00)\tAcc@1  50.78 ( 53.68)\tAcc@5  81.25 ( 83.36)\n","Epoch: [23][180/391]\tTime  0.082 ( 0.073)\tLoss 1.7990e+00 (1.6789e+00)\tAcc@1  49.22 ( 53.39)\tAcc@5  83.59 ( 83.14)\n","Epoch: [23][210/391]\tTime  0.073 ( 0.073)\tLoss 1.6583e+00 (1.6845e+00)\tAcc@1  53.12 ( 53.30)\tAcc@5  81.25 ( 83.05)\n","Epoch: [23][240/391]\tTime  0.079 ( 0.072)\tLoss 1.8541e+00 (1.6839e+00)\tAcc@1  52.34 ( 53.41)\tAcc@5  79.69 ( 83.01)\n","Epoch: [23][270/391]\tTime  0.072 ( 0.072)\tLoss 1.8734e+00 (1.6856e+00)\tAcc@1  50.00 ( 53.33)\tAcc@5  81.25 ( 82.95)\n","Epoch: [23][300/391]\tTime  0.066 ( 0.072)\tLoss 1.6528e+00 (1.6880e+00)\tAcc@1  51.56 ( 53.32)\tAcc@5  82.03 ( 82.87)\n","Epoch: [23][330/391]\tTime  0.058 ( 0.072)\tLoss 1.5326e+00 (1.6874e+00)\tAcc@1  57.81 ( 53.31)\tAcc@5  81.25 ( 82.92)\n","Epoch: [23][360/391]\tTime  0.076 ( 0.072)\tLoss 1.6934e+00 (1.6899e+00)\tAcc@1  50.00 ( 53.24)\tAcc@5  82.81 ( 82.88)\n","Epoch: [23][390/391]\tTime  0.047 ( 0.072)\tLoss 1.7081e+00 (1.6927e+00)\tAcc@1  57.50 ( 53.23)\tAcc@5  82.50 ( 82.83)\n","==> Train Accuracy: Acc@1 53.230 || Acc@5 82.830\n","==> Test Accuracy:  Acc@1 55.190 || Acc@5 84.410\n","==> 30.24 seconds to train this epoch\n","\n","\n","----- epoch: 24, lr: 0.1 -----\n","Epoch: [24][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.2981e+00 (1.2981e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  87.50 ( 87.50)\n","Epoch: [24][ 30/391]\tTime  0.066 ( 0.077)\tLoss 1.5854e+00 (1.6484e+00)\tAcc@1  60.16 ( 54.54)\tAcc@5  83.59 ( 83.49)\n","Epoch: [24][ 60/391]\tTime  0.086 ( 0.074)\tLoss 1.7026e+00 (1.6437e+00)\tAcc@1  55.47 ( 54.39)\tAcc@5  80.47 ( 83.61)\n","Epoch: [24][ 90/391]\tTime  0.094 ( 0.073)\tLoss 1.5497e+00 (1.6569e+00)\tAcc@1  58.59 ( 54.03)\tAcc@5  83.59 ( 83.77)\n","Epoch: [24][120/391]\tTime  0.067 ( 0.073)\tLoss 1.6746e+00 (1.6601e+00)\tAcc@1  53.12 ( 54.02)\tAcc@5  82.81 ( 83.70)\n","Epoch: [24][150/391]\tTime  0.073 ( 0.073)\tLoss 1.6204e+00 (1.6645e+00)\tAcc@1  53.12 ( 53.96)\tAcc@5  82.81 ( 83.50)\n","Epoch: [24][180/391]\tTime  0.069 ( 0.073)\tLoss 1.5802e+00 (1.6672e+00)\tAcc@1  58.59 ( 53.90)\tAcc@5  84.38 ( 83.43)\n","Epoch: [24][210/391]\tTime  0.077 ( 0.073)\tLoss 1.6637e+00 (1.6749e+00)\tAcc@1  50.78 ( 53.79)\tAcc@5  86.72 ( 83.33)\n","Epoch: [24][240/391]\tTime  0.101 ( 0.073)\tLoss 1.5747e+00 (1.6799e+00)\tAcc@1  53.91 ( 53.55)\tAcc@5  84.38 ( 83.19)\n","Epoch: [24][270/391]\tTime  0.066 ( 0.072)\tLoss 1.6462e+00 (1.6834e+00)\tAcc@1  53.12 ( 53.46)\tAcc@5  79.69 ( 83.09)\n","Epoch: [24][300/391]\tTime  0.062 ( 0.072)\tLoss 1.6518e+00 (1.6867e+00)\tAcc@1  54.69 ( 53.34)\tAcc@5  83.59 ( 82.99)\n","Epoch: [24][330/391]\tTime  0.094 ( 0.072)\tLoss 1.7140e+00 (1.6876e+00)\tAcc@1  60.16 ( 53.37)\tAcc@5  82.81 ( 82.96)\n","Epoch: [24][360/391]\tTime  0.109 ( 0.072)\tLoss 1.8245e+00 (1.6858e+00)\tAcc@1  56.25 ( 53.42)\tAcc@5  78.91 ( 82.98)\n","Epoch: [24][390/391]\tTime  0.047 ( 0.072)\tLoss 2.0141e+00 (1.6877e+00)\tAcc@1  48.75 ( 53.40)\tAcc@5  73.75 ( 82.90)\n","==> Train Accuracy: Acc@1 53.398 || Acc@5 82.904\n","==> Test Accuracy:  Acc@1 52.040 || Acc@5 80.860\n","==> 30.22 seconds to train this epoch\n","\n","\n","----- epoch: 25, lr: 0.1 -----\n","Epoch: [25][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.7210e+00 (1.7210e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  85.94 ( 85.94)\n","Epoch: [25][ 30/391]\tTime  0.066 ( 0.076)\tLoss 1.6223e+00 (1.6185e+00)\tAcc@1  52.34 ( 54.46)\tAcc@5  85.94 ( 84.45)\n","Epoch: [25][ 60/391]\tTime  0.052 ( 0.073)\tLoss 1.5731e+00 (1.6406e+00)\tAcc@1  54.69 ( 54.41)\tAcc@5  85.94 ( 83.79)\n","Epoch: [25][ 90/391]\tTime  0.104 ( 0.072)\tLoss 1.6264e+00 (1.6471e+00)\tAcc@1  58.59 ( 54.26)\tAcc@5  85.16 ( 83.71)\n","Epoch: [25][120/391]\tTime  0.064 ( 0.072)\tLoss 1.4690e+00 (1.6398e+00)\tAcc@1  58.59 ( 54.38)\tAcc@5  86.72 ( 83.94)\n","Epoch: [25][150/391]\tTime  0.085 ( 0.072)\tLoss 1.9505e+00 (1.6491e+00)\tAcc@1  50.00 ( 54.19)\tAcc@5  82.81 ( 83.78)\n","Epoch: [25][180/391]\tTime  0.093 ( 0.072)\tLoss 1.7169e+00 (1.6476e+00)\tAcc@1  50.78 ( 54.29)\tAcc@5  85.94 ( 83.83)\n","Epoch: [25][210/391]\tTime  0.097 ( 0.072)\tLoss 1.5965e+00 (1.6498e+00)\tAcc@1  60.16 ( 54.35)\tAcc@5  83.59 ( 83.73)\n","Epoch: [25][240/391]\tTime  0.077 ( 0.072)\tLoss 1.6748e+00 (1.6559e+00)\tAcc@1  50.78 ( 54.18)\tAcc@5  84.38 ( 83.62)\n","Epoch: [25][270/391]\tTime  0.082 ( 0.072)\tLoss 1.7208e+00 (1.6593e+00)\tAcc@1  53.12 ( 54.12)\tAcc@5  80.47 ( 83.59)\n","Epoch: [25][300/391]\tTime  0.073 ( 0.071)\tLoss 1.8379e+00 (1.6622e+00)\tAcc@1  50.78 ( 54.06)\tAcc@5  82.81 ( 83.59)\n","Epoch: [25][330/391]\tTime  0.079 ( 0.071)\tLoss 1.7883e+00 (1.6659e+00)\tAcc@1  52.34 ( 53.97)\tAcc@5  81.25 ( 83.47)\n","Epoch: [25][360/391]\tTime  0.082 ( 0.071)\tLoss 1.6732e+00 (1.6688e+00)\tAcc@1  49.22 ( 53.85)\tAcc@5  85.16 ( 83.41)\n","Epoch: [25][390/391]\tTime  0.048 ( 0.071)\tLoss 1.8068e+00 (1.6704e+00)\tAcc@1  47.50 ( 53.85)\tAcc@5  86.25 ( 83.38)\n","==> Train Accuracy: Acc@1 53.846 || Acc@5 83.382\n","==> Test Accuracy:  Acc@1 55.390 || Acc@5 84.930\n","==> 29.94 seconds to train this epoch\n","\n","\n","----- epoch: 26, lr: 0.1 -----\n","Epoch: [26][  0/391]\tTime  0.251 ( 0.251)\tLoss 1.5733e+00 (1.5733e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  87.50 ( 87.50)\n","Epoch: [26][ 30/391]\tTime  0.081 ( 0.076)\tLoss 1.7595e+00 (1.5913e+00)\tAcc@1  53.12 ( 56.07)\tAcc@5  79.69 ( 84.17)\n","Epoch: [26][ 60/391]\tTime  0.080 ( 0.074)\tLoss 1.6361e+00 (1.5945e+00)\tAcc@1  57.81 ( 55.84)\tAcc@5  82.81 ( 84.40)\n","Epoch: [26][ 90/391]\tTime  0.064 ( 0.073)\tLoss 1.6130e+00 (1.6120e+00)\tAcc@1  58.59 ( 55.40)\tAcc@5  79.69 ( 84.43)\n","Epoch: [26][120/391]\tTime  0.104 ( 0.073)\tLoss 1.6438e+00 (1.6151e+00)\tAcc@1  56.25 ( 55.27)\tAcc@5  82.81 ( 84.51)\n","Epoch: [26][150/391]\tTime  0.078 ( 0.073)\tLoss 1.5263e+00 (1.6149e+00)\tAcc@1  55.47 ( 55.33)\tAcc@5  86.72 ( 84.59)\n","Epoch: [26][180/391]\tTime  0.115 ( 0.072)\tLoss 1.7410e+00 (1.6143e+00)\tAcc@1  52.34 ( 55.34)\tAcc@5  82.03 ( 84.57)\n","Epoch: [26][210/391]\tTime  0.089 ( 0.072)\tLoss 1.6472e+00 (1.6234e+00)\tAcc@1  54.69 ( 55.09)\tAcc@5  81.25 ( 84.31)\n","Epoch: [26][240/391]\tTime  0.080 ( 0.072)\tLoss 1.7575e+00 (1.6289e+00)\tAcc@1  49.22 ( 54.88)\tAcc@5  82.03 ( 84.16)\n","Epoch: [26][270/391]\tTime  0.069 ( 0.072)\tLoss 1.7042e+00 (1.6345e+00)\tAcc@1  51.56 ( 54.73)\tAcc@5  85.94 ( 84.07)\n","Epoch: [26][300/391]\tTime  0.067 ( 0.072)\tLoss 1.4679e+00 (1.6370e+00)\tAcc@1  59.38 ( 54.71)\tAcc@5  88.28 ( 84.05)\n","Epoch: [26][330/391]\tTime  0.056 ( 0.072)\tLoss 1.7595e+00 (1.6417e+00)\tAcc@1  51.56 ( 54.60)\tAcc@5  78.12 ( 83.94)\n","Epoch: [26][360/391]\tTime  0.076 ( 0.072)\tLoss 1.7087e+00 (1.6474e+00)\tAcc@1  50.78 ( 54.42)\tAcc@5  83.59 ( 83.88)\n","Epoch: [26][390/391]\tTime  0.048 ( 0.071)\tLoss 2.1036e+00 (1.6505e+00)\tAcc@1  43.75 ( 54.34)\tAcc@5  75.00 ( 83.78)\n","==> Train Accuracy: Acc@1 54.338 || Acc@5 83.776\n","==> Test Accuracy:  Acc@1 54.980 || Acc@5 84.700\n","==> 30.11 seconds to train this epoch\n","\n","\n","----- epoch: 27, lr: 0.1 -----\n","Epoch: [27][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.6958e+00 (1.6958e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  82.03 ( 82.03)\n","Epoch: [27][ 30/391]\tTime  0.064 ( 0.077)\tLoss 1.5145e+00 (1.5790e+00)\tAcc@1  58.59 ( 55.85)\tAcc@5  85.94 ( 85.03)\n","Epoch: [27][ 60/391]\tTime  0.069 ( 0.073)\tLoss 1.6004e+00 (1.5798e+00)\tAcc@1  57.03 ( 55.78)\tAcc@5  84.38 ( 85.03)\n","Epoch: [27][ 90/391]\tTime  0.079 ( 0.073)\tLoss 1.4317e+00 (1.5920e+00)\tAcc@1  60.16 ( 55.46)\tAcc@5  85.16 ( 84.75)\n","Epoch: [27][120/391]\tTime  0.052 ( 0.072)\tLoss 1.5888e+00 (1.6008e+00)\tAcc@1  51.56 ( 55.26)\tAcc@5  86.72 ( 84.69)\n","Epoch: [27][150/391]\tTime  0.054 ( 0.072)\tLoss 1.5462e+00 (1.6166e+00)\tAcc@1  55.47 ( 54.95)\tAcc@5  87.50 ( 84.51)\n","Epoch: [27][180/391]\tTime  0.082 ( 0.072)\tLoss 1.5757e+00 (1.6229e+00)\tAcc@1  54.69 ( 54.77)\tAcc@5  85.94 ( 84.41)\n","Epoch: [27][210/391]\tTime  0.067 ( 0.072)\tLoss 1.7945e+00 (1.6277e+00)\tAcc@1  50.78 ( 54.78)\tAcc@5  77.34 ( 84.18)\n","Epoch: [27][240/391]\tTime  0.083 ( 0.072)\tLoss 1.5425e+00 (1.6277e+00)\tAcc@1  51.56 ( 54.76)\tAcc@5  85.16 ( 84.09)\n","Epoch: [27][270/391]\tTime  0.050 ( 0.072)\tLoss 1.6760e+00 (1.6345e+00)\tAcc@1  50.00 ( 54.59)\tAcc@5  82.81 ( 83.99)\n","Epoch: [27][300/391]\tTime  0.069 ( 0.072)\tLoss 1.6346e+00 (1.6364e+00)\tAcc@1  59.38 ( 54.60)\tAcc@5  81.25 ( 83.96)\n","Epoch: [27][330/391]\tTime  0.064 ( 0.072)\tLoss 1.7525e+00 (1.6373e+00)\tAcc@1  53.12 ( 54.55)\tAcc@5  83.59 ( 83.99)\n","Epoch: [27][360/391]\tTime  0.064 ( 0.072)\tLoss 1.5721e+00 (1.6404e+00)\tAcc@1  53.91 ( 54.48)\tAcc@5  82.03 ( 83.91)\n","Epoch: [27][390/391]\tTime  0.047 ( 0.071)\tLoss 2.0298e+00 (1.6429e+00)\tAcc@1  43.75 ( 54.47)\tAcc@5  78.75 ( 83.77)\n","==> Train Accuracy: Acc@1 54.466 || Acc@5 83.766\n","==> Test Accuracy:  Acc@1 56.080 || Acc@5 84.800\n","==> 30.17 seconds to train this epoch\n","\n","\n","----- epoch: 28, lr: 0.1 -----\n","Epoch: [28][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.5248e+00 (1.5248e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  85.16 ( 85.16)\n","Epoch: [28][ 30/391]\tTime  0.082 ( 0.080)\tLoss 1.5732e+00 (1.6074e+00)\tAcc@1  56.25 ( 55.57)\tAcc@5  85.94 ( 84.98)\n","Epoch: [28][ 60/391]\tTime  0.063 ( 0.075)\tLoss 1.6128e+00 (1.6078e+00)\tAcc@1  50.00 ( 55.89)\tAcc@5  84.38 ( 84.34)\n","Epoch: [28][ 90/391]\tTime  0.070 ( 0.074)\tLoss 1.8114e+00 (1.6279e+00)\tAcc@1  47.66 ( 55.04)\tAcc@5  78.12 ( 84.00)\n","Epoch: [28][120/391]\tTime  0.069 ( 0.074)\tLoss 1.5458e+00 (1.6345e+00)\tAcc@1  59.38 ( 55.04)\tAcc@5  84.38 ( 83.92)\n","Epoch: [28][150/391]\tTime  0.087 ( 0.073)\tLoss 1.6563e+00 (1.6250e+00)\tAcc@1  54.69 ( 55.19)\tAcc@5  84.38 ( 84.18)\n","Epoch: [28][180/391]\tTime  0.065 ( 0.073)\tLoss 1.6474e+00 (1.6282e+00)\tAcc@1  54.69 ( 55.11)\tAcc@5  84.38 ( 84.22)\n","Epoch: [28][210/391]\tTime  0.068 ( 0.072)\tLoss 1.7094e+00 (1.6365e+00)\tAcc@1  56.25 ( 54.91)\tAcc@5  82.81 ( 84.10)\n","Epoch: [28][240/391]\tTime  0.061 ( 0.072)\tLoss 2.0412e+00 (1.6433e+00)\tAcc@1  46.09 ( 54.72)\tAcc@5  76.56 ( 83.91)\n","Epoch: [28][270/391]\tTime  0.053 ( 0.072)\tLoss 1.8792e+00 (1.6399e+00)\tAcc@1  50.00 ( 54.86)\tAcc@5  80.47 ( 83.93)\n","Epoch: [28][300/391]\tTime  0.064 ( 0.073)\tLoss 1.8464e+00 (1.6397e+00)\tAcc@1  43.75 ( 54.81)\tAcc@5  84.38 ( 84.02)\n","Epoch: [28][330/391]\tTime  0.072 ( 0.072)\tLoss 1.5934e+00 (1.6379e+00)\tAcc@1  61.72 ( 54.87)\tAcc@5  85.16 ( 84.05)\n","Epoch: [28][360/391]\tTime  0.055 ( 0.072)\tLoss 1.6049e+00 (1.6441e+00)\tAcc@1  55.47 ( 54.77)\tAcc@5  85.16 ( 83.91)\n","Epoch: [28][390/391]\tTime  0.049 ( 0.072)\tLoss 1.4550e+00 (1.6450e+00)\tAcc@1  58.75 ( 54.72)\tAcc@5  87.50 ( 83.90)\n","==> Train Accuracy: Acc@1 54.722 || Acc@5 83.896\n","==> Test Accuracy:  Acc@1 55.140 || Acc@5 84.310\n","==> 30.47 seconds to train this epoch\n","\n","\n","----- epoch: 29, lr: 0.1 -----\n","Epoch: [29][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.5412e+00 (1.5412e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  83.59 ( 83.59)\n","Epoch: [29][ 30/391]\tTime  0.061 ( 0.077)\tLoss 1.7318e+00 (1.5540e+00)\tAcc@1  50.78 ( 56.43)\tAcc@5  85.16 ( 85.11)\n","Epoch: [29][ 60/391]\tTime  0.064 ( 0.073)\tLoss 1.6333e+00 (1.5669e+00)\tAcc@1  53.91 ( 56.16)\tAcc@5  82.81 ( 84.87)\n","Epoch: [29][ 90/391]\tTime  0.055 ( 0.072)\tLoss 1.8257e+00 (1.5728e+00)\tAcc@1  48.44 ( 56.45)\tAcc@5  75.00 ( 84.70)\n","Epoch: [29][120/391]\tTime  0.053 ( 0.072)\tLoss 1.6722e+00 (1.5733e+00)\tAcc@1  57.81 ( 56.29)\tAcc@5  82.81 ( 84.75)\n","Epoch: [29][150/391]\tTime  0.069 ( 0.072)\tLoss 1.8964e+00 (1.5975e+00)\tAcc@1  46.09 ( 55.68)\tAcc@5  78.91 ( 84.29)\n","Epoch: [29][180/391]\tTime  0.081 ( 0.072)\tLoss 1.5124e+00 (1.6035e+00)\tAcc@1  58.59 ( 55.59)\tAcc@5  85.16 ( 84.31)\n","Epoch: [29][210/391]\tTime  0.061 ( 0.071)\tLoss 1.4739e+00 (1.6078e+00)\tAcc@1  61.72 ( 55.47)\tAcc@5  89.06 ( 84.32)\n","Epoch: [29][240/391]\tTime  0.108 ( 0.071)\tLoss 1.8369e+00 (1.6145e+00)\tAcc@1  50.00 ( 55.24)\tAcc@5  80.47 ( 84.24)\n","Epoch: [29][270/391]\tTime  0.073 ( 0.071)\tLoss 1.7760e+00 (1.6200e+00)\tAcc@1  52.34 ( 55.01)\tAcc@5  79.69 ( 84.16)\n","Epoch: [29][300/391]\tTime  0.072 ( 0.071)\tLoss 1.8199e+00 (1.6210e+00)\tAcc@1  50.78 ( 54.96)\tAcc@5  77.34 ( 84.18)\n","Epoch: [29][330/391]\tTime  0.083 ( 0.071)\tLoss 1.7255e+00 (1.6244e+00)\tAcc@1  53.12 ( 54.89)\tAcc@5  85.16 ( 84.10)\n","Epoch: [29][360/391]\tTime  0.071 ( 0.072)\tLoss 1.5840e+00 (1.6275e+00)\tAcc@1  55.47 ( 54.89)\tAcc@5  81.25 ( 84.03)\n","Epoch: [29][390/391]\tTime  0.046 ( 0.071)\tLoss 1.6788e+00 (1.6293e+00)\tAcc@1  52.50 ( 54.82)\tAcc@5  86.25 ( 83.99)\n","==> Train Accuracy: Acc@1 54.818 || Acc@5 83.992\n","==> Test Accuracy:  Acc@1 52.840 || Acc@5 81.280\n","==> 30.15 seconds to train this epoch\n","\n","\n","----- epoch: 30, lr: 0.1 -----\n","Epoch: [30][  0/391]\tTime  0.266 ( 0.266)\tLoss 1.5745e+00 (1.5745e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  85.94 ( 85.94)\n","Epoch: [30][ 30/391]\tTime  0.061 ( 0.078)\tLoss 1.7146e+00 (1.5690e+00)\tAcc@1  53.12 ( 56.07)\tAcc@5  83.59 ( 84.78)\n","Epoch: [30][ 60/391]\tTime  0.069 ( 0.074)\tLoss 1.5192e+00 (1.5764e+00)\tAcc@1  57.03 ( 55.64)\tAcc@5  84.38 ( 85.12)\n","Epoch: [30][ 90/391]\tTime  0.078 ( 0.073)\tLoss 1.4732e+00 (1.5830e+00)\tAcc@1  59.38 ( 55.40)\tAcc@5  84.38 ( 85.09)\n","Epoch: [30][120/391]\tTime  0.090 ( 0.072)\tLoss 1.7976e+00 (1.5984e+00)\tAcc@1  50.00 ( 55.20)\tAcc@5  81.25 ( 84.79)\n","Epoch: [30][150/391]\tTime  0.102 ( 0.072)\tLoss 1.4298e+00 (1.5869e+00)\tAcc@1  61.72 ( 55.58)\tAcc@5  86.72 ( 85.01)\n","Epoch: [30][180/391]\tTime  0.071 ( 0.072)\tLoss 1.5308e+00 (1.5910e+00)\tAcc@1  54.69 ( 55.53)\tAcc@5  85.16 ( 84.84)\n","Epoch: [30][210/391]\tTime  0.053 ( 0.072)\tLoss 1.5783e+00 (1.5959e+00)\tAcc@1  55.47 ( 55.44)\tAcc@5  81.25 ( 84.67)\n","Epoch: [30][240/391]\tTime  0.094 ( 0.072)\tLoss 1.6811e+00 (1.6029e+00)\tAcc@1  53.12 ( 55.23)\tAcc@5  82.03 ( 84.49)\n","Epoch: [30][270/391]\tTime  0.059 ( 0.071)\tLoss 1.5463e+00 (1.6078e+00)\tAcc@1  58.59 ( 55.10)\tAcc@5  87.50 ( 84.43)\n","Epoch: [30][300/391]\tTime  0.113 ( 0.072)\tLoss 1.7110e+00 (1.6171e+00)\tAcc@1  52.34 ( 54.90)\tAcc@5  85.16 ( 84.26)\n","Epoch: [30][330/391]\tTime  0.084 ( 0.072)\tLoss 1.6938e+00 (1.6179e+00)\tAcc@1  53.12 ( 54.88)\tAcc@5  84.38 ( 84.23)\n","Epoch: [30][360/391]\tTime  0.044 ( 0.072)\tLoss 1.4231e+00 (1.6172e+00)\tAcc@1  60.16 ( 55.02)\tAcc@5  90.62 ( 84.17)\n","Epoch: [30][390/391]\tTime  0.048 ( 0.071)\tLoss 1.3698e+00 (1.6169e+00)\tAcc@1  57.50 ( 55.01)\tAcc@5  86.25 ( 84.16)\n","==> Train Accuracy: Acc@1 55.012 || Acc@5 84.162\n","==> Test Accuracy:  Acc@1 53.480 || Acc@5 82.770\n","==> 30.12 seconds to train this epoch\n","\n","\n","----- epoch: 31, lr: 0.1 -----\n","Epoch: [31][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.5338e+00 (1.5338e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  83.59 ( 83.59)\n","Epoch: [31][ 30/391]\tTime  0.073 ( 0.076)\tLoss 1.5196e+00 (1.5156e+00)\tAcc@1  58.59 ( 57.38)\tAcc@5  86.72 ( 86.11)\n","Epoch: [31][ 60/391]\tTime  0.054 ( 0.074)\tLoss 1.7116e+00 (1.5452e+00)\tAcc@1  55.47 ( 56.93)\tAcc@5  80.47 ( 85.27)\n","Epoch: [31][ 90/391]\tTime  0.076 ( 0.073)\tLoss 1.5713e+00 (1.5591e+00)\tAcc@1  56.25 ( 56.57)\tAcc@5  88.28 ( 85.20)\n","Epoch: [31][120/391]\tTime  0.080 ( 0.073)\tLoss 1.5248e+00 (1.5716e+00)\tAcc@1  60.16 ( 56.22)\tAcc@5  82.81 ( 85.09)\n","Epoch: [31][150/391]\tTime  0.084 ( 0.072)\tLoss 1.7985e+00 (1.5808e+00)\tAcc@1  52.34 ( 56.04)\tAcc@5  83.59 ( 85.00)\n","Epoch: [31][180/391]\tTime  0.068 ( 0.072)\tLoss 1.7515e+00 (1.5847e+00)\tAcc@1  49.22 ( 55.93)\tAcc@5  82.03 ( 84.91)\n","Epoch: [31][210/391]\tTime  0.061 ( 0.072)\tLoss 1.5008e+00 (1.5888e+00)\tAcc@1  60.16 ( 55.92)\tAcc@5  89.06 ( 84.86)\n","Epoch: [31][240/391]\tTime  0.062 ( 0.072)\tLoss 1.5415e+00 (1.6004e+00)\tAcc@1  57.81 ( 55.61)\tAcc@5  85.16 ( 84.63)\n","Epoch: [31][270/391]\tTime  0.054 ( 0.072)\tLoss 1.5287e+00 (1.6058e+00)\tAcc@1  59.38 ( 55.47)\tAcc@5  87.50 ( 84.48)\n","Epoch: [31][300/391]\tTime  0.090 ( 0.072)\tLoss 1.6166e+00 (1.6054e+00)\tAcc@1  53.91 ( 55.42)\tAcc@5  83.59 ( 84.45)\n","Epoch: [31][330/391]\tTime  0.115 ( 0.072)\tLoss 1.5584e+00 (1.6075e+00)\tAcc@1  58.59 ( 55.47)\tAcc@5  82.81 ( 84.37)\n","Epoch: [31][360/391]\tTime  0.070 ( 0.072)\tLoss 1.7095e+00 (1.6088e+00)\tAcc@1  53.12 ( 55.52)\tAcc@5  80.47 ( 84.34)\n","Epoch: [31][390/391]\tTime  0.048 ( 0.071)\tLoss 1.5186e+00 (1.6110e+00)\tAcc@1  62.50 ( 55.53)\tAcc@5  86.25 ( 84.31)\n","==> Train Accuracy: Acc@1 55.534 || Acc@5 84.312\n","==> Test Accuracy:  Acc@1 53.970 || Acc@5 84.150\n","==> 30.12 seconds to train this epoch\n","\n","\n","----- epoch: 32, lr: 0.1 -----\n","Epoch: [32][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.6398e+00 (1.6398e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  83.59 ( 83.59)\n","Epoch: [32][ 30/391]\tTime  0.095 ( 0.076)\tLoss 1.3510e+00 (1.5596e+00)\tAcc@1  63.28 ( 56.73)\tAcc@5  90.62 ( 85.41)\n","Epoch: [32][ 60/391]\tTime  0.059 ( 0.075)\tLoss 1.5537e+00 (1.5625e+00)\tAcc@1  58.59 ( 56.12)\tAcc@5  84.38 ( 85.30)\n","Epoch: [32][ 90/391]\tTime  0.073 ( 0.073)\tLoss 1.6261e+00 (1.5808e+00)\tAcc@1  50.00 ( 55.76)\tAcc@5  83.59 ( 84.86)\n","Epoch: [32][120/391]\tTime  0.102 ( 0.073)\tLoss 1.4790e+00 (1.5819e+00)\tAcc@1  59.38 ( 55.66)\tAcc@5  85.94 ( 84.83)\n","Epoch: [32][150/391]\tTime  0.068 ( 0.073)\tLoss 1.6001e+00 (1.5793e+00)\tAcc@1  53.12 ( 55.71)\tAcc@5  84.38 ( 84.72)\n","Epoch: [32][180/391]\tTime  0.065 ( 0.072)\tLoss 1.4828e+00 (1.5835e+00)\tAcc@1  56.25 ( 55.65)\tAcc@5  84.38 ( 84.66)\n","Epoch: [32][210/391]\tTime  0.051 ( 0.072)\tLoss 1.7164e+00 (1.5906e+00)\tAcc@1  50.78 ( 55.44)\tAcc@5  82.81 ( 84.56)\n","Epoch: [32][240/391]\tTime  0.101 ( 0.072)\tLoss 1.7247e+00 (1.5995e+00)\tAcc@1  51.56 ( 55.14)\tAcc@5  84.38 ( 84.47)\n","Epoch: [32][270/391]\tTime  0.063 ( 0.072)\tLoss 1.3786e+00 (1.6044e+00)\tAcc@1  59.38 ( 55.08)\tAcc@5  89.84 ( 84.29)\n","Epoch: [32][300/391]\tTime  0.065 ( 0.072)\tLoss 1.7630e+00 (1.6024e+00)\tAcc@1  51.56 ( 55.20)\tAcc@5  84.38 ( 84.28)\n","Epoch: [32][330/391]\tTime  0.089 ( 0.072)\tLoss 1.5498e+00 (1.6037e+00)\tAcc@1  59.38 ( 55.25)\tAcc@5  82.03 ( 84.28)\n","Epoch: [32][360/391]\tTime  0.069 ( 0.071)\tLoss 1.6037e+00 (1.6080e+00)\tAcc@1  58.59 ( 55.10)\tAcc@5  85.16 ( 84.23)\n","Epoch: [32][390/391]\tTime  0.048 ( 0.071)\tLoss 1.4440e+00 (1.6130e+00)\tAcc@1  56.25 ( 54.99)\tAcc@5  83.75 ( 84.12)\n","==> Train Accuracy: Acc@1 54.990 || Acc@5 84.116\n","==> Test Accuracy:  Acc@1 51.680 || Acc@5 81.910\n","==> 30.12 seconds to train this epoch\n","\n","\n","----- epoch: 33, lr: 0.1 -----\n","Epoch: [33][  0/391]\tTime  0.262 ( 0.262)\tLoss 1.3811e+00 (1.3811e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  88.28 ( 88.28)\n","Epoch: [33][ 30/391]\tTime  0.083 ( 0.077)\tLoss 1.2464e+00 (1.4870e+00)\tAcc@1  66.41 ( 57.76)\tAcc@5  89.06 ( 86.47)\n","Epoch: [33][ 60/391]\tTime  0.053 ( 0.074)\tLoss 1.4174e+00 (1.5304e+00)\tAcc@1  52.34 ( 56.66)\tAcc@5  87.50 ( 85.51)\n","Epoch: [33][ 90/391]\tTime  0.078 ( 0.073)\tLoss 1.5045e+00 (1.5572e+00)\tAcc@1  57.81 ( 56.23)\tAcc@5  85.16 ( 84.91)\n","Epoch: [33][120/391]\tTime  0.074 ( 0.073)\tLoss 1.6886e+00 (1.5712e+00)\tAcc@1  51.56 ( 56.00)\tAcc@5  79.69 ( 84.76)\n","Epoch: [33][150/391]\tTime  0.079 ( 0.073)\tLoss 1.5672e+00 (1.5774e+00)\tAcc@1  56.25 ( 55.90)\tAcc@5  87.50 ( 84.70)\n","Epoch: [33][180/391]\tTime  0.071 ( 0.072)\tLoss 1.5556e+00 (1.5840e+00)\tAcc@1  57.03 ( 55.72)\tAcc@5  85.16 ( 84.60)\n","Epoch: [33][210/391]\tTime  0.063 ( 0.072)\tLoss 1.4728e+00 (1.5851e+00)\tAcc@1  63.28 ( 55.84)\tAcc@5  85.94 ( 84.55)\n","Epoch: [33][240/391]\tTime  0.051 ( 0.072)\tLoss 1.7087e+00 (1.5883e+00)\tAcc@1  50.00 ( 55.74)\tAcc@5  85.94 ( 84.56)\n","Epoch: [33][270/391]\tTime  0.057 ( 0.072)\tLoss 1.6753e+00 (1.5977e+00)\tAcc@1  50.00 ( 55.40)\tAcc@5  82.03 ( 84.48)\n","Epoch: [33][300/391]\tTime  0.071 ( 0.072)\tLoss 1.4455e+00 (1.5965e+00)\tAcc@1  57.03 ( 55.42)\tAcc@5  89.06 ( 84.54)\n","Epoch: [33][330/391]\tTime  0.093 ( 0.072)\tLoss 1.5866e+00 (1.5981e+00)\tAcc@1  53.12 ( 55.39)\tAcc@5  85.16 ( 84.50)\n","Epoch: [33][360/391]\tTime  0.066 ( 0.072)\tLoss 1.8897e+00 (1.6060e+00)\tAcc@1  46.88 ( 55.30)\tAcc@5  82.03 ( 84.36)\n","Epoch: [33][390/391]\tTime  0.042 ( 0.072)\tLoss 1.6347e+00 (1.6079e+00)\tAcc@1  52.50 ( 55.27)\tAcc@5  78.75 ( 84.32)\n","==> Train Accuracy: Acc@1 55.266 || Acc@5 84.322\n","==> Test Accuracy:  Acc@1 54.600 || Acc@5 84.040\n","==> 30.33 seconds to train this epoch\n","\n","\n","----- epoch: 34, lr: 0.1 -----\n","Epoch: [34][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.4176e+00 (1.4176e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  88.28 ( 88.28)\n","Epoch: [34][ 30/391]\tTime  0.080 ( 0.078)\tLoss 1.5191e+00 (1.5685e+00)\tAcc@1  59.38 ( 56.48)\tAcc@5  85.94 ( 84.83)\n","Epoch: [34][ 60/391]\tTime  0.071 ( 0.074)\tLoss 1.4330e+00 (1.5526e+00)\tAcc@1  68.75 ( 56.80)\tAcc@5  85.16 ( 85.07)\n","Epoch: [34][ 90/391]\tTime  0.076 ( 0.073)\tLoss 1.2972e+00 (1.5320e+00)\tAcc@1  58.59 ( 57.28)\tAcc@5  88.28 ( 85.52)\n","Epoch: [34][120/391]\tTime  0.110 ( 0.073)\tLoss 1.4644e+00 (1.5444e+00)\tAcc@1  59.38 ( 57.04)\tAcc@5  89.06 ( 85.35)\n","Epoch: [34][150/391]\tTime  0.096 ( 0.073)\tLoss 1.6220e+00 (1.5528e+00)\tAcc@1  56.25 ( 56.80)\tAcc@5  86.72 ( 85.20)\n","Epoch: [34][180/391]\tTime  0.071 ( 0.072)\tLoss 1.2916e+00 (1.5595e+00)\tAcc@1  64.84 ( 56.75)\tAcc@5  89.06 ( 85.08)\n","Epoch: [34][210/391]\tTime  0.056 ( 0.072)\tLoss 1.8345e+00 (1.5660e+00)\tAcc@1  49.22 ( 56.63)\tAcc@5  84.38 ( 84.98)\n","Epoch: [34][240/391]\tTime  0.080 ( 0.072)\tLoss 1.5494e+00 (1.5692e+00)\tAcc@1  55.47 ( 56.52)\tAcc@5  82.81 ( 84.94)\n","Epoch: [34][270/391]\tTime  0.084 ( 0.072)\tLoss 1.4670e+00 (1.5747e+00)\tAcc@1  57.03 ( 56.36)\tAcc@5  89.84 ( 84.93)\n","Epoch: [34][300/391]\tTime  0.059 ( 0.072)\tLoss 1.7241e+00 (1.5791e+00)\tAcc@1  51.56 ( 56.19)\tAcc@5  81.25 ( 84.88)\n","Epoch: [34][330/391]\tTime  0.056 ( 0.072)\tLoss 1.7241e+00 (1.5883e+00)\tAcc@1  53.91 ( 56.02)\tAcc@5  84.38 ( 84.70)\n","Epoch: [34][360/391]\tTime  0.049 ( 0.072)\tLoss 1.6341e+00 (1.5932e+00)\tAcc@1  53.91 ( 55.87)\tAcc@5  82.03 ( 84.63)\n","Epoch: [34][390/391]\tTime  0.048 ( 0.072)\tLoss 1.3581e+00 (1.5944e+00)\tAcc@1  62.50 ( 55.88)\tAcc@5  82.50 ( 84.56)\n","==> Train Accuracy: Acc@1 55.884 || Acc@5 84.560\n","==> Test Accuracy:  Acc@1 58.040 || Acc@5 85.470\n","==> 30.23 seconds to train this epoch\n","\n","\n","----- epoch: 35, lr: 0.1 -----\n","Epoch: [35][  0/391]\tTime  0.242 ( 0.242)\tLoss 1.3452e+00 (1.3452e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  89.84 ( 89.84)\n","Epoch: [35][ 30/391]\tTime  0.093 ( 0.077)\tLoss 1.6918e+00 (1.5397e+00)\tAcc@1  54.69 ( 56.60)\tAcc@5  82.81 ( 84.93)\n","Epoch: [35][ 60/391]\tTime  0.099 ( 0.077)\tLoss 1.4766e+00 (1.5076e+00)\tAcc@1  58.59 ( 57.91)\tAcc@5  88.28 ( 85.37)\n","Epoch: [35][ 90/391]\tTime  0.059 ( 0.075)\tLoss 1.6800e+00 (1.5371e+00)\tAcc@1  56.25 ( 57.10)\tAcc@5  84.38 ( 85.18)\n","Epoch: [35][120/391]\tTime  0.067 ( 0.074)\tLoss 1.7384e+00 (1.5532e+00)\tAcc@1  49.22 ( 56.74)\tAcc@5  84.38 ( 85.03)\n","Epoch: [35][150/391]\tTime  0.077 ( 0.073)\tLoss 1.6230e+00 (1.5620e+00)\tAcc@1  51.56 ( 56.60)\tAcc@5  82.03 ( 84.94)\n","Epoch: [35][180/391]\tTime  0.082 ( 0.073)\tLoss 1.7273e+00 (1.5683e+00)\tAcc@1  50.78 ( 56.41)\tAcc@5  80.47 ( 84.85)\n","Epoch: [35][210/391]\tTime  0.068 ( 0.073)\tLoss 1.5994e+00 (1.5728e+00)\tAcc@1  53.91 ( 56.30)\tAcc@5  84.38 ( 84.77)\n","Epoch: [35][240/391]\tTime  0.061 ( 0.072)\tLoss 1.7678e+00 (1.5766e+00)\tAcc@1  49.22 ( 56.24)\tAcc@5  83.59 ( 84.72)\n","Epoch: [35][270/391]\tTime  0.076 ( 0.072)\tLoss 1.6016e+00 (1.5786e+00)\tAcc@1  55.47 ( 56.09)\tAcc@5  82.81 ( 84.68)\n","Epoch: [35][300/391]\tTime  0.083 ( 0.072)\tLoss 1.6089e+00 (1.5829e+00)\tAcc@1  57.03 ( 56.05)\tAcc@5  87.50 ( 84.63)\n","Epoch: [35][330/391]\tTime  0.087 ( 0.072)\tLoss 1.6007e+00 (1.5820e+00)\tAcc@1  57.03 ( 56.05)\tAcc@5  86.72 ( 84.71)\n","Epoch: [35][360/391]\tTime  0.064 ( 0.072)\tLoss 1.4701e+00 (1.5837e+00)\tAcc@1  56.25 ( 56.01)\tAcc@5  87.50 ( 84.67)\n","Epoch: [35][390/391]\tTime  0.047 ( 0.072)\tLoss 1.9760e+00 (1.5875e+00)\tAcc@1  47.50 ( 55.86)\tAcc@5  80.00 ( 84.62)\n","==> Train Accuracy: Acc@1 55.860 || Acc@5 84.622\n","==> Test Accuracy:  Acc@1 55.000 || Acc@5 83.650\n","==> 30.26 seconds to train this epoch\n","\n","\n","----- epoch: 36, lr: 0.1 -----\n","Epoch: [36][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.4334e+00 (1.4334e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  87.50 ( 87.50)\n","Epoch: [36][ 30/391]\tTime  0.067 ( 0.077)\tLoss 1.4378e+00 (1.5711e+00)\tAcc@1  58.59 ( 55.54)\tAcc@5  85.16 ( 84.98)\n","Epoch: [36][ 60/391]\tTime  0.052 ( 0.074)\tLoss 1.5083e+00 (1.5720e+00)\tAcc@1  60.16 ( 55.96)\tAcc@5  84.38 ( 84.71)\n","Epoch: [36][ 90/391]\tTime  0.097 ( 0.074)\tLoss 1.6259e+00 (1.5741e+00)\tAcc@1  53.91 ( 55.85)\tAcc@5  85.94 ( 84.79)\n","Epoch: [36][120/391]\tTime  0.089 ( 0.073)\tLoss 1.6925e+00 (1.5672e+00)\tAcc@1  52.34 ( 56.14)\tAcc@5  82.81 ( 84.98)\n","Epoch: [36][150/391]\tTime  0.065 ( 0.073)\tLoss 1.5417e+00 (1.5754e+00)\tAcc@1  57.03 ( 55.93)\tAcc@5  84.38 ( 84.90)\n","Epoch: [36][180/391]\tTime  0.053 ( 0.073)\tLoss 1.8063e+00 (1.5808e+00)\tAcc@1  50.78 ( 55.83)\tAcc@5  80.47 ( 84.83)\n","Epoch: [36][210/391]\tTime  0.060 ( 0.073)\tLoss 1.6867e+00 (1.5867e+00)\tAcc@1  57.03 ( 55.66)\tAcc@5  79.69 ( 84.75)\n","Epoch: [36][240/391]\tTime  0.060 ( 0.072)\tLoss 1.4231e+00 (1.5876e+00)\tAcc@1  54.69 ( 55.64)\tAcc@5  89.84 ( 84.71)\n","Epoch: [36][270/391]\tTime  0.051 ( 0.072)\tLoss 1.4546e+00 (1.5839e+00)\tAcc@1  53.91 ( 55.66)\tAcc@5  87.50 ( 84.81)\n","Epoch: [36][300/391]\tTime  0.062 ( 0.072)\tLoss 1.6816e+00 (1.5885e+00)\tAcc@1  53.91 ( 55.53)\tAcc@5  86.72 ( 84.72)\n","Epoch: [36][330/391]\tTime  0.059 ( 0.072)\tLoss 1.5211e+00 (1.5903e+00)\tAcc@1  63.28 ( 55.61)\tAcc@5  88.28 ( 84.63)\n","Epoch: [36][360/391]\tTime  0.064 ( 0.072)\tLoss 1.5905e+00 (1.5854e+00)\tAcc@1  57.81 ( 55.61)\tAcc@5  89.06 ( 84.72)\n","Epoch: [36][390/391]\tTime  0.047 ( 0.072)\tLoss 2.1352e+00 (1.5898e+00)\tAcc@1  47.50 ( 55.54)\tAcc@5  75.00 ( 84.63)\n","==> Train Accuracy: Acc@1 55.536 || Acc@5 84.632\n","==> Test Accuracy:  Acc@1 53.350 || Acc@5 83.140\n","==> 30.20 seconds to train this epoch\n","\n","\n","----- epoch: 37, lr: 0.1 -----\n","Epoch: [37][  0/391]\tTime  0.255 ( 0.255)\tLoss 1.6870e+00 (1.6870e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  83.59 ( 83.59)\n","Epoch: [37][ 30/391]\tTime  0.077 ( 0.076)\tLoss 1.7127e+00 (1.5536e+00)\tAcc@1  54.69 ( 56.22)\tAcc@5  83.59 ( 85.41)\n","Epoch: [37][ 60/391]\tTime  0.081 ( 0.073)\tLoss 1.7123e+00 (1.5489e+00)\tAcc@1  57.03 ( 56.67)\tAcc@5  82.81 ( 85.62)\n","Epoch: [37][ 90/391]\tTime  0.086 ( 0.072)\tLoss 1.7311e+00 (1.5583e+00)\tAcc@1  56.25 ( 56.74)\tAcc@5  82.81 ( 85.40)\n","Epoch: [37][120/391]\tTime  0.082 ( 0.072)\tLoss 1.5057e+00 (1.5545e+00)\tAcc@1  57.03 ( 56.75)\tAcc@5  84.38 ( 85.42)\n","Epoch: [37][150/391]\tTime  0.060 ( 0.072)\tLoss 1.8253e+00 (1.5709e+00)\tAcc@1  53.12 ( 56.45)\tAcc@5  81.25 ( 85.11)\n","Epoch: [37][180/391]\tTime  0.070 ( 0.071)\tLoss 1.4468e+00 (1.5764e+00)\tAcc@1  62.50 ( 56.38)\tAcc@5  85.94 ( 84.83)\n","Epoch: [37][210/391]\tTime  0.057 ( 0.072)\tLoss 1.4244e+00 (1.5743e+00)\tAcc@1  53.91 ( 56.36)\tAcc@5  90.62 ( 84.99)\n","Epoch: [37][240/391]\tTime  0.072 ( 0.072)\tLoss 1.5962e+00 (1.5753e+00)\tAcc@1  57.03 ( 56.34)\tAcc@5  84.38 ( 84.95)\n","Epoch: [37][270/391]\tTime  0.077 ( 0.072)\tLoss 1.5563e+00 (1.5766e+00)\tAcc@1  62.50 ( 56.30)\tAcc@5  85.94 ( 84.88)\n","Epoch: [37][300/391]\tTime  0.052 ( 0.071)\tLoss 1.4675e+00 (1.5804e+00)\tAcc@1  63.28 ( 56.28)\tAcc@5  85.94 ( 84.81)\n","Epoch: [37][330/391]\tTime  0.049 ( 0.071)\tLoss 1.6231e+00 (1.5842e+00)\tAcc@1  52.34 ( 56.13)\tAcc@5  84.38 ( 84.80)\n","Epoch: [37][360/391]\tTime  0.073 ( 0.071)\tLoss 1.3738e+00 (1.5876e+00)\tAcc@1  61.72 ( 56.06)\tAcc@5  86.72 ( 84.74)\n","Epoch: [37][390/391]\tTime  0.048 ( 0.071)\tLoss 1.3786e+00 (1.5878e+00)\tAcc@1  58.75 ( 56.04)\tAcc@5  91.25 ( 84.73)\n","==> Train Accuracy: Acc@1 56.038 || Acc@5 84.732\n","==> Test Accuracy:  Acc@1 58.950 || Acc@5 86.080\n","==> 30.13 seconds to train this epoch\n","\n","\n","----- epoch: 38, lr: 0.1 -----\n","Epoch: [38][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.4571e+00 (1.4571e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  86.72 ( 86.72)\n","Epoch: [38][ 30/391]\tTime  0.055 ( 0.078)\tLoss 1.5547e+00 (1.5048e+00)\tAcc@1  55.47 ( 58.17)\tAcc@5  87.50 ( 86.44)\n","Epoch: [38][ 60/391]\tTime  0.057 ( 0.075)\tLoss 1.4491e+00 (1.5189e+00)\tAcc@1  60.94 ( 58.07)\tAcc@5  85.94 ( 86.18)\n","Epoch: [38][ 90/391]\tTime  0.067 ( 0.073)\tLoss 1.4230e+00 (1.5279e+00)\tAcc@1  59.38 ( 57.58)\tAcc@5  85.16 ( 85.71)\n","Epoch: [38][120/391]\tTime  0.062 ( 0.073)\tLoss 1.5289e+00 (1.5406e+00)\tAcc@1  63.28 ( 57.46)\tAcc@5  84.38 ( 85.41)\n","Epoch: [38][150/391]\tTime  0.072 ( 0.072)\tLoss 1.6612e+00 (1.5403e+00)\tAcc@1  50.78 ( 57.40)\tAcc@5  82.81 ( 85.36)\n","Epoch: [38][180/391]\tTime  0.078 ( 0.072)\tLoss 1.8716e+00 (1.5521e+00)\tAcc@1  49.22 ( 57.13)\tAcc@5  78.12 ( 85.05)\n","Epoch: [38][210/391]\tTime  0.046 ( 0.072)\tLoss 1.5785e+00 (1.5586e+00)\tAcc@1  53.91 ( 56.92)\tAcc@5  85.16 ( 84.98)\n","Epoch: [38][240/391]\tTime  0.062 ( 0.072)\tLoss 1.7410e+00 (1.5596e+00)\tAcc@1  52.34 ( 56.80)\tAcc@5  78.91 ( 85.02)\n","Epoch: [38][270/391]\tTime  0.072 ( 0.072)\tLoss 1.7104e+00 (1.5598e+00)\tAcc@1  50.78 ( 56.73)\tAcc@5  83.59 ( 85.00)\n","Epoch: [38][300/391]\tTime  0.059 ( 0.072)\tLoss 1.6600e+00 (1.5674e+00)\tAcc@1  49.22 ( 56.53)\tAcc@5  85.16 ( 84.96)\n","Epoch: [38][330/391]\tTime  0.080 ( 0.072)\tLoss 1.6342e+00 (1.5742e+00)\tAcc@1  55.47 ( 56.29)\tAcc@5  85.16 ( 84.89)\n","Epoch: [38][360/391]\tTime  0.061 ( 0.072)\tLoss 1.4640e+00 (1.5784e+00)\tAcc@1  63.28 ( 56.25)\tAcc@5  87.50 ( 84.79)\n","Epoch: [38][390/391]\tTime  0.047 ( 0.071)\tLoss 1.5257e+00 (1.5802e+00)\tAcc@1  61.25 ( 56.28)\tAcc@5  87.50 ( 84.78)\n","==> Train Accuracy: Acc@1 56.282 || Acc@5 84.778\n","==> Test Accuracy:  Acc@1 57.050 || Acc@5 85.330\n","==> 30.03 seconds to train this epoch\n","\n","\n","----- epoch: 39, lr: 0.1 -----\n","Epoch: [39][  0/391]\tTime  0.254 ( 0.254)\tLoss 1.5274e+00 (1.5274e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  85.94 ( 85.94)\n","Epoch: [39][ 30/391]\tTime  0.075 ( 0.076)\tLoss 1.3729e+00 (1.5020e+00)\tAcc@1  57.03 ( 58.47)\tAcc@5  89.84 ( 85.94)\n","Epoch: [39][ 60/391]\tTime  0.071 ( 0.074)\tLoss 1.4458e+00 (1.5120e+00)\tAcc@1  57.81 ( 57.79)\tAcc@5  89.84 ( 85.90)\n","Epoch: [39][ 90/391]\tTime  0.074 ( 0.074)\tLoss 1.4180e+00 (1.5130e+00)\tAcc@1  58.59 ( 57.96)\tAcc@5  88.28 ( 85.92)\n","Epoch: [39][120/391]\tTime  0.070 ( 0.074)\tLoss 1.5848e+00 (1.5328e+00)\tAcc@1  58.59 ( 57.51)\tAcc@5  85.94 ( 85.48)\n","Epoch: [39][150/391]\tTime  0.073 ( 0.074)\tLoss 1.3408e+00 (1.5445e+00)\tAcc@1  64.06 ( 57.03)\tAcc@5  89.84 ( 85.31)\n","Epoch: [39][180/391]\tTime  0.070 ( 0.074)\tLoss 1.8363e+00 (1.5475e+00)\tAcc@1  48.44 ( 57.15)\tAcc@5  84.38 ( 85.32)\n","Epoch: [39][210/391]\tTime  0.063 ( 0.073)\tLoss 1.6583e+00 (1.5528e+00)\tAcc@1  54.69 ( 56.95)\tAcc@5  85.94 ( 85.23)\n","Epoch: [39][240/391]\tTime  0.079 ( 0.074)\tLoss 1.4422e+00 (1.5511e+00)\tAcc@1  62.50 ( 57.02)\tAcc@5  88.28 ( 85.22)\n","Epoch: [39][270/391]\tTime  0.053 ( 0.073)\tLoss 1.5270e+00 (1.5544e+00)\tAcc@1  60.16 ( 56.81)\tAcc@5  85.16 ( 85.23)\n","Epoch: [39][300/391]\tTime  0.083 ( 0.073)\tLoss 1.8787e+00 (1.5575e+00)\tAcc@1  47.66 ( 56.78)\tAcc@5  78.91 ( 85.11)\n","Epoch: [39][330/391]\tTime  0.062 ( 0.073)\tLoss 1.3918e+00 (1.5608e+00)\tAcc@1  63.28 ( 56.69)\tAcc@5  86.72 ( 85.05)\n","Epoch: [39][360/391]\tTime  0.058 ( 0.073)\tLoss 1.5757e+00 (1.5634e+00)\tAcc@1  58.59 ( 56.55)\tAcc@5  85.94 ( 85.04)\n","Epoch: [39][390/391]\tTime  0.047 ( 0.073)\tLoss 1.5417e+00 (1.5678e+00)\tAcc@1  58.75 ( 56.45)\tAcc@5  87.50 ( 84.98)\n","==> Train Accuracy: Acc@1 56.448 || Acc@5 84.980\n","==> Test Accuracy:  Acc@1 57.040 || Acc@5 86.210\n","==> 30.76 seconds to train this epoch\n","\n","\n","----- epoch: 40, lr: 0.1 -----\n","Epoch: [40][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.4241e+00 (1.4241e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  89.06 ( 89.06)\n","Epoch: [40][ 30/391]\tTime  0.057 ( 0.076)\tLoss 1.6335e+00 (1.4926e+00)\tAcc@1  50.78 ( 57.48)\tAcc@5  83.59 ( 86.14)\n","Epoch: [40][ 60/391]\tTime  0.073 ( 0.075)\tLoss 1.2683e+00 (1.5020e+00)\tAcc@1  64.84 ( 57.75)\tAcc@5  92.97 ( 86.10)\n","Epoch: [40][ 90/391]\tTime  0.071 ( 0.074)\tLoss 1.6607e+00 (1.5127e+00)\tAcc@1  53.91 ( 57.43)\tAcc@5  82.81 ( 86.01)\n","Epoch: [40][120/391]\tTime  0.092 ( 0.074)\tLoss 1.6733e+00 (1.5228e+00)\tAcc@1  52.34 ( 57.19)\tAcc@5  83.59 ( 85.70)\n","Epoch: [40][150/391]\tTime  0.064 ( 0.073)\tLoss 1.2524e+00 (1.5274e+00)\tAcc@1  61.72 ( 56.96)\tAcc@5  87.50 ( 85.57)\n","Epoch: [40][180/391]\tTime  0.070 ( 0.073)\tLoss 1.5192e+00 (1.5342e+00)\tAcc@1  60.16 ( 57.04)\tAcc@5  86.72 ( 85.52)\n","Epoch: [40][210/391]\tTime  0.069 ( 0.073)\tLoss 1.7713e+00 (1.5436e+00)\tAcc@1  46.88 ( 56.58)\tAcc@5  84.38 ( 85.40)\n","Epoch: [40][240/391]\tTime  0.077 ( 0.073)\tLoss 1.3940e+00 (1.5448e+00)\tAcc@1  62.50 ( 56.55)\tAcc@5  90.62 ( 85.41)\n","Epoch: [40][270/391]\tTime  0.064 ( 0.073)\tLoss 1.7022e+00 (1.5531e+00)\tAcc@1  53.91 ( 56.34)\tAcc@5  82.03 ( 85.27)\n","Epoch: [40][300/391]\tTime  0.081 ( 0.073)\tLoss 1.5525e+00 (1.5594e+00)\tAcc@1  59.38 ( 56.23)\tAcc@5  89.06 ( 85.21)\n","Epoch: [40][330/391]\tTime  0.069 ( 0.073)\tLoss 1.5178e+00 (1.5612e+00)\tAcc@1  58.59 ( 56.20)\tAcc@5  82.03 ( 85.13)\n","Epoch: [40][360/391]\tTime  0.076 ( 0.073)\tLoss 1.5265e+00 (1.5629e+00)\tAcc@1  57.03 ( 56.19)\tAcc@5  87.50 ( 85.12)\n","Epoch: [40][390/391]\tTime  0.048 ( 0.072)\tLoss 1.2035e+00 (1.5677e+00)\tAcc@1  67.50 ( 56.11)\tAcc@5  92.50 ( 85.02)\n","==> Train Accuracy: Acc@1 56.106 || Acc@5 85.018\n","==> Test Accuracy:  Acc@1 56.580 || Acc@5 85.910\n","==> 30.57 seconds to train this epoch\n","\n","\n","----- epoch: 41, lr: 0.1 -----\n","Epoch: [41][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.7402e+00 (1.7402e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  81.25 ( 81.25)\n","Epoch: [41][ 30/391]\tTime  0.071 ( 0.077)\tLoss 1.5432e+00 (1.5350e+00)\tAcc@1  58.59 ( 57.51)\tAcc@5  82.81 ( 85.03)\n","Epoch: [41][ 60/391]\tTime  0.068 ( 0.074)\tLoss 1.3778e+00 (1.5167e+00)\tAcc@1  59.38 ( 58.04)\tAcc@5  85.94 ( 85.13)\n","Epoch: [41][ 90/391]\tTime  0.061 ( 0.073)\tLoss 1.3453e+00 (1.5195e+00)\tAcc@1  63.28 ( 57.75)\tAcc@5  89.06 ( 85.29)\n","Epoch: [41][120/391]\tTime  0.072 ( 0.073)\tLoss 1.3010e+00 (1.5328e+00)\tAcc@1  67.19 ( 57.68)\tAcc@5  88.28 ( 85.18)\n","Epoch: [41][150/391]\tTime  0.077 ( 0.072)\tLoss 1.3905e+00 (1.5339e+00)\tAcc@1  64.06 ( 57.55)\tAcc@5  89.84 ( 85.21)\n","Epoch: [41][180/391]\tTime  0.076 ( 0.072)\tLoss 1.6480e+00 (1.5416e+00)\tAcc@1  59.38 ( 57.43)\tAcc@5  83.59 ( 85.07)\n","Epoch: [41][210/391]\tTime  0.079 ( 0.072)\tLoss 1.5571e+00 (1.5503e+00)\tAcc@1  57.03 ( 57.17)\tAcc@5  82.81 ( 84.94)\n","Epoch: [41][240/391]\tTime  0.056 ( 0.072)\tLoss 1.7327e+00 (1.5531e+00)\tAcc@1  54.69 ( 57.05)\tAcc@5  81.25 ( 84.95)\n","Epoch: [41][270/391]\tTime  0.062 ( 0.072)\tLoss 1.7670e+00 (1.5530e+00)\tAcc@1  53.12 ( 57.10)\tAcc@5  79.69 ( 84.98)\n","Epoch: [41][300/391]\tTime  0.107 ( 0.072)\tLoss 1.5513e+00 (1.5573e+00)\tAcc@1  57.81 ( 57.08)\tAcc@5  82.03 ( 84.89)\n","Epoch: [41][330/391]\tTime  0.078 ( 0.072)\tLoss 1.5986e+00 (1.5563e+00)\tAcc@1  51.56 ( 57.09)\tAcc@5  86.72 ( 84.89)\n","Epoch: [41][360/391]\tTime  0.078 ( 0.072)\tLoss 1.5055e+00 (1.5597e+00)\tAcc@1  57.81 ( 56.92)\tAcc@5  80.47 ( 84.89)\n","Epoch: [41][390/391]\tTime  0.045 ( 0.072)\tLoss 1.7725e+00 (1.5661e+00)\tAcc@1  48.75 ( 56.78)\tAcc@5  86.25 ( 84.83)\n","==> Train Accuracy: Acc@1 56.780 || Acc@5 84.832\n","==> Test Accuracy:  Acc@1 56.060 || Acc@5 84.960\n","==> 30.34 seconds to train this epoch\n","\n","\n","----- epoch: 42, lr: 0.1 -----\n","Epoch: [42][  0/391]\tTime  0.251 ( 0.251)\tLoss 1.3929e+00 (1.3929e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  88.28 ( 88.28)\n","Epoch: [42][ 30/391]\tTime  0.092 ( 0.080)\tLoss 1.3877e+00 (1.5066e+00)\tAcc@1  62.50 ( 58.52)\tAcc@5  84.38 ( 85.66)\n","Epoch: [42][ 60/391]\tTime  0.047 ( 0.075)\tLoss 1.5396e+00 (1.5015e+00)\tAcc@1  55.47 ( 58.66)\tAcc@5  85.94 ( 85.71)\n","Epoch: [42][ 90/391]\tTime  0.057 ( 0.074)\tLoss 1.6324e+00 (1.5118e+00)\tAcc@1  56.25 ( 58.10)\tAcc@5  85.94 ( 85.68)\n","Epoch: [42][120/391]\tTime  0.086 ( 0.073)\tLoss 1.5098e+00 (1.5258e+00)\tAcc@1  63.28 ( 57.74)\tAcc@5  83.59 ( 85.44)\n","Epoch: [42][150/391]\tTime  0.087 ( 0.073)\tLoss 1.5559e+00 (1.5341e+00)\tAcc@1  56.25 ( 57.75)\tAcc@5  85.16 ( 85.28)\n","Epoch: [42][180/391]\tTime  0.104 ( 0.073)\tLoss 1.6914e+00 (1.5352e+00)\tAcc@1  51.56 ( 57.62)\tAcc@5  84.38 ( 85.33)\n","Epoch: [42][210/391]\tTime  0.053 ( 0.073)\tLoss 1.4460e+00 (1.5385e+00)\tAcc@1  60.94 ( 57.62)\tAcc@5  87.50 ( 85.30)\n","Epoch: [42][240/391]\tTime  0.110 ( 0.073)\tLoss 1.8312e+00 (1.5440e+00)\tAcc@1  51.56 ( 57.48)\tAcc@5  78.12 ( 85.20)\n","Epoch: [42][270/391]\tTime  0.121 ( 0.073)\tLoss 1.7299e+00 (1.5443e+00)\tAcc@1  50.78 ( 57.39)\tAcc@5  81.25 ( 85.21)\n","Epoch: [42][300/391]\tTime  0.108 ( 0.073)\tLoss 1.4077e+00 (1.5448e+00)\tAcc@1  58.59 ( 57.22)\tAcc@5  91.41 ( 85.25)\n","Epoch: [42][330/391]\tTime  0.084 ( 0.073)\tLoss 1.6441e+00 (1.5517e+00)\tAcc@1  54.69 ( 57.03)\tAcc@5  83.59 ( 85.19)\n","Epoch: [42][360/391]\tTime  0.081 ( 0.073)\tLoss 1.4242e+00 (1.5552e+00)\tAcc@1  60.94 ( 56.94)\tAcc@5  87.50 ( 85.12)\n","Epoch: [42][390/391]\tTime  0.048 ( 0.072)\tLoss 1.7828e+00 (1.5546e+00)\tAcc@1  53.75 ( 56.98)\tAcc@5  83.75 ( 85.12)\n","==> Train Accuracy: Acc@1 56.978 || Acc@5 85.116\n","==> Test Accuracy:  Acc@1 55.590 || Acc@5 84.520\n","==> 30.54 seconds to train this epoch\n","\n","\n","----- epoch: 43, lr: 0.1 -----\n","Epoch: [43][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.5880e+00 (1.5880e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  85.16 ( 85.16)\n","Epoch: [43][ 30/391]\tTime  0.054 ( 0.078)\tLoss 1.6038e+00 (1.5159e+00)\tAcc@1  49.22 ( 57.43)\tAcc@5  85.16 ( 86.59)\n","Epoch: [43][ 60/391]\tTime  0.071 ( 0.075)\tLoss 1.3884e+00 (1.4988e+00)\tAcc@1  57.81 ( 57.80)\tAcc@5  89.06 ( 86.51)\n","Epoch: [43][ 90/391]\tTime  0.068 ( 0.074)\tLoss 1.4550e+00 (1.5130e+00)\tAcc@1  57.81 ( 57.41)\tAcc@5  88.28 ( 86.26)\n","Epoch: [43][120/391]\tTime  0.104 ( 0.073)\tLoss 1.4513e+00 (1.5130e+00)\tAcc@1  60.94 ( 57.55)\tAcc@5  89.06 ( 86.19)\n","Epoch: [43][150/391]\tTime  0.065 ( 0.073)\tLoss 1.5240e+00 (1.5245e+00)\tAcc@1  59.38 ( 57.30)\tAcc@5  84.38 ( 85.83)\n","Epoch: [43][180/391]\tTime  0.065 ( 0.073)\tLoss 1.5029e+00 (1.5360e+00)\tAcc@1  59.38 ( 57.07)\tAcc@5  84.38 ( 85.64)\n","Epoch: [43][210/391]\tTime  0.093 ( 0.073)\tLoss 1.6401e+00 (1.5414e+00)\tAcc@1  59.38 ( 56.96)\tAcc@5  81.25 ( 85.55)\n","Epoch: [43][240/391]\tTime  0.065 ( 0.073)\tLoss 1.6008e+00 (1.5512e+00)\tAcc@1  52.34 ( 56.77)\tAcc@5  88.28 ( 85.39)\n","Epoch: [43][270/391]\tTime  0.053 ( 0.073)\tLoss 1.6855e+00 (1.5502e+00)\tAcc@1  55.47 ( 56.84)\tAcc@5  84.38 ( 85.36)\n","Epoch: [43][300/391]\tTime  0.062 ( 0.073)\tLoss 1.5922e+00 (1.5486e+00)\tAcc@1  53.91 ( 56.94)\tAcc@5  85.16 ( 85.38)\n","Epoch: [43][330/391]\tTime  0.079 ( 0.072)\tLoss 1.5562e+00 (1.5483e+00)\tAcc@1  56.25 ( 57.04)\tAcc@5  85.16 ( 85.36)\n","Epoch: [43][360/391]\tTime  0.066 ( 0.073)\tLoss 1.3411e+00 (1.5541e+00)\tAcc@1  57.81 ( 56.89)\tAcc@5  90.62 ( 85.29)\n","Epoch: [43][390/391]\tTime  0.049 ( 0.072)\tLoss 1.8407e+00 (1.5566e+00)\tAcc@1  47.50 ( 56.84)\tAcc@5  82.50 ( 85.22)\n","==> Train Accuracy: Acc@1 56.842 || Acc@5 85.222\n","==> Test Accuracy:  Acc@1 50.370 || Acc@5 79.940\n","==> 30.55 seconds to train this epoch\n","\n","\n","----- epoch: 44, lr: 0.1 -----\n","Epoch: [44][  0/391]\tTime  0.255 ( 0.255)\tLoss 1.5549e+00 (1.5549e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  85.94 ( 85.94)\n","Epoch: [44][ 30/391]\tTime  0.064 ( 0.078)\tLoss 1.2809e+00 (1.4980e+00)\tAcc@1  57.81 ( 57.74)\tAcc@5  92.97 ( 86.04)\n","Epoch: [44][ 60/391]\tTime  0.059 ( 0.075)\tLoss 1.5114e+00 (1.5156e+00)\tAcc@1  58.59 ( 57.77)\tAcc@5  88.28 ( 85.86)\n","Epoch: [44][ 90/391]\tTime  0.058 ( 0.074)\tLoss 1.5574e+00 (1.5221e+00)\tAcc@1  57.03 ( 57.67)\tAcc@5  89.84 ( 85.88)\n","Epoch: [44][120/391]\tTime  0.070 ( 0.074)\tLoss 1.4722e+00 (1.5211e+00)\tAcc@1  57.81 ( 57.77)\tAcc@5  84.38 ( 85.72)\n","Epoch: [44][150/391]\tTime  0.054 ( 0.073)\tLoss 1.4720e+00 (1.5348e+00)\tAcc@1  53.91 ( 57.35)\tAcc@5  85.94 ( 85.41)\n","Epoch: [44][180/391]\tTime  0.046 ( 0.073)\tLoss 1.4166e+00 (1.5391e+00)\tAcc@1  61.72 ( 57.20)\tAcc@5  87.50 ( 85.35)\n","Epoch: [44][210/391]\tTime  0.088 ( 0.073)\tLoss 1.3445e+00 (1.5440e+00)\tAcc@1  60.16 ( 57.06)\tAcc@5  86.72 ( 85.19)\n","Epoch: [44][240/391]\tTime  0.097 ( 0.073)\tLoss 1.6980e+00 (1.5489e+00)\tAcc@1  57.81 ( 56.95)\tAcc@5  78.12 ( 85.10)\n","Epoch: [44][270/391]\tTime  0.067 ( 0.072)\tLoss 1.4567e+00 (1.5506e+00)\tAcc@1  60.16 ( 56.93)\tAcc@5  85.94 ( 85.04)\n","Epoch: [44][300/391]\tTime  0.074 ( 0.072)\tLoss 1.6775e+00 (1.5525e+00)\tAcc@1  55.47 ( 56.91)\tAcc@5  78.12 ( 85.05)\n","Epoch: [44][330/391]\tTime  0.076 ( 0.072)\tLoss 1.8333e+00 (1.5497e+00)\tAcc@1  50.78 ( 56.94)\tAcc@5  80.47 ( 85.08)\n","Epoch: [44][360/391]\tTime  0.062 ( 0.072)\tLoss 1.5587e+00 (1.5499e+00)\tAcc@1  53.12 ( 56.96)\tAcc@5  89.84 ( 85.10)\n","Epoch: [44][390/391]\tTime  0.049 ( 0.072)\tLoss 1.5538e+00 (1.5535e+00)\tAcc@1  52.50 ( 56.86)\tAcc@5  81.25 ( 85.05)\n","==> Train Accuracy: Acc@1 56.860 || Acc@5 85.050\n","==> Test Accuracy:  Acc@1 56.470 || Acc@5 84.430\n","==> 30.41 seconds to train this epoch\n","\n","\n","----- epoch: 45, lr: 0.1 -----\n","Epoch: [45][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.5554e+00 (1.5554e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  86.72 ( 86.72)\n","Epoch: [45][ 30/391]\tTime  0.083 ( 0.077)\tLoss 1.5135e+00 (1.4625e+00)\tAcc@1  60.94 ( 59.70)\tAcc@5  83.59 ( 86.49)\n","Epoch: [45][ 60/391]\tTime  0.051 ( 0.073)\tLoss 1.7958e+00 (1.5059e+00)\tAcc@1  46.88 ( 58.44)\tAcc@5  82.81 ( 86.13)\n","Epoch: [45][ 90/391]\tTime  0.071 ( 0.073)\tLoss 1.3171e+00 (1.5066e+00)\tAcc@1  62.50 ( 58.23)\tAcc@5  86.72 ( 85.96)\n","Epoch: [45][120/391]\tTime  0.066 ( 0.072)\tLoss 1.5973e+00 (1.5210e+00)\tAcc@1  60.94 ( 57.95)\tAcc@5  81.25 ( 85.60)\n","Epoch: [45][150/391]\tTime  0.091 ( 0.072)\tLoss 1.4681e+00 (1.5264e+00)\tAcc@1  58.59 ( 57.75)\tAcc@5  85.16 ( 85.45)\n","Epoch: [45][180/391]\tTime  0.066 ( 0.072)\tLoss 1.5003e+00 (1.5279e+00)\tAcc@1  53.12 ( 57.71)\tAcc@5  89.84 ( 85.45)\n","Epoch: [45][210/391]\tTime  0.099 ( 0.072)\tLoss 1.5304e+00 (1.5362e+00)\tAcc@1  52.34 ( 57.56)\tAcc@5  85.16 ( 85.29)\n","Epoch: [45][240/391]\tTime  0.083 ( 0.072)\tLoss 1.4849e+00 (1.5395e+00)\tAcc@1  54.69 ( 57.41)\tAcc@5  86.72 ( 85.34)\n","Epoch: [45][270/391]\tTime  0.063 ( 0.072)\tLoss 1.7123e+00 (1.5431e+00)\tAcc@1  57.03 ( 57.30)\tAcc@5  83.59 ( 85.26)\n","Epoch: [45][300/391]\tTime  0.071 ( 0.072)\tLoss 1.5123e+00 (1.5450e+00)\tAcc@1  59.38 ( 57.27)\tAcc@5  83.59 ( 85.25)\n","Epoch: [45][330/391]\tTime  0.059 ( 0.072)\tLoss 1.6452e+00 (1.5454e+00)\tAcc@1  51.56 ( 57.14)\tAcc@5  85.94 ( 85.29)\n","Epoch: [45][360/391]\tTime  0.064 ( 0.072)\tLoss 1.5891e+00 (1.5464e+00)\tAcc@1  57.03 ( 57.12)\tAcc@5  85.94 ( 85.34)\n","Epoch: [45][390/391]\tTime  0.048 ( 0.072)\tLoss 1.8374e+00 (1.5509e+00)\tAcc@1  51.25 ( 56.99)\tAcc@5  83.75 ( 85.28)\n","==> Train Accuracy: Acc@1 56.992 || Acc@5 85.284\n","==> Test Accuracy:  Acc@1 52.510 || Acc@5 82.020\n","==> 30.36 seconds to train this epoch\n","\n","\n","----- epoch: 46, lr: 0.1 -----\n","Epoch: [46][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.3514e+00 (1.3514e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  88.28 ( 88.28)\n","Epoch: [46][ 30/391]\tTime  0.104 ( 0.079)\tLoss 1.4588e+00 (1.4831e+00)\tAcc@1  59.38 ( 57.96)\tAcc@5  85.16 ( 86.62)\n","Epoch: [46][ 60/391]\tTime  0.073 ( 0.075)\tLoss 1.2350e+00 (1.4662e+00)\tAcc@1  67.97 ( 58.72)\tAcc@5  91.41 ( 86.78)\n","Epoch: [46][ 90/391]\tTime  0.063 ( 0.074)\tLoss 1.6331e+00 (1.5044e+00)\tAcc@1  55.47 ( 57.67)\tAcc@5  82.03 ( 86.04)\n","Epoch: [46][120/391]\tTime  0.062 ( 0.073)\tLoss 1.4573e+00 (1.5068e+00)\tAcc@1  56.25 ( 57.75)\tAcc@5  85.94 ( 85.93)\n","Epoch: [46][150/391]\tTime  0.088 ( 0.074)\tLoss 1.4342e+00 (1.5271e+00)\tAcc@1  64.84 ( 57.43)\tAcc@5  84.38 ( 85.61)\n","Epoch: [46][180/391]\tTime  0.078 ( 0.073)\tLoss 1.5983e+00 (1.5225e+00)\tAcc@1  57.81 ( 57.59)\tAcc@5  83.59 ( 85.57)\n","Epoch: [46][210/391]\tTime  0.071 ( 0.073)\tLoss 1.7388e+00 (1.5297e+00)\tAcc@1  53.12 ( 57.32)\tAcc@5  82.81 ( 85.44)\n","Epoch: [46][240/391]\tTime  0.054 ( 0.073)\tLoss 1.4644e+00 (1.5333e+00)\tAcc@1  57.81 ( 57.18)\tAcc@5  86.72 ( 85.36)\n","Epoch: [46][270/391]\tTime  0.059 ( 0.072)\tLoss 1.5118e+00 (1.5369e+00)\tAcc@1  57.81 ( 57.18)\tAcc@5  85.16 ( 85.32)\n","Epoch: [46][300/391]\tTime  0.061 ( 0.072)\tLoss 1.7923e+00 (1.5446e+00)\tAcc@1  54.69 ( 57.04)\tAcc@5  77.34 ( 85.15)\n","Epoch: [46][330/391]\tTime  0.064 ( 0.072)\tLoss 1.4019e+00 (1.5438e+00)\tAcc@1  60.16 ( 57.15)\tAcc@5  89.84 ( 85.21)\n","Epoch: [46][360/391]\tTime  0.081 ( 0.072)\tLoss 1.5910e+00 (1.5461e+00)\tAcc@1  53.12 ( 57.07)\tAcc@5  85.16 ( 85.17)\n","Epoch: [46][390/391]\tTime  0.048 ( 0.072)\tLoss 1.5673e+00 (1.5471e+00)\tAcc@1  56.25 ( 57.02)\tAcc@5  85.00 ( 85.18)\n","==> Train Accuracy: Acc@1 57.022 || Acc@5 85.180\n","==> Test Accuracy:  Acc@1 57.450 || Acc@5 85.040\n","==> 30.34 seconds to train this epoch\n","\n","\n","----- epoch: 47, lr: 0.1 -----\n","Epoch: [47][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.7651e+00 (1.7651e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  82.03 ( 82.03)\n","Epoch: [47][ 30/391]\tTime  0.067 ( 0.076)\tLoss 1.4580e+00 (1.4916e+00)\tAcc@1  56.25 ( 58.42)\tAcc@5  87.50 ( 86.82)\n","Epoch: [47][ 60/391]\tTime  0.059 ( 0.075)\tLoss 1.5402e+00 (1.4993e+00)\tAcc@1  57.81 ( 58.17)\tAcc@5  85.16 ( 86.17)\n","Epoch: [47][ 90/391]\tTime  0.060 ( 0.074)\tLoss 1.6225e+00 (1.4989e+00)\tAcc@1  54.69 ( 58.13)\tAcc@5  85.94 ( 86.15)\n","Epoch: [47][120/391]\tTime  0.106 ( 0.073)\tLoss 1.6116e+00 (1.5086e+00)\tAcc@1  53.91 ( 57.77)\tAcc@5  82.03 ( 85.96)\n","Epoch: [47][150/391]\tTime  0.052 ( 0.073)\tLoss 1.6502e+00 (1.5185e+00)\tAcc@1  52.34 ( 57.43)\tAcc@5  85.16 ( 85.86)\n","Epoch: [47][180/391]\tTime  0.064 ( 0.073)\tLoss 1.6932e+00 (1.5335e+00)\tAcc@1  53.12 ( 57.05)\tAcc@5  78.12 ( 85.48)\n","Epoch: [47][210/391]\tTime  0.078 ( 0.073)\tLoss 1.4572e+00 (1.5357e+00)\tAcc@1  59.38 ( 57.00)\tAcc@5  89.06 ( 85.51)\n","Epoch: [47][240/391]\tTime  0.076 ( 0.073)\tLoss 1.6324e+00 (1.5391e+00)\tAcc@1  53.91 ( 57.01)\tAcc@5  86.72 ( 85.36)\n","Epoch: [47][270/391]\tTime  0.080 ( 0.072)\tLoss 1.1608e+00 (1.5367e+00)\tAcc@1  64.84 ( 57.02)\tAcc@5  92.97 ( 85.49)\n","Epoch: [47][300/391]\tTime  0.070 ( 0.072)\tLoss 1.5242e+00 (1.5379e+00)\tAcc@1  57.81 ( 57.08)\tAcc@5  84.38 ( 85.47)\n","Epoch: [47][330/391]\tTime  0.063 ( 0.072)\tLoss 1.7307e+00 (1.5440e+00)\tAcc@1  52.34 ( 56.90)\tAcc@5  78.91 ( 85.37)\n","Epoch: [47][360/391]\tTime  0.070 ( 0.072)\tLoss 1.5799e+00 (1.5483e+00)\tAcc@1  55.47 ( 56.79)\tAcc@5  82.81 ( 85.31)\n","Epoch: [47][390/391]\tTime  0.047 ( 0.072)\tLoss 1.7012e+00 (1.5462e+00)\tAcc@1  47.50 ( 56.86)\tAcc@5  88.75 ( 85.38)\n","==> Train Accuracy: Acc@1 56.860 || Acc@5 85.376\n","==> Test Accuracy:  Acc@1 59.270 || Acc@5 86.850\n","==> 30.38 seconds to train this epoch\n","\n","\n","----- epoch: 48, lr: 0.1 -----\n","Epoch: [48][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.5029e+00 (1.5029e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  88.28 ( 88.28)\n","Epoch: [48][ 30/391]\tTime  0.053 ( 0.080)\tLoss 1.5091e+00 (1.4717e+00)\tAcc@1  54.69 ( 58.42)\tAcc@5  84.38 ( 86.47)\n","Epoch: [48][ 60/391]\tTime  0.061 ( 0.076)\tLoss 1.4374e+00 (1.4805e+00)\tAcc@1  55.47 ( 58.02)\tAcc@5  89.06 ( 86.91)\n","Epoch: [48][ 90/391]\tTime  0.068 ( 0.076)\tLoss 1.7205e+00 (1.4863e+00)\tAcc@1  53.91 ( 58.31)\tAcc@5  79.69 ( 86.56)\n","Epoch: [48][120/391]\tTime  0.068 ( 0.075)\tLoss 1.4704e+00 (1.5002e+00)\tAcc@1  57.81 ( 58.11)\tAcc@5  89.06 ( 86.35)\n","Epoch: [48][150/391]\tTime  0.051 ( 0.074)\tLoss 1.7787e+00 (1.5066e+00)\tAcc@1  51.56 ( 57.96)\tAcc@5  84.38 ( 86.34)\n","Epoch: [48][180/391]\tTime  0.045 ( 0.074)\tLoss 1.5386e+00 (1.5183e+00)\tAcc@1  57.03 ( 57.73)\tAcc@5  84.38 ( 86.14)\n","Epoch: [48][210/391]\tTime  0.110 ( 0.074)\tLoss 1.4482e+00 (1.5203e+00)\tAcc@1  62.50 ( 57.79)\tAcc@5  87.50 ( 85.98)\n","Epoch: [48][240/391]\tTime  0.062 ( 0.074)\tLoss 1.6167e+00 (1.5244e+00)\tAcc@1  53.12 ( 57.65)\tAcc@5  81.25 ( 85.94)\n","Epoch: [48][270/391]\tTime  0.060 ( 0.073)\tLoss 1.3230e+00 (1.5249e+00)\tAcc@1  63.28 ( 57.66)\tAcc@5  89.06 ( 85.89)\n","Epoch: [48][300/391]\tTime  0.064 ( 0.073)\tLoss 1.6779e+00 (1.5298e+00)\tAcc@1  53.12 ( 57.53)\tAcc@5  86.72 ( 85.86)\n","Epoch: [48][330/391]\tTime  0.068 ( 0.073)\tLoss 1.5937e+00 (1.5317e+00)\tAcc@1  51.56 ( 57.47)\tAcc@5  88.28 ( 85.78)\n","Epoch: [48][360/391]\tTime  0.077 ( 0.073)\tLoss 1.5851e+00 (1.5326e+00)\tAcc@1  53.12 ( 57.39)\tAcc@5  85.16 ( 85.73)\n","Epoch: [48][390/391]\tTime  0.048 ( 0.073)\tLoss 1.7161e+00 (1.5323e+00)\tAcc@1  56.25 ( 57.36)\tAcc@5  86.25 ( 85.72)\n","==> Train Accuracy: Acc@1 57.360 || Acc@5 85.724\n","==> Test Accuracy:  Acc@1 58.390 || Acc@5 87.210\n","==> 30.65 seconds to train this epoch\n","\n","\n","----- epoch: 49, lr: 0.1 -----\n","Epoch: [49][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.4232e+00 (1.4232e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  87.50 ( 87.50)\n","Epoch: [49][ 30/391]\tTime  0.091 ( 0.077)\tLoss 1.4967e+00 (1.4823e+00)\tAcc@1  57.81 ( 58.67)\tAcc@5  91.41 ( 86.49)\n","Epoch: [49][ 60/391]\tTime  0.064 ( 0.074)\tLoss 1.7625e+00 (1.5090e+00)\tAcc@1  53.91 ( 58.26)\tAcc@5  84.38 ( 86.12)\n","Epoch: [49][ 90/391]\tTime  0.072 ( 0.073)\tLoss 1.4490e+00 (1.5133e+00)\tAcc@1  57.81 ( 57.83)\tAcc@5  89.84 ( 86.01)\n","Epoch: [49][120/391]\tTime  0.100 ( 0.073)\tLoss 1.5641e+00 (1.5097e+00)\tAcc@1  58.59 ( 58.08)\tAcc@5  82.81 ( 85.88)\n","Epoch: [49][150/391]\tTime  0.065 ( 0.072)\tLoss 1.4752e+00 (1.5178e+00)\tAcc@1  58.59 ( 57.76)\tAcc@5  85.94 ( 85.89)\n","Epoch: [49][180/391]\tTime  0.076 ( 0.072)\tLoss 1.6080e+00 (1.5170e+00)\tAcc@1  57.03 ( 57.77)\tAcc@5  83.59 ( 85.95)\n","Epoch: [49][210/391]\tTime  0.067 ( 0.072)\tLoss 1.8124e+00 (1.5191e+00)\tAcc@1  56.25 ( 57.82)\tAcc@5  84.38 ( 85.94)\n","Epoch: [49][240/391]\tTime  0.075 ( 0.072)\tLoss 1.5806e+00 (1.5220e+00)\tAcc@1  57.03 ( 57.72)\tAcc@5  85.94 ( 85.98)\n","Epoch: [49][270/391]\tTime  0.052 ( 0.072)\tLoss 1.5367e+00 (1.5278e+00)\tAcc@1  62.50 ( 57.51)\tAcc@5  85.94 ( 85.91)\n","Epoch: [49][300/391]\tTime  0.086 ( 0.072)\tLoss 1.5789e+00 (1.5338e+00)\tAcc@1  58.59 ( 57.38)\tAcc@5  84.38 ( 85.72)\n","Epoch: [49][330/391]\tTime  0.077 ( 0.072)\tLoss 1.6974e+00 (1.5359e+00)\tAcc@1  53.91 ( 57.31)\tAcc@5  87.50 ( 85.60)\n","Epoch: [49][360/391]\tTime  0.060 ( 0.072)\tLoss 1.5147e+00 (1.5343e+00)\tAcc@1  60.16 ( 57.34)\tAcc@5  84.38 ( 85.59)\n","Epoch: [49][390/391]\tTime  0.047 ( 0.072)\tLoss 1.5325e+00 (1.5316e+00)\tAcc@1  56.25 ( 57.40)\tAcc@5  87.50 ( 85.64)\n","==> Train Accuracy: Acc@1 57.396 || Acc@5 85.636\n","==> Test Accuracy:  Acc@1 56.780 || Acc@5 85.510\n","==> 30.24 seconds to train this epoch\n","\n","\n","----- epoch: 50, lr: 0.1 -----\n","Epoch: [50][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.2400e+00 (1.2400e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.06 ( 89.06)\n","Epoch: [50][ 30/391]\tTime  0.055 ( 0.077)\tLoss 1.6267e+00 (1.4331e+00)\tAcc@1  53.91 ( 59.73)\tAcc@5  85.16 ( 87.15)\n","Epoch: [50][ 60/391]\tTime  0.066 ( 0.073)\tLoss 1.2919e+00 (1.4828e+00)\tAcc@1  63.28 ( 58.50)\tAcc@5  87.50 ( 86.01)\n","Epoch: [50][ 90/391]\tTime  0.092 ( 0.073)\tLoss 1.3695e+00 (1.4922e+00)\tAcc@1  61.72 ( 58.23)\tAcc@5  86.72 ( 86.01)\n","Epoch: [50][120/391]\tTime  0.065 ( 0.072)\tLoss 1.8573e+00 (1.4993e+00)\tAcc@1  53.91 ( 58.18)\tAcc@5  81.25 ( 85.84)\n","Epoch: [50][150/391]\tTime  0.068 ( 0.073)\tLoss 1.5316e+00 (1.5098e+00)\tAcc@1  58.59 ( 57.75)\tAcc@5  86.72 ( 85.80)\n","Epoch: [50][180/391]\tTime  0.075 ( 0.072)\tLoss 1.4586e+00 (1.5124e+00)\tAcc@1  60.16 ( 57.74)\tAcc@5  84.38 ( 85.80)\n","Epoch: [50][210/391]\tTime  0.067 ( 0.072)\tLoss 1.4913e+00 (1.5164e+00)\tAcc@1  58.59 ( 57.53)\tAcc@5  86.72 ( 85.75)\n","Epoch: [50][240/391]\tTime  0.075 ( 0.072)\tLoss 1.5437e+00 (1.5190e+00)\tAcc@1  56.25 ( 57.55)\tAcc@5  88.28 ( 85.75)\n","Epoch: [50][270/391]\tTime  0.068 ( 0.072)\tLoss 1.6499e+00 (1.5200e+00)\tAcc@1  52.34 ( 57.56)\tAcc@5  80.47 ( 85.73)\n","Epoch: [50][300/391]\tTime  0.073 ( 0.072)\tLoss 1.6910e+00 (1.5246e+00)\tAcc@1  48.44 ( 57.41)\tAcc@5  82.81 ( 85.65)\n","Epoch: [50][330/391]\tTime  0.074 ( 0.072)\tLoss 1.3863e+00 (1.5253e+00)\tAcc@1  60.94 ( 57.37)\tAcc@5  89.84 ( 85.61)\n","Epoch: [50][360/391]\tTime  0.076 ( 0.072)\tLoss 1.7594e+00 (1.5320e+00)\tAcc@1  56.25 ( 57.17)\tAcc@5  81.25 ( 85.48)\n","Epoch: [50][390/391]\tTime  0.047 ( 0.071)\tLoss 1.7263e+00 (1.5348e+00)\tAcc@1  53.75 ( 57.15)\tAcc@5  83.75 ( 85.43)\n","==> Train Accuracy: Acc@1 57.146 || Acc@5 85.434\n","==> Test Accuracy:  Acc@1 57.360 || Acc@5 86.330\n","==> 30.14 seconds to train this epoch\n","\n","\n","----- epoch: 51, lr: 0.1 -----\n","Epoch: [51][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.4538e+00 (1.4538e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  91.41 ( 91.41)\n","Epoch: [51][ 30/391]\tTime  0.078 ( 0.078)\tLoss 1.4400e+00 (1.4349e+00)\tAcc@1  61.72 ( 59.80)\tAcc@5  83.59 ( 87.47)\n","Epoch: [51][ 60/391]\tTime  0.070 ( 0.075)\tLoss 1.5015e+00 (1.4738e+00)\tAcc@1  56.25 ( 59.02)\tAcc@5  84.38 ( 86.73)\n","Epoch: [51][ 90/391]\tTime  0.063 ( 0.074)\tLoss 1.2919e+00 (1.4910e+00)\tAcc@1  60.94 ( 58.46)\tAcc@5  89.84 ( 86.31)\n","Epoch: [51][120/391]\tTime  0.071 ( 0.073)\tLoss 1.3371e+00 (1.4893e+00)\tAcc@1  63.28 ( 58.49)\tAcc@5  90.62 ( 86.34)\n","Epoch: [51][150/391]\tTime  0.068 ( 0.073)\tLoss 1.4219e+00 (1.4923e+00)\tAcc@1  55.47 ( 58.30)\tAcc@5  87.50 ( 86.30)\n","Epoch: [51][180/391]\tTime  0.074 ( 0.072)\tLoss 1.4954e+00 (1.4993e+00)\tAcc@1  57.81 ( 58.14)\tAcc@5  84.38 ( 86.10)\n","Epoch: [51][210/391]\tTime  0.047 ( 0.072)\tLoss 1.7617e+00 (1.5117e+00)\tAcc@1  52.34 ( 57.93)\tAcc@5  78.12 ( 85.82)\n","Epoch: [51][240/391]\tTime  0.058 ( 0.072)\tLoss 1.7115e+00 (1.5157e+00)\tAcc@1  53.91 ( 57.75)\tAcc@5  79.69 ( 85.71)\n","Epoch: [51][270/391]\tTime  0.054 ( 0.072)\tLoss 1.6614e+00 (1.5150e+00)\tAcc@1  54.69 ( 57.87)\tAcc@5  84.38 ( 85.65)\n","Epoch: [51][300/391]\tTime  0.084 ( 0.072)\tLoss 1.4064e+00 (1.5142e+00)\tAcc@1  60.16 ( 57.92)\tAcc@5  86.72 ( 85.64)\n","Epoch: [51][330/391]\tTime  0.072 ( 0.072)\tLoss 1.3639e+00 (1.5176e+00)\tAcc@1  58.59 ( 57.86)\tAcc@5  88.28 ( 85.59)\n","Epoch: [51][360/391]\tTime  0.067 ( 0.072)\tLoss 1.7357e+00 (1.5239e+00)\tAcc@1  53.12 ( 57.63)\tAcc@5  82.03 ( 85.52)\n","Epoch: [51][390/391]\tTime  0.048 ( 0.071)\tLoss 1.8636e+00 (1.5288e+00)\tAcc@1  48.75 ( 57.47)\tAcc@5  81.25 ( 85.46)\n","==> Train Accuracy: Acc@1 57.472 || Acc@5 85.462\n","==> Test Accuracy:  Acc@1 54.980 || Acc@5 84.840\n","==> 30.13 seconds to train this epoch\n","\n","\n","----- epoch: 52, lr: 0.1 -----\n","Epoch: [52][  0/391]\tTime  0.260 ( 0.260)\tLoss 1.6203e+00 (1.6203e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  85.94 ( 85.94)\n","Epoch: [52][ 30/391]\tTime  0.076 ( 0.076)\tLoss 1.1304e+00 (1.4139e+00)\tAcc@1  62.50 ( 60.31)\tAcc@5  92.97 ( 87.75)\n","Epoch: [52][ 60/391]\tTime  0.059 ( 0.073)\tLoss 1.4253e+00 (1.4287e+00)\tAcc@1  64.84 ( 60.11)\tAcc@5  85.16 ( 87.13)\n","Epoch: [52][ 90/391]\tTime  0.090 ( 0.073)\tLoss 1.6357e+00 (1.4401e+00)\tAcc@1  53.12 ( 59.90)\tAcc@5  82.03 ( 86.77)\n","Epoch: [52][120/391]\tTime  0.091 ( 0.073)\tLoss 1.4923e+00 (1.4665e+00)\tAcc@1  54.69 ( 59.14)\tAcc@5  89.84 ( 86.52)\n","Epoch: [52][150/391]\tTime  0.063 ( 0.072)\tLoss 1.4595e+00 (1.4759e+00)\tAcc@1  55.47 ( 58.86)\tAcc@5  86.72 ( 86.41)\n","Epoch: [52][180/391]\tTime  0.062 ( 0.072)\tLoss 1.7215e+00 (1.5006e+00)\tAcc@1  48.44 ( 58.20)\tAcc@5  83.59 ( 86.13)\n","Epoch: [52][210/391]\tTime  0.068 ( 0.072)\tLoss 1.7684e+00 (1.5091e+00)\tAcc@1  49.22 ( 57.87)\tAcc@5  82.81 ( 86.05)\n","Epoch: [52][240/391]\tTime  0.055 ( 0.072)\tLoss 1.6770e+00 (1.5152e+00)\tAcc@1  52.34 ( 57.72)\tAcc@5  82.81 ( 85.90)\n","Epoch: [52][270/391]\tTime  0.060 ( 0.072)\tLoss 1.5178e+00 (1.5210e+00)\tAcc@1  57.03 ( 57.58)\tAcc@5  86.72 ( 85.76)\n","Epoch: [52][300/391]\tTime  0.061 ( 0.071)\tLoss 1.5007e+00 (1.5218e+00)\tAcc@1  61.72 ( 57.60)\tAcc@5  85.16 ( 85.76)\n","Epoch: [52][330/391]\tTime  0.067 ( 0.071)\tLoss 1.5008e+00 (1.5250e+00)\tAcc@1  57.81 ( 57.41)\tAcc@5  91.41 ( 85.72)\n","Epoch: [52][360/391]\tTime  0.057 ( 0.071)\tLoss 1.6554e+00 (1.5299e+00)\tAcc@1  53.12 ( 57.38)\tAcc@5  85.94 ( 85.59)\n","Epoch: [52][390/391]\tTime  0.048 ( 0.071)\tLoss 1.7221e+00 (1.5317e+00)\tAcc@1  53.75 ( 57.34)\tAcc@5  83.75 ( 85.57)\n","==> Train Accuracy: Acc@1 57.336 || Acc@5 85.566\n","==> Test Accuracy:  Acc@1 59.650 || Acc@5 87.330\n","==> 30.01 seconds to train this epoch\n","\n","\n","----- epoch: 53, lr: 0.1 -----\n","Epoch: [53][  0/391]\tTime  0.270 ( 0.270)\tLoss 1.3782e+00 (1.3782e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  86.72 ( 86.72)\n","Epoch: [53][ 30/391]\tTime  0.072 ( 0.077)\tLoss 1.5112e+00 (1.4678e+00)\tAcc@1  54.69 ( 58.32)\tAcc@5  82.81 ( 86.82)\n","Epoch: [53][ 60/391]\tTime  0.056 ( 0.074)\tLoss 1.8276e+00 (1.4710e+00)\tAcc@1  45.31 ( 58.85)\tAcc@5  83.59 ( 86.55)\n","Epoch: [53][ 90/391]\tTime  0.066 ( 0.073)\tLoss 1.4785e+00 (1.4756e+00)\tAcc@1  59.38 ( 58.69)\tAcc@5  87.50 ( 86.73)\n","Epoch: [53][120/391]\tTime  0.058 ( 0.072)\tLoss 1.6138e+00 (1.4858e+00)\tAcc@1  54.69 ( 58.36)\tAcc@5  85.94 ( 86.43)\n","Epoch: [53][150/391]\tTime  0.062 ( 0.072)\tLoss 1.5635e+00 (1.4955e+00)\tAcc@1  54.69 ( 58.02)\tAcc@5  85.16 ( 86.27)\n","Epoch: [53][180/391]\tTime  0.076 ( 0.072)\tLoss 1.5135e+00 (1.5070e+00)\tAcc@1  60.94 ( 57.72)\tAcc@5  89.06 ( 86.17)\n","Epoch: [53][210/391]\tTime  0.100 ( 0.072)\tLoss 1.5687e+00 (1.5035e+00)\tAcc@1  54.69 ( 57.82)\tAcc@5  86.72 ( 86.23)\n","Epoch: [53][240/391]\tTime  0.078 ( 0.072)\tLoss 1.6021e+00 (1.5093e+00)\tAcc@1  60.16 ( 57.70)\tAcc@5  83.59 ( 86.02)\n","Epoch: [53][270/391]\tTime  0.092 ( 0.072)\tLoss 1.3631e+00 (1.5146e+00)\tAcc@1  64.84 ( 57.59)\tAcc@5  85.16 ( 85.95)\n","Epoch: [53][300/391]\tTime  0.096 ( 0.072)\tLoss 1.7191e+00 (1.5136e+00)\tAcc@1  55.47 ( 57.67)\tAcc@5  81.25 ( 85.90)\n","Epoch: [53][330/391]\tTime  0.057 ( 0.072)\tLoss 1.4059e+00 (1.5195e+00)\tAcc@1  62.50 ( 57.59)\tAcc@5  87.50 ( 85.83)\n","Epoch: [53][360/391]\tTime  0.068 ( 0.072)\tLoss 1.7871e+00 (1.5235e+00)\tAcc@1  51.56 ( 57.54)\tAcc@5  82.81 ( 85.82)\n","Epoch: [53][390/391]\tTime  0.047 ( 0.072)\tLoss 2.1407e+00 (1.5261e+00)\tAcc@1  46.25 ( 57.44)\tAcc@5  75.00 ( 85.76)\n","==> Train Accuracy: Acc@1 57.442 || Acc@5 85.764\n","==> Test Accuracy:  Acc@1 56.960 || Acc@5 85.550\n","==> 30.39 seconds to train this epoch\n","\n","\n","----- epoch: 54, lr: 0.1 -----\n","Epoch: [54][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.5167e+00 (1.5167e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  85.16 ( 85.16)\n","Epoch: [54][ 30/391]\tTime  0.079 ( 0.077)\tLoss 1.3934e+00 (1.4409e+00)\tAcc@1  54.69 ( 59.17)\tAcc@5  88.28 ( 87.15)\n","Epoch: [54][ 60/391]\tTime  0.100 ( 0.074)\tLoss 1.5584e+00 (1.4528e+00)\tAcc@1  56.25 ( 58.97)\tAcc@5  82.03 ( 86.95)\n","Epoch: [54][ 90/391]\tTime  0.062 ( 0.072)\tLoss 1.5683e+00 (1.4717e+00)\tAcc@1  57.03 ( 58.22)\tAcc@5  85.16 ( 86.61)\n","Epoch: [54][120/391]\tTime  0.067 ( 0.073)\tLoss 1.4711e+00 (1.4858e+00)\tAcc@1  61.72 ( 58.07)\tAcc@5  84.38 ( 86.38)\n","Epoch: [54][150/391]\tTime  0.072 ( 0.073)\tLoss 1.6302e+00 (1.4841e+00)\tAcc@1  54.69 ( 58.38)\tAcc@5  83.59 ( 86.29)\n","Epoch: [54][180/391]\tTime  0.057 ( 0.072)\tLoss 1.4415e+00 (1.4933e+00)\tAcc@1  61.72 ( 58.13)\tAcc@5  86.72 ( 86.10)\n","Epoch: [54][210/391]\tTime  0.086 ( 0.072)\tLoss 1.5604e+00 (1.4985e+00)\tAcc@1  60.16 ( 57.98)\tAcc@5  85.16 ( 86.10)\n","Epoch: [54][240/391]\tTime  0.089 ( 0.072)\tLoss 1.3636e+00 (1.5049e+00)\tAcc@1  57.81 ( 57.88)\tAcc@5  92.97 ( 86.05)\n","Epoch: [54][270/391]\tTime  0.072 ( 0.072)\tLoss 1.6903e+00 (1.5153e+00)\tAcc@1  54.69 ( 57.66)\tAcc@5  86.72 ( 85.91)\n","Epoch: [54][300/391]\tTime  0.064 ( 0.072)\tLoss 1.5729e+00 (1.5175e+00)\tAcc@1  52.34 ( 57.60)\tAcc@5  88.28 ( 85.89)\n","Epoch: [54][330/391]\tTime  0.077 ( 0.072)\tLoss 1.5530e+00 (1.5212e+00)\tAcc@1  57.03 ( 57.57)\tAcc@5  83.59 ( 85.93)\n","Epoch: [54][360/391]\tTime  0.097 ( 0.072)\tLoss 1.5142e+00 (1.5216e+00)\tAcc@1  56.25 ( 57.56)\tAcc@5  86.72 ( 85.93)\n","Epoch: [54][390/391]\tTime  0.045 ( 0.072)\tLoss 1.7616e+00 (1.5235e+00)\tAcc@1  52.50 ( 57.50)\tAcc@5  81.25 ( 85.90)\n","==> Train Accuracy: Acc@1 57.500 || Acc@5 85.902\n","==> Test Accuracy:  Acc@1 59.420 || Acc@5 86.920\n","==> 30.30 seconds to train this epoch\n","\n","\n","----- epoch: 55, lr: 0.1 -----\n","Epoch: [55][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.4397e+00 (1.4397e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  83.59 ( 83.59)\n","Epoch: [55][ 30/391]\tTime  0.057 ( 0.078)\tLoss 1.4660e+00 (1.5130e+00)\tAcc@1  57.03 ( 57.71)\tAcc@5  89.06 ( 86.06)\n","Epoch: [55][ 60/391]\tTime  0.068 ( 0.074)\tLoss 1.5392e+00 (1.4884e+00)\tAcc@1  56.25 ( 58.25)\tAcc@5  87.50 ( 86.39)\n","Epoch: [55][ 90/391]\tTime  0.071 ( 0.073)\tLoss 1.4872e+00 (1.4895e+00)\tAcc@1  57.81 ( 58.09)\tAcc@5  87.50 ( 86.32)\n","Epoch: [55][120/391]\tTime  0.065 ( 0.072)\tLoss 1.8962e+00 (1.4942e+00)\tAcc@1  44.53 ( 57.94)\tAcc@5  85.16 ( 86.27)\n","Epoch: [55][150/391]\tTime  0.078 ( 0.072)\tLoss 1.4211e+00 (1.5096e+00)\tAcc@1  58.59 ( 57.60)\tAcc@5  89.06 ( 85.91)\n","Epoch: [55][180/391]\tTime  0.098 ( 0.071)\tLoss 1.3868e+00 (1.5122e+00)\tAcc@1  60.16 ( 57.62)\tAcc@5  91.41 ( 85.83)\n","Epoch: [55][210/391]\tTime  0.072 ( 0.071)\tLoss 1.5120e+00 (1.5131e+00)\tAcc@1  54.69 ( 57.64)\tAcc@5  86.72 ( 85.86)\n","Epoch: [55][240/391]\tTime  0.060 ( 0.071)\tLoss 1.5697e+00 (1.5136e+00)\tAcc@1  53.12 ( 57.67)\tAcc@5  85.94 ( 85.82)\n","Epoch: [55][270/391]\tTime  0.055 ( 0.071)\tLoss 1.7322e+00 (1.5158e+00)\tAcc@1  49.22 ( 57.63)\tAcc@5  89.06 ( 85.87)\n","Epoch: [55][300/391]\tTime  0.071 ( 0.071)\tLoss 1.5940e+00 (1.5161e+00)\tAcc@1  57.81 ( 57.72)\tAcc@5  83.59 ( 85.84)\n","Epoch: [55][330/391]\tTime  0.108 ( 0.071)\tLoss 1.5419e+00 (1.5194e+00)\tAcc@1  62.50 ( 57.66)\tAcc@5  80.47 ( 85.78)\n","Epoch: [55][360/391]\tTime  0.092 ( 0.071)\tLoss 1.6291e+00 (1.5208e+00)\tAcc@1  52.34 ( 57.63)\tAcc@5  87.50 ( 85.72)\n","Epoch: [55][390/391]\tTime  0.048 ( 0.071)\tLoss 1.4903e+00 (1.5240e+00)\tAcc@1  60.00 ( 57.52)\tAcc@5  85.00 ( 85.67)\n","==> Train Accuracy: Acc@1 57.524 || Acc@5 85.672\n","==> Test Accuracy:  Acc@1 57.380 || Acc@5 85.440\n","==> 29.95 seconds to train this epoch\n","\n","\n","----- epoch: 56, lr: 0.1 -----\n","Epoch: [56][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.6411e+00 (1.6411e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  85.16 ( 85.16)\n","Epoch: [56][ 30/391]\tTime  0.089 ( 0.078)\tLoss 1.6703e+00 (1.4726e+00)\tAcc@1  53.91 ( 57.71)\tAcc@5  82.03 ( 86.09)\n","Epoch: [56][ 60/391]\tTime  0.079 ( 0.075)\tLoss 1.5505e+00 (1.4759e+00)\tAcc@1  59.38 ( 58.11)\tAcc@5  85.94 ( 86.12)\n","Epoch: [56][ 90/391]\tTime  0.052 ( 0.073)\tLoss 1.5533e+00 (1.4893e+00)\tAcc@1  52.34 ( 58.08)\tAcc@5  87.50 ( 86.13)\n","Epoch: [56][120/391]\tTime  0.081 ( 0.073)\tLoss 1.3652e+00 (1.4901e+00)\tAcc@1  65.62 ( 58.17)\tAcc@5  88.28 ( 86.03)\n","Epoch: [56][150/391]\tTime  0.055 ( 0.072)\tLoss 1.2805e+00 (1.4959e+00)\tAcc@1  62.50 ( 58.04)\tAcc@5  90.62 ( 86.06)\n","Epoch: [56][180/391]\tTime  0.067 ( 0.072)\tLoss 1.6130e+00 (1.4967e+00)\tAcc@1  53.91 ( 58.10)\tAcc@5  84.38 ( 86.07)\n","Epoch: [56][210/391]\tTime  0.085 ( 0.072)\tLoss 1.4493e+00 (1.4950e+00)\tAcc@1  63.28 ( 58.19)\tAcc@5  89.06 ( 86.09)\n","Epoch: [56][240/391]\tTime  0.064 ( 0.072)\tLoss 1.7264e+00 (1.4982e+00)\tAcc@1  52.34 ( 58.10)\tAcc@5  82.03 ( 86.14)\n","Epoch: [56][270/391]\tTime  0.099 ( 0.072)\tLoss 1.8109e+00 (1.5081e+00)\tAcc@1  49.22 ( 57.77)\tAcc@5  80.47 ( 86.06)\n","Epoch: [56][300/391]\tTime  0.095 ( 0.072)\tLoss 1.4972e+00 (1.5097e+00)\tAcc@1  58.59 ( 57.83)\tAcc@5  85.94 ( 85.99)\n","Epoch: [56][330/391]\tTime  0.053 ( 0.071)\tLoss 1.5985e+00 (1.5123e+00)\tAcc@1  53.12 ( 57.74)\tAcc@5  85.94 ( 85.96)\n","Epoch: [56][360/391]\tTime  0.072 ( 0.071)\tLoss 1.5699e+00 (1.5156e+00)\tAcc@1  57.03 ( 57.68)\tAcc@5  89.06 ( 85.93)\n","Epoch: [56][390/391]\tTime  0.048 ( 0.071)\tLoss 1.5142e+00 (1.5179e+00)\tAcc@1  60.00 ( 57.67)\tAcc@5  85.00 ( 85.88)\n","==> Train Accuracy: Acc@1 57.668 || Acc@5 85.878\n","==> Test Accuracy:  Acc@1 54.610 || Acc@5 84.230\n","==> 30.08 seconds to train this epoch\n","\n","\n","----- epoch: 57, lr: 0.1 -----\n","Epoch: [57][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.5697e+00 (1.5697e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  85.16 ( 85.16)\n","Epoch: [57][ 30/391]\tTime  0.065 ( 0.078)\tLoss 1.4582e+00 (1.5389e+00)\tAcc@1  60.16 ( 57.16)\tAcc@5  82.03 ( 85.89)\n","Epoch: [57][ 60/391]\tTime  0.065 ( 0.075)\tLoss 1.4753e+00 (1.4979e+00)\tAcc@1  60.94 ( 57.80)\tAcc@5  86.72 ( 86.40)\n","Epoch: [57][ 90/391]\tTime  0.072 ( 0.074)\tLoss 1.2761e+00 (1.4805e+00)\tAcc@1  64.06 ( 58.49)\tAcc@5  91.41 ( 86.69)\n","Epoch: [57][120/391]\tTime  0.061 ( 0.073)\tLoss 1.6421e+00 (1.4848e+00)\tAcc@1  50.78 ( 58.39)\tAcc@5  88.28 ( 86.59)\n","Epoch: [57][150/391]\tTime  0.058 ( 0.073)\tLoss 1.4581e+00 (1.4974e+00)\tAcc@1  61.72 ( 58.06)\tAcc@5  87.50 ( 86.29)\n","Epoch: [57][180/391]\tTime  0.067 ( 0.072)\tLoss 1.2871e+00 (1.4975e+00)\tAcc@1  66.41 ( 58.28)\tAcc@5  89.84 ( 86.13)\n","Epoch: [57][210/391]\tTime  0.070 ( 0.072)\tLoss 1.5616e+00 (1.4993e+00)\tAcc@1  51.56 ( 58.18)\tAcc@5  88.28 ( 86.09)\n","Epoch: [57][240/391]\tTime  0.083 ( 0.072)\tLoss 1.4077e+00 (1.5091e+00)\tAcc@1  63.28 ( 57.90)\tAcc@5  88.28 ( 85.93)\n","Epoch: [57][270/391]\tTime  0.097 ( 0.072)\tLoss 1.5011e+00 (1.5153e+00)\tAcc@1  57.81 ( 57.77)\tAcc@5  87.50 ( 85.81)\n","Epoch: [57][300/391]\tTime  0.070 ( 0.071)\tLoss 1.7212e+00 (1.5199e+00)\tAcc@1  50.78 ( 57.60)\tAcc@5  82.03 ( 85.75)\n","Epoch: [57][330/391]\tTime  0.075 ( 0.071)\tLoss 1.3873e+00 (1.5188e+00)\tAcc@1  64.06 ( 57.59)\tAcc@5  85.16 ( 85.72)\n","Epoch: [57][360/391]\tTime  0.064 ( 0.071)\tLoss 1.5581e+00 (1.5216e+00)\tAcc@1  55.47 ( 57.54)\tAcc@5  88.28 ( 85.74)\n","Epoch: [57][390/391]\tTime  0.048 ( 0.071)\tLoss 1.7186e+00 (1.5249e+00)\tAcc@1  51.25 ( 57.43)\tAcc@5  81.25 ( 85.66)\n","==> Train Accuracy: Acc@1 57.428 || Acc@5 85.658\n","==> Test Accuracy:  Acc@1 55.750 || Acc@5 83.630\n","==> 30.07 seconds to train this epoch\n","\n","\n","----- epoch: 58, lr: 0.1 -----\n","Epoch: [58][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.5731e+00 (1.5731e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.16 ( 85.16)\n","Epoch: [58][ 30/391]\tTime  0.059 ( 0.075)\tLoss 1.4175e+00 (1.4139e+00)\tAcc@1  62.50 ( 61.21)\tAcc@5  88.28 ( 87.63)\n","Epoch: [58][ 60/391]\tTime  0.091 ( 0.074)\tLoss 1.3892e+00 (1.4434e+00)\tAcc@1  60.16 ( 60.09)\tAcc@5  87.50 ( 87.00)\n","Epoch: [58][ 90/391]\tTime  0.068 ( 0.073)\tLoss 1.2818e+00 (1.4384e+00)\tAcc@1  64.06 ( 60.20)\tAcc@5  90.62 ( 87.14)\n","Epoch: [58][120/391]\tTime  0.058 ( 0.072)\tLoss 1.4801e+00 (1.4595e+00)\tAcc@1  59.38 ( 59.50)\tAcc@5  89.06 ( 86.71)\n","Epoch: [58][150/391]\tTime  0.054 ( 0.072)\tLoss 1.6398e+00 (1.4736e+00)\tAcc@1  56.25 ( 59.13)\tAcc@5  84.38 ( 86.51)\n","Epoch: [58][180/391]\tTime  0.060 ( 0.072)\tLoss 1.4095e+00 (1.4811e+00)\tAcc@1  54.69 ( 58.75)\tAcc@5  89.06 ( 86.33)\n","Epoch: [58][210/391]\tTime  0.054 ( 0.072)\tLoss 1.3125e+00 (1.4766e+00)\tAcc@1  59.38 ( 58.85)\tAcc@5  89.06 ( 86.33)\n","Epoch: [58][240/391]\tTime  0.061 ( 0.072)\tLoss 1.8426e+00 (1.4843e+00)\tAcc@1  46.09 ( 58.56)\tAcc@5  83.59 ( 86.26)\n","Epoch: [58][270/391]\tTime  0.056 ( 0.072)\tLoss 1.8418e+00 (1.4890e+00)\tAcc@1  46.09 ( 58.49)\tAcc@5  82.03 ( 86.23)\n","Epoch: [58][300/391]\tTime  0.057 ( 0.071)\tLoss 1.5227e+00 (1.4949e+00)\tAcc@1  58.59 ( 58.33)\tAcc@5  85.94 ( 86.10)\n","Epoch: [58][330/391]\tTime  0.079 ( 0.071)\tLoss 1.4234e+00 (1.5012e+00)\tAcc@1  62.50 ( 58.24)\tAcc@5  87.50 ( 86.04)\n","Epoch: [58][360/391]\tTime  0.066 ( 0.071)\tLoss 1.6027e+00 (1.5113e+00)\tAcc@1  53.91 ( 57.99)\tAcc@5  82.81 ( 85.84)\n","Epoch: [58][390/391]\tTime  0.048 ( 0.071)\tLoss 1.7853e+00 (1.5128e+00)\tAcc@1  45.00 ( 57.89)\tAcc@5  80.00 ( 85.87)\n","==> Train Accuracy: Acc@1 57.886 || Acc@5 85.870\n","==> Test Accuracy:  Acc@1 58.080 || Acc@5 85.440\n","==> 30.05 seconds to train this epoch\n","\n","\n","----- epoch: 59, lr: 0.1 -----\n","Epoch: [59][  0/391]\tTime  0.251 ( 0.251)\tLoss 1.3675e+00 (1.3675e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  85.94 ( 85.94)\n","Epoch: [59][ 30/391]\tTime  0.071 ( 0.076)\tLoss 1.6263e+00 (1.4445e+00)\tAcc@1  55.47 ( 59.35)\tAcc@5  85.16 ( 86.74)\n","Epoch: [59][ 60/391]\tTime  0.053 ( 0.075)\tLoss 1.5630e+00 (1.4797e+00)\tAcc@1  57.81 ( 58.67)\tAcc@5  86.72 ( 86.57)\n","Epoch: [59][ 90/391]\tTime  0.067 ( 0.074)\tLoss 1.5889e+00 (1.4851e+00)\tAcc@1  55.47 ( 58.32)\tAcc@5  83.59 ( 86.44)\n","Epoch: [59][120/391]\tTime  0.071 ( 0.073)\tLoss 1.9658e+00 (1.4993e+00)\tAcc@1  45.31 ( 58.34)\tAcc@5  82.03 ( 86.24)\n","Epoch: [59][150/391]\tTime  0.069 ( 0.073)\tLoss 1.5943e+00 (1.5027e+00)\tAcc@1  58.59 ( 58.25)\tAcc@5  88.28 ( 86.35)\n","Epoch: [59][180/391]\tTime  0.083 ( 0.073)\tLoss 1.8108e+00 (1.5114e+00)\tAcc@1  52.34 ( 58.07)\tAcc@5  80.47 ( 86.10)\n","Epoch: [59][210/391]\tTime  0.075 ( 0.072)\tLoss 1.3528e+00 (1.5106e+00)\tAcc@1  63.28 ( 58.10)\tAcc@5  86.72 ( 86.03)\n","Epoch: [59][240/391]\tTime  0.060 ( 0.072)\tLoss 1.4977e+00 (1.5111e+00)\tAcc@1  58.59 ( 58.04)\tAcc@5  85.94 ( 85.99)\n","Epoch: [59][270/391]\tTime  0.060 ( 0.072)\tLoss 1.3674e+00 (1.5129e+00)\tAcc@1  62.50 ( 57.98)\tAcc@5  90.62 ( 85.99)\n","Epoch: [59][300/391]\tTime  0.064 ( 0.072)\tLoss 1.3858e+00 (1.5126e+00)\tAcc@1  61.72 ( 57.94)\tAcc@5  85.94 ( 86.02)\n","Epoch: [59][330/391]\tTime  0.072 ( 0.072)\tLoss 1.4193e+00 (1.5156e+00)\tAcc@1  59.38 ( 57.85)\tAcc@5  88.28 ( 86.02)\n","Epoch: [59][360/391]\tTime  0.048 ( 0.072)\tLoss 1.5006e+00 (1.5188e+00)\tAcc@1  55.47 ( 57.86)\tAcc@5  85.16 ( 85.93)\n","Epoch: [59][390/391]\tTime  0.048 ( 0.071)\tLoss 1.6692e+00 (1.5167e+00)\tAcc@1  56.25 ( 57.90)\tAcc@5  86.25 ( 85.94)\n","==> Train Accuracy: Acc@1 57.898 || Acc@5 85.938\n","==> Test Accuracy:  Acc@1 56.550 || Acc@5 84.940\n","==> 30.10 seconds to train this epoch\n","\n","\n","----- epoch: 60, lr: 0.020000000000000004 -----\n","Epoch: [60][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.5141e+00 (1.5141e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  83.59 ( 83.59)\n","Epoch: [60][ 30/391]\tTime  0.055 ( 0.076)\tLoss 9.9641e-01 (1.3121e+00)\tAcc@1  69.53 ( 62.80)\tAcc@5  91.41 ( 88.63)\n","Epoch: [60][ 60/391]\tTime  0.078 ( 0.074)\tLoss 1.1390e+00 (1.2496e+00)\tAcc@1  65.62 ( 64.49)\tAcc@5  91.41 ( 89.47)\n","Epoch: [60][ 90/391]\tTime  0.065 ( 0.073)\tLoss 9.8202e-01 (1.2045e+00)\tAcc@1  66.41 ( 65.74)\tAcc@5  96.09 ( 89.98)\n","Epoch: [60][120/391]\tTime  0.097 ( 0.073)\tLoss 8.8016e-01 (1.1767e+00)\tAcc@1  74.22 ( 66.38)\tAcc@5  92.97 ( 90.38)\n","Epoch: [60][150/391]\tTime  0.067 ( 0.073)\tLoss 1.0505e+00 (1.1604e+00)\tAcc@1  67.19 ( 66.98)\tAcc@5  94.53 ( 90.57)\n","Epoch: [60][180/391]\tTime  0.062 ( 0.073)\tLoss 9.2590e-01 (1.1388e+00)\tAcc@1  72.66 ( 67.46)\tAcc@5  92.19 ( 90.89)\n","Epoch: [60][210/391]\tTime  0.072 ( 0.072)\tLoss 9.6598e-01 (1.1269e+00)\tAcc@1  67.97 ( 67.67)\tAcc@5  93.75 ( 91.18)\n","Epoch: [60][240/391]\tTime  0.051 ( 0.072)\tLoss 9.9194e-01 (1.1130e+00)\tAcc@1  71.09 ( 68.11)\tAcc@5  92.97 ( 91.27)\n","Epoch: [60][270/391]\tTime  0.064 ( 0.072)\tLoss 9.9181e-01 (1.1050e+00)\tAcc@1  71.88 ( 68.29)\tAcc@5  92.97 ( 91.29)\n","Epoch: [60][300/391]\tTime  0.065 ( 0.072)\tLoss 8.7069e-01 (1.0962e+00)\tAcc@1  75.78 ( 68.58)\tAcc@5  91.41 ( 91.35)\n","Epoch: [60][330/391]\tTime  0.097 ( 0.072)\tLoss 1.0320e+00 (1.0873e+00)\tAcc@1  72.66 ( 68.82)\tAcc@5  91.41 ( 91.49)\n","Epoch: [60][360/391]\tTime  0.062 ( 0.072)\tLoss 1.2762e+00 (1.0837e+00)\tAcc@1  66.41 ( 68.86)\tAcc@5  89.06 ( 91.54)\n","Epoch: [60][390/391]\tTime  0.047 ( 0.071)\tLoss 1.3596e+00 (1.0748e+00)\tAcc@1  62.50 ( 69.06)\tAcc@5  86.25 ( 91.67)\n","==> Train Accuracy: Acc@1 69.056 || Acc@5 91.670\n","==> Test Accuracy:  Acc@1 71.140 || Acc@5 93.150\n","==> 30.12 seconds to train this epoch\n","\n","\n","----- epoch: 61, lr: 0.020000000000000004 -----\n","Epoch: [61][  0/391]\tTime  0.257 ( 0.257)\tLoss 8.5608e-01 (8.5608e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  92.97 ( 92.97)\n","Epoch: [61][ 30/391]\tTime  0.097 ( 0.077)\tLoss 8.9488e-01 (9.3318e-01)\tAcc@1  71.09 ( 72.48)\tAcc@5  98.44 ( 93.57)\n","Epoch: [61][ 60/391]\tTime  0.053 ( 0.074)\tLoss 9.3108e-01 (9.6720e-01)\tAcc@1  74.22 ( 71.57)\tAcc@5  93.75 ( 93.17)\n","Epoch: [61][ 90/391]\tTime  0.055 ( 0.073)\tLoss 9.1225e-01 (9.8136e-01)\tAcc@1  75.00 ( 71.17)\tAcc@5  94.53 ( 92.88)\n","Epoch: [61][120/391]\tTime  0.103 ( 0.073)\tLoss 8.4588e-01 (9.7156e-01)\tAcc@1  74.22 ( 71.43)\tAcc@5  95.31 ( 92.98)\n","Epoch: [61][150/391]\tTime  0.085 ( 0.073)\tLoss 1.0119e+00 (9.6784e-01)\tAcc@1  66.41 ( 71.51)\tAcc@5  94.53 ( 93.10)\n","Epoch: [61][180/391]\tTime  0.094 ( 0.073)\tLoss 8.5845e-01 (9.6283e-01)\tAcc@1  75.00 ( 71.56)\tAcc@5  92.97 ( 93.09)\n","Epoch: [61][210/391]\tTime  0.108 ( 0.072)\tLoss 1.0722e+00 (9.5705e-01)\tAcc@1  70.31 ( 71.70)\tAcc@5  92.19 ( 93.24)\n","Epoch: [61][240/391]\tTime  0.078 ( 0.072)\tLoss 9.1847e-01 (9.5508e-01)\tAcc@1  75.78 ( 71.82)\tAcc@5  92.97 ( 93.25)\n","Epoch: [61][270/391]\tTime  0.077 ( 0.072)\tLoss 8.5035e-01 (9.5448e-01)\tAcc@1  75.78 ( 71.90)\tAcc@5  96.09 ( 93.21)\n","Epoch: [61][300/391]\tTime  0.078 ( 0.072)\tLoss 7.0443e-01 (9.5275e-01)\tAcc@1  75.78 ( 71.94)\tAcc@5  96.88 ( 93.18)\n","Epoch: [61][330/391]\tTime  0.059 ( 0.072)\tLoss 9.8387e-01 (9.5147e-01)\tAcc@1  74.22 ( 71.95)\tAcc@5  92.97 ( 93.25)\n","Epoch: [61][360/391]\tTime  0.068 ( 0.072)\tLoss 8.3672e-01 (9.4925e-01)\tAcc@1  78.12 ( 72.04)\tAcc@5  96.09 ( 93.32)\n","Epoch: [61][390/391]\tTime  0.047 ( 0.072)\tLoss 1.1740e+00 (9.5031e-01)\tAcc@1  67.50 ( 72.03)\tAcc@5  90.00 ( 93.30)\n","==> Train Accuracy: Acc@1 72.032 || Acc@5 93.298\n","==> Test Accuracy:  Acc@1 72.460 || Acc@5 93.200\n","==> 30.16 seconds to train this epoch\n","\n","\n","----- epoch: 62, lr: 0.020000000000000004 -----\n","Epoch: [62][  0/391]\tTime  0.241 ( 0.241)\tLoss 7.8298e-01 (7.8298e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  96.09 ( 96.09)\n","Epoch: [62][ 30/391]\tTime  0.065 ( 0.078)\tLoss 9.5737e-01 (8.9605e-01)\tAcc@1  69.53 ( 73.61)\tAcc@5  92.19 ( 93.60)\n","Epoch: [62][ 60/391]\tTime  0.058 ( 0.076)\tLoss 9.1419e-01 (8.7829e-01)\tAcc@1  75.78 ( 74.35)\tAcc@5  93.75 ( 94.12)\n","Epoch: [62][ 90/391]\tTime  0.100 ( 0.075)\tLoss 7.9452e-01 (8.8776e-01)\tAcc@1  78.12 ( 74.19)\tAcc@5  94.53 ( 93.84)\n","Epoch: [62][120/391]\tTime  0.069 ( 0.075)\tLoss 8.7876e-01 (8.7876e-01)\tAcc@1  76.56 ( 74.37)\tAcc@5  94.53 ( 93.98)\n","Epoch: [62][150/391]\tTime  0.074 ( 0.074)\tLoss 8.9519e-01 (8.8141e-01)\tAcc@1  74.22 ( 74.15)\tAcc@5  93.75 ( 94.03)\n","Epoch: [62][180/391]\tTime  0.074 ( 0.074)\tLoss 8.6209e-01 (8.8288e-01)\tAcc@1  70.31 ( 74.11)\tAcc@5  94.53 ( 94.05)\n","Epoch: [62][210/391]\tTime  0.082 ( 0.073)\tLoss 8.0504e-01 (8.9075e-01)\tAcc@1  75.78 ( 73.95)\tAcc@5  96.09 ( 93.98)\n","Epoch: [62][240/391]\tTime  0.065 ( 0.073)\tLoss 8.6208e-01 (8.9311e-01)\tAcc@1  76.56 ( 73.84)\tAcc@5  96.09 ( 94.00)\n","Epoch: [62][270/391]\tTime  0.058 ( 0.073)\tLoss 9.5729e-01 (8.9757e-01)\tAcc@1  75.00 ( 73.69)\tAcc@5  95.31 ( 93.99)\n","Epoch: [62][300/391]\tTime  0.059 ( 0.073)\tLoss 1.2369e+00 (9.0035e-01)\tAcc@1  61.72 ( 73.54)\tAcc@5  92.19 ( 93.93)\n","Epoch: [62][330/391]\tTime  0.105 ( 0.072)\tLoss 9.9676e-01 (9.0336e-01)\tAcc@1  71.88 ( 73.45)\tAcc@5  91.41 ( 93.86)\n","Epoch: [62][360/391]\tTime  0.051 ( 0.072)\tLoss 7.1536e-01 (9.0461e-01)\tAcc@1  78.12 ( 73.43)\tAcc@5  96.88 ( 93.84)\n","Epoch: [62][390/391]\tTime  0.047 ( 0.072)\tLoss 8.3211e-01 (9.0341e-01)\tAcc@1  73.75 ( 73.45)\tAcc@5  95.00 ( 93.85)\n","==> Train Accuracy: Acc@1 73.450 || Acc@5 93.852\n","==> Test Accuracy:  Acc@1 72.560 || Acc@5 93.390\n","==> 30.42 seconds to train this epoch\n","\n","\n","----- epoch: 63, lr: 0.020000000000000004 -----\n","Epoch: [63][  0/391]\tTime  0.256 ( 0.256)\tLoss 9.6328e-01 (9.6328e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  89.06 ( 89.06)\n","Epoch: [63][ 30/391]\tTime  0.065 ( 0.077)\tLoss 8.3243e-01 (8.3608e-01)\tAcc@1  75.00 ( 75.50)\tAcc@5  92.97 ( 94.43)\n","Epoch: [63][ 60/391]\tTime  0.100 ( 0.075)\tLoss 7.3637e-01 (8.6634e-01)\tAcc@1  80.47 ( 74.54)\tAcc@5  95.31 ( 94.04)\n","Epoch: [63][ 90/391]\tTime  0.065 ( 0.073)\tLoss 7.2157e-01 (8.6477e-01)\tAcc@1  79.69 ( 74.61)\tAcc@5  97.66 ( 94.12)\n","Epoch: [63][120/391]\tTime  0.074 ( 0.073)\tLoss 8.2079e-01 (8.6264e-01)\tAcc@1  75.78 ( 74.66)\tAcc@5  96.09 ( 94.20)\n","Epoch: [63][150/391]\tTime  0.074 ( 0.072)\tLoss 7.4367e-01 (8.6857e-01)\tAcc@1  75.78 ( 74.47)\tAcc@5  98.44 ( 94.22)\n","Epoch: [63][180/391]\tTime  0.069 ( 0.072)\tLoss 7.8818e-01 (8.6527e-01)\tAcc@1  76.56 ( 74.54)\tAcc@5  96.88 ( 94.26)\n","Epoch: [63][210/391]\tTime  0.117 ( 0.072)\tLoss 7.0905e-01 (8.6465e-01)\tAcc@1  78.12 ( 74.51)\tAcc@5  96.09 ( 94.25)\n","Epoch: [63][240/391]\tTime  0.069 ( 0.072)\tLoss 9.6766e-01 (8.6948e-01)\tAcc@1  69.53 ( 74.38)\tAcc@5  90.62 ( 94.19)\n","Epoch: [63][270/391]\tTime  0.077 ( 0.072)\tLoss 8.2299e-01 (8.7266e-01)\tAcc@1  70.31 ( 74.25)\tAcc@5  97.66 ( 94.20)\n","Epoch: [63][300/391]\tTime  0.044 ( 0.072)\tLoss 9.1866e-01 (8.7349e-01)\tAcc@1  70.31 ( 74.16)\tAcc@5  94.53 ( 94.19)\n","Epoch: [63][330/391]\tTime  0.072 ( 0.072)\tLoss 8.7979e-01 (8.7516e-01)\tAcc@1  73.44 ( 74.12)\tAcc@5  96.88 ( 94.20)\n","Epoch: [63][360/391]\tTime  0.066 ( 0.072)\tLoss 7.4211e-01 (8.7571e-01)\tAcc@1  76.56 ( 74.07)\tAcc@5  96.88 ( 94.21)\n","Epoch: [63][390/391]\tTime  0.050 ( 0.072)\tLoss 9.4415e-01 (8.7884e-01)\tAcc@1  67.50 ( 73.91)\tAcc@5  93.75 ( 94.17)\n","==> Train Accuracy: Acc@1 73.912 || Acc@5 94.168\n","==> Test Accuracy:  Acc@1 71.800 || Acc@5 93.360\n","==> 30.26 seconds to train this epoch\n","\n","\n","----- epoch: 64, lr: 0.020000000000000004 -----\n","Epoch: [64][  0/391]\tTime  0.250 ( 0.250)\tLoss 8.1689e-01 (8.1689e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  96.09 ( 96.09)\n","Epoch: [64][ 30/391]\tTime  0.053 ( 0.075)\tLoss 7.9068e-01 (8.1121e-01)\tAcc@1  80.47 ( 76.41)\tAcc@5  95.31 ( 94.96)\n","Epoch: [64][ 60/391]\tTime  0.082 ( 0.073)\tLoss 1.0243e+00 (8.2235e-01)\tAcc@1  69.53 ( 76.02)\tAcc@5  91.41 ( 94.86)\n","Epoch: [64][ 90/391]\tTime  0.064 ( 0.073)\tLoss 8.3211e-01 (8.3984e-01)\tAcc@1  75.00 ( 75.39)\tAcc@5  95.31 ( 94.62)\n","Epoch: [64][120/391]\tTime  0.060 ( 0.072)\tLoss 1.0898e+00 (8.4262e-01)\tAcc@1  69.53 ( 75.22)\tAcc@5  92.19 ( 94.64)\n","Epoch: [64][150/391]\tTime  0.055 ( 0.072)\tLoss 8.9891e-01 (8.4578e-01)\tAcc@1  71.09 ( 75.17)\tAcc@5  92.97 ( 94.63)\n","Epoch: [64][180/391]\tTime  0.058 ( 0.072)\tLoss 6.2720e-01 (8.4731e-01)\tAcc@1  82.81 ( 75.15)\tAcc@5  97.66 ( 94.54)\n","Epoch: [64][210/391]\tTime  0.097 ( 0.072)\tLoss 5.9255e-01 (8.4753e-01)\tAcc@1  81.25 ( 75.07)\tAcc@5  97.66 ( 94.59)\n","Epoch: [64][240/391]\tTime  0.067 ( 0.072)\tLoss 8.2052e-01 (8.5024e-01)\tAcc@1  77.34 ( 75.03)\tAcc@5  92.19 ( 94.54)\n","Epoch: [64][270/391]\tTime  0.061 ( 0.072)\tLoss 7.9372e-01 (8.5477e-01)\tAcc@1  75.78 ( 74.86)\tAcc@5  92.97 ( 94.48)\n","Epoch: [64][300/391]\tTime  0.069 ( 0.072)\tLoss 1.0058e+00 (8.5933e-01)\tAcc@1  65.62 ( 74.70)\tAcc@5  91.41 ( 94.39)\n","Epoch: [64][330/391]\tTime  0.059 ( 0.071)\tLoss 8.9033e-01 (8.6161e-01)\tAcc@1  73.44 ( 74.61)\tAcc@5  93.75 ( 94.34)\n","Epoch: [64][360/391]\tTime  0.076 ( 0.071)\tLoss 1.0304e+00 (8.6362e-01)\tAcc@1  69.53 ( 74.61)\tAcc@5  90.62 ( 94.27)\n","Epoch: [64][390/391]\tTime  0.048 ( 0.071)\tLoss 8.3973e-01 (8.6453e-01)\tAcc@1  75.00 ( 74.54)\tAcc@5  95.00 ( 94.27)\n","==> Train Accuracy: Acc@1 74.542 || Acc@5 94.272\n","==> Test Accuracy:  Acc@1 72.490 || Acc@5 93.190\n","==> 30.02 seconds to train this epoch\n","\n","\n","----- epoch: 65, lr: 0.020000000000000004 -----\n","Epoch: [65][  0/391]\tTime  0.267 ( 0.267)\tLoss 6.3906e-01 (6.3906e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.09 ( 96.09)\n","Epoch: [65][ 30/391]\tTime  0.061 ( 0.074)\tLoss 5.1441e-01 (8.0400e-01)\tAcc@1  85.16 ( 76.34)\tAcc@5  97.66 ( 95.06)\n","Epoch: [65][ 60/391]\tTime  0.066 ( 0.072)\tLoss 7.0252e-01 (7.9619e-01)\tAcc@1  79.69 ( 76.69)\tAcc@5  94.53 ( 95.15)\n","Epoch: [65][ 90/391]\tTime  0.081 ( 0.071)\tLoss 6.5574e-01 (8.0207e-01)\tAcc@1  78.91 ( 76.51)\tAcc@5  96.88 ( 95.09)\n","Epoch: [65][120/391]\tTime  0.063 ( 0.071)\tLoss 7.6479e-01 (8.0929e-01)\tAcc@1  75.00 ( 76.18)\tAcc@5  98.44 ( 95.03)\n","Epoch: [65][150/391]\tTime  0.064 ( 0.071)\tLoss 8.1200e-01 (8.1286e-01)\tAcc@1  77.34 ( 76.03)\tAcc@5  96.09 ( 94.91)\n","Epoch: [65][180/391]\tTime  0.063 ( 0.071)\tLoss 7.7937e-01 (8.1892e-01)\tAcc@1  78.91 ( 75.85)\tAcc@5  90.62 ( 94.76)\n","Epoch: [65][210/391]\tTime  0.096 ( 0.071)\tLoss 7.8278e-01 (8.2049e-01)\tAcc@1  78.12 ( 75.68)\tAcc@5  93.75 ( 94.77)\n","Epoch: [65][240/391]\tTime  0.060 ( 0.071)\tLoss 7.8720e-01 (8.2321e-01)\tAcc@1  76.56 ( 75.66)\tAcc@5  93.75 ( 94.75)\n","Epoch: [65][270/391]\tTime  0.063 ( 0.071)\tLoss 9.5389e-01 (8.2852e-01)\tAcc@1  70.31 ( 75.43)\tAcc@5  95.31 ( 94.74)\n","Epoch: [65][300/391]\tTime  0.056 ( 0.071)\tLoss 8.6064e-01 (8.3105e-01)\tAcc@1  75.00 ( 75.33)\tAcc@5  96.09 ( 94.71)\n","Epoch: [65][330/391]\tTime  0.067 ( 0.071)\tLoss 8.6258e-01 (8.3542e-01)\tAcc@1  71.88 ( 75.18)\tAcc@5  94.53 ( 94.65)\n","Epoch: [65][360/391]\tTime  0.046 ( 0.071)\tLoss 8.4234e-01 (8.3790e-01)\tAcc@1  78.12 ( 75.10)\tAcc@5  92.97 ( 94.61)\n","Epoch: [65][390/391]\tTime  0.048 ( 0.071)\tLoss 8.9852e-01 (8.3890e-01)\tAcc@1  76.25 ( 75.12)\tAcc@5  95.00 ( 94.56)\n","==> Train Accuracy: Acc@1 75.116 || Acc@5 94.564\n","==> Test Accuracy:  Acc@1 72.090 || Acc@5 93.070\n","==> 29.86 seconds to train this epoch\n","\n","\n","----- epoch: 66, lr: 0.020000000000000004 -----\n","Epoch: [66][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.0164e+00 (1.0164e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  91.41 ( 91.41)\n","Epoch: [66][ 30/391]\tTime  0.068 ( 0.075)\tLoss 8.5501e-01 (8.1845e-01)\tAcc@1  77.34 ( 76.16)\tAcc@5  92.97 ( 94.33)\n","Epoch: [66][ 60/391]\tTime  0.091 ( 0.073)\tLoss 5.8074e-01 (8.0680e-01)\tAcc@1  82.81 ( 76.20)\tAcc@5  96.88 ( 94.79)\n","Epoch: [66][ 90/391]\tTime  0.052 ( 0.071)\tLoss 8.0438e-01 (8.1603e-01)\tAcc@1  74.22 ( 75.96)\tAcc@5  97.66 ( 94.69)\n","Epoch: [66][120/391]\tTime  0.070 ( 0.072)\tLoss 8.3598e-01 (8.1033e-01)\tAcc@1  74.22 ( 76.07)\tAcc@5  94.53 ( 94.78)\n","Epoch: [66][150/391]\tTime  0.100 ( 0.072)\tLoss 7.6719e-01 (8.1663e-01)\tAcc@1  78.91 ( 76.00)\tAcc@5  94.53 ( 94.77)\n","Epoch: [66][180/391]\tTime  0.054 ( 0.071)\tLoss 9.7044e-01 (8.1890e-01)\tAcc@1  67.19 ( 75.82)\tAcc@5  94.53 ( 94.85)\n","Epoch: [66][210/391]\tTime  0.076 ( 0.071)\tLoss 8.4555e-01 (8.2363e-01)\tAcc@1  76.56 ( 75.68)\tAcc@5  91.41 ( 94.81)\n","Epoch: [66][240/391]\tTime  0.052 ( 0.071)\tLoss 9.0993e-01 (8.3032e-01)\tAcc@1  68.75 ( 75.48)\tAcc@5  92.97 ( 94.74)\n","Epoch: [66][270/391]\tTime  0.055 ( 0.071)\tLoss 7.1486e-01 (8.3586e-01)\tAcc@1  77.34 ( 75.33)\tAcc@5  98.44 ( 94.70)\n","Epoch: [66][300/391]\tTime  0.053 ( 0.071)\tLoss 8.1944e-01 (8.3528e-01)\tAcc@1  77.34 ( 75.40)\tAcc@5  92.97 ( 94.69)\n","Epoch: [66][330/391]\tTime  0.060 ( 0.071)\tLoss 9.3876e-01 (8.3619e-01)\tAcc@1  75.00 ( 75.37)\tAcc@5  92.19 ( 94.67)\n","Epoch: [66][360/391]\tTime  0.051 ( 0.071)\tLoss 1.0235e+00 (8.3908e-01)\tAcc@1  72.66 ( 75.31)\tAcc@5  92.97 ( 94.63)\n","Epoch: [66][390/391]\tTime  0.048 ( 0.071)\tLoss 1.1277e+00 (8.3976e-01)\tAcc@1  66.25 ( 75.31)\tAcc@5  93.75 ( 94.63)\n","==> Train Accuracy: Acc@1 75.306 || Acc@5 94.626\n","==> Test Accuracy:  Acc@1 72.420 || Acc@5 93.310\n","==> 29.91 seconds to train this epoch\n","\n","\n","----- epoch: 67, lr: 0.020000000000000004 -----\n","Epoch: [67][  0/391]\tTime  0.272 ( 0.272)\tLoss 9.6749e-01 (9.6749e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  92.97 ( 92.97)\n","Epoch: [67][ 30/391]\tTime  0.071 ( 0.078)\tLoss 7.1376e-01 (7.9285e-01)\tAcc@1  78.91 ( 75.48)\tAcc@5  96.09 ( 95.31)\n","Epoch: [67][ 60/391]\tTime  0.091 ( 0.075)\tLoss 9.4615e-01 (7.9781e-01)\tAcc@1  68.75 ( 75.45)\tAcc@5  90.62 ( 95.26)\n","Epoch: [67][ 90/391]\tTime  0.092 ( 0.074)\tLoss 6.7862e-01 (7.9945e-01)\tAcc@1  78.91 ( 75.45)\tAcc@5  92.97 ( 95.08)\n","Epoch: [67][120/391]\tTime  0.091 ( 0.073)\tLoss 8.0246e-01 (7.9919e-01)\tAcc@1  75.78 ( 75.75)\tAcc@5  95.31 ( 95.05)\n","Epoch: [67][150/391]\tTime  0.066 ( 0.073)\tLoss 7.6084e-01 (8.0429e-01)\tAcc@1  74.22 ( 75.77)\tAcc@5  96.09 ( 94.98)\n","Epoch: [67][180/391]\tTime  0.065 ( 0.072)\tLoss 8.5107e-01 (8.0583e-01)\tAcc@1  75.78 ( 75.76)\tAcc@5  95.31 ( 94.98)\n","Epoch: [67][210/391]\tTime  0.073 ( 0.072)\tLoss 7.7455e-01 (8.1126e-01)\tAcc@1  80.47 ( 75.69)\tAcc@5  95.31 ( 94.91)\n","Epoch: [67][240/391]\tTime  0.052 ( 0.072)\tLoss 6.9581e-01 (8.1734e-01)\tAcc@1  75.78 ( 75.55)\tAcc@5  96.88 ( 94.85)\n","Epoch: [67][270/391]\tTime  0.062 ( 0.072)\tLoss 7.3146e-01 (8.2442e-01)\tAcc@1  75.00 ( 75.37)\tAcc@5  96.09 ( 94.73)\n","Epoch: [67][300/391]\tTime  0.070 ( 0.072)\tLoss 9.2671e-01 (8.2958e-01)\tAcc@1  76.56 ( 75.21)\tAcc@5  93.75 ( 94.69)\n","Epoch: [67][330/391]\tTime  0.057 ( 0.072)\tLoss 8.8788e-01 (8.2950e-01)\tAcc@1  72.66 ( 75.23)\tAcc@5  96.88 ( 94.70)\n","Epoch: [67][360/391]\tTime  0.054 ( 0.072)\tLoss 8.4460e-01 (8.3097e-01)\tAcc@1  75.00 ( 75.20)\tAcc@5  96.09 ( 94.68)\n","Epoch: [67][390/391]\tTime  0.048 ( 0.071)\tLoss 7.2191e-01 (8.3333e-01)\tAcc@1  82.50 ( 75.10)\tAcc@5  95.00 ( 94.65)\n","==> Train Accuracy: Acc@1 75.102 || Acc@5 94.652\n","==> Test Accuracy:  Acc@1 73.010 || Acc@5 93.240\n","==> 30.14 seconds to train this epoch\n","\n","\n","----- epoch: 68, lr: 0.020000000000000004 -----\n","Epoch: [68][  0/391]\tTime  0.262 ( 0.262)\tLoss 7.5290e-01 (7.5290e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.88 ( 96.88)\n","Epoch: [68][ 30/391]\tTime  0.065 ( 0.077)\tLoss 9.4025e-01 (8.0062e-01)\tAcc@1  72.66 ( 76.16)\tAcc@5  94.53 ( 94.88)\n","Epoch: [68][ 60/391]\tTime  0.065 ( 0.075)\tLoss 9.1383e-01 (7.8010e-01)\tAcc@1  71.09 ( 76.70)\tAcc@5  91.41 ( 95.02)\n","Epoch: [68][ 90/391]\tTime  0.071 ( 0.073)\tLoss 9.4310e-01 (7.8013e-01)\tAcc@1  71.09 ( 76.93)\tAcc@5  91.41 ( 95.05)\n","Epoch: [68][120/391]\tTime  0.077 ( 0.073)\tLoss 7.8392e-01 (7.8234e-01)\tAcc@1  77.34 ( 76.79)\tAcc@5  96.09 ( 95.13)\n","Epoch: [68][150/391]\tTime  0.096 ( 0.072)\tLoss 8.2452e-01 (7.8276e-01)\tAcc@1  75.00 ( 76.67)\tAcc@5  95.31 ( 95.19)\n","Epoch: [68][180/391]\tTime  0.078 ( 0.072)\tLoss 7.7640e-01 (7.8224e-01)\tAcc@1  71.88 ( 76.57)\tAcc@5  96.09 ( 95.21)\n","Epoch: [68][210/391]\tTime  0.069 ( 0.072)\tLoss 8.2849e-01 (7.9045e-01)\tAcc@1  74.22 ( 76.45)\tAcc@5  95.31 ( 95.09)\n","Epoch: [68][240/391]\tTime  0.092 ( 0.071)\tLoss 1.1345e+00 (7.9824e-01)\tAcc@1  63.28 ( 76.22)\tAcc@5  89.84 ( 94.95)\n","Epoch: [68][270/391]\tTime  0.074 ( 0.071)\tLoss 7.4614e-01 (8.0141e-01)\tAcc@1  75.78 ( 76.11)\tAcc@5  97.66 ( 94.95)\n","Epoch: [68][300/391]\tTime  0.102 ( 0.071)\tLoss 6.4698e-01 (8.0413e-01)\tAcc@1  80.47 ( 76.03)\tAcc@5  97.66 ( 94.92)\n","Epoch: [68][330/391]\tTime  0.073 ( 0.071)\tLoss 9.4021e-01 (8.0888e-01)\tAcc@1  68.75 ( 75.87)\tAcc@5  95.31 ( 94.87)\n","Epoch: [68][360/391]\tTime  0.080 ( 0.071)\tLoss 9.0624e-01 (8.1075e-01)\tAcc@1  72.66 ( 75.84)\tAcc@5  92.97 ( 94.87)\n","Epoch: [68][390/391]\tTime  0.048 ( 0.071)\tLoss 7.8640e-01 (8.1754e-01)\tAcc@1  78.75 ( 75.66)\tAcc@5  95.00 ( 94.80)\n","==> Train Accuracy: Acc@1 75.664 || Acc@5 94.800\n","==> Test Accuracy:  Acc@1 71.850 || Acc@5 92.930\n","==> 29.95 seconds to train this epoch\n","\n","\n","----- epoch: 69, lr: 0.020000000000000004 -----\n","Epoch: [69][  0/391]\tTime  0.270 ( 0.270)\tLoss 8.8686e-01 (8.8686e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  92.19 ( 92.19)\n","Epoch: [69][ 30/391]\tTime  0.063 ( 0.077)\tLoss 8.8607e-01 (7.9007e-01)\tAcc@1  73.44 ( 76.92)\tAcc@5  92.19 ( 95.09)\n","Epoch: [69][ 60/391]\tTime  0.077 ( 0.075)\tLoss 8.2694e-01 (7.9904e-01)\tAcc@1  75.78 ( 76.47)\tAcc@5  95.31 ( 95.11)\n","Epoch: [69][ 90/391]\tTime  0.062 ( 0.073)\tLoss 8.2959e-01 (8.0365e-01)\tAcc@1  78.91 ( 76.31)\tAcc@5  95.31 ( 94.88)\n","Epoch: [69][120/391]\tTime  0.074 ( 0.072)\tLoss 6.7870e-01 (8.0647e-01)\tAcc@1  81.25 ( 76.34)\tAcc@5  97.66 ( 94.95)\n","Epoch: [69][150/391]\tTime  0.059 ( 0.072)\tLoss 7.5346e-01 (8.0592e-01)\tAcc@1  82.81 ( 76.45)\tAcc@5  96.88 ( 94.98)\n","Epoch: [69][180/391]\tTime  0.064 ( 0.071)\tLoss 8.3010e-01 (8.1004e-01)\tAcc@1  77.34 ( 76.33)\tAcc@5  95.31 ( 94.94)\n","Epoch: [69][210/391]\tTime  0.075 ( 0.071)\tLoss 7.8657e-01 (8.0802e-01)\tAcc@1  75.78 ( 76.38)\tAcc@5  97.66 ( 94.91)\n","Epoch: [69][240/391]\tTime  0.065 ( 0.071)\tLoss 7.1768e-01 (8.0805e-01)\tAcc@1  78.91 ( 76.33)\tAcc@5  97.66 ( 94.91)\n","Epoch: [69][270/391]\tTime  0.078 ( 0.071)\tLoss 8.4826e-01 (8.0743e-01)\tAcc@1  76.56 ( 76.30)\tAcc@5  97.66 ( 94.87)\n","Epoch: [69][300/391]\tTime  0.060 ( 0.071)\tLoss 5.2989e-01 (8.1122e-01)\tAcc@1  85.94 ( 76.20)\tAcc@5  96.88 ( 94.83)\n","Epoch: [69][330/391]\tTime  0.107 ( 0.071)\tLoss 8.5226e-01 (8.1366e-01)\tAcc@1  74.22 ( 76.06)\tAcc@5  94.53 ( 94.79)\n","Epoch: [69][360/391]\tTime  0.086 ( 0.071)\tLoss 9.1740e-01 (8.1675e-01)\tAcc@1  76.56 ( 75.99)\tAcc@5  93.75 ( 94.75)\n","Epoch: [69][390/391]\tTime  0.048 ( 0.071)\tLoss 9.0825e-01 (8.1763e-01)\tAcc@1  75.00 ( 75.94)\tAcc@5  92.50 ( 94.73)\n","==> Train Accuracy: Acc@1 75.938 || Acc@5 94.732\n","==> Test Accuracy:  Acc@1 72.070 || Acc@5 92.950\n","==> 29.83 seconds to train this epoch\n","\n","\n","----- epoch: 70, lr: 0.020000000000000004 -----\n","Epoch: [70][  0/391]\tTime  0.263 ( 0.263)\tLoss 9.5038e-01 (9.5038e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  94.53 ( 94.53)\n","Epoch: [70][ 30/391]\tTime  0.047 ( 0.075)\tLoss 9.3792e-01 (7.3721e-01)\tAcc@1  74.22 ( 78.28)\tAcc@5  94.53 ( 96.17)\n","Epoch: [70][ 60/391]\tTime  0.056 ( 0.073)\tLoss 6.5047e-01 (7.4568e-01)\tAcc@1  78.12 ( 77.84)\tAcc@5  96.09 ( 95.84)\n","Epoch: [70][ 90/391]\tTime  0.075 ( 0.072)\tLoss 8.1322e-01 (7.6390e-01)\tAcc@1  78.12 ( 77.39)\tAcc@5  95.31 ( 95.64)\n","Epoch: [70][120/391]\tTime  0.071 ( 0.072)\tLoss 7.0791e-01 (7.7913e-01)\tAcc@1  76.56 ( 76.97)\tAcc@5  96.09 ( 95.44)\n","Epoch: [70][150/391]\tTime  0.047 ( 0.072)\tLoss 6.5265e-01 (7.7993e-01)\tAcc@1  79.69 ( 76.88)\tAcc@5  96.88 ( 95.44)\n","Epoch: [70][180/391]\tTime  0.053 ( 0.072)\tLoss 8.2012e-01 (7.8751e-01)\tAcc@1  75.00 ( 76.56)\tAcc@5  94.53 ( 95.30)\n","Epoch: [70][210/391]\tTime  0.077 ( 0.072)\tLoss 9.4453e-01 (7.9644e-01)\tAcc@1  74.22 ( 76.31)\tAcc@5  91.41 ( 95.20)\n","Epoch: [70][240/391]\tTime  0.087 ( 0.071)\tLoss 7.7923e-01 (8.0368e-01)\tAcc@1  78.12 ( 76.19)\tAcc@5  92.97 ( 95.05)\n","Epoch: [70][270/391]\tTime  0.077 ( 0.071)\tLoss 9.0612e-01 (8.1261e-01)\tAcc@1  74.22 ( 75.86)\tAcc@5  94.53 ( 94.95)\n","Epoch: [70][300/391]\tTime  0.064 ( 0.071)\tLoss 7.2034e-01 (8.1147e-01)\tAcc@1  81.25 ( 75.88)\tAcc@5  94.53 ( 94.96)\n","Epoch: [70][330/391]\tTime  0.075 ( 0.071)\tLoss 8.9007e-01 (8.1178e-01)\tAcc@1  75.00 ( 75.89)\tAcc@5  92.97 ( 94.99)\n","Epoch: [70][360/391]\tTime  0.071 ( 0.071)\tLoss 7.9450e-01 (8.1605e-01)\tAcc@1  80.47 ( 75.80)\tAcc@5  95.31 ( 95.00)\n","Epoch: [70][390/391]\tTime  0.048 ( 0.071)\tLoss 8.7800e-01 (8.1734e-01)\tAcc@1  75.00 ( 75.78)\tAcc@5  96.25 ( 94.98)\n","==> Train Accuracy: Acc@1 75.782 || Acc@5 94.980\n","==> Test Accuracy:  Acc@1 71.570 || Acc@5 92.940\n","==> 29.79 seconds to train this epoch\n","\n","\n","----- epoch: 71, lr: 0.020000000000000004 -----\n","Epoch: [71][  0/391]\tTime  0.266 ( 0.266)\tLoss 1.0574e+00 (1.0574e+00)\tAcc@1  77.34 ( 77.34)\tAcc@5  93.75 ( 93.75)\n","Epoch: [71][ 30/391]\tTime  0.077 ( 0.076)\tLoss 8.8957e-01 (7.5532e-01)\tAcc@1  69.53 ( 77.52)\tAcc@5  96.88 ( 95.99)\n","Epoch: [71][ 60/391]\tTime  0.061 ( 0.073)\tLoss 8.9311e-01 (7.6705e-01)\tAcc@1  72.66 ( 76.99)\tAcc@5  95.31 ( 95.75)\n","Epoch: [71][ 90/391]\tTime  0.063 ( 0.072)\tLoss 8.0295e-01 (7.7509e-01)\tAcc@1  75.78 ( 76.72)\tAcc@5  96.09 ( 95.63)\n","Epoch: [71][120/391]\tTime  0.053 ( 0.072)\tLoss 9.2654e-01 (7.8800e-01)\tAcc@1  72.66 ( 76.41)\tAcc@5  94.53 ( 95.35)\n","Epoch: [71][150/391]\tTime  0.055 ( 0.072)\tLoss 6.9891e-01 (7.8463e-01)\tAcc@1  75.78 ( 76.48)\tAcc@5  96.09 ( 95.43)\n","Epoch: [71][180/391]\tTime  0.059 ( 0.072)\tLoss 7.8811e-01 (7.8543e-01)\tAcc@1  75.00 ( 76.55)\tAcc@5  96.88 ( 95.42)\n","Epoch: [71][210/391]\tTime  0.046 ( 0.071)\tLoss 7.1287e-01 (7.8399e-01)\tAcc@1  82.81 ( 76.64)\tAcc@5  96.09 ( 95.36)\n","Epoch: [71][240/391]\tTime  0.079 ( 0.071)\tLoss 7.8387e-01 (7.8613e-01)\tAcc@1  76.56 ( 76.52)\tAcc@5  96.88 ( 95.36)\n","Epoch: [71][270/391]\tTime  0.065 ( 0.071)\tLoss 9.0907e-01 (7.9472e-01)\tAcc@1  72.66 ( 76.30)\tAcc@5  95.31 ( 95.28)\n","Epoch: [71][300/391]\tTime  0.054 ( 0.071)\tLoss 6.7762e-01 (7.9974e-01)\tAcc@1  82.03 ( 76.14)\tAcc@5  96.09 ( 95.23)\n","Epoch: [71][330/391]\tTime  0.075 ( 0.071)\tLoss 9.0282e-01 (8.0321e-01)\tAcc@1  73.44 ( 76.05)\tAcc@5  95.31 ( 95.16)\n","Epoch: [71][360/391]\tTime  0.065 ( 0.071)\tLoss 9.8120e-01 (8.0898e-01)\tAcc@1  72.66 ( 75.94)\tAcc@5  92.19 ( 95.06)\n","Epoch: [71][390/391]\tTime  0.048 ( 0.071)\tLoss 9.6342e-01 (8.1130e-01)\tAcc@1  73.75 ( 75.89)\tAcc@5  90.00 ( 95.06)\n","==> Train Accuracy: Acc@1 75.890 || Acc@5 95.056\n","==> Test Accuracy:  Acc@1 70.590 || Acc@5 92.210\n","==> 29.80 seconds to train this epoch\n","\n","\n","----- epoch: 72, lr: 0.020000000000000004 -----\n","Epoch: [72][  0/391]\tTime  0.259 ( 0.259)\tLoss 7.9962e-01 (7.9962e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  92.97 ( 92.97)\n","Epoch: [72][ 30/391]\tTime  0.068 ( 0.075)\tLoss 7.2222e-01 (7.6748e-01)\tAcc@1  78.12 ( 77.34)\tAcc@5  96.88 ( 95.19)\n","Epoch: [72][ 60/391]\tTime  0.064 ( 0.073)\tLoss 6.9958e-01 (7.5635e-01)\tAcc@1  77.34 ( 77.73)\tAcc@5  96.88 ( 95.39)\n","Epoch: [72][ 90/391]\tTime  0.055 ( 0.072)\tLoss 7.4390e-01 (7.5629e-01)\tAcc@1  77.34 ( 77.88)\tAcc@5  96.88 ( 95.36)\n","Epoch: [72][120/391]\tTime  0.103 ( 0.072)\tLoss 6.8834e-01 (7.6749e-01)\tAcc@1  79.69 ( 77.58)\tAcc@5  98.44 ( 95.25)\n","Epoch: [72][150/391]\tTime  0.062 ( 0.072)\tLoss 8.2475e-01 (7.7556e-01)\tAcc@1  80.47 ( 77.24)\tAcc@5  92.97 ( 95.19)\n","Epoch: [72][180/391]\tTime  0.067 ( 0.071)\tLoss 6.8127e-01 (7.8225e-01)\tAcc@1  81.25 ( 76.99)\tAcc@5  96.09 ( 95.09)\n","Epoch: [72][210/391]\tTime  0.064 ( 0.071)\tLoss 6.4995e-01 (7.8740e-01)\tAcc@1  81.25 ( 76.84)\tAcc@5  96.88 ( 95.07)\n","Epoch: [72][240/391]\tTime  0.100 ( 0.071)\tLoss 8.7482e-01 (7.9080e-01)\tAcc@1  68.75 ( 76.64)\tAcc@5  94.53 ( 95.05)\n","Epoch: [72][270/391]\tTime  0.079 ( 0.071)\tLoss 5.9667e-01 (7.9766e-01)\tAcc@1  82.03 ( 76.43)\tAcc@5  96.88 ( 94.96)\n","Epoch: [72][300/391]\tTime  0.064 ( 0.071)\tLoss 8.7469e-01 (8.0293e-01)\tAcc@1  71.09 ( 76.21)\tAcc@5  92.97 ( 94.93)\n","Epoch: [72][330/391]\tTime  0.063 ( 0.071)\tLoss 9.1527e-01 (8.0295e-01)\tAcc@1  77.34 ( 76.25)\tAcc@5  93.75 ( 94.95)\n","Epoch: [72][360/391]\tTime  0.060 ( 0.071)\tLoss 8.6873e-01 (8.0169e-01)\tAcc@1  74.22 ( 76.30)\tAcc@5  94.53 ( 95.00)\n","Epoch: [72][390/391]\tTime  0.048 ( 0.071)\tLoss 1.0019e+00 (8.0215e-01)\tAcc@1  75.00 ( 76.30)\tAcc@5  92.50 ( 94.98)\n","==> Train Accuracy: Acc@1 76.296 || Acc@5 94.978\n","==> Test Accuracy:  Acc@1 71.130 || Acc@5 92.380\n","==> 29.96 seconds to train this epoch\n","\n","\n","----- epoch: 73, lr: 0.020000000000000004 -----\n","Epoch: [73][  0/391]\tTime  0.255 ( 0.255)\tLoss 9.4363e-01 (9.4363e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  92.97 ( 92.97)\n","Epoch: [73][ 30/391]\tTime  0.089 ( 0.075)\tLoss 6.9612e-01 (7.1509e-01)\tAcc@1  79.69 ( 78.43)\tAcc@5  94.53 ( 96.14)\n","Epoch: [73][ 60/391]\tTime  0.054 ( 0.073)\tLoss 8.6484e-01 (7.3138e-01)\tAcc@1  73.44 ( 77.65)\tAcc@5  96.88 ( 96.00)\n","Epoch: [73][ 90/391]\tTime  0.068 ( 0.072)\tLoss 8.4106e-01 (7.3821e-01)\tAcc@1  75.78 ( 77.44)\tAcc@5  91.41 ( 95.84)\n","Epoch: [73][120/391]\tTime  0.084 ( 0.072)\tLoss 8.8408e-01 (7.5204e-01)\tAcc@1  74.22 ( 77.23)\tAcc@5  96.09 ( 95.74)\n","Epoch: [73][150/391]\tTime  0.054 ( 0.072)\tLoss 8.9721e-01 (7.6721e-01)\tAcc@1  68.75 ( 76.78)\tAcc@5  92.97 ( 95.47)\n","Epoch: [73][180/391]\tTime  0.066 ( 0.072)\tLoss 9.1652e-01 (7.7229e-01)\tAcc@1  73.44 ( 76.74)\tAcc@5  94.53 ( 95.35)\n","Epoch: [73][210/391]\tTime  0.068 ( 0.072)\tLoss 8.9854e-01 (7.7656e-01)\tAcc@1  71.09 ( 76.63)\tAcc@5  95.31 ( 95.32)\n","Epoch: [73][240/391]\tTime  0.072 ( 0.072)\tLoss 8.1923e-01 (7.8097e-01)\tAcc@1  73.44 ( 76.56)\tAcc@5  96.09 ( 95.30)\n","Epoch: [73][270/391]\tTime  0.059 ( 0.072)\tLoss 9.3161e-01 (7.8705e-01)\tAcc@1  73.44 ( 76.39)\tAcc@5  93.75 ( 95.24)\n","Epoch: [73][300/391]\tTime  0.058 ( 0.071)\tLoss 8.0973e-01 (7.8966e-01)\tAcc@1  76.56 ( 76.39)\tAcc@5  94.53 ( 95.19)\n","Epoch: [73][330/391]\tTime  0.079 ( 0.071)\tLoss 6.4546e-01 (7.9282e-01)\tAcc@1  79.69 ( 76.27)\tAcc@5  97.66 ( 95.15)\n","Epoch: [73][360/391]\tTime  0.065 ( 0.071)\tLoss 7.6501e-01 (7.9582e-01)\tAcc@1  78.91 ( 76.15)\tAcc@5  96.88 ( 95.12)\n","Epoch: [73][390/391]\tTime  0.048 ( 0.071)\tLoss 9.7438e-01 (8.0247e-01)\tAcc@1  75.00 ( 75.97)\tAcc@5  93.75 ( 95.03)\n","==> Train Accuracy: Acc@1 75.968 || Acc@5 95.034\n","==> Test Accuracy:  Acc@1 70.640 || Acc@5 92.560\n","==> 29.84 seconds to train this epoch\n","\n","\n","----- epoch: 74, lr: 0.020000000000000004 -----\n","Epoch: [74][  0/391]\tTime  0.260 ( 0.260)\tLoss 6.3642e-01 (6.3642e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.09 ( 96.09)\n","Epoch: [74][ 30/391]\tTime  0.050 ( 0.075)\tLoss 6.8121e-01 (7.4670e-01)\tAcc@1  75.78 ( 77.65)\tAcc@5  97.66 ( 95.56)\n","Epoch: [74][ 60/391]\tTime  0.067 ( 0.071)\tLoss 5.8387e-01 (7.6411e-01)\tAcc@1  85.94 ( 77.54)\tAcc@5  96.88 ( 95.36)\n","Epoch: [74][ 90/391]\tTime  0.080 ( 0.070)\tLoss 6.1048e-01 (7.6022e-01)\tAcc@1  80.47 ( 77.88)\tAcc@5  96.88 ( 95.42)\n","Epoch: [74][120/391]\tTime  0.065 ( 0.070)\tLoss 6.4020e-01 (7.5676e-01)\tAcc@1  79.69 ( 77.83)\tAcc@5  96.88 ( 95.46)\n","Epoch: [74][150/391]\tTime  0.062 ( 0.070)\tLoss 7.0804e-01 (7.5904e-01)\tAcc@1  78.12 ( 77.60)\tAcc@5  95.31 ( 95.43)\n","Epoch: [74][180/391]\tTime  0.055 ( 0.070)\tLoss 8.4166e-01 (7.6427e-01)\tAcc@1  73.44 ( 77.52)\tAcc@5  96.88 ( 95.38)\n","Epoch: [74][210/391]\tTime  0.060 ( 0.070)\tLoss 6.5855e-01 (7.6905e-01)\tAcc@1  78.12 ( 77.37)\tAcc@5  98.44 ( 95.32)\n","Epoch: [74][240/391]\tTime  0.063 ( 0.070)\tLoss 6.5099e-01 (7.7541e-01)\tAcc@1  81.25 ( 77.16)\tAcc@5  95.31 ( 95.24)\n","Epoch: [74][270/391]\tTime  0.068 ( 0.070)\tLoss 1.0512e+00 (7.7968e-01)\tAcc@1  69.53 ( 77.04)\tAcc@5  93.75 ( 95.26)\n","Epoch: [74][300/391]\tTime  0.071 ( 0.070)\tLoss 7.5836e-01 (7.8164e-01)\tAcc@1  78.12 ( 76.95)\tAcc@5  95.31 ( 95.21)\n","Epoch: [74][330/391]\tTime  0.050 ( 0.069)\tLoss 8.3733e-01 (7.8574e-01)\tAcc@1  74.22 ( 76.83)\tAcc@5  95.31 ( 95.19)\n","Epoch: [74][360/391]\tTime  0.059 ( 0.070)\tLoss 9.9881e-01 (7.9245e-01)\tAcc@1  68.75 ( 76.58)\tAcc@5  96.09 ( 95.10)\n","Epoch: [74][390/391]\tTime  0.047 ( 0.069)\tLoss 9.6258e-01 (7.9840e-01)\tAcc@1  72.50 ( 76.43)\tAcc@5  93.75 ( 95.04)\n","==> Train Accuracy: Acc@1 76.430 || Acc@5 95.036\n","==> Test Accuracy:  Acc@1 69.840 || Acc@5 91.580\n","==> 29.23 seconds to train this epoch\n","\n","\n","----- epoch: 75, lr: 0.020000000000000004 -----\n","Epoch: [75][  0/391]\tTime  0.254 ( 0.254)\tLoss 8.9272e-01 (8.9272e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  94.53 ( 94.53)\n","Epoch: [75][ 30/391]\tTime  0.048 ( 0.075)\tLoss 9.5632e-01 (7.4104e-01)\tAcc@1  74.22 ( 78.98)\tAcc@5  92.19 ( 95.56)\n","Epoch: [75][ 60/391]\tTime  0.064 ( 0.072)\tLoss 1.0178e+00 (7.5487e-01)\tAcc@1  73.44 ( 78.32)\tAcc@5  90.62 ( 95.58)\n","Epoch: [75][ 90/391]\tTime  0.067 ( 0.071)\tLoss 8.2811e-01 (7.6249e-01)\tAcc@1  76.56 ( 77.66)\tAcc@5  97.66 ( 95.58)\n","Epoch: [75][120/391]\tTime  0.071 ( 0.070)\tLoss 8.0097e-01 (7.6465e-01)\tAcc@1  74.22 ( 77.43)\tAcc@5  94.53 ( 95.56)\n","Epoch: [75][150/391]\tTime  0.065 ( 0.070)\tLoss 6.2758e-01 (7.6899e-01)\tAcc@1  83.59 ( 77.28)\tAcc@5  98.44 ( 95.55)\n","Epoch: [75][180/391]\tTime  0.058 ( 0.069)\tLoss 8.5113e-01 (7.7238e-01)\tAcc@1  74.22 ( 77.23)\tAcc@5  94.53 ( 95.48)\n","Epoch: [75][210/391]\tTime  0.092 ( 0.069)\tLoss 6.7270e-01 (7.7515e-01)\tAcc@1  83.59 ( 77.16)\tAcc@5  94.53 ( 95.38)\n","Epoch: [75][240/391]\tTime  0.063 ( 0.069)\tLoss 7.7922e-01 (7.8267e-01)\tAcc@1  79.69 ( 76.90)\tAcc@5  95.31 ( 95.29)\n","Epoch: [75][270/391]\tTime  0.054 ( 0.069)\tLoss 7.5530e-01 (7.8774e-01)\tAcc@1  77.34 ( 76.76)\tAcc@5  96.88 ( 95.27)\n","Epoch: [75][300/391]\tTime  0.077 ( 0.069)\tLoss 8.2643e-01 (7.9288e-01)\tAcc@1  74.22 ( 76.58)\tAcc@5  93.75 ( 95.24)\n","Epoch: [75][330/391]\tTime  0.066 ( 0.069)\tLoss 8.5158e-01 (7.9760e-01)\tAcc@1  73.44 ( 76.39)\tAcc@5  93.75 ( 95.16)\n","Epoch: [75][360/391]\tTime  0.059 ( 0.069)\tLoss 7.8209e-01 (7.9999e-01)\tAcc@1  75.78 ( 76.34)\tAcc@5  93.75 ( 95.14)\n","Epoch: [75][390/391]\tTime  0.047 ( 0.069)\tLoss 8.7847e-01 (8.0154e-01)\tAcc@1  71.25 ( 76.30)\tAcc@5  97.50 ( 95.10)\n","==> Train Accuracy: Acc@1 76.298 || Acc@5 95.102\n","==> Test Accuracy:  Acc@1 72.070 || Acc@5 93.180\n","==> 29.02 seconds to train this epoch\n","\n","\n","----- epoch: 76, lr: 0.020000000000000004 -----\n","Epoch: [76][  0/391]\tTime  0.254 ( 0.254)\tLoss 5.3095e-01 (5.3095e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  98.44 ( 98.44)\n","Epoch: [76][ 30/391]\tTime  0.080 ( 0.077)\tLoss 5.4129e-01 (7.1840e-01)\tAcc@1  84.38 ( 78.76)\tAcc@5  97.66 ( 95.74)\n","Epoch: [76][ 60/391]\tTime  0.065 ( 0.073)\tLoss 7.9609e-01 (7.4133e-01)\tAcc@1  80.47 ( 78.05)\tAcc@5  92.97 ( 95.75)\n","Epoch: [76][ 90/391]\tTime  0.045 ( 0.071)\tLoss 8.7283e-01 (7.6064e-01)\tAcc@1  75.78 ( 77.57)\tAcc@5  92.19 ( 95.47)\n","Epoch: [76][120/391]\tTime  0.074 ( 0.070)\tLoss 8.1329e-01 (7.6577e-01)\tAcc@1  75.78 ( 77.39)\tAcc@5  93.75 ( 95.40)\n","Epoch: [76][150/391]\tTime  0.070 ( 0.070)\tLoss 7.5427e-01 (7.6864e-01)\tAcc@1  79.69 ( 77.42)\tAcc@5  95.31 ( 95.33)\n","Epoch: [76][180/391]\tTime  0.064 ( 0.070)\tLoss 8.0550e-01 (7.7560e-01)\tAcc@1  80.47 ( 77.03)\tAcc@5  96.88 ( 95.34)\n","Epoch: [76][210/391]\tTime  0.059 ( 0.069)\tLoss 6.6899e-01 (7.7836e-01)\tAcc@1  82.81 ( 76.95)\tAcc@5  96.88 ( 95.34)\n","Epoch: [76][240/391]\tTime  0.073 ( 0.069)\tLoss 5.0885e-01 (7.8085e-01)\tAcc@1  87.50 ( 76.94)\tAcc@5  97.66 ( 95.35)\n","Epoch: [76][270/391]\tTime  0.079 ( 0.069)\tLoss 7.9522e-01 (7.8216e-01)\tAcc@1  75.78 ( 76.89)\tAcc@5  96.09 ( 95.35)\n","Epoch: [76][300/391]\tTime  0.085 ( 0.069)\tLoss 7.2466e-01 (7.8953e-01)\tAcc@1  80.47 ( 76.78)\tAcc@5  94.53 ( 95.24)\n","Epoch: [76][330/391]\tTime  0.074 ( 0.069)\tLoss 8.9077e-01 (7.9302e-01)\tAcc@1  77.34 ( 76.59)\tAcc@5  95.31 ( 95.19)\n","Epoch: [76][360/391]\tTime  0.070 ( 0.069)\tLoss 8.4245e-01 (7.9674e-01)\tAcc@1  73.44 ( 76.47)\tAcc@5  95.31 ( 95.14)\n","Epoch: [76][390/391]\tTime  0.048 ( 0.069)\tLoss 1.0516e+00 (7.9814e-01)\tAcc@1  67.50 ( 76.44)\tAcc@5  93.75 ( 95.10)\n","==> Train Accuracy: Acc@1 76.440 || Acc@5 95.096\n","==> Test Accuracy:  Acc@1 72.090 || Acc@5 92.790\n","==> 29.07 seconds to train this epoch\n","\n","\n","----- epoch: 77, lr: 0.020000000000000004 -----\n","Epoch: [77][  0/391]\tTime  0.256 ( 0.256)\tLoss 6.1181e-01 (6.1181e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  96.09 ( 96.09)\n","Epoch: [77][ 30/391]\tTime  0.063 ( 0.075)\tLoss 5.7377e-01 (7.2552e-01)\tAcc@1  81.25 ( 78.12)\tAcc@5  97.66 ( 95.72)\n","Epoch: [77][ 60/391]\tTime  0.059 ( 0.072)\tLoss 7.9825e-01 (7.4104e-01)\tAcc@1  78.12 ( 78.39)\tAcc@5  95.31 ( 95.52)\n","Epoch: [77][ 90/391]\tTime  0.066 ( 0.070)\tLoss 6.2999e-01 (7.4357e-01)\tAcc@1  81.25 ( 77.86)\tAcc@5  95.31 ( 95.47)\n","Epoch: [77][120/391]\tTime  0.050 ( 0.070)\tLoss 6.5696e-01 (7.5244e-01)\tAcc@1  83.59 ( 77.74)\tAcc@5  97.66 ( 95.47)\n","Epoch: [77][150/391]\tTime  0.066 ( 0.070)\tLoss 8.4576e-01 (7.6383e-01)\tAcc@1  73.44 ( 77.21)\tAcc@5  96.88 ( 95.36)\n","Epoch: [77][180/391]\tTime  0.096 ( 0.069)\tLoss 9.5463e-01 (7.6956e-01)\tAcc@1  71.09 ( 77.11)\tAcc@5  95.31 ( 95.28)\n","Epoch: [77][210/391]\tTime  0.051 ( 0.069)\tLoss 6.5889e-01 (7.7403e-01)\tAcc@1  75.78 ( 76.95)\tAcc@5  96.09 ( 95.33)\n","Epoch: [77][240/391]\tTime  0.080 ( 0.069)\tLoss 7.2078e-01 (7.8020e-01)\tAcc@1  77.34 ( 76.79)\tAcc@5  98.44 ( 95.33)\n","Epoch: [77][270/391]\tTime  0.071 ( 0.069)\tLoss 8.4354e-01 (7.8462e-01)\tAcc@1  75.78 ( 76.70)\tAcc@5  94.53 ( 95.27)\n","Epoch: [77][300/391]\tTime  0.077 ( 0.069)\tLoss 7.4850e-01 (7.8704e-01)\tAcc@1  76.56 ( 76.69)\tAcc@5  98.44 ( 95.27)\n","Epoch: [77][330/391]\tTime  0.058 ( 0.069)\tLoss 8.1839e-01 (7.9186e-01)\tAcc@1  75.78 ( 76.63)\tAcc@5  93.75 ( 95.19)\n","Epoch: [77][360/391]\tTime  0.056 ( 0.069)\tLoss 6.6042e-01 (7.9567e-01)\tAcc@1  80.47 ( 76.54)\tAcc@5  96.09 ( 95.16)\n","Epoch: [77][390/391]\tTime  0.047 ( 0.069)\tLoss 7.1151e-01 (7.9593e-01)\tAcc@1  80.00 ( 76.48)\tAcc@5  95.00 ( 95.16)\n","==> Train Accuracy: Acc@1 76.480 || Acc@5 95.158\n","==> Test Accuracy:  Acc@1 70.800 || Acc@5 92.320\n","==> 29.02 seconds to train this epoch\n","\n","\n","----- epoch: 78, lr: 0.020000000000000004 -----\n","Epoch: [78][  0/391]\tTime  0.266 ( 0.266)\tLoss 7.8147e-01 (7.8147e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  93.75 ( 93.75)\n","Epoch: [78][ 30/391]\tTime  0.063 ( 0.076)\tLoss 7.2088e-01 (7.4320e-01)\tAcc@1  76.56 ( 77.75)\tAcc@5  95.31 ( 95.72)\n","Epoch: [78][ 60/391]\tTime  0.070 ( 0.072)\tLoss 7.9860e-01 (7.4680e-01)\tAcc@1  75.78 ( 77.70)\tAcc@5  95.31 ( 95.74)\n","Epoch: [78][ 90/391]\tTime  0.078 ( 0.071)\tLoss 6.9204e-01 (7.4423e-01)\tAcc@1  78.91 ( 77.76)\tAcc@5  96.88 ( 95.72)\n","Epoch: [78][120/391]\tTime  0.077 ( 0.071)\tLoss 6.8769e-01 (7.6677e-01)\tAcc@1  82.81 ( 77.20)\tAcc@5  95.31 ( 95.36)\n","Epoch: [78][150/391]\tTime  0.057 ( 0.070)\tLoss 7.7527e-01 (7.6574e-01)\tAcc@1  79.69 ( 77.26)\tAcc@5  93.75 ( 95.37)\n","Epoch: [78][180/391]\tTime  0.074 ( 0.070)\tLoss 7.2546e-01 (7.6303e-01)\tAcc@1  75.78 ( 77.24)\tAcc@5  94.53 ( 95.46)\n","Epoch: [78][210/391]\tTime  0.045 ( 0.070)\tLoss 8.1438e-01 (7.6532e-01)\tAcc@1  77.34 ( 77.04)\tAcc@5  92.97 ( 95.46)\n","Epoch: [78][240/391]\tTime  0.051 ( 0.070)\tLoss 7.2010e-01 (7.7109e-01)\tAcc@1  78.91 ( 76.86)\tAcc@5  95.31 ( 95.41)\n","Epoch: [78][270/391]\tTime  0.067 ( 0.069)\tLoss 6.9821e-01 (7.7623e-01)\tAcc@1  78.91 ( 76.77)\tAcc@5  95.31 ( 95.36)\n","Epoch: [78][300/391]\tTime  0.063 ( 0.069)\tLoss 7.7895e-01 (7.8053e-01)\tAcc@1  78.12 ( 76.65)\tAcc@5  95.31 ( 95.32)\n","Epoch: [78][330/391]\tTime  0.063 ( 0.069)\tLoss 8.7331e-01 (7.8229e-01)\tAcc@1  72.66 ( 76.58)\tAcc@5  94.53 ( 95.28)\n","Epoch: [78][360/391]\tTime  0.051 ( 0.069)\tLoss 8.4514e-01 (7.8649e-01)\tAcc@1  79.69 ( 76.49)\tAcc@5  93.75 ( 95.26)\n","Epoch: [78][390/391]\tTime  0.047 ( 0.069)\tLoss 8.3279e-01 (7.8959e-01)\tAcc@1  76.25 ( 76.38)\tAcc@5  96.25 ( 95.23)\n","==> Train Accuracy: Acc@1 76.380 || Acc@5 95.234\n","==> Test Accuracy:  Acc@1 70.750 || Acc@5 92.020\n","==> 29.07 seconds to train this epoch\n","\n","\n","----- epoch: 79, lr: 0.020000000000000004 -----\n","Epoch: [79][  0/391]\tTime  0.243 ( 0.243)\tLoss 6.3083e-01 (6.3083e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  96.88 ( 96.88)\n","Epoch: [79][ 30/391]\tTime  0.044 ( 0.075)\tLoss 5.9264e-01 (7.3015e-01)\tAcc@1  83.59 ( 78.15)\tAcc@5  96.09 ( 95.56)\n","Epoch: [79][ 60/391]\tTime  0.065 ( 0.073)\tLoss 8.9137e-01 (7.4328e-01)\tAcc@1  78.12 ( 77.57)\tAcc@5  94.53 ( 95.43)\n","Epoch: [79][ 90/391]\tTime  0.069 ( 0.071)\tLoss 5.9817e-01 (7.6004e-01)\tAcc@1  84.38 ( 77.09)\tAcc@5  96.09 ( 95.43)\n","Epoch: [79][120/391]\tTime  0.100 ( 0.071)\tLoss 8.0391e-01 (7.5964e-01)\tAcc@1  76.56 ( 77.21)\tAcc@5  92.19 ( 95.39)\n","Epoch: [79][150/391]\tTime  0.065 ( 0.071)\tLoss 9.3496e-01 (7.6443e-01)\tAcc@1  72.66 ( 77.06)\tAcc@5  94.53 ( 95.42)\n","Epoch: [79][180/391]\tTime  0.083 ( 0.070)\tLoss 9.4119e-01 (7.6724e-01)\tAcc@1  75.78 ( 77.01)\tAcc@5  94.53 ( 95.38)\n","Epoch: [79][210/391]\tTime  0.110 ( 0.070)\tLoss 6.8034e-01 (7.6236e-01)\tAcc@1  84.38 ( 77.18)\tAcc@5  95.31 ( 95.48)\n","Epoch: [79][240/391]\tTime  0.056 ( 0.070)\tLoss 6.7935e-01 (7.6703e-01)\tAcc@1  82.03 ( 77.08)\tAcc@5  96.88 ( 95.43)\n","Epoch: [79][270/391]\tTime  0.074 ( 0.070)\tLoss 8.3510e-01 (7.7062e-01)\tAcc@1  71.09 ( 77.00)\tAcc@5  95.31 ( 95.41)\n","Epoch: [79][300/391]\tTime  0.063 ( 0.070)\tLoss 9.5655e-01 (7.7631e-01)\tAcc@1  71.88 ( 76.80)\tAcc@5  94.53 ( 95.37)\n","Epoch: [79][330/391]\tTime  0.065 ( 0.069)\tLoss 7.5796e-01 (7.8004e-01)\tAcc@1  75.00 ( 76.70)\tAcc@5  98.44 ( 95.35)\n","Epoch: [79][360/391]\tTime  0.066 ( 0.069)\tLoss 9.5246e-01 (7.8507e-01)\tAcc@1  70.31 ( 76.53)\tAcc@5  95.31 ( 95.30)\n","Epoch: [79][390/391]\tTime  0.047 ( 0.069)\tLoss 9.6506e-01 (7.8858e-01)\tAcc@1  75.00 ( 76.42)\tAcc@5  88.75 ( 95.25)\n","==> Train Accuracy: Acc@1 76.418 || Acc@5 95.252\n","==> Test Accuracy:  Acc@1 69.760 || Acc@5 92.070\n","==> 29.11 seconds to train this epoch\n","\n","\n","----- epoch: 80, lr: 0.020000000000000004 -----\n","Epoch: [80][  0/391]\tTime  0.254 ( 0.254)\tLoss 7.5540e-01 (7.5540e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  97.66 ( 97.66)\n","Epoch: [80][ 30/391]\tTime  0.060 ( 0.073)\tLoss 5.4970e-01 (7.6567e-01)\tAcc@1  85.16 ( 76.89)\tAcc@5  97.66 ( 95.79)\n","Epoch: [80][ 60/391]\tTime  0.064 ( 0.072)\tLoss 7.6793e-01 (7.5078e-01)\tAcc@1  78.91 ( 77.69)\tAcc@5  94.53 ( 95.61)\n","Epoch: [80][ 90/391]\tTime  0.061 ( 0.071)\tLoss 5.8567e-01 (7.4232e-01)\tAcc@1  82.81 ( 77.86)\tAcc@5  96.09 ( 95.60)\n","Epoch: [80][120/391]\tTime  0.082 ( 0.071)\tLoss 7.9000e-01 (7.4494e-01)\tAcc@1  76.56 ( 77.66)\tAcc@5  93.75 ( 95.65)\n","Epoch: [80][150/391]\tTime  0.063 ( 0.071)\tLoss 8.4116e-01 (7.5060e-01)\tAcc@1  76.56 ( 77.58)\tAcc@5  96.09 ( 95.66)\n","Epoch: [80][180/391]\tTime  0.070 ( 0.070)\tLoss 7.1739e-01 (7.5825e-01)\tAcc@1  76.56 ( 77.30)\tAcc@5  95.31 ( 95.60)\n","Epoch: [80][210/391]\tTime  0.062 ( 0.070)\tLoss 9.6282e-01 (7.6386e-01)\tAcc@1  71.09 ( 77.08)\tAcc@5  95.31 ( 95.59)\n","Epoch: [80][240/391]\tTime  0.075 ( 0.070)\tLoss 8.1306e-01 (7.6627e-01)\tAcc@1  78.12 ( 77.03)\tAcc@5  95.31 ( 95.55)\n","Epoch: [80][270/391]\tTime  0.064 ( 0.070)\tLoss 7.7682e-01 (7.6807e-01)\tAcc@1  72.66 ( 76.94)\tAcc@5  98.44 ( 95.54)\n","Epoch: [80][300/391]\tTime  0.069 ( 0.070)\tLoss 9.2497e-01 (7.7348e-01)\tAcc@1  71.88 ( 76.76)\tAcc@5  95.31 ( 95.49)\n","Epoch: [80][330/391]\tTime  0.060 ( 0.070)\tLoss 8.2572e-01 (7.7986e-01)\tAcc@1  74.22 ( 76.58)\tAcc@5  96.09 ( 95.44)\n","Epoch: [80][360/391]\tTime  0.057 ( 0.070)\tLoss 7.6458e-01 (7.8096e-01)\tAcc@1  78.12 ( 76.56)\tAcc@5  96.09 ( 95.43)\n","Epoch: [80][390/391]\tTime  0.047 ( 0.070)\tLoss 8.8143e-01 (7.8535e-01)\tAcc@1  73.75 ( 76.44)\tAcc@5  95.00 ( 95.36)\n","==> Train Accuracy: Acc@1 76.436 || Acc@5 95.360\n","==> Test Accuracy:  Acc@1 70.760 || Acc@5 92.160\n","==> 29.30 seconds to train this epoch\n","\n","\n","----- epoch: 81, lr: 0.020000000000000004 -----\n","Epoch: [81][  0/391]\tTime  0.264 ( 0.264)\tLoss 6.9255e-01 (6.9255e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.88 ( 96.88)\n","Epoch: [81][ 30/391]\tTime  0.048 ( 0.075)\tLoss 6.9131e-01 (7.2237e-01)\tAcc@1  73.44 ( 78.18)\tAcc@5  96.88 ( 96.37)\n","Epoch: [81][ 60/391]\tTime  0.066 ( 0.071)\tLoss 6.7893e-01 (7.2686e-01)\tAcc@1  79.69 ( 78.52)\tAcc@5  97.66 ( 96.09)\n","Epoch: [81][ 90/391]\tTime  0.070 ( 0.071)\tLoss 6.9853e-01 (7.3788e-01)\tAcc@1  80.47 ( 78.27)\tAcc@5  94.53 ( 95.87)\n","Epoch: [81][120/391]\tTime  0.061 ( 0.070)\tLoss 8.5973e-01 (7.4312e-01)\tAcc@1  72.66 ( 78.25)\tAcc@5  92.97 ( 95.75)\n","Epoch: [81][150/391]\tTime  0.065 ( 0.070)\tLoss 6.5213e-01 (7.5261e-01)\tAcc@1  81.25 ( 77.94)\tAcc@5  98.44 ( 95.66)\n","Epoch: [81][180/391]\tTime  0.057 ( 0.070)\tLoss 8.1465e-01 (7.5503e-01)\tAcc@1  75.78 ( 77.82)\tAcc@5  93.75 ( 95.66)\n","Epoch: [81][210/391]\tTime  0.064 ( 0.069)\tLoss 7.5891e-01 (7.5573e-01)\tAcc@1  75.78 ( 77.73)\tAcc@5  96.09 ( 95.63)\n","Epoch: [81][240/391]\tTime  0.065 ( 0.069)\tLoss 7.5226e-01 (7.5985e-01)\tAcc@1  76.56 ( 77.57)\tAcc@5  96.09 ( 95.62)\n","Epoch: [81][270/391]\tTime  0.053 ( 0.069)\tLoss 8.6279e-01 (7.6794e-01)\tAcc@1  73.44 ( 77.33)\tAcc@5  96.09 ( 95.55)\n","Epoch: [81][300/391]\tTime  0.074 ( 0.069)\tLoss 8.1457e-01 (7.7446e-01)\tAcc@1  77.34 ( 77.09)\tAcc@5  96.88 ( 95.47)\n","Epoch: [81][330/391]\tTime  0.087 ( 0.069)\tLoss 7.8678e-01 (7.7650e-01)\tAcc@1  74.22 ( 76.97)\tAcc@5  97.66 ( 95.45)\n","Epoch: [81][360/391]\tTime  0.057 ( 0.069)\tLoss 8.9590e-01 (7.7974e-01)\tAcc@1  71.09 ( 76.87)\tAcc@5  94.53 ( 95.42)\n","Epoch: [81][390/391]\tTime  0.044 ( 0.069)\tLoss 1.2330e+00 (7.8327e-01)\tAcc@1  65.00 ( 76.74)\tAcc@5  88.75 ( 95.34)\n","==> Train Accuracy: Acc@1 76.744 || Acc@5 95.344\n","==> Test Accuracy:  Acc@1 70.760 || Acc@5 92.150\n","==> 29.08 seconds to train this epoch\n","\n","\n","----- epoch: 82, lr: 0.020000000000000004 -----\n","Epoch: [82][  0/391]\tTime  0.264 ( 0.264)\tLoss 5.9733e-01 (5.9733e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  96.09 ( 96.09)\n","Epoch: [82][ 30/391]\tTime  0.052 ( 0.074)\tLoss 7.8489e-01 (7.7997e-01)\tAcc@1  74.22 ( 76.71)\tAcc@5  93.75 ( 95.36)\n","Epoch: [82][ 60/391]\tTime  0.060 ( 0.071)\tLoss 6.1621e-01 (7.6178e-01)\tAcc@1  79.69 ( 77.52)\tAcc@5  96.09 ( 95.36)\n","Epoch: [82][ 90/391]\tTime  0.057 ( 0.070)\tLoss 8.5124e-01 (7.6668e-01)\tAcc@1  76.56 ( 77.29)\tAcc@5  94.53 ( 95.50)\n","Epoch: [82][120/391]\tTime  0.047 ( 0.070)\tLoss 8.4614e-01 (7.6632e-01)\tAcc@1  72.66 ( 77.20)\tAcc@5  94.53 ( 95.59)\n","Epoch: [82][150/391]\tTime  0.069 ( 0.069)\tLoss 7.2168e-01 (7.6975e-01)\tAcc@1  80.47 ( 77.04)\tAcc@5  96.88 ( 95.60)\n","Epoch: [82][180/391]\tTime  0.069 ( 0.069)\tLoss 8.1511e-01 (7.7022e-01)\tAcc@1  74.22 ( 77.05)\tAcc@5  95.31 ( 95.55)\n","Epoch: [82][210/391]\tTime  0.057 ( 0.069)\tLoss 1.0269e+00 (7.7167e-01)\tAcc@1  72.66 ( 77.03)\tAcc@5  92.97 ( 95.47)\n","Epoch: [82][240/391]\tTime  0.112 ( 0.070)\tLoss 6.5670e-01 (7.7321e-01)\tAcc@1  82.03 ( 77.01)\tAcc@5  97.66 ( 95.46)\n","Epoch: [82][270/391]\tTime  0.101 ( 0.069)\tLoss 6.8905e-01 (7.7396e-01)\tAcc@1  78.91 ( 76.97)\tAcc@5  99.22 ( 95.43)\n","Epoch: [82][300/391]\tTime  0.045 ( 0.070)\tLoss 8.8342e-01 (7.7809e-01)\tAcc@1  75.78 ( 76.94)\tAcc@5  92.19 ( 95.36)\n","Epoch: [82][330/391]\tTime  0.046 ( 0.070)\tLoss 7.5259e-01 (7.8258e-01)\tAcc@1  78.12 ( 76.82)\tAcc@5  96.09 ( 95.33)\n","Epoch: [82][360/391]\tTime  0.059 ( 0.069)\tLoss 9.0294e-01 (7.8489e-01)\tAcc@1  76.56 ( 76.73)\tAcc@5  93.75 ( 95.32)\n","Epoch: [82][390/391]\tTime  0.048 ( 0.069)\tLoss 7.1859e-01 (7.8564e-01)\tAcc@1  78.75 ( 76.70)\tAcc@5  96.25 ( 95.29)\n","==> Train Accuracy: Acc@1 76.696 || Acc@5 95.292\n","==> Test Accuracy:  Acc@1 70.500 || Acc@5 92.250\n","==> 29.18 seconds to train this epoch\n","\n","\n","----- epoch: 83, lr: 0.020000000000000004 -----\n","Epoch: [83][  0/391]\tTime  0.258 ( 0.258)\tLoss 8.3812e-01 (8.3812e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  96.88 ( 96.88)\n","Epoch: [83][ 30/391]\tTime  0.094 ( 0.075)\tLoss 6.3143e-01 (7.4636e-01)\tAcc@1  82.81 ( 78.33)\tAcc@5  95.31 ( 95.67)\n","Epoch: [83][ 60/391]\tTime  0.053 ( 0.072)\tLoss 7.2704e-01 (7.2143e-01)\tAcc@1  78.12 ( 78.46)\tAcc@5  97.66 ( 95.95)\n","Epoch: [83][ 90/391]\tTime  0.059 ( 0.071)\tLoss 7.6211e-01 (7.2093e-01)\tAcc@1  75.78 ( 78.48)\tAcc@5  95.31 ( 95.93)\n","Epoch: [83][120/391]\tTime  0.065 ( 0.070)\tLoss 7.4649e-01 (7.2704e-01)\tAcc@1  78.91 ( 78.27)\tAcc@5  95.31 ( 95.98)\n","Epoch: [83][150/391]\tTime  0.089 ( 0.069)\tLoss 8.6612e-01 (7.3689e-01)\tAcc@1  76.56 ( 78.09)\tAcc@5  94.53 ( 95.86)\n","Epoch: [83][180/391]\tTime  0.092 ( 0.069)\tLoss 9.7000e-01 (7.4784e-01)\tAcc@1  75.00 ( 77.80)\tAcc@5  92.97 ( 95.71)\n","Epoch: [83][210/391]\tTime  0.098 ( 0.070)\tLoss 8.1048e-01 (7.4956e-01)\tAcc@1  79.69 ( 77.74)\tAcc@5  92.97 ( 95.67)\n","Epoch: [83][240/391]\tTime  0.077 ( 0.070)\tLoss 6.5848e-01 (7.5511e-01)\tAcc@1  81.25 ( 77.51)\tAcc@5  96.09 ( 95.61)\n","Epoch: [83][270/391]\tTime  0.061 ( 0.070)\tLoss 6.9671e-01 (7.6006e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  96.88 ( 95.58)\n","Epoch: [83][300/391]\tTime  0.067 ( 0.070)\tLoss 7.8314e-01 (7.5888e-01)\tAcc@1  73.44 ( 77.35)\tAcc@5  95.31 ( 95.64)\n","Epoch: [83][330/391]\tTime  0.088 ( 0.070)\tLoss 6.8046e-01 (7.6505e-01)\tAcc@1  78.12 ( 77.14)\tAcc@5  97.66 ( 95.63)\n","Epoch: [83][360/391]\tTime  0.051 ( 0.070)\tLoss 8.0832e-01 (7.6957e-01)\tAcc@1  75.00 ( 77.12)\tAcc@5  92.97 ( 95.55)\n","Epoch: [83][390/391]\tTime  0.047 ( 0.070)\tLoss 6.4980e-01 (7.7264e-01)\tAcc@1  76.25 ( 77.05)\tAcc@5  96.25 ( 95.52)\n","==> Train Accuracy: Acc@1 77.052 || Acc@5 95.520\n","==> Test Accuracy:  Acc@1 70.550 || Acc@5 92.240\n","==> 29.44 seconds to train this epoch\n","\n","\n","----- epoch: 84, lr: 0.020000000000000004 -----\n","Epoch: [84][  0/391]\tTime  0.240 ( 0.240)\tLoss 8.0708e-01 (8.0708e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  95.31 ( 95.31)\n","Epoch: [84][ 30/391]\tTime  0.108 ( 0.074)\tLoss 5.7991e-01 (6.8514e-01)\tAcc@1  83.59 ( 79.89)\tAcc@5  96.88 ( 96.50)\n","Epoch: [84][ 60/391]\tTime  0.086 ( 0.072)\tLoss 8.9384e-01 (7.0233e-01)\tAcc@1  72.66 ( 79.15)\tAcc@5  93.75 ( 96.26)\n","Epoch: [84][ 90/391]\tTime  0.054 ( 0.072)\tLoss 6.5576e-01 (7.1248e-01)\tAcc@1  83.59 ( 78.86)\tAcc@5  96.88 ( 96.15)\n","Epoch: [84][120/391]\tTime  0.056 ( 0.071)\tLoss 7.7926e-01 (7.1214e-01)\tAcc@1  76.56 ( 78.96)\tAcc@5  94.53 ( 96.10)\n","Epoch: [84][150/391]\tTime  0.062 ( 0.070)\tLoss 5.6291e-01 (7.2061e-01)\tAcc@1  82.81 ( 78.60)\tAcc@5  98.44 ( 95.98)\n","Epoch: [84][180/391]\tTime  0.059 ( 0.070)\tLoss 6.9817e-01 (7.2682e-01)\tAcc@1  80.47 ( 78.46)\tAcc@5  95.31 ( 95.89)\n","Epoch: [84][210/391]\tTime  0.068 ( 0.070)\tLoss 7.4330e-01 (7.3767e-01)\tAcc@1  76.56 ( 78.08)\tAcc@5  97.66 ( 95.85)\n","Epoch: [84][240/391]\tTime  0.059 ( 0.070)\tLoss 7.3166e-01 (7.4631e-01)\tAcc@1  82.81 ( 77.80)\tAcc@5  94.53 ( 95.77)\n","Epoch: [84][270/391]\tTime  0.079 ( 0.070)\tLoss 7.9080e-01 (7.5229e-01)\tAcc@1  75.00 ( 77.64)\tAcc@5  96.88 ( 95.65)\n","Epoch: [84][300/391]\tTime  0.088 ( 0.070)\tLoss 8.8703e-01 (7.5610e-01)\tAcc@1  75.00 ( 77.57)\tAcc@5  93.75 ( 95.62)\n","Epoch: [84][330/391]\tTime  0.057 ( 0.070)\tLoss 8.9960e-01 (7.5904e-01)\tAcc@1  73.44 ( 77.51)\tAcc@5  92.97 ( 95.61)\n","Epoch: [84][360/391]\tTime  0.039 ( 0.070)\tLoss 8.2967e-01 (7.6433e-01)\tAcc@1  77.34 ( 77.35)\tAcc@5  95.31 ( 95.55)\n","Epoch: [84][390/391]\tTime  0.047 ( 0.070)\tLoss 9.6994e-01 (7.6894e-01)\tAcc@1  73.75 ( 77.22)\tAcc@5  90.00 ( 95.48)\n","==> Train Accuracy: Acc@1 77.220 || Acc@5 95.484\n","==> Test Accuracy:  Acc@1 70.640 || Acc@5 92.230\n","==> 29.37 seconds to train this epoch\n","\n","\n","----- epoch: 85, lr: 0.020000000000000004 -----\n","Epoch: [85][  0/391]\tTime  0.276 ( 0.276)\tLoss 6.0988e-01 (6.0988e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.09 ( 96.09)\n","Epoch: [85][ 30/391]\tTime  0.058 ( 0.074)\tLoss 7.2860e-01 (7.2946e-01)\tAcc@1  77.34 ( 79.08)\tAcc@5  96.88 ( 96.02)\n","Epoch: [85][ 60/391]\tTime  0.077 ( 0.071)\tLoss 7.8768e-01 (7.1783e-01)\tAcc@1  76.56 ( 78.98)\tAcc@5  93.75 ( 96.11)\n","Epoch: [85][ 90/391]\tTime  0.100 ( 0.071)\tLoss 6.2234e-01 (7.0881e-01)\tAcc@1  85.16 ( 79.11)\tAcc@5  95.31 ( 96.10)\n","Epoch: [85][120/391]\tTime  0.092 ( 0.071)\tLoss 8.7466e-01 (7.1573e-01)\tAcc@1  72.66 ( 78.91)\tAcc@5  96.09 ( 95.96)\n","Epoch: [85][150/391]\tTime  0.082 ( 0.070)\tLoss 6.8679e-01 (7.2707e-01)\tAcc@1  82.03 ( 78.58)\tAcc@5  96.09 ( 95.85)\n","Epoch: [85][180/391]\tTime  0.069 ( 0.070)\tLoss 8.1916e-01 (7.3589e-01)\tAcc@1  75.78 ( 78.38)\tAcc@5  93.75 ( 95.81)\n","Epoch: [85][210/391]\tTime  0.047 ( 0.070)\tLoss 7.2656e-01 (7.3794e-01)\tAcc@1  75.78 ( 78.18)\tAcc@5  96.88 ( 95.86)\n","Epoch: [85][240/391]\tTime  0.057 ( 0.069)\tLoss 8.9395e-01 (7.4400e-01)\tAcc@1  71.88 ( 77.99)\tAcc@5  95.31 ( 95.78)\n","Epoch: [85][270/391]\tTime  0.072 ( 0.069)\tLoss 8.0415e-01 (7.4870e-01)\tAcc@1  75.78 ( 77.83)\tAcc@5  94.53 ( 95.72)\n","Epoch: [85][300/391]\tTime  0.055 ( 0.069)\tLoss 7.7081e-01 (7.5341e-01)\tAcc@1  78.12 ( 77.66)\tAcc@5  92.97 ( 95.67)\n","Epoch: [85][330/391]\tTime  0.080 ( 0.069)\tLoss 8.2301e-01 (7.5787e-01)\tAcc@1  78.12 ( 77.46)\tAcc@5  93.75 ( 95.65)\n","Epoch: [85][360/391]\tTime  0.063 ( 0.069)\tLoss 6.6661e-01 (7.6103e-01)\tAcc@1  81.25 ( 77.33)\tAcc@5  94.53 ( 95.61)\n","Epoch: [85][390/391]\tTime  0.047 ( 0.069)\tLoss 6.7559e-01 (7.6333e-01)\tAcc@1  80.00 ( 77.24)\tAcc@5  96.25 ( 95.58)\n","==> Train Accuracy: Acc@1 77.236 || Acc@5 95.580\n","==> Test Accuracy:  Acc@1 71.150 || Acc@5 92.670\n","==> 29.03 seconds to train this epoch\n","\n","\n","----- epoch: 86, lr: 0.020000000000000004 -----\n","Epoch: [86][  0/391]\tTime  0.264 ( 0.264)\tLoss 7.8024e-01 (7.8024e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  94.53 ( 94.53)\n","Epoch: [86][ 30/391]\tTime  0.064 ( 0.076)\tLoss 7.1404e-01 (7.1723e-01)\tAcc@1  82.81 ( 78.78)\tAcc@5  93.75 ( 96.07)\n","Epoch: [86][ 60/391]\tTime  0.075 ( 0.073)\tLoss 6.3765e-01 (7.0930e-01)\tAcc@1  78.12 ( 79.16)\tAcc@5  96.09 ( 96.11)\n","Epoch: [86][ 90/391]\tTime  0.080 ( 0.071)\tLoss 5.8788e-01 (7.0666e-01)\tAcc@1  82.81 ( 79.10)\tAcc@5  96.09 ( 96.15)\n","Epoch: [86][120/391]\tTime  0.064 ( 0.070)\tLoss 9.6739e-01 (7.1225e-01)\tAcc@1  71.88 ( 78.88)\tAcc@5  93.75 ( 96.06)\n","Epoch: [86][150/391]\tTime  0.064 ( 0.070)\tLoss 8.2409e-01 (7.1998e-01)\tAcc@1  76.56 ( 78.59)\tAcc@5  93.75 ( 95.91)\n","Epoch: [86][180/391]\tTime  0.080 ( 0.070)\tLoss 5.3970e-01 (7.3405e-01)\tAcc@1  85.94 ( 78.18)\tAcc@5  97.66 ( 95.83)\n","Epoch: [86][210/391]\tTime  0.070 ( 0.069)\tLoss 6.7229e-01 (7.3819e-01)\tAcc@1  79.69 ( 78.03)\tAcc@5  96.09 ( 95.75)\n","Epoch: [86][240/391]\tTime  0.077 ( 0.069)\tLoss 6.7803e-01 (7.4413e-01)\tAcc@1  77.34 ( 77.87)\tAcc@5  98.44 ( 95.70)\n","Epoch: [86][270/391]\tTime  0.065 ( 0.069)\tLoss 7.4460e-01 (7.4779e-01)\tAcc@1  77.34 ( 77.76)\tAcc@5 100.00 ( 95.72)\n","Epoch: [86][300/391]\tTime  0.095 ( 0.069)\tLoss 5.1137e-01 (7.4990e-01)\tAcc@1  86.72 ( 77.71)\tAcc@5  97.66 ( 95.69)\n","Epoch: [86][330/391]\tTime  0.084 ( 0.069)\tLoss 8.3804e-01 (7.5219e-01)\tAcc@1  75.78 ( 77.60)\tAcc@5  93.75 ( 95.71)\n","Epoch: [86][360/391]\tTime  0.055 ( 0.069)\tLoss 8.2734e-01 (7.5681e-01)\tAcc@1  77.34 ( 77.46)\tAcc@5  94.53 ( 95.68)\n","Epoch: [86][390/391]\tTime  0.048 ( 0.069)\tLoss 9.0012e-01 (7.6002e-01)\tAcc@1  70.00 ( 77.36)\tAcc@5  91.25 ( 95.66)\n","==> Train Accuracy: Acc@1 77.360 || Acc@5 95.656\n","==> Test Accuracy:  Acc@1 70.390 || Acc@5 92.020\n","==> 29.26 seconds to train this epoch\n","\n","\n","----- epoch: 87, lr: 0.020000000000000004 -----\n","Epoch: [87][  0/391]\tTime  0.283 ( 0.283)\tLoss 6.8001e-01 (6.8001e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  97.66 ( 97.66)\n","Epoch: [87][ 30/391]\tTime  0.089 ( 0.075)\tLoss 6.5168e-01 (6.6993e-01)\tAcc@1  83.59 ( 79.23)\tAcc@5  96.88 ( 96.62)\n","Epoch: [87][ 60/391]\tTime  0.067 ( 0.072)\tLoss 6.6038e-01 (6.9079e-01)\tAcc@1  80.47 ( 79.10)\tAcc@5  96.09 ( 96.30)\n","Epoch: [87][ 90/391]\tTime  0.053 ( 0.071)\tLoss 8.3322e-01 (7.1323e-01)\tAcc@1  74.22 ( 78.60)\tAcc@5  94.53 ( 96.02)\n","Epoch: [87][120/391]\tTime  0.050 ( 0.071)\tLoss 8.2351e-01 (7.1751e-01)\tAcc@1  75.78 ( 78.64)\tAcc@5  94.53 ( 96.01)\n","Epoch: [87][150/391]\tTime  0.069 ( 0.070)\tLoss 6.2407e-01 (7.2332e-01)\tAcc@1  78.12 ( 78.48)\tAcc@5  98.44 ( 95.99)\n","Epoch: [87][180/391]\tTime  0.065 ( 0.070)\tLoss 5.6099e-01 (7.2703e-01)\tAcc@1  82.03 ( 78.33)\tAcc@5  97.66 ( 95.96)\n","Epoch: [87][210/391]\tTime  0.062 ( 0.070)\tLoss 9.6609e-01 (7.3059e-01)\tAcc@1  75.78 ( 78.25)\tAcc@5  94.53 ( 95.94)\n","Epoch: [87][240/391]\tTime  0.097 ( 0.070)\tLoss 8.3751e-01 (7.3762e-01)\tAcc@1  77.34 ( 78.10)\tAcc@5  93.75 ( 95.88)\n","Epoch: [87][270/391]\tTime  0.059 ( 0.069)\tLoss 6.7017e-01 (7.4227e-01)\tAcc@1  80.47 ( 77.95)\tAcc@5  96.88 ( 95.77)\n","Epoch: [87][300/391]\tTime  0.071 ( 0.069)\tLoss 8.2458e-01 (7.4628e-01)\tAcc@1  75.00 ( 77.88)\tAcc@5  95.31 ( 95.73)\n","Epoch: [87][330/391]\tTime  0.069 ( 0.069)\tLoss 7.5586e-01 (7.5273e-01)\tAcc@1  75.78 ( 77.62)\tAcc@5  97.66 ( 95.68)\n","Epoch: [87][360/391]\tTime  0.067 ( 0.069)\tLoss 8.2763e-01 (7.5375e-01)\tAcc@1  74.22 ( 77.55)\tAcc@5  95.31 ( 95.66)\n","Epoch: [87][390/391]\tTime  0.046 ( 0.069)\tLoss 6.0783e-01 (7.5784e-01)\tAcc@1  82.50 ( 77.35)\tAcc@5  96.25 ( 95.64)\n","==> Train Accuracy: Acc@1 77.350 || Acc@5 95.638\n","==> Test Accuracy:  Acc@1 70.240 || Acc@5 92.130\n","==> 29.00 seconds to train this epoch\n","\n","\n","----- epoch: 88, lr: 0.020000000000000004 -----\n","Epoch: [88][  0/391]\tTime  0.263 ( 0.263)\tLoss 6.0538e-01 (6.0538e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  97.66 ( 97.66)\n","Epoch: [88][ 30/391]\tTime  0.053 ( 0.077)\tLoss 6.9994e-01 (6.8629e-01)\tAcc@1  78.12 ( 79.64)\tAcc@5  96.09 ( 96.37)\n","Epoch: [88][ 60/391]\tTime  0.076 ( 0.076)\tLoss 6.6617e-01 (6.9934e-01)\tAcc@1  78.12 ( 79.19)\tAcc@5  96.88 ( 96.12)\n","Epoch: [88][ 90/391]\tTime  0.066 ( 0.075)\tLoss 7.3686e-01 (6.9776e-01)\tAcc@1  76.56 ( 79.05)\tAcc@5  97.66 ( 96.21)\n","Epoch: [88][120/391]\tTime  0.060 ( 0.074)\tLoss 7.5945e-01 (7.0272e-01)\tAcc@1  75.78 ( 78.88)\tAcc@5  97.66 ( 96.10)\n","Epoch: [88][150/391]\tTime  0.079 ( 0.073)\tLoss 8.3924e-01 (7.1603e-01)\tAcc@1  71.88 ( 78.60)\tAcc@5  94.53 ( 95.91)\n","Epoch: [88][180/391]\tTime  0.074 ( 0.073)\tLoss 8.5189e-01 (7.2825e-01)\tAcc@1  73.44 ( 78.18)\tAcc@5  93.75 ( 95.78)\n","Epoch: [88][210/391]\tTime  0.075 ( 0.072)\tLoss 6.3025e-01 (7.2896e-01)\tAcc@1  81.25 ( 78.07)\tAcc@5  96.88 ( 95.84)\n","Epoch: [88][240/391]\tTime  0.063 ( 0.072)\tLoss 6.1861e-01 (7.3074e-01)\tAcc@1  80.47 ( 78.06)\tAcc@5  97.66 ( 95.83)\n","Epoch: [88][270/391]\tTime  0.107 ( 0.072)\tLoss 8.0472e-01 (7.3886e-01)\tAcc@1  75.78 ( 77.83)\tAcc@5  92.97 ( 95.79)\n","Epoch: [88][300/391]\tTime  0.093 ( 0.072)\tLoss 8.0590e-01 (7.4049e-01)\tAcc@1  76.56 ( 77.87)\tAcc@5  94.53 ( 95.76)\n","Epoch: [88][330/391]\tTime  0.061 ( 0.072)\tLoss 7.8257e-01 (7.4563e-01)\tAcc@1  75.78 ( 77.71)\tAcc@5  95.31 ( 95.69)\n","Epoch: [88][360/391]\tTime  0.075 ( 0.072)\tLoss 9.5125e-01 (7.5045e-01)\tAcc@1  72.66 ( 77.59)\tAcc@5  93.75 ( 95.64)\n","Epoch: [88][390/391]\tTime  0.047 ( 0.072)\tLoss 7.1853e-01 (7.5488e-01)\tAcc@1  77.50 ( 77.44)\tAcc@5  97.50 ( 95.60)\n","==> Train Accuracy: Acc@1 77.438 || Acc@5 95.598\n","==> Test Accuracy:  Acc@1 71.610 || Acc@5 92.250\n","==> 30.44 seconds to train this epoch\n","\n","\n","----- epoch: 89, lr: 0.020000000000000004 -----\n","Epoch: [89][  0/391]\tTime  0.263 ( 0.263)\tLoss 6.7796e-01 (6.7796e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  96.88 ( 96.88)\n","Epoch: [89][ 30/391]\tTime  0.058 ( 0.078)\tLoss 8.2350e-01 (6.8041e-01)\tAcc@1  78.12 ( 79.79)\tAcc@5  96.09 ( 96.60)\n","Epoch: [89][ 60/391]\tTime  0.065 ( 0.075)\tLoss 8.6428e-01 (6.8393e-01)\tAcc@1  73.44 ( 79.73)\tAcc@5  93.75 ( 96.58)\n","Epoch: [89][ 90/391]\tTime  0.061 ( 0.074)\tLoss 7.8000e-01 (6.9291e-01)\tAcc@1  78.91 ( 79.45)\tAcc@5  94.53 ( 96.40)\n","Epoch: [89][120/391]\tTime  0.067 ( 0.073)\tLoss 7.3326e-01 (7.0569e-01)\tAcc@1  76.56 ( 79.15)\tAcc@5  97.66 ( 96.23)\n","Epoch: [89][150/391]\tTime  0.077 ( 0.073)\tLoss 8.7323e-01 (7.1102e-01)\tAcc@1  76.56 ( 78.82)\tAcc@5  94.53 ( 96.18)\n","Epoch: [89][180/391]\tTime  0.077 ( 0.072)\tLoss 8.2888e-01 (7.1831e-01)\tAcc@1  76.56 ( 78.56)\tAcc@5  94.53 ( 96.14)\n","Epoch: [89][210/391]\tTime  0.068 ( 0.072)\tLoss 7.5246e-01 (7.1858e-01)\tAcc@1  78.91 ( 78.63)\tAcc@5  97.66 ( 96.13)\n","Epoch: [89][240/391]\tTime  0.064 ( 0.072)\tLoss 6.0646e-01 (7.2406e-01)\tAcc@1  79.69 ( 78.42)\tAcc@5  98.44 ( 96.06)\n","Epoch: [89][270/391]\tTime  0.077 ( 0.071)\tLoss 8.5606e-01 (7.2769e-01)\tAcc@1  73.44 ( 78.25)\tAcc@5  94.53 ( 96.00)\n","Epoch: [89][300/391]\tTime  0.095 ( 0.071)\tLoss 7.4168e-01 (7.2841e-01)\tAcc@1  78.91 ( 78.27)\tAcc@5  96.09 ( 95.95)\n","Epoch: [89][330/391]\tTime  0.057 ( 0.071)\tLoss 6.8829e-01 (7.2730e-01)\tAcc@1  78.91 ( 78.31)\tAcc@5  96.88 ( 95.93)\n","Epoch: [89][360/391]\tTime  0.055 ( 0.071)\tLoss 9.2814e-01 (7.3342e-01)\tAcc@1  74.22 ( 78.10)\tAcc@5  92.19 ( 95.91)\n","Epoch: [89][390/391]\tTime  0.047 ( 0.071)\tLoss 8.7377e-01 (7.3985e-01)\tAcc@1  75.00 ( 77.89)\tAcc@5  91.25 ( 95.86)\n","==> Train Accuracy: Acc@1 77.888 || Acc@5 95.856\n","==> Test Accuracy:  Acc@1 69.820 || Acc@5 92.010\n","==> 29.73 seconds to train this epoch\n","\n","\n","----- epoch: 90, lr: 0.004000000000000001 -----\n","Epoch: [90][  0/391]\tTime  0.253 ( 0.253)\tLoss 7.0495e-01 (7.0495e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  95.31 ( 95.31)\n","Epoch: [90][ 30/391]\tTime  0.100 ( 0.076)\tLoss 6.0102e-01 (6.5184e-01)\tAcc@1  84.38 ( 80.75)\tAcc@5  96.09 ( 96.40)\n","Epoch: [90][ 60/391]\tTime  0.068 ( 0.072)\tLoss 5.3052e-01 (6.1069e-01)\tAcc@1  82.03 ( 81.97)\tAcc@5  96.09 ( 96.64)\n","Epoch: [90][ 90/391]\tTime  0.055 ( 0.072)\tLoss 4.9603e-01 (5.9382e-01)\tAcc@1  84.38 ( 82.52)\tAcc@5  97.66 ( 96.81)\n","Epoch: [90][120/391]\tTime  0.072 ( 0.071)\tLoss 5.6334e-01 (5.7720e-01)\tAcc@1  82.03 ( 82.83)\tAcc@5  97.66 ( 97.06)\n","Epoch: [90][150/391]\tTime  0.064 ( 0.071)\tLoss 4.3798e-01 (5.6148e-01)\tAcc@1  86.72 ( 83.21)\tAcc@5  96.88 ( 97.18)\n","Epoch: [90][180/391]\tTime  0.068 ( 0.071)\tLoss 5.6870e-01 (5.5126e-01)\tAcc@1  83.59 ( 83.54)\tAcc@5  98.44 ( 97.30)\n","Epoch: [90][210/391]\tTime  0.078 ( 0.071)\tLoss 5.3963e-01 (5.3982e-01)\tAcc@1  83.59 ( 83.85)\tAcc@5  97.66 ( 97.39)\n","Epoch: [90][240/391]\tTime  0.058 ( 0.071)\tLoss 3.1848e-01 (5.2737e-01)\tAcc@1  91.41 ( 84.29)\tAcc@5  99.22 ( 97.50)\n","Epoch: [90][270/391]\tTime  0.072 ( 0.071)\tLoss 4.4807e-01 (5.2126e-01)\tAcc@1  85.94 ( 84.51)\tAcc@5  99.22 ( 97.58)\n","Epoch: [90][300/391]\tTime  0.068 ( 0.071)\tLoss 4.0136e-01 (5.1459e-01)\tAcc@1  87.50 ( 84.73)\tAcc@5  97.66 ( 97.63)\n","Epoch: [90][330/391]\tTime  0.124 ( 0.071)\tLoss 4.2585e-01 (5.1179e-01)\tAcc@1  88.28 ( 84.82)\tAcc@5  98.44 ( 97.63)\n","Epoch: [90][360/391]\tTime  0.062 ( 0.071)\tLoss 5.7164e-01 (5.0852e-01)\tAcc@1  83.59 ( 84.93)\tAcc@5  95.31 ( 97.66)\n","Epoch: [90][390/391]\tTime  0.048 ( 0.070)\tLoss 4.4130e-01 (5.0440e-01)\tAcc@1  85.00 ( 85.10)\tAcc@5  98.75 ( 97.69)\n","==> Train Accuracy: Acc@1 85.096 || Acc@5 97.690\n","==> Test Accuracy:  Acc@1 77.110 || Acc@5 94.490\n","==> 29.63 seconds to train this epoch\n","\n","\n","----- epoch: 91, lr: 0.004000000000000001 -----\n","Epoch: [91][  0/391]\tTime  0.273 ( 0.273)\tLoss 5.0123e-01 (5.0123e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  97.66 ( 97.66)\n","Epoch: [91][ 30/391]\tTime  0.059 ( 0.077)\tLoss 3.7673e-01 (4.1916e-01)\tAcc@1  88.28 ( 87.73)\tAcc@5  98.44 ( 97.98)\n","Epoch: [91][ 60/391]\tTime  0.053 ( 0.073)\tLoss 3.8848e-01 (4.1345e-01)\tAcc@1  87.50 ( 87.77)\tAcc@5  97.66 ( 98.07)\n","Epoch: [91][ 90/391]\tTime  0.079 ( 0.071)\tLoss 5.3443e-01 (4.1695e-01)\tAcc@1  86.72 ( 87.91)\tAcc@5  96.88 ( 98.18)\n","Epoch: [91][120/391]\tTime  0.059 ( 0.071)\tLoss 4.0191e-01 (4.2575e-01)\tAcc@1  86.72 ( 87.72)\tAcc@5  98.44 ( 98.17)\n","Epoch: [91][150/391]\tTime  0.084 ( 0.071)\tLoss 5.4172e-01 (4.2032e-01)\tAcc@1  86.72 ( 87.97)\tAcc@5  95.31 ( 98.21)\n","Epoch: [91][180/391]\tTime  0.060 ( 0.071)\tLoss 3.5376e-01 (4.1997e-01)\tAcc@1  91.41 ( 87.95)\tAcc@5  99.22 ( 98.17)\n","Epoch: [91][210/391]\tTime  0.067 ( 0.071)\tLoss 5.0007e-01 (4.1780e-01)\tAcc@1  85.94 ( 88.00)\tAcc@5  96.88 ( 98.21)\n","Epoch: [91][240/391]\tTime  0.071 ( 0.070)\tLoss 6.0273e-01 (4.1872e-01)\tAcc@1  82.81 ( 88.00)\tAcc@5  94.53 ( 98.21)\n","Epoch: [91][270/391]\tTime  0.072 ( 0.070)\tLoss 2.7668e-01 (4.1982e-01)\tAcc@1  93.75 ( 87.92)\tAcc@5  98.44 ( 98.20)\n","Epoch: [91][300/391]\tTime  0.072 ( 0.071)\tLoss 3.8465e-01 (4.2027e-01)\tAcc@1  88.28 ( 87.88)\tAcc@5  97.66 ( 98.19)\n","Epoch: [91][330/391]\tTime  0.075 ( 0.070)\tLoss 4.4275e-01 (4.1983e-01)\tAcc@1  85.16 ( 87.90)\tAcc@5  99.22 ( 98.20)\n","Epoch: [91][360/391]\tTime  0.075 ( 0.070)\tLoss 4.4945e-01 (4.2267e-01)\tAcc@1  89.84 ( 87.82)\tAcc@5  96.09 ( 98.16)\n","Epoch: [91][390/391]\tTime  0.047 ( 0.070)\tLoss 4.7748e-01 (4.2159e-01)\tAcc@1  85.00 ( 87.80)\tAcc@5  98.75 ( 98.19)\n","==> Train Accuracy: Acc@1 87.802 || Acc@5 98.190\n","==> Test Accuracy:  Acc@1 76.860 || Acc@5 94.520\n","==> 29.53 seconds to train this epoch\n","\n","\n","----- epoch: 92, lr: 0.004000000000000001 -----\n","Epoch: [92][  0/391]\tTime  0.263 ( 0.263)\tLoss 5.4242e-01 (5.4242e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  99.22 ( 99.22)\n","Epoch: [92][ 30/391]\tTime  0.068 ( 0.075)\tLoss 4.0294e-01 (3.9842e-01)\tAcc@1  89.06 ( 87.85)\tAcc@5  97.66 ( 98.44)\n","Epoch: [92][ 60/391]\tTime  0.068 ( 0.073)\tLoss 2.6266e-01 (3.9401e-01)\tAcc@1  92.97 ( 88.01)\tAcc@5  99.22 ( 98.53)\n","Epoch: [92][ 90/391]\tTime  0.075 ( 0.073)\tLoss 4.4952e-01 (3.8971e-01)\tAcc@1  89.84 ( 88.39)\tAcc@5  96.09 ( 98.51)\n","Epoch: [92][120/391]\tTime  0.080 ( 0.072)\tLoss 3.2503e-01 (3.8781e-01)\tAcc@1  90.62 ( 88.45)\tAcc@5  98.44 ( 98.53)\n","Epoch: [92][150/391]\tTime  0.058 ( 0.071)\tLoss 3.4860e-01 (3.8756e-01)\tAcc@1  89.06 ( 88.48)\tAcc@5  98.44 ( 98.53)\n","Epoch: [92][180/391]\tTime  0.070 ( 0.071)\tLoss 2.6760e-01 (3.8774e-01)\tAcc@1  92.19 ( 88.57)\tAcc@5  98.44 ( 98.48)\n","Epoch: [92][210/391]\tTime  0.060 ( 0.071)\tLoss 4.0907e-01 (3.8709e-01)\tAcc@1  89.06 ( 88.62)\tAcc@5  98.44 ( 98.47)\n","Epoch: [92][240/391]\tTime  0.057 ( 0.071)\tLoss 3.9638e-01 (3.8730e-01)\tAcc@1  86.72 ( 88.61)\tAcc@5  98.44 ( 98.46)\n","Epoch: [92][270/391]\tTime  0.059 ( 0.071)\tLoss 3.3391e-01 (3.8608e-01)\tAcc@1  89.84 ( 88.61)\tAcc@5  98.44 ( 98.46)\n","Epoch: [92][300/391]\tTime  0.079 ( 0.071)\tLoss 3.7430e-01 (3.8430e-01)\tAcc@1  87.50 ( 88.65)\tAcc@5  98.44 ( 98.47)\n","Epoch: [92][330/391]\tTime  0.070 ( 0.071)\tLoss 4.0318e-01 (3.8441e-01)\tAcc@1  88.28 ( 88.67)\tAcc@5  97.66 ( 98.47)\n","Epoch: [92][360/391]\tTime  0.065 ( 0.071)\tLoss 4.4708e-01 (3.8481e-01)\tAcc@1  84.38 ( 88.66)\tAcc@5  98.44 ( 98.47)\n","Epoch: [92][390/391]\tTime  0.048 ( 0.071)\tLoss 3.5276e-01 (3.8589e-01)\tAcc@1  88.75 ( 88.62)\tAcc@5  98.75 ( 98.44)\n","==> Train Accuracy: Acc@1 88.624 || Acc@5 98.442\n","==> Test Accuracy:  Acc@1 77.330 || Acc@5 94.710\n","==> 29.74 seconds to train this epoch\n","\n","\n","----- epoch: 93, lr: 0.004000000000000001 -----\n","Epoch: [93][  0/391]\tTime  0.295 ( 0.295)\tLoss 4.0229e-01 (4.0229e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  98.44 ( 98.44)\n","Epoch: [93][ 30/391]\tTime  0.091 ( 0.077)\tLoss 3.0546e-01 (3.5084e-01)\tAcc@1  91.41 ( 89.82)\tAcc@5  99.22 ( 98.51)\n","Epoch: [93][ 60/391]\tTime  0.051 ( 0.072)\tLoss 4.7117e-01 (3.5538e-01)\tAcc@1  89.06 ( 89.77)\tAcc@5  96.09 ( 98.35)\n","Epoch: [93][ 90/391]\tTime  0.070 ( 0.072)\tLoss 3.3383e-01 (3.5216e-01)\tAcc@1  91.41 ( 89.78)\tAcc@5  98.44 ( 98.47)\n","Epoch: [93][120/391]\tTime  0.063 ( 0.071)\tLoss 3.4089e-01 (3.5583e-01)\tAcc@1  88.28 ( 89.62)\tAcc@5  99.22 ( 98.48)\n","Epoch: [93][150/391]\tTime  0.070 ( 0.070)\tLoss 3.7336e-01 (3.6222e-01)\tAcc@1  86.72 ( 89.33)\tAcc@5  98.44 ( 98.47)\n","Epoch: [93][180/391]\tTime  0.074 ( 0.070)\tLoss 4.3981e-01 (3.6150e-01)\tAcc@1  85.16 ( 89.42)\tAcc@5  99.22 ( 98.48)\n","Epoch: [93][210/391]\tTime  0.055 ( 0.070)\tLoss 3.3563e-01 (3.6342e-01)\tAcc@1  89.06 ( 89.28)\tAcc@5  99.22 ( 98.47)\n","Epoch: [93][240/391]\tTime  0.070 ( 0.070)\tLoss 3.7365e-01 (3.6277e-01)\tAcc@1  89.06 ( 89.33)\tAcc@5  99.22 ( 98.51)\n","Epoch: [93][270/391]\tTime  0.058 ( 0.070)\tLoss 3.3024e-01 (3.6333e-01)\tAcc@1  89.84 ( 89.28)\tAcc@5  98.44 ( 98.52)\n","Epoch: [93][300/391]\tTime  0.058 ( 0.070)\tLoss 4.7024e-01 (3.6366e-01)\tAcc@1  86.72 ( 89.32)\tAcc@5  97.66 ( 98.55)\n","Epoch: [93][330/391]\tTime  0.079 ( 0.070)\tLoss 4.2501e-01 (3.6373e-01)\tAcc@1  88.28 ( 89.31)\tAcc@5  97.66 ( 98.57)\n","Epoch: [93][360/391]\tTime  0.059 ( 0.070)\tLoss 4.3728e-01 (3.6370e-01)\tAcc@1  85.16 ( 89.31)\tAcc@5  98.44 ( 98.59)\n","Epoch: [93][390/391]\tTime  0.047 ( 0.070)\tLoss 3.9480e-01 (3.6271e-01)\tAcc@1  88.75 ( 89.33)\tAcc@5  97.50 ( 98.60)\n","==> Train Accuracy: Acc@1 89.328 || Acc@5 98.600\n","==> Test Accuracy:  Acc@1 77.270 || Acc@5 94.540\n","==> 29.54 seconds to train this epoch\n","\n","\n","----- epoch: 94, lr: 0.004000000000000001 -----\n","Epoch: [94][  0/391]\tTime  0.270 ( 0.270)\tLoss 3.4175e-01 (3.4175e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n","Epoch: [94][ 30/391]\tTime  0.071 ( 0.077)\tLoss 2.3896e-01 (3.1972e-01)\tAcc@1  93.75 ( 91.08)\tAcc@5  99.22 ( 98.87)\n","Epoch: [94][ 60/391]\tTime  0.067 ( 0.074)\tLoss 2.6642e-01 (3.2590e-01)\tAcc@1  93.75 ( 90.61)\tAcc@5  99.22 ( 98.73)\n","Epoch: [94][ 90/391]\tTime  0.063 ( 0.073)\tLoss 2.4771e-01 (3.3113e-01)\tAcc@1  92.19 ( 90.26)\tAcc@5  99.22 ( 98.68)\n","Epoch: [94][120/391]\tTime  0.073 ( 0.072)\tLoss 4.4605e-01 (3.3187e-01)\tAcc@1  85.16 ( 90.24)\tAcc@5  98.44 ( 98.70)\n","Epoch: [94][150/391]\tTime  0.047 ( 0.072)\tLoss 5.0052e-01 (3.3445e-01)\tAcc@1  84.38 ( 90.12)\tAcc@5 100.00 ( 98.73)\n","Epoch: [94][180/391]\tTime  0.054 ( 0.071)\tLoss 3.1128e-01 (3.4078e-01)\tAcc@1  90.62 ( 89.89)\tAcc@5  99.22 ( 98.70)\n","Epoch: [94][210/391]\tTime  0.057 ( 0.071)\tLoss 4.4482e-01 (3.4503e-01)\tAcc@1  88.28 ( 89.78)\tAcc@5  99.22 ( 98.68)\n","Epoch: [94][240/391]\tTime  0.052 ( 0.071)\tLoss 3.0393e-01 (3.4319e-01)\tAcc@1  89.84 ( 89.86)\tAcc@5  99.22 ( 98.71)\n","Epoch: [94][270/391]\tTime  0.064 ( 0.071)\tLoss 4.8070e-01 (3.4683e-01)\tAcc@1  83.59 ( 89.73)\tAcc@5  99.22 ( 98.69)\n","Epoch: [94][300/391]\tTime  0.060 ( 0.070)\tLoss 3.5634e-01 (3.4719e-01)\tAcc@1  89.84 ( 89.72)\tAcc@5  98.44 ( 98.71)\n","Epoch: [94][330/391]\tTime  0.053 ( 0.070)\tLoss 3.2210e-01 (3.4659e-01)\tAcc@1  89.84 ( 89.75)\tAcc@5  99.22 ( 98.73)\n","Epoch: [94][360/391]\tTime  0.066 ( 0.071)\tLoss 3.5970e-01 (3.4664e-01)\tAcc@1  89.06 ( 89.75)\tAcc@5  98.44 ( 98.72)\n","Epoch: [94][390/391]\tTime  0.047 ( 0.070)\tLoss 2.6636e-01 (3.4871e-01)\tAcc@1  92.50 ( 89.72)\tAcc@5  98.75 ( 98.71)\n","==> Train Accuracy: Acc@1 89.716 || Acc@5 98.708\n","==> Test Accuracy:  Acc@1 77.150 || Acc@5 94.530\n","==> 29.70 seconds to train this epoch\n","\n","\n","----- epoch: 95, lr: 0.004000000000000001 -----\n","Epoch: [95][  0/391]\tTime  0.256 ( 0.256)\tLoss 2.7928e-01 (2.7928e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5 100.00 (100.00)\n","Epoch: [95][ 30/391]\tTime  0.075 ( 0.075)\tLoss 2.0391e-01 (3.2497e-01)\tAcc@1  95.31 ( 90.42)\tAcc@5  99.22 ( 98.79)\n","Epoch: [95][ 60/391]\tTime  0.069 ( 0.072)\tLoss 4.6064e-01 (3.2866e-01)\tAcc@1  85.16 ( 90.46)\tAcc@5  98.44 ( 98.76)\n","Epoch: [95][ 90/391]\tTime  0.061 ( 0.071)\tLoss 3.7266e-01 (3.3446e-01)\tAcc@1  89.84 ( 90.14)\tAcc@5  98.44 ( 98.75)\n","Epoch: [95][120/391]\tTime  0.098 ( 0.072)\tLoss 2.9129e-01 (3.3281e-01)\tAcc@1  89.06 ( 90.20)\tAcc@5  98.44 ( 98.64)\n","Epoch: [95][150/391]\tTime  0.083 ( 0.071)\tLoss 3.5338e-01 (3.3322e-01)\tAcc@1  88.28 ( 90.10)\tAcc@5  97.66 ( 98.64)\n","Epoch: [95][180/391]\tTime  0.083 ( 0.071)\tLoss 2.7123e-01 (3.3192e-01)\tAcc@1  92.19 ( 90.06)\tAcc@5  99.22 ( 98.69)\n","Epoch: [95][210/391]\tTime  0.053 ( 0.071)\tLoss 3.2594e-01 (3.3166e-01)\tAcc@1  90.62 ( 90.07)\tAcc@5  97.66 ( 98.74)\n","Epoch: [95][240/391]\tTime  0.073 ( 0.071)\tLoss 4.0864e-01 (3.3498e-01)\tAcc@1  89.84 ( 89.99)\tAcc@5  97.66 ( 98.71)\n","Epoch: [95][270/391]\tTime  0.058 ( 0.070)\tLoss 2.1509e-01 (3.3437e-01)\tAcc@1  94.53 ( 90.03)\tAcc@5 100.00 ( 98.72)\n","Epoch: [95][300/391]\tTime  0.069 ( 0.071)\tLoss 3.7156e-01 (3.3478e-01)\tAcc@1  91.41 ( 90.09)\tAcc@5  98.44 ( 98.71)\n","Epoch: [95][330/391]\tTime  0.095 ( 0.071)\tLoss 2.3106e-01 (3.3343e-01)\tAcc@1  94.53 ( 90.12)\tAcc@5  99.22 ( 98.73)\n","Epoch: [95][360/391]\tTime  0.069 ( 0.071)\tLoss 3.3407e-01 (3.3520e-01)\tAcc@1  88.28 ( 90.09)\tAcc@5  99.22 ( 98.73)\n","Epoch: [95][390/391]\tTime  0.041 ( 0.071)\tLoss 4.8672e-01 (3.3505e-01)\tAcc@1  86.25 ( 90.08)\tAcc@5  97.50 ( 98.75)\n","==> Train Accuracy: Acc@1 90.078 || Acc@5 98.748\n","==> Test Accuracy:  Acc@1 76.860 || Acc@5 94.470\n","==> 29.78 seconds to train this epoch\n","\n","\n","----- epoch: 96, lr: 0.004000000000000001 -----\n","Epoch: [96][  0/391]\tTime  0.258 ( 0.258)\tLoss 2.4602e-01 (2.4602e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [96][ 30/391]\tTime  0.070 ( 0.076)\tLoss 4.1368e-01 (3.1724e-01)\tAcc@1  86.72 ( 90.95)\tAcc@5  98.44 ( 98.77)\n","Epoch: [96][ 60/391]\tTime  0.068 ( 0.074)\tLoss 3.1958e-01 (3.1568e-01)\tAcc@1  89.06 ( 90.73)\tAcc@5  98.44 ( 98.83)\n","Epoch: [96][ 90/391]\tTime  0.068 ( 0.073)\tLoss 1.9847e-01 (3.1661e-01)\tAcc@1  95.31 ( 90.64)\tAcc@5 100.00 ( 98.82)\n","Epoch: [96][120/391]\tTime  0.085 ( 0.072)\tLoss 4.1237e-01 (3.2126e-01)\tAcc@1  85.16 ( 90.41)\tAcc@5  97.66 ( 98.81)\n","Epoch: [96][150/391]\tTime  0.069 ( 0.071)\tLoss 2.4715e-01 (3.2155e-01)\tAcc@1  90.62 ( 90.46)\tAcc@5  99.22 ( 98.79)\n","Epoch: [96][180/391]\tTime  0.068 ( 0.071)\tLoss 2.9219e-01 (3.2109e-01)\tAcc@1  89.84 ( 90.47)\tAcc@5 100.00 ( 98.77)\n","Epoch: [96][210/391]\tTime  0.068 ( 0.071)\tLoss 3.1998e-01 (3.1930e-01)\tAcc@1  89.84 ( 90.51)\tAcc@5  99.22 ( 98.82)\n","Epoch: [96][240/391]\tTime  0.100 ( 0.071)\tLoss 3.0009e-01 (3.1968e-01)\tAcc@1  91.41 ( 90.53)\tAcc@5  99.22 ( 98.84)\n","Epoch: [96][270/391]\tTime  0.092 ( 0.071)\tLoss 2.8034e-01 (3.1925e-01)\tAcc@1  89.84 ( 90.54)\tAcc@5  99.22 ( 98.86)\n","Epoch: [96][300/391]\tTime  0.072 ( 0.071)\tLoss 2.7710e-01 (3.1835e-01)\tAcc@1  92.97 ( 90.56)\tAcc@5  97.66 ( 98.86)\n","Epoch: [96][330/391]\tTime  0.076 ( 0.071)\tLoss 3.1208e-01 (3.1903e-01)\tAcc@1  91.41 ( 90.52)\tAcc@5  99.22 ( 98.87)\n","Epoch: [96][360/391]\tTime  0.087 ( 0.071)\tLoss 3.6426e-01 (3.1993e-01)\tAcc@1  89.84 ( 90.53)\tAcc@5  99.22 ( 98.87)\n","Epoch: [96][390/391]\tTime  0.048 ( 0.070)\tLoss 2.5590e-01 (3.2124e-01)\tAcc@1  91.25 ( 90.53)\tAcc@5  98.75 ( 98.84)\n","==> Train Accuracy: Acc@1 90.534 || Acc@5 98.842\n","==> Test Accuracy:  Acc@1 77.150 || Acc@5 94.580\n","==> 29.68 seconds to train this epoch\n","\n","\n","----- epoch: 97, lr: 0.004000000000000001 -----\n","Epoch: [97][  0/391]\tTime  0.262 ( 0.262)\tLoss 2.9601e-01 (2.9601e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  98.44 ( 98.44)\n","Epoch: [97][ 30/391]\tTime  0.069 ( 0.076)\tLoss 2.1787e-01 (3.0710e-01)\tAcc@1  95.31 ( 91.26)\tAcc@5  98.44 ( 98.87)\n","Epoch: [97][ 60/391]\tTime  0.054 ( 0.073)\tLoss 3.2315e-01 (3.1207e-01)\tAcc@1  89.84 ( 91.07)\tAcc@5 100.00 ( 98.85)\n","Epoch: [97][ 90/391]\tTime  0.098 ( 0.072)\tLoss 4.0724e-01 (3.0353e-01)\tAcc@1  87.50 ( 91.28)\tAcc@5  96.09 ( 98.95)\n","Epoch: [97][120/391]\tTime  0.077 ( 0.072)\tLoss 4.0948e-01 (3.0715e-01)\tAcc@1  86.72 ( 91.17)\tAcc@5  97.66 ( 98.86)\n","Epoch: [97][150/391]\tTime  0.066 ( 0.072)\tLoss 3.9962e-01 (3.1135e-01)\tAcc@1  89.06 ( 91.01)\tAcc@5  98.44 ( 98.77)\n","Epoch: [97][180/391]\tTime  0.079 ( 0.071)\tLoss 3.7645e-01 (3.1067e-01)\tAcc@1  88.28 ( 91.06)\tAcc@5  96.09 ( 98.77)\n","Epoch: [97][210/391]\tTime  0.059 ( 0.071)\tLoss 2.3938e-01 (3.1376e-01)\tAcc@1  92.97 ( 90.88)\tAcc@5 100.00 ( 98.77)\n","Epoch: [97][240/391]\tTime  0.048 ( 0.071)\tLoss 3.9106e-01 (3.1283e-01)\tAcc@1  89.84 ( 90.91)\tAcc@5  98.44 ( 98.77)\n","Epoch: [97][270/391]\tTime  0.067 ( 0.071)\tLoss 2.7299e-01 (3.1138e-01)\tAcc@1  94.53 ( 90.93)\tAcc@5 100.00 ( 98.80)\n","Epoch: [97][300/391]\tTime  0.062 ( 0.071)\tLoss 2.4913e-01 (3.1239e-01)\tAcc@1  91.41 ( 90.88)\tAcc@5 100.00 ( 98.81)\n","Epoch: [97][330/391]\tTime  0.055 ( 0.071)\tLoss 2.7054e-01 (3.1240e-01)\tAcc@1  93.75 ( 90.86)\tAcc@5  99.22 ( 98.81)\n","Epoch: [97][360/391]\tTime  0.080 ( 0.071)\tLoss 3.4455e-01 (3.1129e-01)\tAcc@1  89.06 ( 90.89)\tAcc@5  99.22 ( 98.83)\n","Epoch: [97][390/391]\tTime  0.048 ( 0.071)\tLoss 3.3986e-01 (3.1238e-01)\tAcc@1  90.00 ( 90.85)\tAcc@5  98.75 ( 98.82)\n","==> Train Accuracy: Acc@1 90.850 || Acc@5 98.824\n","==> Test Accuracy:  Acc@1 77.180 || Acc@5 94.490\n","==> 29.84 seconds to train this epoch\n","\n","\n","----- epoch: 98, lr: 0.004000000000000001 -----\n","Epoch: [98][  0/391]\tTime  0.261 ( 0.261)\tLoss 4.4112e-01 (4.4112e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n","Epoch: [98][ 30/391]\tTime  0.068 ( 0.075)\tLoss 3.6639e-01 (2.9069e-01)\tAcc@1  91.41 ( 91.33)\tAcc@5  98.44 ( 99.02)\n","Epoch: [98][ 60/391]\tTime  0.075 ( 0.072)\tLoss 3.2343e-01 (2.9152e-01)\tAcc@1  89.06 ( 91.32)\tAcc@5  99.22 ( 99.01)\n","Epoch: [98][ 90/391]\tTime  0.059 ( 0.072)\tLoss 2.0291e-01 (2.9645e-01)\tAcc@1  92.97 ( 91.20)\tAcc@5 100.00 ( 98.97)\n","Epoch: [98][120/391]\tTime  0.072 ( 0.071)\tLoss 2.8010e-01 (2.9691e-01)\tAcc@1  91.41 ( 91.28)\tAcc@5  99.22 ( 98.97)\n","Epoch: [98][150/391]\tTime  0.093 ( 0.071)\tLoss 2.4128e-01 (2.9735e-01)\tAcc@1  93.75 ( 91.36)\tAcc@5 100.00 ( 98.94)\n","Epoch: [98][180/391]\tTime  0.085 ( 0.071)\tLoss 4.9926e-01 (2.9882e-01)\tAcc@1  85.94 ( 91.30)\tAcc@5  97.66 ( 98.92)\n","Epoch: [98][210/391]\tTime  0.085 ( 0.071)\tLoss 3.2753e-01 (2.9741e-01)\tAcc@1  89.06 ( 91.29)\tAcc@5  98.44 ( 98.94)\n","Epoch: [98][240/391]\tTime  0.069 ( 0.071)\tLoss 2.2761e-01 (2.9904e-01)\tAcc@1  92.19 ( 91.25)\tAcc@5  99.22 ( 98.92)\n","Epoch: [98][270/391]\tTime  0.053 ( 0.070)\tLoss 2.1991e-01 (2.9872e-01)\tAcc@1  93.75 ( 91.28)\tAcc@5 100.00 ( 98.94)\n","Epoch: [98][300/391]\tTime  0.072 ( 0.070)\tLoss 2.6909e-01 (2.9852e-01)\tAcc@1  91.41 ( 91.31)\tAcc@5  99.22 ( 98.94)\n","Epoch: [98][330/391]\tTime  0.074 ( 0.070)\tLoss 2.4394e-01 (2.9857e-01)\tAcc@1  94.53 ( 91.28)\tAcc@5  99.22 ( 98.95)\n","Epoch: [98][360/391]\tTime  0.072 ( 0.070)\tLoss 1.7293e-01 (2.9826e-01)\tAcc@1  96.09 ( 91.26)\tAcc@5 100.00 ( 98.97)\n","Epoch: [98][390/391]\tTime  0.047 ( 0.070)\tLoss 3.7817e-01 (2.9883e-01)\tAcc@1  85.00 ( 91.23)\tAcc@5 100.00 ( 98.98)\n","==> Train Accuracy: Acc@1 91.230 || Acc@5 98.980\n","==> Test Accuracy:  Acc@1 77.290 || Acc@5 94.590\n","==> 29.44 seconds to train this epoch\n","\n","\n","----- epoch: 99, lr: 0.004000000000000001 -----\n","Epoch: [99][  0/391]\tTime  0.253 ( 0.253)\tLoss 3.1342e-01 (3.1342e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [99][ 30/391]\tTime  0.060 ( 0.075)\tLoss 3.4620e-01 (2.9385e-01)\tAcc@1  89.84 ( 91.33)\tAcc@5  98.44 ( 98.89)\n","Epoch: [99][ 60/391]\tTime  0.048 ( 0.072)\tLoss 2.7647e-01 (2.9352e-01)\tAcc@1  92.19 ( 91.33)\tAcc@5  98.44 ( 98.95)\n","Epoch: [99][ 90/391]\tTime  0.106 ( 0.071)\tLoss 3.0632e-01 (2.9162e-01)\tAcc@1  89.84 ( 91.47)\tAcc@5  99.22 ( 98.86)\n","Epoch: [99][120/391]\tTime  0.068 ( 0.071)\tLoss 3.7836e-01 (2.9824e-01)\tAcc@1  89.06 ( 91.26)\tAcc@5  99.22 ( 98.81)\n","Epoch: [99][150/391]\tTime  0.076 ( 0.070)\tLoss 4.4946e-01 (2.9165e-01)\tAcc@1  83.59 ( 91.57)\tAcc@5  98.44 ( 98.86)\n","Epoch: [99][180/391]\tTime  0.065 ( 0.070)\tLoss 3.1299e-01 (2.9347e-01)\tAcc@1  91.41 ( 91.45)\tAcc@5  98.44 ( 98.84)\n","Epoch: [99][210/391]\tTime  0.073 ( 0.070)\tLoss 3.1903e-01 (2.9222e-01)\tAcc@1  92.97 ( 91.46)\tAcc@5  99.22 ( 98.87)\n","Epoch: [99][240/391]\tTime  0.057 ( 0.070)\tLoss 3.0733e-01 (2.9330e-01)\tAcc@1  90.62 ( 91.42)\tAcc@5 100.00 ( 98.89)\n","Epoch: [99][270/391]\tTime  0.054 ( 0.070)\tLoss 2.5144e-01 (2.9330e-01)\tAcc@1  91.41 ( 91.44)\tAcc@5 100.00 ( 98.89)\n","Epoch: [99][300/391]\tTime  0.093 ( 0.070)\tLoss 2.3011e-01 (2.9268e-01)\tAcc@1  92.97 ( 91.40)\tAcc@5  99.22 ( 98.90)\n","Epoch: [99][330/391]\tTime  0.086 ( 0.070)\tLoss 2.0069e-01 (2.9147e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5 100.00 ( 98.92)\n","Epoch: [99][360/391]\tTime  0.069 ( 0.070)\tLoss 3.1705e-01 (2.9258e-01)\tAcc@1  91.41 ( 91.36)\tAcc@5  99.22 ( 98.91)\n","Epoch: [99][390/391]\tTime  0.047 ( 0.070)\tLoss 2.7114e-01 (2.9272e-01)\tAcc@1  92.50 ( 91.33)\tAcc@5 100.00 ( 98.92)\n","==> Train Accuracy: Acc@1 91.328 || Acc@5 98.916\n","==> Test Accuracy:  Acc@1 77.000 || Acc@5 94.490\n","==> 29.48 seconds to train this epoch\n","\n","\n","----- epoch: 100, lr: 0.004000000000000001 -----\n","Epoch: [100][  0/391]\tTime  0.242 ( 0.242)\tLoss 1.8723e-01 (1.8723e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [100][ 30/391]\tTime  0.054 ( 0.075)\tLoss 2.4618e-01 (2.6193e-01)\tAcc@1  93.75 ( 92.46)\tAcc@5 100.00 ( 99.45)\n","Epoch: [100][ 60/391]\tTime  0.068 ( 0.073)\tLoss 3.1349e-01 (2.7257e-01)\tAcc@1  91.41 ( 92.21)\tAcc@5  97.66 ( 99.19)\n","Epoch: [100][ 90/391]\tTime  0.067 ( 0.071)\tLoss 1.7504e-01 (2.7875e-01)\tAcc@1  94.53 ( 91.96)\tAcc@5 100.00 ( 99.08)\n","Epoch: [100][120/391]\tTime  0.086 ( 0.071)\tLoss 2.7502e-01 (2.8429e-01)\tAcc@1  92.19 ( 91.79)\tAcc@5  98.44 ( 99.06)\n","Epoch: [100][150/391]\tTime  0.073 ( 0.071)\tLoss 3.8421e-01 (2.8549e-01)\tAcc@1  86.72 ( 91.77)\tAcc@5  98.44 ( 98.99)\n","Epoch: [100][180/391]\tTime  0.063 ( 0.071)\tLoss 2.9546e-01 (2.8364e-01)\tAcc@1  89.84 ( 91.85)\tAcc@5 100.00 ( 99.01)\n","Epoch: [100][210/391]\tTime  0.067 ( 0.070)\tLoss 3.7031e-01 (2.8594e-01)\tAcc@1  90.62 ( 91.78)\tAcc@5  96.88 ( 98.98)\n","Epoch: [100][240/391]\tTime  0.063 ( 0.070)\tLoss 4.1191e-01 (2.8574e-01)\tAcc@1  87.50 ( 91.78)\tAcc@5  98.44 ( 99.01)\n","Epoch: [100][270/391]\tTime  0.093 ( 0.070)\tLoss 3.7908e-01 (2.8750e-01)\tAcc@1  90.62 ( 91.67)\tAcc@5  96.88 ( 98.99)\n","Epoch: [100][300/391]\tTime  0.068 ( 0.070)\tLoss 2.3202e-01 (2.8692e-01)\tAcc@1  92.19 ( 91.67)\tAcc@5 100.00 ( 98.99)\n","Epoch: [100][330/391]\tTime  0.070 ( 0.070)\tLoss 4.1707e-01 (2.8623e-01)\tAcc@1  88.28 ( 91.70)\tAcc@5  98.44 ( 99.00)\n","Epoch: [100][360/391]\tTime  0.057 ( 0.070)\tLoss 2.5158e-01 (2.8680e-01)\tAcc@1  92.19 ( 91.69)\tAcc@5  99.22 ( 99.00)\n","Epoch: [100][390/391]\tTime  0.048 ( 0.070)\tLoss 1.9206e-01 (2.8619e-01)\tAcc@1  95.00 ( 91.67)\tAcc@5  98.75 ( 99.01)\n","==> Train Accuracy: Acc@1 91.674 || Acc@5 99.014\n","==> Test Accuracy:  Acc@1 77.240 || Acc@5 94.300\n","==> 29.42 seconds to train this epoch\n","\n","\n","----- epoch: 101, lr: 0.004000000000000001 -----\n","Epoch: [101][  0/391]\tTime  0.274 ( 0.274)\tLoss 2.4853e-01 (2.4853e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  97.66 ( 97.66)\n","Epoch: [101][ 30/391]\tTime  0.081 ( 0.074)\tLoss 2.2245e-01 (2.7720e-01)\tAcc@1  92.19 ( 92.34)\tAcc@5 100.00 ( 99.02)\n","Epoch: [101][ 60/391]\tTime  0.079 ( 0.072)\tLoss 2.1292e-01 (2.7840e-01)\tAcc@1  96.88 ( 92.15)\tAcc@5  98.44 ( 98.95)\n","Epoch: [101][ 90/391]\tTime  0.079 ( 0.071)\tLoss 2.6659e-01 (2.7739e-01)\tAcc@1  89.84 ( 91.99)\tAcc@5  99.22 ( 99.00)\n","Epoch: [101][120/391]\tTime  0.119 ( 0.070)\tLoss 3.6371e-01 (2.8065e-01)\tAcc@1  89.06 ( 91.96)\tAcc@5  98.44 ( 99.00)\n","Epoch: [101][150/391]\tTime  0.088 ( 0.070)\tLoss 2.9228e-01 (2.8171e-01)\tAcc@1  89.06 ( 91.93)\tAcc@5  98.44 ( 98.97)\n","Epoch: [101][180/391]\tTime  0.071 ( 0.070)\tLoss 2.1087e-01 (2.8025e-01)\tAcc@1  92.97 ( 91.92)\tAcc@5 100.00 ( 98.99)\n","Epoch: [101][210/391]\tTime  0.053 ( 0.070)\tLoss 3.3929e-01 (2.7998e-01)\tAcc@1  90.62 ( 91.95)\tAcc@5 100.00 ( 99.03)\n","Epoch: [101][240/391]\tTime  0.063 ( 0.070)\tLoss 3.3143e-01 (2.8106e-01)\tAcc@1  90.62 ( 91.92)\tAcc@5  97.66 ( 99.01)\n","Epoch: [101][270/391]\tTime  0.061 ( 0.070)\tLoss 2.6997e-01 (2.8252e-01)\tAcc@1  94.53 ( 91.87)\tAcc@5  98.44 ( 98.99)\n","Epoch: [101][300/391]\tTime  0.057 ( 0.070)\tLoss 2.9159e-01 (2.8359e-01)\tAcc@1  92.19 ( 91.82)\tAcc@5  98.44 ( 99.00)\n","Epoch: [101][330/391]\tTime  0.065 ( 0.070)\tLoss 3.6840e-01 (2.8185e-01)\tAcc@1  86.72 ( 91.85)\tAcc@5  98.44 ( 99.01)\n","Epoch: [101][360/391]\tTime  0.062 ( 0.070)\tLoss 3.5959e-01 (2.8322e-01)\tAcc@1  89.84 ( 91.82)\tAcc@5  98.44 ( 99.00)\n","Epoch: [101][390/391]\tTime  0.047 ( 0.070)\tLoss 2.3112e-01 (2.8369e-01)\tAcc@1  92.50 ( 91.77)\tAcc@5 100.00 ( 99.00)\n","==> Train Accuracy: Acc@1 91.774 || Acc@5 99.002\n","==> Test Accuracy:  Acc@1 77.140 || Acc@5 94.250\n","==> 29.43 seconds to train this epoch\n","\n","\n","----- epoch: 102, lr: 0.004000000000000001 -----\n","Epoch: [102][  0/391]\tTime  0.259 ( 0.259)\tLoss 3.4275e-01 (3.4275e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5  97.66 ( 97.66)\n","Epoch: [102][ 30/391]\tTime  0.065 ( 0.075)\tLoss 2.0054e-01 (2.7595e-01)\tAcc@1  92.97 ( 92.21)\tAcc@5 100.00 ( 99.02)\n","Epoch: [102][ 60/391]\tTime  0.060 ( 0.072)\tLoss 2.1322e-01 (2.7237e-01)\tAcc@1  92.97 ( 92.00)\tAcc@5 100.00 ( 99.12)\n","Epoch: [102][ 90/391]\tTime  0.059 ( 0.071)\tLoss 2.0992e-01 (2.7357e-01)\tAcc@1  92.97 ( 91.88)\tAcc@5  99.22 ( 99.02)\n","Epoch: [102][120/391]\tTime  0.093 ( 0.071)\tLoss 3.4465e-01 (2.7809e-01)\tAcc@1  90.62 ( 91.85)\tAcc@5  98.44 ( 98.99)\n","Epoch: [102][150/391]\tTime  0.087 ( 0.071)\tLoss 3.0503e-01 (2.8163e-01)\tAcc@1  89.06 ( 91.71)\tAcc@5  99.22 ( 98.98)\n","Epoch: [102][180/391]\tTime  0.091 ( 0.070)\tLoss 4.6206e-01 (2.8098e-01)\tAcc@1  84.38 ( 91.77)\tAcc@5  98.44 ( 98.99)\n","Epoch: [102][210/391]\tTime  0.073 ( 0.070)\tLoss 2.7971e-01 (2.8007e-01)\tAcc@1  92.97 ( 91.88)\tAcc@5 100.00 ( 99.03)\n","Epoch: [102][240/391]\tTime  0.071 ( 0.070)\tLoss 2.4478e-01 (2.7929e-01)\tAcc@1  89.84 ( 91.85)\tAcc@5 100.00 ( 99.03)\n","Epoch: [102][270/391]\tTime  0.052 ( 0.070)\tLoss 3.5304e-01 (2.8113e-01)\tAcc@1  91.41 ( 91.76)\tAcc@5  97.66 ( 99.03)\n","Epoch: [102][300/391]\tTime  0.063 ( 0.070)\tLoss 2.1782e-01 (2.7865e-01)\tAcc@1  95.31 ( 91.83)\tAcc@5  99.22 ( 99.05)\n","Epoch: [102][330/391]\tTime  0.094 ( 0.070)\tLoss 2.5721e-01 (2.8021e-01)\tAcc@1  92.97 ( 91.79)\tAcc@5  97.66 ( 99.04)\n","Epoch: [102][360/391]\tTime  0.080 ( 0.070)\tLoss 2.5951e-01 (2.8062e-01)\tAcc@1  92.19 ( 91.78)\tAcc@5  98.44 ( 99.03)\n","Epoch: [102][390/391]\tTime  0.047 ( 0.070)\tLoss 3.5983e-01 (2.8136e-01)\tAcc@1  87.50 ( 91.74)\tAcc@5  98.75 ( 99.00)\n","==> Train Accuracy: Acc@1 91.740 || Acc@5 99.002\n","==> Test Accuracy:  Acc@1 77.160 || Acc@5 94.350\n","==> 29.56 seconds to train this epoch\n","\n","\n","----- epoch: 103, lr: 0.004000000000000001 -----\n","Epoch: [103][  0/391]\tTime  0.276 ( 0.276)\tLoss 2.2524e-01 (2.2524e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n","Epoch: [103][ 30/391]\tTime  0.061 ( 0.075)\tLoss 2.3122e-01 (2.5095e-01)\tAcc@1  91.41 ( 92.64)\tAcc@5 100.00 ( 99.17)\n","Epoch: [103][ 60/391]\tTime  0.063 ( 0.072)\tLoss 2.3531e-01 (2.5153e-01)\tAcc@1  91.41 ( 92.60)\tAcc@5  99.22 ( 99.05)\n","Epoch: [103][ 90/391]\tTime  0.085 ( 0.071)\tLoss 1.3241e-01 (2.4838e-01)\tAcc@1  96.88 ( 92.81)\tAcc@5 100.00 ( 99.05)\n","Epoch: [103][120/391]\tTime  0.091 ( 0.070)\tLoss 3.2272e-01 (2.5117e-01)\tAcc@1  91.41 ( 92.74)\tAcc@5  97.66 ( 99.09)\n","Epoch: [103][150/391]\tTime  0.065 ( 0.070)\tLoss 2.3703e-01 (2.5396e-01)\tAcc@1  92.19 ( 92.69)\tAcc@5 100.00 ( 99.12)\n","Epoch: [103][180/391]\tTime  0.073 ( 0.070)\tLoss 2.9008e-01 (2.5702e-01)\tAcc@1  92.19 ( 92.61)\tAcc@5  99.22 ( 99.10)\n","Epoch: [103][210/391]\tTime  0.068 ( 0.070)\tLoss 2.4358e-01 (2.6030e-01)\tAcc@1  91.41 ( 92.46)\tAcc@5 100.00 ( 99.08)\n","Epoch: [103][240/391]\tTime  0.061 ( 0.070)\tLoss 1.9716e-01 (2.6395e-01)\tAcc@1  94.53 ( 92.36)\tAcc@5  99.22 ( 99.05)\n","Epoch: [103][270/391]\tTime  0.054 ( 0.070)\tLoss 3.6129e-01 (2.6698e-01)\tAcc@1  89.06 ( 92.25)\tAcc@5 100.00 ( 99.04)\n","Epoch: [103][300/391]\tTime  0.074 ( 0.070)\tLoss 1.3157e-01 (2.6754e-01)\tAcc@1  96.88 ( 92.27)\tAcc@5 100.00 ( 99.03)\n","Epoch: [103][330/391]\tTime  0.085 ( 0.070)\tLoss 3.1521e-01 (2.6831e-01)\tAcc@1  88.28 ( 92.24)\tAcc@5  99.22 ( 99.04)\n","Epoch: [103][360/391]\tTime  0.060 ( 0.070)\tLoss 3.7209e-01 (2.7062e-01)\tAcc@1  86.72 ( 92.16)\tAcc@5  99.22 ( 99.02)\n","Epoch: [103][390/391]\tTime  0.048 ( 0.070)\tLoss 2.3176e-01 (2.7233e-01)\tAcc@1  91.25 ( 92.09)\tAcc@5 100.00 ( 99.02)\n","==> Train Accuracy: Acc@1 92.086 || Acc@5 99.022\n","==> Test Accuracy:  Acc@1 77.250 || Acc@5 94.520\n","==> 29.35 seconds to train this epoch\n","\n","\n","----- epoch: 104, lr: 0.004000000000000001 -----\n","Epoch: [104][  0/391]\tTime  0.252 ( 0.252)\tLoss 2.9010e-01 (2.9010e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n","Epoch: [104][ 30/391]\tTime  0.096 ( 0.075)\tLoss 3.2203e-01 (2.5131e-01)\tAcc@1  89.84 ( 92.59)\tAcc@5  98.44 ( 99.17)\n","Epoch: [104][ 60/391]\tTime  0.068 ( 0.073)\tLoss 2.0003e-01 (2.6618e-01)\tAcc@1  92.97 ( 92.03)\tAcc@5 100.00 ( 99.15)\n","Epoch: [104][ 90/391]\tTime  0.058 ( 0.072)\tLoss 1.7671e-01 (2.5912e-01)\tAcc@1  93.75 ( 92.24)\tAcc@5 100.00 ( 99.26)\n","Epoch: [104][120/391]\tTime  0.079 ( 0.071)\tLoss 2.0354e-01 (2.6144e-01)\tAcc@1  91.41 ( 92.24)\tAcc@5 100.00 ( 99.26)\n","Epoch: [104][150/391]\tTime  0.092 ( 0.071)\tLoss 2.0394e-01 (2.6213e-01)\tAcc@1  94.53 ( 92.28)\tAcc@5  99.22 ( 99.25)\n","Epoch: [104][180/391]\tTime  0.061 ( 0.071)\tLoss 1.9294e-01 (2.5965e-01)\tAcc@1  92.97 ( 92.40)\tAcc@5 100.00 ( 99.22)\n","Epoch: [104][210/391]\tTime  0.075 ( 0.070)\tLoss 2.6041e-01 (2.5898e-01)\tAcc@1  92.19 ( 92.41)\tAcc@5 100.00 ( 99.22)\n","Epoch: [104][240/391]\tTime  0.059 ( 0.070)\tLoss 3.0882e-01 (2.6139e-01)\tAcc@1  92.97 ( 92.36)\tAcc@5  98.44 ( 99.21)\n","Epoch: [104][270/391]\tTime  0.081 ( 0.070)\tLoss 3.5443e-01 (2.6182e-01)\tAcc@1  90.62 ( 92.35)\tAcc@5  96.88 ( 99.18)\n","Epoch: [104][300/391]\tTime  0.058 ( 0.070)\tLoss 2.1152e-01 (2.6360e-01)\tAcc@1  92.19 ( 92.26)\tAcc@5 100.00 ( 99.17)\n","Epoch: [104][330/391]\tTime  0.097 ( 0.070)\tLoss 1.4564e-01 (2.6524e-01)\tAcc@1  94.53 ( 92.23)\tAcc@5 100.00 ( 99.16)\n","Epoch: [104][360/391]\tTime  0.068 ( 0.070)\tLoss 2.0234e-01 (2.6640e-01)\tAcc@1  93.75 ( 92.20)\tAcc@5 100.00 ( 99.14)\n","Epoch: [104][390/391]\tTime  0.047 ( 0.070)\tLoss 3.0371e-01 (2.6755e-01)\tAcc@1  95.00 ( 92.16)\tAcc@5  98.75 ( 99.15)\n","==> Train Accuracy: Acc@1 92.158 || Acc@5 99.148\n","==> Test Accuracy:  Acc@1 77.270 || Acc@5 94.420\n","==> 29.50 seconds to train this epoch\n","\n","\n","----- epoch: 105, lr: 0.004000000000000001 -----\n","Epoch: [105][  0/391]\tTime  0.265 ( 0.265)\tLoss 2.6808e-01 (2.6808e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n","Epoch: [105][ 30/391]\tTime  0.063 ( 0.076)\tLoss 1.7982e-01 (2.4325e-01)\tAcc@1  93.75 ( 92.84)\tAcc@5 100.00 ( 99.22)\n","Epoch: [105][ 60/391]\tTime  0.074 ( 0.073)\tLoss 2.4734e-01 (2.5523e-01)\tAcc@1  92.19 ( 92.52)\tAcc@5  99.22 ( 99.10)\n","Epoch: [105][ 90/391]\tTime  0.066 ( 0.071)\tLoss 2.9380e-01 (2.5428e-01)\tAcc@1  91.41 ( 92.44)\tAcc@5  98.44 ( 99.14)\n","Epoch: [105][120/391]\tTime  0.062 ( 0.071)\tLoss 1.8172e-01 (2.5442e-01)\tAcc@1  93.75 ( 92.47)\tAcc@5  99.22 ( 99.13)\n","Epoch: [105][150/391]\tTime  0.067 ( 0.070)\tLoss 2.3591e-01 (2.5599e-01)\tAcc@1  90.62 ( 92.39)\tAcc@5  98.44 ( 99.09)\n","Epoch: [105][180/391]\tTime  0.066 ( 0.070)\tLoss 1.4486e-01 (2.5403e-01)\tAcc@1  96.88 ( 92.48)\tAcc@5 100.00 ( 99.14)\n","Epoch: [105][210/391]\tTime  0.050 ( 0.070)\tLoss 2.0956e-01 (2.5653e-01)\tAcc@1  95.31 ( 92.39)\tAcc@5 100.00 ( 99.10)\n","Epoch: [105][240/391]\tTime  0.108 ( 0.070)\tLoss 2.8129e-01 (2.5939e-01)\tAcc@1  89.84 ( 92.32)\tAcc@5 100.00 ( 99.09)\n","Epoch: [105][270/391]\tTime  0.063 ( 0.070)\tLoss 2.4235e-01 (2.6128e-01)\tAcc@1  91.41 ( 92.29)\tAcc@5  99.22 ( 99.09)\n","Epoch: [105][300/391]\tTime  0.071 ( 0.070)\tLoss 2.2482e-01 (2.6275e-01)\tAcc@1  92.97 ( 92.25)\tAcc@5  99.22 ( 99.08)\n","Epoch: [105][330/391]\tTime  0.048 ( 0.070)\tLoss 3.1051e-01 (2.6338e-01)\tAcc@1  92.19 ( 92.23)\tAcc@5  98.44 ( 99.08)\n","Epoch: [105][360/391]\tTime  0.078 ( 0.070)\tLoss 3.9170e-01 (2.6389e-01)\tAcc@1  87.50 ( 92.20)\tAcc@5  99.22 ( 99.08)\n","Epoch: [105][390/391]\tTime  0.047 ( 0.070)\tLoss 1.6775e-01 (2.6335e-01)\tAcc@1  93.75 ( 92.22)\tAcc@5 100.00 ( 99.09)\n","==> Train Accuracy: Acc@1 92.224 || Acc@5 99.094\n","==> Test Accuracy:  Acc@1 76.990 || Acc@5 94.280\n","==> 29.39 seconds to train this epoch\n","\n","\n","----- epoch: 106, lr: 0.004000000000000001 -----\n","Epoch: [106][  0/391]\tTime  0.271 ( 0.271)\tLoss 3.2656e-01 (3.2656e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  99.22 ( 99.22)\n","Epoch: [106][ 30/391]\tTime  0.068 ( 0.076)\tLoss 2.8566e-01 (2.7322e-01)\tAcc@1  94.53 ( 92.06)\tAcc@5  97.66 ( 98.99)\n","Epoch: [106][ 60/391]\tTime  0.068 ( 0.074)\tLoss 1.6109e-01 (2.6757e-01)\tAcc@1  96.88 ( 92.39)\tAcc@5 100.00 ( 99.12)\n","Epoch: [106][ 90/391]\tTime  0.066 ( 0.072)\tLoss 2.0771e-01 (2.6012e-01)\tAcc@1  96.09 ( 92.74)\tAcc@5 100.00 ( 99.11)\n","Epoch: [106][120/391]\tTime  0.070 ( 0.072)\tLoss 3.7150e-01 (2.5631e-01)\tAcc@1  88.28 ( 92.82)\tAcc@5  96.88 ( 99.10)\n","Epoch: [106][150/391]\tTime  0.062 ( 0.071)\tLoss 2.9786e-01 (2.5656e-01)\tAcc@1  91.41 ( 92.67)\tAcc@5  99.22 ( 99.12)\n","Epoch: [106][180/391]\tTime  0.062 ( 0.071)\tLoss 1.6073e-01 (2.5591e-01)\tAcc@1  92.97 ( 92.68)\tAcc@5 100.00 ( 99.13)\n","Epoch: [106][210/391]\tTime  0.058 ( 0.071)\tLoss 2.6388e-01 (2.5587e-01)\tAcc@1  91.41 ( 92.71)\tAcc@5 100.00 ( 99.16)\n","Epoch: [106][240/391]\tTime  0.063 ( 0.070)\tLoss 2.3743e-01 (2.5740e-01)\tAcc@1  91.41 ( 92.63)\tAcc@5  99.22 ( 99.13)\n","Epoch: [106][270/391]\tTime  0.050 ( 0.070)\tLoss 2.2123e-01 (2.5719e-01)\tAcc@1  92.19 ( 92.65)\tAcc@5  99.22 ( 99.12)\n","Epoch: [106][300/391]\tTime  0.069 ( 0.070)\tLoss 1.9823e-01 (2.5854e-01)\tAcc@1  94.53 ( 92.60)\tAcc@5  99.22 ( 99.11)\n","Epoch: [106][330/391]\tTime  0.057 ( 0.070)\tLoss 2.5522e-01 (2.5976e-01)\tAcc@1  92.19 ( 92.54)\tAcc@5  99.22 ( 99.10)\n","Epoch: [106][360/391]\tTime  0.069 ( 0.070)\tLoss 3.0707e-01 (2.6063e-01)\tAcc@1  91.41 ( 92.48)\tAcc@5  98.44 ( 99.10)\n","Epoch: [106][390/391]\tTime  0.047 ( 0.070)\tLoss 2.6085e-01 (2.6101e-01)\tAcc@1  90.00 ( 92.46)\tAcc@5  98.75 ( 99.09)\n","==> Train Accuracy: Acc@1 92.458 || Acc@5 99.094\n","==> Test Accuracy:  Acc@1 76.830 || Acc@5 94.230\n","==> 29.38 seconds to train this epoch\n","\n","\n","----- epoch: 107, lr: 0.004000000000000001 -----\n","Epoch: [107][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.8234e-01 (1.8234e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [107][ 30/391]\tTime  0.059 ( 0.075)\tLoss 2.9835e-01 (2.4888e-01)\tAcc@1  89.84 ( 92.74)\tAcc@5  98.44 ( 98.92)\n","Epoch: [107][ 60/391]\tTime  0.092 ( 0.073)\tLoss 2.7316e-01 (2.4811e-01)\tAcc@1  90.62 ( 92.56)\tAcc@5 100.00 ( 99.19)\n","Epoch: [107][ 90/391]\tTime  0.076 ( 0.072)\tLoss 3.3286e-01 (2.5036e-01)\tAcc@1  89.06 ( 92.47)\tAcc@5 100.00 ( 99.18)\n","Epoch: [107][120/391]\tTime  0.059 ( 0.071)\tLoss 2.6179e-01 (2.5344e-01)\tAcc@1  92.97 ( 92.38)\tAcc@5 100.00 ( 99.13)\n","Epoch: [107][150/391]\tTime  0.075 ( 0.071)\tLoss 2.0297e-01 (2.6095e-01)\tAcc@1  93.75 ( 92.35)\tAcc@5 100.00 ( 99.05)\n","Epoch: [107][180/391]\tTime  0.066 ( 0.071)\tLoss 1.9868e-01 (2.5935e-01)\tAcc@1  94.53 ( 92.45)\tAcc@5  99.22 ( 99.09)\n","Epoch: [107][210/391]\tTime  0.090 ( 0.071)\tLoss 1.6285e-01 (2.5784e-01)\tAcc@1  95.31 ( 92.48)\tAcc@5 100.00 ( 99.09)\n","Epoch: [107][240/391]\tTime  0.068 ( 0.071)\tLoss 3.5603e-01 (2.5965e-01)\tAcc@1  85.94 ( 92.40)\tAcc@5  99.22 ( 99.06)\n","Epoch: [107][270/391]\tTime  0.078 ( 0.070)\tLoss 2.7106e-01 (2.6084e-01)\tAcc@1  91.41 ( 92.37)\tAcc@5  99.22 ( 99.06)\n","Epoch: [107][300/391]\tTime  0.080 ( 0.070)\tLoss 2.8938e-01 (2.6054e-01)\tAcc@1  92.97 ( 92.37)\tAcc@5  97.66 ( 99.06)\n","Epoch: [107][330/391]\tTime  0.065 ( 0.070)\tLoss 2.8154e-01 (2.6225e-01)\tAcc@1  91.41 ( 92.31)\tAcc@5  98.44 ( 99.04)\n","Epoch: [107][360/391]\tTime  0.057 ( 0.070)\tLoss 3.9401e-01 (2.6413e-01)\tAcc@1  87.50 ( 92.23)\tAcc@5  97.66 ( 99.02)\n","Epoch: [107][390/391]\tTime  0.048 ( 0.070)\tLoss 3.3737e-01 (2.6374e-01)\tAcc@1  86.25 ( 92.25)\tAcc@5 100.00 ( 99.02)\n","==> Train Accuracy: Acc@1 92.254 || Acc@5 99.022\n","==> Test Accuracy:  Acc@1 76.860 || Acc@5 94.130\n","==> 29.35 seconds to train this epoch\n","\n","\n","----- epoch: 108, lr: 0.004000000000000001 -----\n","Epoch: [108][  0/391]\tTime  0.259 ( 0.259)\tLoss 2.9507e-01 (2.9507e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  99.22 ( 99.22)\n","Epoch: [108][ 30/391]\tTime  0.063 ( 0.075)\tLoss 2.3569e-01 (2.4173e-01)\tAcc@1  92.97 ( 93.32)\tAcc@5  98.44 ( 99.02)\n","Epoch: [108][ 60/391]\tTime  0.050 ( 0.072)\tLoss 2.4598e-01 (2.4963e-01)\tAcc@1  95.31 ( 92.70)\tAcc@5  98.44 ( 99.21)\n","Epoch: [108][ 90/391]\tTime  0.061 ( 0.071)\tLoss 2.1010e-01 (2.4472e-01)\tAcc@1  94.53 ( 92.85)\tAcc@5 100.00 ( 99.17)\n","Epoch: [108][120/391]\tTime  0.049 ( 0.071)\tLoss 2.2698e-01 (2.5201e-01)\tAcc@1  95.31 ( 92.70)\tAcc@5  98.44 ( 99.13)\n","Epoch: [108][150/391]\tTime  0.091 ( 0.071)\tLoss 1.9616e-01 (2.5039e-01)\tAcc@1  97.66 ( 92.69)\tAcc@5 100.00 ( 99.18)\n","Epoch: [108][180/391]\tTime  0.077 ( 0.071)\tLoss 2.2439e-01 (2.4854e-01)\tAcc@1  93.75 ( 92.71)\tAcc@5  99.22 ( 99.17)\n","Epoch: [108][210/391]\tTime  0.042 ( 0.071)\tLoss 1.7918e-01 (2.4779e-01)\tAcc@1  92.97 ( 92.70)\tAcc@5 100.00 ( 99.17)\n","Epoch: [108][240/391]\tTime  0.082 ( 0.071)\tLoss 2.9575e-01 (2.4833e-01)\tAcc@1  91.41 ( 92.71)\tAcc@5  96.88 ( 99.17)\n","Epoch: [108][270/391]\tTime  0.062 ( 0.071)\tLoss 2.1616e-01 (2.5084e-01)\tAcc@1  95.31 ( 92.65)\tAcc@5  99.22 ( 99.14)\n","Epoch: [108][300/391]\tTime  0.056 ( 0.071)\tLoss 2.8768e-01 (2.5049e-01)\tAcc@1  91.41 ( 92.63)\tAcc@5  98.44 ( 99.16)\n","Epoch: [108][330/391]\tTime  0.074 ( 0.070)\tLoss 3.0433e-01 (2.5088e-01)\tAcc@1  89.84 ( 92.64)\tAcc@5  99.22 ( 99.16)\n","Epoch: [108][360/391]\tTime  0.085 ( 0.071)\tLoss 2.5493e-01 (2.5164e-01)\tAcc@1  90.62 ( 92.60)\tAcc@5 100.00 ( 99.17)\n","Epoch: [108][390/391]\tTime  0.048 ( 0.070)\tLoss 1.7496e-01 (2.5112e-01)\tAcc@1  95.00 ( 92.61)\tAcc@5 100.00 ( 99.18)\n","==> Train Accuracy: Acc@1 92.608 || Acc@5 99.182\n","==> Test Accuracy:  Acc@1 77.000 || Acc@5 94.060\n","==> 29.67 seconds to train this epoch\n","\n","\n","----- epoch: 109, lr: 0.004000000000000001 -----\n","Epoch: [109][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.9219e-01 (1.9219e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n","Epoch: [109][ 30/391]\tTime  0.061 ( 0.075)\tLoss 1.7367e-01 (2.2789e-01)\tAcc@1  92.97 ( 93.17)\tAcc@5  99.22 ( 99.19)\n","Epoch: [109][ 60/391]\tTime  0.070 ( 0.073)\tLoss 2.3466e-01 (2.2886e-01)\tAcc@1  92.97 ( 93.39)\tAcc@5  98.44 ( 99.07)\n","Epoch: [109][ 90/391]\tTime  0.073 ( 0.072)\tLoss 2.1192e-01 (2.2524e-01)\tAcc@1  95.31 ( 93.42)\tAcc@5 100.00 ( 99.14)\n","Epoch: [109][120/391]\tTime  0.070 ( 0.071)\tLoss 2.1030e-01 (2.3577e-01)\tAcc@1  93.75 ( 93.02)\tAcc@5  99.22 ( 99.16)\n","Epoch: [109][150/391]\tTime  0.061 ( 0.071)\tLoss 2.1214e-01 (2.3455e-01)\tAcc@1  92.19 ( 93.18)\tAcc@5 100.00 ( 99.16)\n","Epoch: [109][180/391]\tTime  0.091 ( 0.071)\tLoss 3.1769e-01 (2.3525e-01)\tAcc@1  90.62 ( 93.10)\tAcc@5  99.22 ( 99.19)\n","Epoch: [109][210/391]\tTime  0.069 ( 0.071)\tLoss 2.0951e-01 (2.3484e-01)\tAcc@1  93.75 ( 93.09)\tAcc@5 100.00 ( 99.22)\n","Epoch: [109][240/391]\tTime  0.069 ( 0.071)\tLoss 2.0030e-01 (2.3586e-01)\tAcc@1  95.31 ( 93.08)\tAcc@5  99.22 ( 99.22)\n","Epoch: [109][270/391]\tTime  0.063 ( 0.070)\tLoss 3.2347e-01 (2.3888e-01)\tAcc@1  89.84 ( 92.99)\tAcc@5  98.44 ( 99.18)\n","Epoch: [109][300/391]\tTime  0.072 ( 0.070)\tLoss 1.7088e-01 (2.4089e-01)\tAcc@1  95.31 ( 92.95)\tAcc@5  99.22 ( 99.16)\n","Epoch: [109][330/391]\tTime  0.053 ( 0.070)\tLoss 2.8904e-01 (2.4533e-01)\tAcc@1  89.84 ( 92.83)\tAcc@5  99.22 ( 99.14)\n","Epoch: [109][360/391]\tTime  0.085 ( 0.070)\tLoss 2.8983e-01 (2.4675e-01)\tAcc@1  88.28 ( 92.80)\tAcc@5  98.44 ( 99.15)\n","Epoch: [109][390/391]\tTime  0.048 ( 0.070)\tLoss 1.6475e-01 (2.4917e-01)\tAcc@1  97.50 ( 92.69)\tAcc@5 100.00 ( 99.14)\n","==> Train Accuracy: Acc@1 92.686 || Acc@5 99.138\n","==> Test Accuracy:  Acc@1 77.040 || Acc@5 94.140\n","==> 29.44 seconds to train this epoch\n","\n","\n","----- epoch: 110, lr: 0.004000000000000001 -----\n","Epoch: [110][  0/391]\tTime  0.257 ( 0.257)\tLoss 2.4234e-01 (2.4234e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n","Epoch: [110][ 30/391]\tTime  0.068 ( 0.077)\tLoss 2.6496e-01 (2.2369e-01)\tAcc@1  91.41 ( 93.57)\tAcc@5 100.00 ( 99.24)\n","Epoch: [110][ 60/391]\tTime  0.066 ( 0.072)\tLoss 2.9907e-01 (2.3541e-01)\tAcc@1  89.06 ( 93.15)\tAcc@5  97.66 ( 99.19)\n","Epoch: [110][ 90/391]\tTime  0.058 ( 0.071)\tLoss 2.5887e-01 (2.3385e-01)\tAcc@1  89.84 ( 93.31)\tAcc@5  98.44 ( 99.21)\n","Epoch: [110][120/391]\tTime  0.057 ( 0.071)\tLoss 1.2353e-01 (2.3247e-01)\tAcc@1  96.88 ( 93.40)\tAcc@5 100.00 ( 99.26)\n","Epoch: [110][150/391]\tTime  0.073 ( 0.071)\tLoss 2.1388e-01 (2.3654e-01)\tAcc@1  93.75 ( 93.13)\tAcc@5  99.22 ( 99.24)\n","Epoch: [110][180/391]\tTime  0.073 ( 0.071)\tLoss 3.8367e-01 (2.4001e-01)\tAcc@1  87.50 ( 93.07)\tAcc@5  96.88 ( 99.23)\n","Epoch: [110][210/391]\tTime  0.072 ( 0.071)\tLoss 2.2396e-01 (2.4286e-01)\tAcc@1  95.31 ( 92.97)\tAcc@5 100.00 ( 99.20)\n","Epoch: [110][240/391]\tTime  0.058 ( 0.071)\tLoss 2.5055e-01 (2.4413e-01)\tAcc@1  94.53 ( 92.94)\tAcc@5  98.44 ( 99.19)\n","Epoch: [110][270/391]\tTime  0.079 ( 0.071)\tLoss 1.9964e-01 (2.4392e-01)\tAcc@1  94.53 ( 92.94)\tAcc@5  99.22 ( 99.17)\n","Epoch: [110][300/391]\tTime  0.055 ( 0.070)\tLoss 2.5021e-01 (2.4685e-01)\tAcc@1  90.62 ( 92.85)\tAcc@5  99.22 ( 99.16)\n","Epoch: [110][330/391]\tTime  0.065 ( 0.070)\tLoss 2.0208e-01 (2.4767e-01)\tAcc@1  92.97 ( 92.80)\tAcc@5 100.00 ( 99.16)\n","Epoch: [110][360/391]\tTime  0.096 ( 0.071)\tLoss 2.9394e-01 (2.4861e-01)\tAcc@1  91.41 ( 92.72)\tAcc@5  98.44 ( 99.17)\n","Epoch: [110][390/391]\tTime  0.048 ( 0.070)\tLoss 2.4329e-01 (2.4787e-01)\tAcc@1  91.25 ( 92.76)\tAcc@5  98.75 ( 99.19)\n","==> Train Accuracy: Acc@1 92.760 || Acc@5 99.186\n","==> Test Accuracy:  Acc@1 76.550 || Acc@5 93.960\n","==> 29.68 seconds to train this epoch\n","\n","\n","----- epoch: 111, lr: 0.004000000000000001 -----\n","Epoch: [111][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.7556e-01 (1.7556e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n","Epoch: [111][ 30/391]\tTime  0.046 ( 0.075)\tLoss 2.6825e-01 (2.2613e-01)\tAcc@1  89.84 ( 93.62)\tAcc@5 100.00 ( 99.27)\n","Epoch: [111][ 60/391]\tTime  0.080 ( 0.073)\tLoss 3.2388e-01 (2.3447e-01)\tAcc@1  89.84 ( 93.28)\tAcc@5  99.22 ( 99.19)\n","Epoch: [111][ 90/391]\tTime  0.049 ( 0.072)\tLoss 1.0415e-01 (2.3317e-01)\tAcc@1  97.66 ( 93.36)\tAcc@5 100.00 ( 99.19)\n","Epoch: [111][120/391]\tTime  0.077 ( 0.072)\tLoss 3.2866e-01 (2.3822e-01)\tAcc@1  89.84 ( 93.18)\tAcc@5 100.00 ( 99.19)\n","Epoch: [111][150/391]\tTime  0.106 ( 0.071)\tLoss 2.7598e-01 (2.4361e-01)\tAcc@1  90.62 ( 92.99)\tAcc@5 100.00 ( 99.15)\n","Epoch: [111][180/391]\tTime  0.078 ( 0.071)\tLoss 2.2189e-01 (2.4646e-01)\tAcc@1  94.53 ( 92.85)\tAcc@5  99.22 ( 99.16)\n","Epoch: [111][210/391]\tTime  0.054 ( 0.071)\tLoss 2.2797e-01 (2.4553e-01)\tAcc@1  92.97 ( 92.87)\tAcc@5 100.00 ( 99.21)\n","Epoch: [111][240/391]\tTime  0.077 ( 0.071)\tLoss 3.1322e-01 (2.4545e-01)\tAcc@1  90.62 ( 92.84)\tAcc@5  98.44 ( 99.21)\n","Epoch: [111][270/391]\tTime  0.067 ( 0.071)\tLoss 2.2877e-01 (2.4409e-01)\tAcc@1  92.97 ( 92.90)\tAcc@5  99.22 ( 99.20)\n","Epoch: [111][300/391]\tTime  0.067 ( 0.071)\tLoss 2.4313e-01 (2.4439e-01)\tAcc@1  92.97 ( 92.88)\tAcc@5  97.66 ( 99.17)\n","Epoch: [111][330/391]\tTime  0.074 ( 0.071)\tLoss 2.0747e-01 (2.4491e-01)\tAcc@1  92.97 ( 92.88)\tAcc@5  99.22 ( 99.16)\n","Epoch: [111][360/391]\tTime  0.059 ( 0.071)\tLoss 2.8789e-01 (2.4494e-01)\tAcc@1  90.62 ( 92.88)\tAcc@5  99.22 ( 99.18)\n","Epoch: [111][390/391]\tTime  0.048 ( 0.071)\tLoss 3.2777e-01 (2.4490e-01)\tAcc@1  88.75 ( 92.88)\tAcc@5 100.00 ( 99.18)\n","==> Train Accuracy: Acc@1 92.884 || Acc@5 99.176\n","==> Test Accuracy:  Acc@1 76.460 || Acc@5 94.090\n","==> 29.83 seconds to train this epoch\n","\n","\n","----- epoch: 112, lr: 0.004000000000000001 -----\n","Epoch: [112][  0/391]\tTime  0.256 ( 0.256)\tLoss 3.6291e-01 (3.6291e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  98.44 ( 98.44)\n","Epoch: [112][ 30/391]\tTime  0.062 ( 0.076)\tLoss 2.0228e-01 (2.2332e-01)\tAcc@1  93.75 ( 93.40)\tAcc@5  99.22 ( 99.17)\n","Epoch: [112][ 60/391]\tTime  0.062 ( 0.073)\tLoss 1.7306e-01 (2.3437e-01)\tAcc@1  94.53 ( 93.15)\tAcc@5 100.00 ( 99.08)\n","Epoch: [112][ 90/391]\tTime  0.070 ( 0.072)\tLoss 2.8509e-01 (2.3835e-01)\tAcc@1  89.06 ( 92.99)\tAcc@5 100.00 ( 99.14)\n","Epoch: [112][120/391]\tTime  0.051 ( 0.071)\tLoss 1.0463e-01 (2.4072e-01)\tAcc@1  97.66 ( 92.87)\tAcc@5 100.00 ( 99.17)\n","Epoch: [112][150/391]\tTime  0.065 ( 0.071)\tLoss 2.5629e-01 (2.3971e-01)\tAcc@1  91.41 ( 92.95)\tAcc@5  99.22 ( 99.21)\n","Epoch: [112][180/391]\tTime  0.046 ( 0.071)\tLoss 1.6487e-01 (2.4169e-01)\tAcc@1  95.31 ( 92.85)\tAcc@5  99.22 ( 99.21)\n","Epoch: [112][210/391]\tTime  0.053 ( 0.071)\tLoss 1.4303e-01 (2.4074e-01)\tAcc@1  96.09 ( 92.91)\tAcc@5 100.00 ( 99.22)\n","Epoch: [112][240/391]\tTime  0.053 ( 0.071)\tLoss 2.5292e-01 (2.4346e-01)\tAcc@1  94.53 ( 92.85)\tAcc@5  99.22 ( 99.22)\n","Epoch: [112][270/391]\tTime  0.061 ( 0.071)\tLoss 2.3656e-01 (2.4525e-01)\tAcc@1  95.31 ( 92.80)\tAcc@5  98.44 ( 99.20)\n","Epoch: [112][300/391]\tTime  0.069 ( 0.071)\tLoss 2.9342e-01 (2.4612e-01)\tAcc@1  92.19 ( 92.77)\tAcc@5  97.66 ( 99.18)\n","Epoch: [112][330/391]\tTime  0.098 ( 0.071)\tLoss 2.8047e-01 (2.4640e-01)\tAcc@1  92.19 ( 92.80)\tAcc@5  99.22 ( 99.18)\n","Epoch: [112][360/391]\tTime  0.049 ( 0.071)\tLoss 1.8376e-01 (2.4660e-01)\tAcc@1  95.31 ( 92.82)\tAcc@5 100.00 ( 99.18)\n","Epoch: [112][390/391]\tTime  0.047 ( 0.071)\tLoss 9.4546e-02 (2.4560e-01)\tAcc@1  97.50 ( 92.85)\tAcc@5 100.00 ( 99.21)\n","==> Train Accuracy: Acc@1 92.848 || Acc@5 99.206\n","==> Test Accuracy:  Acc@1 76.360 || Acc@5 94.120\n","==> 30.04 seconds to train this epoch\n","\n","\n","----- epoch: 113, lr: 0.004000000000000001 -----\n","Epoch: [113][  0/391]\tTime  0.290 ( 0.290)\tLoss 3.1898e-01 (3.1898e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n","Epoch: [113][ 30/391]\tTime  0.071 ( 0.076)\tLoss 2.2124e-01 (2.4013e-01)\tAcc@1  93.75 ( 92.67)\tAcc@5  99.22 ( 99.40)\n","Epoch: [113][ 60/391]\tTime  0.066 ( 0.073)\tLoss 1.9943e-01 (2.3828e-01)\tAcc@1  94.53 ( 93.01)\tAcc@5 100.00 ( 99.21)\n","Epoch: [113][ 90/391]\tTime  0.059 ( 0.072)\tLoss 2.1701e-01 (2.3983e-01)\tAcc@1  96.88 ( 93.02)\tAcc@5  98.44 ( 99.22)\n","Epoch: [113][120/391]\tTime  0.085 ( 0.072)\tLoss 1.9968e-01 (2.4056e-01)\tAcc@1  92.97 ( 92.93)\tAcc@5 100.00 ( 99.25)\n","Epoch: [113][150/391]\tTime  0.067 ( 0.071)\tLoss 2.0782e-01 (2.4051e-01)\tAcc@1  94.53 ( 92.97)\tAcc@5  99.22 ( 99.21)\n","Epoch: [113][180/391]\tTime  0.056 ( 0.071)\tLoss 2.0528e-01 (2.4364e-01)\tAcc@1  94.53 ( 92.95)\tAcc@5 100.00 ( 99.19)\n","Epoch: [113][210/391]\tTime  0.067 ( 0.071)\tLoss 3.9524e-01 (2.4552e-01)\tAcc@1  89.06 ( 92.96)\tAcc@5  98.44 ( 99.16)\n","Epoch: [113][240/391]\tTime  0.061 ( 0.071)\tLoss 3.1822e-01 (2.4629e-01)\tAcc@1  91.41 ( 92.96)\tAcc@5  98.44 ( 99.15)\n","Epoch: [113][270/391]\tTime  0.084 ( 0.071)\tLoss 3.2656e-01 (2.4825e-01)\tAcc@1  89.06 ( 92.84)\tAcc@5  98.44 ( 99.13)\n","Epoch: [113][300/391]\tTime  0.068 ( 0.071)\tLoss 2.2071e-01 (2.5012e-01)\tAcc@1  92.97 ( 92.79)\tAcc@5 100.00 ( 99.11)\n","Epoch: [113][330/391]\tTime  0.080 ( 0.071)\tLoss 2.7105e-01 (2.4971e-01)\tAcc@1  92.19 ( 92.75)\tAcc@5  99.22 ( 99.13)\n","Epoch: [113][360/391]\tTime  0.065 ( 0.071)\tLoss 3.0855e-01 (2.4933e-01)\tAcc@1  91.41 ( 92.75)\tAcc@5  99.22 ( 99.15)\n","Epoch: [113][390/391]\tTime  0.048 ( 0.071)\tLoss 2.3014e-01 (2.5130e-01)\tAcc@1  95.00 ( 92.67)\tAcc@5 100.00 ( 99.14)\n","==> Train Accuracy: Acc@1 92.670 || Acc@5 99.138\n","==> Test Accuracy:  Acc@1 76.540 || Acc@5 94.090\n","==> 29.90 seconds to train this epoch\n","\n","\n","----- epoch: 114, lr: 0.004000000000000001 -----\n","Epoch: [114][  0/391]\tTime  0.262 ( 0.262)\tLoss 2.7987e-01 (2.7987e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  99.22 ( 99.22)\n","Epoch: [114][ 30/391]\tTime  0.090 ( 0.080)\tLoss 2.6789e-01 (2.2668e-01)\tAcc@1  91.41 ( 93.52)\tAcc@5  98.44 ( 99.42)\n","Epoch: [114][ 60/391]\tTime  0.095 ( 0.076)\tLoss 2.2165e-01 (2.3463e-01)\tAcc@1  91.41 ( 93.11)\tAcc@5 100.00 ( 99.28)\n","Epoch: [114][ 90/391]\tTime  0.072 ( 0.073)\tLoss 1.9568e-01 (2.3678e-01)\tAcc@1  93.75 ( 93.06)\tAcc@5 100.00 ( 99.30)\n","Epoch: [114][120/391]\tTime  0.084 ( 0.073)\tLoss 2.3622e-01 (2.4234e-01)\tAcc@1  93.75 ( 92.88)\tAcc@5 100.00 ( 99.23)\n","Epoch: [114][150/391]\tTime  0.060 ( 0.073)\tLoss 2.9911e-01 (2.4403e-01)\tAcc@1  91.41 ( 92.84)\tAcc@5  98.44 ( 99.24)\n","Epoch: [114][180/391]\tTime  0.059 ( 0.072)\tLoss 2.0448e-01 (2.3875e-01)\tAcc@1  94.53 ( 93.01)\tAcc@5  99.22 ( 99.24)\n","Epoch: [114][210/391]\tTime  0.064 ( 0.072)\tLoss 1.0968e-01 (2.3975e-01)\tAcc@1 100.00 ( 92.99)\tAcc@5 100.00 ( 99.25)\n","Epoch: [114][240/391]\tTime  0.049 ( 0.072)\tLoss 2.8265e-01 (2.4103e-01)\tAcc@1  92.19 ( 92.92)\tAcc@5  99.22 ( 99.24)\n","Epoch: [114][270/391]\tTime  0.082 ( 0.072)\tLoss 3.4457e-01 (2.4449e-01)\tAcc@1  90.62 ( 92.86)\tAcc@5  97.66 ( 99.23)\n","Epoch: [114][300/391]\tTime  0.052 ( 0.072)\tLoss 2.4879e-01 (2.4510e-01)\tAcc@1  89.84 ( 92.83)\tAcc@5  99.22 ( 99.21)\n","Epoch: [114][330/391]\tTime  0.063 ( 0.072)\tLoss 2.8455e-01 (2.4486e-01)\tAcc@1  92.19 ( 92.83)\tAcc@5  98.44 ( 99.22)\n","Epoch: [114][360/391]\tTime  0.055 ( 0.072)\tLoss 1.8526e-01 (2.4584e-01)\tAcc@1  93.75 ( 92.83)\tAcc@5 100.00 ( 99.21)\n","Epoch: [114][390/391]\tTime  0.047 ( 0.072)\tLoss 2.5966e-01 (2.4684e-01)\tAcc@1  92.50 ( 92.81)\tAcc@5 100.00 ( 99.19)\n","==> Train Accuracy: Acc@1 92.814 || Acc@5 99.192\n","==> Test Accuracy:  Acc@1 76.790 || Acc@5 93.920\n","==> 30.41 seconds to train this epoch\n","\n","\n","----- epoch: 115, lr: 0.004000000000000001 -----\n","Epoch: [115][  0/391]\tTime  0.273 ( 0.273)\tLoss 4.4614e-01 (4.4614e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  98.44 ( 98.44)\n","Epoch: [115][ 30/391]\tTime  0.057 ( 0.078)\tLoss 1.9437e-01 (2.3330e-01)\tAcc@1  92.97 ( 93.35)\tAcc@5 100.00 ( 99.17)\n","Epoch: [115][ 60/391]\tTime  0.083 ( 0.075)\tLoss 2.0721e-01 (2.2757e-01)\tAcc@1  93.75 ( 93.31)\tAcc@5  99.22 ( 99.28)\n","Epoch: [115][ 90/391]\tTime  0.057 ( 0.074)\tLoss 1.9567e-01 (2.2724e-01)\tAcc@1  92.97 ( 93.32)\tAcc@5  99.22 ( 99.29)\n","Epoch: [115][120/391]\tTime  0.061 ( 0.074)\tLoss 1.6150e-01 (2.2961e-01)\tAcc@1  94.53 ( 93.30)\tAcc@5 100.00 ( 99.31)\n","Epoch: [115][150/391]\tTime  0.063 ( 0.073)\tLoss 2.5189e-01 (2.2813e-01)\tAcc@1  90.62 ( 93.35)\tAcc@5  99.22 ( 99.30)\n","Epoch: [115][180/391]\tTime  0.079 ( 0.073)\tLoss 2.7596e-01 (2.2974e-01)\tAcc@1  90.62 ( 93.32)\tAcc@5  99.22 ( 99.29)\n","Epoch: [115][210/391]\tTime  0.052 ( 0.073)\tLoss 2.2214e-01 (2.3356e-01)\tAcc@1  92.97 ( 93.17)\tAcc@5  98.44 ( 99.24)\n","Epoch: [115][240/391]\tTime  0.064 ( 0.073)\tLoss 2.7034e-01 (2.3564e-01)\tAcc@1  91.41 ( 93.07)\tAcc@5  99.22 ( 99.23)\n","Epoch: [115][270/391]\tTime  0.043 ( 0.073)\tLoss 2.7344e-01 (2.3550e-01)\tAcc@1  89.84 ( 93.07)\tAcc@5  99.22 ( 99.24)\n","Epoch: [115][300/391]\tTime  0.065 ( 0.073)\tLoss 1.9437e-01 (2.3456e-01)\tAcc@1  94.53 ( 93.13)\tAcc@5  99.22 ( 99.25)\n","Epoch: [115][330/391]\tTime  0.087 ( 0.073)\tLoss 1.8365e-01 (2.3625e-01)\tAcc@1  92.97 ( 93.09)\tAcc@5 100.00 ( 99.24)\n","Epoch: [115][360/391]\tTime  0.089 ( 0.073)\tLoss 2.3419e-01 (2.3669e-01)\tAcc@1  94.53 ( 93.09)\tAcc@5  99.22 ( 99.23)\n","Epoch: [115][390/391]\tTime  0.048 ( 0.072)\tLoss 2.8927e-01 (2.3807e-01)\tAcc@1  93.75 ( 93.06)\tAcc@5  98.75 ( 99.24)\n","==> Train Accuracy: Acc@1 93.060 || Acc@5 99.236\n","==> Test Accuracy:  Acc@1 76.570 || Acc@5 93.830\n","==> 30.47 seconds to train this epoch\n","\n","\n","----- epoch: 116, lr: 0.004000000000000001 -----\n","Epoch: [116][  0/391]\tTime  0.261 ( 0.261)\tLoss 2.1016e-01 (2.1016e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n","Epoch: [116][ 30/391]\tTime  0.088 ( 0.077)\tLoss 2.0795e-01 (2.2809e-01)\tAcc@1  92.97 ( 93.50)\tAcc@5  99.22 ( 98.99)\n","Epoch: [116][ 60/391]\tTime  0.073 ( 0.074)\tLoss 2.1908e-01 (2.3069e-01)\tAcc@1  93.75 ( 93.26)\tAcc@5  99.22 ( 99.05)\n","Epoch: [116][ 90/391]\tTime  0.091 ( 0.074)\tLoss 2.3383e-01 (2.3573e-01)\tAcc@1  91.41 ( 93.11)\tAcc@5  99.22 ( 99.14)\n","Epoch: [116][120/391]\tTime  0.073 ( 0.073)\tLoss 5.2300e-01 (2.3902e-01)\tAcc@1  89.06 ( 92.98)\tAcc@5  96.09 ( 99.13)\n","Epoch: [116][150/391]\tTime  0.080 ( 0.073)\tLoss 2.1649e-01 (2.3756e-01)\tAcc@1  94.53 ( 93.02)\tAcc@5 100.00 ( 99.15)\n","Epoch: [116][180/391]\tTime  0.074 ( 0.073)\tLoss 1.9760e-01 (2.3869e-01)\tAcc@1  94.53 ( 92.99)\tAcc@5  99.22 ( 99.14)\n","Epoch: [116][210/391]\tTime  0.083 ( 0.073)\tLoss 1.1824e-01 (2.3974e-01)\tAcc@1  96.88 ( 92.89)\tAcc@5 100.00 ( 99.16)\n","Epoch: [116][240/391]\tTime  0.076 ( 0.072)\tLoss 3.7225e-01 (2.3991e-01)\tAcc@1  89.84 ( 92.94)\tAcc@5  98.44 ( 99.17)\n","Epoch: [116][270/391]\tTime  0.093 ( 0.072)\tLoss 3.6578e-01 (2.4091e-01)\tAcc@1  88.28 ( 92.86)\tAcc@5  99.22 ( 99.17)\n","Epoch: [116][300/391]\tTime  0.093 ( 0.072)\tLoss 1.6909e-01 (2.4053e-01)\tAcc@1  96.09 ( 92.87)\tAcc@5 100.00 ( 99.20)\n","Epoch: [116][330/391]\tTime  0.068 ( 0.072)\tLoss 1.8760e-01 (2.3943e-01)\tAcc@1  93.75 ( 92.90)\tAcc@5 100.00 ( 99.23)\n","Epoch: [116][360/391]\tTime  0.081 ( 0.072)\tLoss 2.0110e-01 (2.3965e-01)\tAcc@1  95.31 ( 92.90)\tAcc@5  99.22 ( 99.22)\n","Epoch: [116][390/391]\tTime  0.048 ( 0.072)\tLoss 4.9242e-01 (2.4023e-01)\tAcc@1  85.00 ( 92.88)\tAcc@5  97.50 ( 99.21)\n","==> Train Accuracy: Acc@1 92.882 || Acc@5 99.212\n","==> Test Accuracy:  Acc@1 76.420 || Acc@5 93.690\n","==> 30.45 seconds to train this epoch\n","\n","\n","----- epoch: 117, lr: 0.004000000000000001 -----\n","Epoch: [117][  0/391]\tTime  0.278 ( 0.278)\tLoss 2.2897e-01 (2.2897e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [117][ 30/391]\tTime  0.056 ( 0.081)\tLoss 1.9219e-01 (2.3377e-01)\tAcc@1  96.09 ( 93.35)\tAcc@5  99.22 ( 99.32)\n","Epoch: [117][ 60/391]\tTime  0.098 ( 0.077)\tLoss 3.4486e-01 (2.3037e-01)\tAcc@1  87.50 ( 93.35)\tAcc@5  97.66 ( 99.24)\n","Epoch: [117][ 90/391]\tTime  0.067 ( 0.076)\tLoss 1.3392e-01 (2.2543e-01)\tAcc@1  98.44 ( 93.48)\tAcc@5 100.00 ( 99.31)\n","Epoch: [117][120/391]\tTime  0.078 ( 0.074)\tLoss 2.3375e-01 (2.3027e-01)\tAcc@1  91.41 ( 93.29)\tAcc@5 100.00 ( 99.26)\n","Epoch: [117][150/391]\tTime  0.065 ( 0.074)\tLoss 2.6565e-01 (2.3691e-01)\tAcc@1  93.75 ( 93.10)\tAcc@5  98.44 ( 99.22)\n","Epoch: [117][180/391]\tTime  0.086 ( 0.074)\tLoss 9.7794e-02 (2.3721e-01)\tAcc@1  96.88 ( 93.15)\tAcc@5 100.00 ( 99.21)\n","Epoch: [117][210/391]\tTime  0.062 ( 0.073)\tLoss 2.9364e-01 (2.3681e-01)\tAcc@1  90.62 ( 93.11)\tAcc@5  99.22 ( 99.22)\n","Epoch: [117][240/391]\tTime  0.075 ( 0.073)\tLoss 2.7503e-01 (2.3780e-01)\tAcc@1  92.19 ( 93.14)\tAcc@5  97.66 ( 99.21)\n","Epoch: [117][270/391]\tTime  0.088 ( 0.073)\tLoss 2.6540e-01 (2.4215e-01)\tAcc@1  89.84 ( 93.03)\tAcc@5 100.00 ( 99.18)\n","Epoch: [117][300/391]\tTime  0.082 ( 0.073)\tLoss 2.8187e-01 (2.4416e-01)\tAcc@1  91.41 ( 92.90)\tAcc@5  99.22 ( 99.18)\n","Epoch: [117][330/391]\tTime  0.063 ( 0.072)\tLoss 1.5621e-01 (2.4467e-01)\tAcc@1  96.88 ( 92.90)\tAcc@5 100.00 ( 99.18)\n","Epoch: [117][360/391]\tTime  0.060 ( 0.073)\tLoss 2.9100e-01 (2.4413e-01)\tAcc@1  91.41 ( 92.90)\tAcc@5  99.22 ( 99.19)\n","Epoch: [117][390/391]\tTime  0.048 ( 0.072)\tLoss 2.2566e-01 (2.4362e-01)\tAcc@1  95.00 ( 92.92)\tAcc@5  98.75 ( 99.19)\n","==> Train Accuracy: Acc@1 92.918 || Acc@5 99.188\n","==> Test Accuracy:  Acc@1 76.680 || Acc@5 94.040\n","==> 30.48 seconds to train this epoch\n","\n","\n","----- epoch: 118, lr: 0.004000000000000001 -----\n","Epoch: [118][  0/391]\tTime  0.279 ( 0.279)\tLoss 3.8371e-01 (3.8371e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  97.66 ( 97.66)\n","Epoch: [118][ 30/391]\tTime  0.096 ( 0.079)\tLoss 1.9181e-01 (2.3761e-01)\tAcc@1  94.53 ( 93.25)\tAcc@5  99.22 ( 99.24)\n","Epoch: [118][ 60/391]\tTime  0.073 ( 0.076)\tLoss 2.3944e-01 (2.3627e-01)\tAcc@1  93.75 ( 92.99)\tAcc@5  99.22 ( 99.27)\n","Epoch: [118][ 90/391]\tTime  0.057 ( 0.074)\tLoss 2.2940e-01 (2.3099e-01)\tAcc@1  93.75 ( 93.13)\tAcc@5  98.44 ( 99.24)\n","Epoch: [118][120/391]\tTime  0.108 ( 0.074)\tLoss 1.7757e-01 (2.3145e-01)\tAcc@1  93.75 ( 93.21)\tAcc@5  99.22 ( 99.19)\n","Epoch: [118][150/391]\tTime  0.067 ( 0.075)\tLoss 3.9209e-01 (2.3552e-01)\tAcc@1  87.50 ( 93.04)\tAcc@5  99.22 ( 99.18)\n","Epoch: [118][180/391]\tTime  0.081 ( 0.075)\tLoss 1.7286e-01 (2.3529e-01)\tAcc@1  96.09 ( 93.06)\tAcc@5 100.00 ( 99.22)\n","Epoch: [118][210/391]\tTime  0.083 ( 0.075)\tLoss 1.8941e-01 (2.3489e-01)\tAcc@1  93.75 ( 93.11)\tAcc@5 100.00 ( 99.24)\n","Epoch: [118][240/391]\tTime  0.061 ( 0.075)\tLoss 2.1896e-01 (2.3542e-01)\tAcc@1  94.53 ( 93.09)\tAcc@5 100.00 ( 99.25)\n","Epoch: [118][270/391]\tTime  0.073 ( 0.074)\tLoss 2.8684e-01 (2.3516e-01)\tAcc@1  93.75 ( 93.06)\tAcc@5  98.44 ( 99.26)\n","Epoch: [118][300/391]\tTime  0.075 ( 0.074)\tLoss 2.0855e-01 (2.3787e-01)\tAcc@1  92.97 ( 93.00)\tAcc@5  98.44 ( 99.24)\n","Epoch: [118][330/391]\tTime  0.059 ( 0.074)\tLoss 3.4789e-01 (2.3710e-01)\tAcc@1  89.84 ( 93.03)\tAcc@5  98.44 ( 99.24)\n","Epoch: [118][360/391]\tTime  0.059 ( 0.074)\tLoss 3.0958e-01 (2.3930e-01)\tAcc@1  89.84 ( 92.94)\tAcc@5  99.22 ( 99.23)\n","Epoch: [118][390/391]\tTime  0.047 ( 0.073)\tLoss 1.6253e-01 (2.4098e-01)\tAcc@1  95.00 ( 92.89)\tAcc@5 100.00 ( 99.20)\n","==> Train Accuracy: Acc@1 92.890 || Acc@5 99.204\n","==> Test Accuracy:  Acc@1 76.510 || Acc@5 93.770\n","==> 30.98 seconds to train this epoch\n","\n","\n","----- epoch: 119, lr: 0.004000000000000001 -----\n","Epoch: [119][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.5233e-01 (1.5233e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [119][ 30/391]\tTime  0.070 ( 0.077)\tLoss 2.6083e-01 (2.1560e-01)\tAcc@1  92.97 ( 93.75)\tAcc@5  99.22 ( 99.32)\n","Epoch: [119][ 60/391]\tTime  0.081 ( 0.077)\tLoss 2.7668e-01 (2.3183e-01)\tAcc@1  90.62 ( 93.37)\tAcc@5  99.22 ( 99.27)\n","Epoch: [119][ 90/391]\tTime  0.074 ( 0.075)\tLoss 2.4477e-01 (2.3217e-01)\tAcc@1  94.53 ( 93.42)\tAcc@5  98.44 ( 99.29)\n","Epoch: [119][120/391]\tTime  0.069 ( 0.075)\tLoss 2.2474e-01 (2.3714e-01)\tAcc@1  90.62 ( 93.16)\tAcc@5 100.00 ( 99.28)\n","Epoch: [119][150/391]\tTime  0.074 ( 0.074)\tLoss 2.5415e-01 (2.3629e-01)\tAcc@1  92.19 ( 93.23)\tAcc@5  99.22 ( 99.26)\n","Epoch: [119][180/391]\tTime  0.060 ( 0.074)\tLoss 2.0843e-01 (2.3531e-01)\tAcc@1  95.31 ( 93.29)\tAcc@5  99.22 ( 99.24)\n","Epoch: [119][210/391]\tTime  0.070 ( 0.074)\tLoss 3.8005e-01 (2.3695e-01)\tAcc@1  88.28 ( 93.18)\tAcc@5  98.44 ( 99.24)\n","Epoch: [119][240/391]\tTime  0.059 ( 0.074)\tLoss 3.0268e-01 (2.3682e-01)\tAcc@1  88.28 ( 93.11)\tAcc@5 100.00 ( 99.28)\n","Epoch: [119][270/391]\tTime  0.106 ( 0.073)\tLoss 2.3465e-01 (2.3683e-01)\tAcc@1  92.97 ( 93.11)\tAcc@5  99.22 ( 99.30)\n","Epoch: [119][300/391]\tTime  0.066 ( 0.073)\tLoss 2.5474e-01 (2.3709e-01)\tAcc@1  91.41 ( 93.06)\tAcc@5  99.22 ( 99.28)\n","Epoch: [119][330/391]\tTime  0.064 ( 0.073)\tLoss 2.5588e-01 (2.3679e-01)\tAcc@1  92.19 ( 93.07)\tAcc@5  98.44 ( 99.29)\n","Epoch: [119][360/391]\tTime  0.064 ( 0.073)\tLoss 1.6924e-01 (2.3700e-01)\tAcc@1  93.75 ( 93.08)\tAcc@5  99.22 ( 99.30)\n","Epoch: [119][390/391]\tTime  0.047 ( 0.073)\tLoss 1.0197e-01 (2.3917e-01)\tAcc@1  98.75 ( 93.01)\tAcc@5 100.00 ( 99.29)\n","==> Train Accuracy: Acc@1 93.010 || Acc@5 99.286\n","==> Test Accuracy:  Acc@1 76.490 || Acc@5 93.960\n","==> 30.72 seconds to train this epoch\n","\n","\n","----- epoch: 120, lr: 0.0008000000000000003 -----\n","Epoch: [120][  0/391]\tTime  0.257 ( 0.257)\tLoss 2.5957e-01 (2.5957e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5 100.00 (100.00)\n","Epoch: [120][ 30/391]\tTime  0.063 ( 0.077)\tLoss 1.8438e-01 (2.2582e-01)\tAcc@1  94.53 ( 93.95)\tAcc@5  99.22 ( 99.24)\n","Epoch: [120][ 60/391]\tTime  0.065 ( 0.075)\tLoss 2.0351e-01 (2.1449e-01)\tAcc@1  94.53 ( 94.12)\tAcc@5  99.22 ( 99.37)\n","Epoch: [120][ 90/391]\tTime  0.081 ( 0.074)\tLoss 1.7810e-01 (2.0772e-01)\tAcc@1  94.53 ( 94.26)\tAcc@5 100.00 ( 99.36)\n","Epoch: [120][120/391]\tTime  0.065 ( 0.073)\tLoss 2.0330e-01 (2.0221e-01)\tAcc@1  94.53 ( 94.43)\tAcc@5  99.22 ( 99.36)\n","Epoch: [120][150/391]\tTime  0.073 ( 0.073)\tLoss 2.5132e-01 (1.9926e-01)\tAcc@1  93.75 ( 94.50)\tAcc@5  97.66 ( 99.32)\n","Epoch: [120][180/391]\tTime  0.076 ( 0.073)\tLoss 1.9102e-01 (1.9719e-01)\tAcc@1  93.75 ( 94.59)\tAcc@5 100.00 ( 99.32)\n","Epoch: [120][210/391]\tTime  0.067 ( 0.073)\tLoss 1.5984e-01 (1.9687e-01)\tAcc@1  95.31 ( 94.54)\tAcc@5  99.22 ( 99.32)\n","Epoch: [120][240/391]\tTime  0.066 ( 0.073)\tLoss 1.4020e-01 (1.9577e-01)\tAcc@1  96.88 ( 94.60)\tAcc@5 100.00 ( 99.31)\n","Epoch: [120][270/391]\tTime  0.063 ( 0.073)\tLoss 1.5494e-01 (1.9343e-01)\tAcc@1  96.88 ( 94.68)\tAcc@5 100.00 ( 99.34)\n","Epoch: [120][300/391]\tTime  0.054 ( 0.072)\tLoss 1.5385e-01 (1.9113e-01)\tAcc@1  95.31 ( 94.76)\tAcc@5  99.22 ( 99.35)\n","Epoch: [120][330/391]\tTime  0.073 ( 0.072)\tLoss 1.2185e-01 (1.8999e-01)\tAcc@1  96.09 ( 94.80)\tAcc@5 100.00 ( 99.36)\n","Epoch: [120][360/391]\tTime  0.079 ( 0.072)\tLoss 1.7276e-01 (1.8836e-01)\tAcc@1  94.53 ( 94.82)\tAcc@5 100.00 ( 99.38)\n","Epoch: [120][390/391]\tTime  0.048 ( 0.072)\tLoss 2.5318e-01 (1.8773e-01)\tAcc@1  93.75 ( 94.84)\tAcc@5 100.00 ( 99.39)\n","==> Train Accuracy: Acc@1 94.836 || Acc@5 99.386\n","==> Test Accuracy:  Acc@1 77.650 || Acc@5 94.470\n","==> 30.41 seconds to train this epoch\n","\n","\n","----- epoch: 121, lr: 0.0008000000000000003 -----\n","Epoch: [121][  0/391]\tTime  0.273 ( 0.273)\tLoss 2.1371e-01 (2.1371e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  98.44 ( 98.44)\n","Epoch: [121][ 30/391]\tTime  0.046 ( 0.080)\tLoss 1.2639e-01 (1.7824e-01)\tAcc@1  96.88 ( 94.93)\tAcc@5 100.00 ( 99.37)\n","Epoch: [121][ 60/391]\tTime  0.069 ( 0.076)\tLoss 1.7552e-01 (1.8051e-01)\tAcc@1  96.09 ( 94.81)\tAcc@5 100.00 ( 99.45)\n","Epoch: [121][ 90/391]\tTime  0.059 ( 0.075)\tLoss 7.4391e-02 (1.7609e-01)\tAcc@1  99.22 ( 95.07)\tAcc@5 100.00 ( 99.47)\n","Epoch: [121][120/391]\tTime  0.065 ( 0.074)\tLoss 1.3163e-01 (1.7293e-01)\tAcc@1  96.09 ( 95.15)\tAcc@5  99.22 ( 99.48)\n","Epoch: [121][150/391]\tTime  0.093 ( 0.074)\tLoss 1.8365e-01 (1.7349e-01)\tAcc@1  92.97 ( 95.15)\tAcc@5 100.00 ( 99.46)\n","Epoch: [121][180/391]\tTime  0.077 ( 0.074)\tLoss 1.1941e-01 (1.6967e-01)\tAcc@1  97.66 ( 95.27)\tAcc@5  99.22 ( 99.47)\n","Epoch: [121][210/391]\tTime  0.066 ( 0.074)\tLoss 1.3057e-01 (1.7150e-01)\tAcc@1  95.31 ( 95.23)\tAcc@5  99.22 ( 99.47)\n","Epoch: [121][240/391]\tTime  0.065 ( 0.073)\tLoss 1.9096e-01 (1.7322e-01)\tAcc@1  94.53 ( 95.17)\tAcc@5 100.00 ( 99.45)\n","Epoch: [121][270/391]\tTime  0.065 ( 0.073)\tLoss 1.9383e-01 (1.7288e-01)\tAcc@1  94.53 ( 95.22)\tAcc@5 100.00 ( 99.45)\n","Epoch: [121][300/391]\tTime  0.078 ( 0.073)\tLoss 1.2076e-01 (1.7501e-01)\tAcc@1  96.88 ( 95.16)\tAcc@5 100.00 ( 99.43)\n","Epoch: [121][330/391]\tTime  0.064 ( 0.073)\tLoss 2.0346e-01 (1.7414e-01)\tAcc@1  93.75 ( 95.19)\tAcc@5  99.22 ( 99.44)\n","Epoch: [121][360/391]\tTime  0.060 ( 0.073)\tLoss 1.6361e-01 (1.7420e-01)\tAcc@1  95.31 ( 95.16)\tAcc@5 100.00 ( 99.45)\n","Epoch: [121][390/391]\tTime  0.048 ( 0.073)\tLoss 2.2441e-01 (1.7365e-01)\tAcc@1  95.00 ( 95.18)\tAcc@5  98.75 ( 99.45)\n","==> Train Accuracy: Acc@1 95.180 || Acc@5 99.446\n","==> Test Accuracy:  Acc@1 77.930 || Acc@5 94.500\n","==> 30.62 seconds to train this epoch\n","\n","\n","----- epoch: 122, lr: 0.0008000000000000003 -----\n","Epoch: [122][  0/391]\tTime  0.284 ( 0.284)\tLoss 2.3513e-01 (2.3513e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n","Epoch: [122][ 30/391]\tTime  0.073 ( 0.077)\tLoss 1.6381e-01 (1.7803e-01)\tAcc@1  95.31 ( 95.04)\tAcc@5 100.00 ( 99.12)\n","Epoch: [122][ 60/391]\tTime  0.065 ( 0.075)\tLoss 1.6024e-01 (1.7100e-01)\tAcc@1  94.53 ( 95.06)\tAcc@5  98.44 ( 99.28)\n","Epoch: [122][ 90/391]\tTime  0.069 ( 0.073)\tLoss 1.3728e-01 (1.6844e-01)\tAcc@1  94.53 ( 95.18)\tAcc@5  99.22 ( 99.38)\n","Epoch: [122][120/391]\tTime  0.067 ( 0.073)\tLoss 1.2406e-01 (1.6734e-01)\tAcc@1  96.88 ( 95.29)\tAcc@5 100.00 ( 99.37)\n","Epoch: [122][150/391]\tTime  0.066 ( 0.073)\tLoss 1.2774e-01 (1.6601e-01)\tAcc@1  96.88 ( 95.33)\tAcc@5 100.00 ( 99.38)\n","Epoch: [122][180/391]\tTime  0.053 ( 0.073)\tLoss 1.8354e-01 (1.6640e-01)\tAcc@1  94.53 ( 95.30)\tAcc@5  99.22 ( 99.39)\n","Epoch: [122][210/391]\tTime  0.081 ( 0.073)\tLoss 1.0575e-01 (1.6706e-01)\tAcc@1  96.09 ( 95.25)\tAcc@5 100.00 ( 99.40)\n","Epoch: [122][240/391]\tTime  0.067 ( 0.072)\tLoss 2.1791e-01 (1.6621e-01)\tAcc@1  93.75 ( 95.33)\tAcc@5  99.22 ( 99.44)\n","Epoch: [122][270/391]\tTime  0.059 ( 0.072)\tLoss 2.3013e-01 (1.6581e-01)\tAcc@1  92.97 ( 95.32)\tAcc@5  99.22 ( 99.44)\n","Epoch: [122][300/391]\tTime  0.075 ( 0.072)\tLoss 6.9387e-02 (1.6444e-01)\tAcc@1  99.22 ( 95.34)\tAcc@5 100.00 ( 99.47)\n","Epoch: [122][330/391]\tTime  0.081 ( 0.072)\tLoss 1.7774e-01 (1.6395e-01)\tAcc@1  94.53 ( 95.33)\tAcc@5  99.22 ( 99.47)\n","Epoch: [122][360/391]\tTime  0.083 ( 0.072)\tLoss 1.6903e-01 (1.6370e-01)\tAcc@1  95.31 ( 95.35)\tAcc@5  99.22 ( 99.49)\n","Epoch: [122][390/391]\tTime  0.047 ( 0.072)\tLoss 1.5117e-01 (1.6381e-01)\tAcc@1  97.50 ( 95.35)\tAcc@5 100.00 ( 99.51)\n","==> Train Accuracy: Acc@1 95.346 || Acc@5 99.506\n","==> Test Accuracy:  Acc@1 78.130 || Acc@5 94.330\n","==> 30.35 seconds to train this epoch\n","\n","\n","----- epoch: 123, lr: 0.0008000000000000003 -----\n","Epoch: [123][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.8026e-01 (1.8026e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [123][ 30/391]\tTime  0.062 ( 0.078)\tLoss 1.6145e-01 (1.5496e-01)\tAcc@1  96.09 ( 95.31)\tAcc@5  99.22 ( 99.50)\n","Epoch: [123][ 60/391]\tTime  0.071 ( 0.075)\tLoss 2.0949e-01 (1.6313e-01)\tAcc@1  94.53 ( 95.27)\tAcc@5  98.44 ( 99.55)\n","Epoch: [123][ 90/391]\tTime  0.099 ( 0.073)\tLoss 1.3016e-01 (1.6490e-01)\tAcc@1  96.09 ( 95.30)\tAcc@5 100.00 ( 99.53)\n","Epoch: [123][120/391]\tTime  0.065 ( 0.073)\tLoss 2.1243e-01 (1.6650e-01)\tAcc@1  93.75 ( 95.23)\tAcc@5  99.22 ( 99.51)\n","Epoch: [123][150/391]\tTime  0.063 ( 0.073)\tLoss 1.3277e-01 (1.6642e-01)\tAcc@1  98.44 ( 95.30)\tAcc@5  99.22 ( 99.50)\n","Epoch: [123][180/391]\tTime  0.069 ( 0.073)\tLoss 9.3789e-02 (1.6494e-01)\tAcc@1  97.66 ( 95.33)\tAcc@5 100.00 ( 99.52)\n","Epoch: [123][210/391]\tTime  0.090 ( 0.073)\tLoss 1.8634e-01 (1.6587e-01)\tAcc@1  95.31 ( 95.29)\tAcc@5  98.44 ( 99.51)\n","Epoch: [123][240/391]\tTime  0.072 ( 0.072)\tLoss 1.1142e-01 (1.6647e-01)\tAcc@1  97.66 ( 95.27)\tAcc@5  99.22 ( 99.51)\n","Epoch: [123][270/391]\tTime  0.083 ( 0.072)\tLoss 1.6351e-01 (1.6618e-01)\tAcc@1  93.75 ( 95.27)\tAcc@5  99.22 ( 99.51)\n","Epoch: [123][300/391]\tTime  0.077 ( 0.072)\tLoss 1.4202e-01 (1.6479e-01)\tAcc@1  94.53 ( 95.33)\tAcc@5 100.00 ( 99.51)\n","Epoch: [123][330/391]\tTime  0.108 ( 0.073)\tLoss 1.2381e-01 (1.6357e-01)\tAcc@1  96.88 ( 95.39)\tAcc@5  99.22 ( 99.51)\n","Epoch: [123][360/391]\tTime  0.059 ( 0.072)\tLoss 1.7113e-01 (1.6269e-01)\tAcc@1  96.09 ( 95.42)\tAcc@5  99.22 ( 99.52)\n","Epoch: [123][390/391]\tTime  0.048 ( 0.072)\tLoss 1.2677e-01 (1.6226e-01)\tAcc@1  96.25 ( 95.44)\tAcc@5 100.00 ( 99.53)\n","==> Train Accuracy: Acc@1 95.436 || Acc@5 99.534\n","==> Test Accuracy:  Acc@1 78.220 || Acc@5 94.450\n","==> 30.61 seconds to train this epoch\n","\n","\n","----- epoch: 124, lr: 0.0008000000000000003 -----\n","Epoch: [124][  0/391]\tTime  0.263 ( 0.263)\tLoss 1.2454e-01 (1.2454e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [124][ 30/391]\tTime  0.057 ( 0.078)\tLoss 1.3087e-01 (1.4757e-01)\tAcc@1  97.66 ( 96.22)\tAcc@5 100.00 ( 99.50)\n","Epoch: [124][ 60/391]\tTime  0.067 ( 0.077)\tLoss 9.6414e-02 (1.4722e-01)\tAcc@1  96.88 ( 96.02)\tAcc@5 100.00 ( 99.47)\n","Epoch: [124][ 90/391]\tTime  0.097 ( 0.076)\tLoss 2.2476e-01 (1.5194e-01)\tAcc@1  92.97 ( 95.81)\tAcc@5  99.22 ( 99.48)\n","Epoch: [124][120/391]\tTime  0.101 ( 0.075)\tLoss 1.7283e-01 (1.5153e-01)\tAcc@1  92.97 ( 95.82)\tAcc@5  99.22 ( 99.47)\n","Epoch: [124][150/391]\tTime  0.092 ( 0.074)\tLoss 1.2746e-01 (1.5197e-01)\tAcc@1  98.44 ( 95.84)\tAcc@5 100.00 ( 99.48)\n","Epoch: [124][180/391]\tTime  0.075 ( 0.074)\tLoss 1.6030e-01 (1.5086e-01)\tAcc@1  93.75 ( 95.85)\tAcc@5 100.00 ( 99.49)\n","Epoch: [124][210/391]\tTime  0.057 ( 0.074)\tLoss 1.0014e-01 (1.4976e-01)\tAcc@1  96.88 ( 95.85)\tAcc@5 100.00 ( 99.51)\n","Epoch: [124][240/391]\tTime  0.066 ( 0.073)\tLoss 1.3837e-01 (1.5001e-01)\tAcc@1  96.09 ( 95.86)\tAcc@5  99.22 ( 99.53)\n","Epoch: [124][270/391]\tTime  0.125 ( 0.074)\tLoss 1.0810e-01 (1.5176e-01)\tAcc@1  97.66 ( 95.79)\tAcc@5 100.00 ( 99.51)\n","Epoch: [124][300/391]\tTime  0.067 ( 0.074)\tLoss 1.4832e-01 (1.5212e-01)\tAcc@1  96.88 ( 95.77)\tAcc@5  98.44 ( 99.51)\n","Epoch: [124][330/391]\tTime  0.081 ( 0.074)\tLoss 1.7018e-01 (1.5397e-01)\tAcc@1  96.09 ( 95.69)\tAcc@5  99.22 ( 99.49)\n","Epoch: [124][360/391]\tTime  0.073 ( 0.074)\tLoss 1.2813e-01 (1.5334e-01)\tAcc@1  97.66 ( 95.71)\tAcc@5  99.22 ( 99.50)\n","Epoch: [124][390/391]\tTime  0.048 ( 0.074)\tLoss 2.0212e-01 (1.5444e-01)\tAcc@1  96.25 ( 95.66)\tAcc@5  97.50 ( 99.50)\n","==> Train Accuracy: Acc@1 95.664 || Acc@5 99.498\n","==> Test Accuracy:  Acc@1 78.070 || Acc@5 94.330\n","==> 31.23 seconds to train this epoch\n","\n","\n","----- epoch: 125, lr: 0.0008000000000000003 -----\n","Epoch: [125][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.5985e-01 (1.5985e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n","Epoch: [125][ 30/391]\tTime  0.091 ( 0.082)\tLoss 2.0394e-01 (1.5770e-01)\tAcc@1  94.53 ( 95.04)\tAcc@5 100.00 ( 99.62)\n","Epoch: [125][ 60/391]\tTime  0.055 ( 0.078)\tLoss 1.8574e-01 (1.5930e-01)\tAcc@1  97.66 ( 95.34)\tAcc@5  99.22 ( 99.59)\n","Epoch: [125][ 90/391]\tTime  0.059 ( 0.076)\tLoss 8.6996e-02 (1.5554e-01)\tAcc@1  98.44 ( 95.53)\tAcc@5 100.00 ( 99.58)\n","Epoch: [125][120/391]\tTime  0.102 ( 0.075)\tLoss 2.0322e-01 (1.5190e-01)\tAcc@1  95.31 ( 95.57)\tAcc@5  98.44 ( 99.60)\n","Epoch: [125][150/391]\tTime  0.063 ( 0.075)\tLoss 1.4709e-01 (1.5435e-01)\tAcc@1  94.53 ( 95.55)\tAcc@5  99.22 ( 99.52)\n","Epoch: [125][180/391]\tTime  0.069 ( 0.075)\tLoss 1.2282e-01 (1.5583e-01)\tAcc@1  96.09 ( 95.55)\tAcc@5 100.00 ( 99.53)\n","Epoch: [125][210/391]\tTime  0.064 ( 0.075)\tLoss 1.1249e-01 (1.5403e-01)\tAcc@1  97.66 ( 95.64)\tAcc@5 100.00 ( 99.54)\n","Epoch: [125][240/391]\tTime  0.074 ( 0.075)\tLoss 1.6817e-01 (1.5378e-01)\tAcc@1  95.31 ( 95.62)\tAcc@5 100.00 ( 99.56)\n","Epoch: [125][270/391]\tTime  0.058 ( 0.075)\tLoss 1.2514e-01 (1.5388e-01)\tAcc@1  94.53 ( 95.62)\tAcc@5 100.00 ( 99.55)\n","Epoch: [125][300/391]\tTime  0.045 ( 0.075)\tLoss 1.0855e-01 (1.5375e-01)\tAcc@1  97.66 ( 95.64)\tAcc@5 100.00 ( 99.57)\n","Epoch: [125][330/391]\tTime  0.063 ( 0.075)\tLoss 1.4403e-01 (1.5410e-01)\tAcc@1  93.75 ( 95.63)\tAcc@5  99.22 ( 99.56)\n","Epoch: [125][360/391]\tTime  0.076 ( 0.075)\tLoss 1.4932e-01 (1.5321e-01)\tAcc@1  96.09 ( 95.67)\tAcc@5 100.00 ( 99.57)\n","Epoch: [125][390/391]\tTime  0.048 ( 0.074)\tLoss 1.1648e-01 (1.5418e-01)\tAcc@1  96.25 ( 95.64)\tAcc@5 100.00 ( 99.55)\n","==> Train Accuracy: Acc@1 95.642 || Acc@5 99.554\n","==> Test Accuracy:  Acc@1 77.900 || Acc@5 94.320\n","==> 31.42 seconds to train this epoch\n","\n","\n","----- epoch: 126, lr: 0.0008000000000000003 -----\n","Epoch: [126][  0/391]\tTime  0.267 ( 0.267)\tLoss 9.6358e-02 (9.6358e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5  99.22 ( 99.22)\n","Epoch: [126][ 30/391]\tTime  0.063 ( 0.078)\tLoss 1.0425e-01 (1.4833e-01)\tAcc@1  96.09 ( 95.87)\tAcc@5 100.00 ( 99.55)\n","Epoch: [126][ 60/391]\tTime  0.072 ( 0.077)\tLoss 9.5284e-02 (1.5235e-01)\tAcc@1  97.66 ( 95.76)\tAcc@5 100.00 ( 99.55)\n","Epoch: [126][ 90/391]\tTime  0.092 ( 0.076)\tLoss 1.2823e-01 (1.5008e-01)\tAcc@1  96.09 ( 95.81)\tAcc@5  99.22 ( 99.54)\n","Epoch: [126][120/391]\tTime  0.060 ( 0.076)\tLoss 1.6152e-01 (1.5217e-01)\tAcc@1  95.31 ( 95.67)\tAcc@5 100.00 ( 99.51)\n","Epoch: [126][150/391]\tTime  0.097 ( 0.075)\tLoss 9.1544e-02 (1.5121e-01)\tAcc@1  97.66 ( 95.65)\tAcc@5 100.00 ( 99.52)\n","Epoch: [126][180/391]\tTime  0.064 ( 0.075)\tLoss 9.5682e-02 (1.4819e-01)\tAcc@1  96.09 ( 95.79)\tAcc@5 100.00 ( 99.55)\n","Epoch: [126][210/391]\tTime  0.093 ( 0.075)\tLoss 1.2575e-01 (1.4898e-01)\tAcc@1  96.09 ( 95.81)\tAcc@5 100.00 ( 99.56)\n","Epoch: [126][240/391]\tTime  0.069 ( 0.075)\tLoss 1.8143e-01 (1.4903e-01)\tAcc@1  94.53 ( 95.79)\tAcc@5  99.22 ( 99.56)\n","Epoch: [126][270/391]\tTime  0.063 ( 0.074)\tLoss 1.5543e-01 (1.5030e-01)\tAcc@1  95.31 ( 95.73)\tAcc@5 100.00 ( 99.54)\n","Epoch: [126][300/391]\tTime  0.099 ( 0.075)\tLoss 1.2269e-01 (1.4935e-01)\tAcc@1  94.53 ( 95.75)\tAcc@5  99.22 ( 99.56)\n","Epoch: [126][330/391]\tTime  0.088 ( 0.074)\tLoss 1.0352e-01 (1.4968e-01)\tAcc@1  97.66 ( 95.73)\tAcc@5 100.00 ( 99.56)\n","Epoch: [126][360/391]\tTime  0.060 ( 0.075)\tLoss 1.1603e-01 (1.4909e-01)\tAcc@1  96.88 ( 95.75)\tAcc@5 100.00 ( 99.57)\n","Epoch: [126][390/391]\tTime  0.044 ( 0.074)\tLoss 1.0409e-01 (1.5010e-01)\tAcc@1  98.75 ( 95.73)\tAcc@5 100.00 ( 99.57)\n","==> Train Accuracy: Acc@1 95.732 || Acc@5 99.566\n","==> Test Accuracy:  Acc@1 78.130 || Acc@5 94.370\n","==> 31.35 seconds to train this epoch\n","\n","\n","----- epoch: 127, lr: 0.0008000000000000003 -----\n","Epoch: [127][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.1853e-01 (1.1853e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [127][ 30/391]\tTime  0.075 ( 0.080)\tLoss 1.0444e-01 (1.4803e-01)\tAcc@1  97.66 ( 95.99)\tAcc@5  99.22 ( 99.45)\n","Epoch: [127][ 60/391]\tTime  0.055 ( 0.077)\tLoss 1.5511e-01 (1.4520e-01)\tAcc@1  96.88 ( 96.04)\tAcc@5  99.22 ( 99.49)\n","Epoch: [127][ 90/391]\tTime  0.054 ( 0.076)\tLoss 2.2484e-01 (1.4494e-01)\tAcc@1  94.53 ( 95.95)\tAcc@5  99.22 ( 99.55)\n","Epoch: [127][120/391]\tTime  0.077 ( 0.076)\tLoss 1.1281e-01 (1.4272e-01)\tAcc@1  96.88 ( 96.04)\tAcc@5 100.00 ( 99.59)\n","Epoch: [127][150/391]\tTime  0.048 ( 0.075)\tLoss 1.9662e-01 (1.4227e-01)\tAcc@1  95.31 ( 96.09)\tAcc@5 100.00 ( 99.61)\n","Epoch: [127][180/391]\tTime  0.074 ( 0.075)\tLoss 1.4739e-01 (1.4274e-01)\tAcc@1  96.88 ( 96.06)\tAcc@5 100.00 ( 99.62)\n","Epoch: [127][210/391]\tTime  0.079 ( 0.075)\tLoss 7.2698e-02 (1.4080e-01)\tAcc@1  97.66 ( 96.09)\tAcc@5 100.00 ( 99.64)\n","Epoch: [127][240/391]\tTime  0.057 ( 0.075)\tLoss 1.3803e-01 (1.4226e-01)\tAcc@1  96.09 ( 96.03)\tAcc@5  99.22 ( 99.64)\n","Epoch: [127][270/391]\tTime  0.064 ( 0.075)\tLoss 1.1563e-01 (1.4160e-01)\tAcc@1  95.31 ( 96.04)\tAcc@5 100.00 ( 99.65)\n","Epoch: [127][300/391]\tTime  0.062 ( 0.075)\tLoss 1.2259e-01 (1.4147e-01)\tAcc@1  94.53 ( 96.02)\tAcc@5 100.00 ( 99.65)\n","Epoch: [127][330/391]\tTime  0.116 ( 0.075)\tLoss 1.3086e-01 (1.4094e-01)\tAcc@1  95.31 ( 96.01)\tAcc@5  99.22 ( 99.66)\n","Epoch: [127][360/391]\tTime  0.050 ( 0.075)\tLoss 1.8617e-01 (1.4285e-01)\tAcc@1  92.97 ( 95.97)\tAcc@5  99.22 ( 99.63)\n","Epoch: [127][390/391]\tTime  0.048 ( 0.074)\tLoss 1.5321e-01 (1.4306e-01)\tAcc@1  96.25 ( 95.97)\tAcc@5  98.75 ( 99.62)\n","==> Train Accuracy: Acc@1 95.972 || Acc@5 99.622\n","==> Test Accuracy:  Acc@1 78.130 || Acc@5 94.370\n","==> 31.43 seconds to train this epoch\n","\n","\n","----- epoch: 128, lr: 0.0008000000000000003 -----\n","Epoch: [128][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.0901e-01 (1.0901e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [128][ 30/391]\tTime  0.064 ( 0.078)\tLoss 1.2525e-01 (1.3385e-01)\tAcc@1  97.66 ( 96.30)\tAcc@5  99.22 ( 99.60)\n","Epoch: [128][ 60/391]\tTime  0.068 ( 0.076)\tLoss 1.0381e-01 (1.4280e-01)\tAcc@1  97.66 ( 95.91)\tAcc@5 100.00 ( 99.53)\n","Epoch: [128][ 90/391]\tTime  0.094 ( 0.075)\tLoss 1.6043e-01 (1.4190e-01)\tAcc@1  95.31 ( 96.03)\tAcc@5 100.00 ( 99.59)\n","Epoch: [128][120/391]\tTime  0.062 ( 0.074)\tLoss 1.7494e-01 (1.4176e-01)\tAcc@1  94.53 ( 96.02)\tAcc@5 100.00 ( 99.59)\n","Epoch: [128][150/391]\tTime  0.078 ( 0.074)\tLoss 9.6992e-02 (1.4146e-01)\tAcc@1  97.66 ( 96.03)\tAcc@5 100.00 ( 99.60)\n","Epoch: [128][180/391]\tTime  0.092 ( 0.074)\tLoss 1.4247e-01 (1.3824e-01)\tAcc@1  96.09 ( 96.07)\tAcc@5  99.22 ( 99.63)\n","Epoch: [128][210/391]\tTime  0.088 ( 0.074)\tLoss 1.3504e-01 (1.3880e-01)\tAcc@1  96.88 ( 96.11)\tAcc@5 100.00 ( 99.62)\n","Epoch: [128][240/391]\tTime  0.074 ( 0.073)\tLoss 1.0304e-01 (1.3999e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 ( 99.61)\n","Epoch: [128][270/391]\tTime  0.060 ( 0.073)\tLoss 1.5261e-01 (1.3960e-01)\tAcc@1  95.31 ( 96.10)\tAcc@5  99.22 ( 99.62)\n","Epoch: [128][300/391]\tTime  0.077 ( 0.073)\tLoss 1.0514e-01 (1.3987e-01)\tAcc@1  96.88 ( 96.08)\tAcc@5 100.00 ( 99.61)\n","Epoch: [128][330/391]\tTime  0.061 ( 0.073)\tLoss 1.0023e-01 (1.3956e-01)\tAcc@1  96.88 ( 96.10)\tAcc@5 100.00 ( 99.61)\n","Epoch: [128][360/391]\tTime  0.068 ( 0.073)\tLoss 1.4421e-01 (1.3905e-01)\tAcc@1  96.09 ( 96.12)\tAcc@5 100.00 ( 99.62)\n","Epoch: [128][390/391]\tTime  0.048 ( 0.073)\tLoss 1.6157e-01 (1.3857e-01)\tAcc@1  97.50 ( 96.15)\tAcc@5 100.00 ( 99.62)\n","==> Train Accuracy: Acc@1 96.152 || Acc@5 99.620\n","==> Test Accuracy:  Acc@1 77.760 || Acc@5 94.400\n","==> 30.96 seconds to train this epoch\n","\n","\n","----- epoch: 129, lr: 0.0008000000000000003 -----\n","Epoch: [129][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.4653e-01 (1.4653e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [129][ 30/391]\tTime  0.078 ( 0.082)\tLoss 1.6570e-01 (1.3964e-01)\tAcc@1  95.31 ( 96.14)\tAcc@5  99.22 ( 99.57)\n","Epoch: [129][ 60/391]\tTime  0.075 ( 0.077)\tLoss 1.3304e-01 (1.4292e-01)\tAcc@1  96.09 ( 96.04)\tAcc@5  99.22 ( 99.45)\n","Epoch: [129][ 90/391]\tTime  0.060 ( 0.077)\tLoss 1.5391e-01 (1.4035e-01)\tAcc@1  98.44 ( 96.22)\tAcc@5  99.22 ( 99.50)\n","Epoch: [129][120/391]\tTime  0.073 ( 0.076)\tLoss 1.1912e-01 (1.4153e-01)\tAcc@1  97.66 ( 96.23)\tAcc@5  99.22 ( 99.50)\n","Epoch: [129][150/391]\tTime  0.076 ( 0.076)\tLoss 7.9931e-02 (1.4263e-01)\tAcc@1  98.44 ( 96.16)\tAcc@5  99.22 ( 99.51)\n","Epoch: [129][180/391]\tTime  0.066 ( 0.075)\tLoss 1.9925e-01 (1.4138e-01)\tAcc@1  93.75 ( 96.18)\tAcc@5  99.22 ( 99.54)\n","Epoch: [129][210/391]\tTime  0.067 ( 0.075)\tLoss 1.5003e-01 (1.3974e-01)\tAcc@1  95.31 ( 96.22)\tAcc@5 100.00 ( 99.57)\n","Epoch: [129][240/391]\tTime  0.063 ( 0.075)\tLoss 6.5591e-02 (1.4086e-01)\tAcc@1  98.44 ( 96.17)\tAcc@5 100.00 ( 99.57)\n","Epoch: [129][270/391]\tTime  0.076 ( 0.075)\tLoss 1.1928e-01 (1.3942e-01)\tAcc@1  95.31 ( 96.21)\tAcc@5 100.00 ( 99.58)\n","Epoch: [129][300/391]\tTime  0.085 ( 0.075)\tLoss 1.2745e-01 (1.3991e-01)\tAcc@1  96.88 ( 96.17)\tAcc@5 100.00 ( 99.58)\n","Epoch: [129][330/391]\tTime  0.069 ( 0.075)\tLoss 1.8861e-01 (1.4009e-01)\tAcc@1  92.97 ( 96.16)\tAcc@5 100.00 ( 99.59)\n","Epoch: [129][360/391]\tTime  0.087 ( 0.075)\tLoss 2.0692e-01 (1.4061e-01)\tAcc@1  92.97 ( 96.16)\tAcc@5 100.00 ( 99.58)\n","Epoch: [129][390/391]\tTime  0.048 ( 0.074)\tLoss 1.5201e-01 (1.4062e-01)\tAcc@1  96.25 ( 96.16)\tAcc@5 100.00 ( 99.57)\n","==> Train Accuracy: Acc@1 96.164 || Acc@5 99.574\n","==> Test Accuracy:  Acc@1 77.870 || Acc@5 94.180\n","==> 31.40 seconds to train this epoch\n","\n","\n","----- epoch: 130, lr: 0.0008000000000000003 -----\n","Epoch: [130][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.8920e-01 (1.8920e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n","Epoch: [130][ 30/391]\tTime  0.072 ( 0.081)\tLoss 1.0312e-01 (1.3574e-01)\tAcc@1  96.88 ( 95.92)\tAcc@5 100.00 ( 99.70)\n","Epoch: [130][ 60/391]\tTime  0.063 ( 0.077)\tLoss 1.2837e-01 (1.3366e-01)\tAcc@1  94.53 ( 96.07)\tAcc@5 100.00 ( 99.69)\n","Epoch: [130][ 90/391]\tTime  0.063 ( 0.076)\tLoss 1.0961e-01 (1.4047e-01)\tAcc@1  97.66 ( 95.82)\tAcc@5 100.00 ( 99.63)\n","Epoch: [130][120/391]\tTime  0.103 ( 0.075)\tLoss 2.0061e-01 (1.4539e-01)\tAcc@1  94.53 ( 95.75)\tAcc@5  99.22 ( 99.59)\n","Epoch: [130][150/391]\tTime  0.066 ( 0.075)\tLoss 1.2769e-01 (1.4513e-01)\tAcc@1  95.31 ( 95.82)\tAcc@5 100.00 ( 99.60)\n","Epoch: [130][180/391]\tTime  0.130 ( 0.076)\tLoss 1.0769e-01 (1.4229e-01)\tAcc@1  97.66 ( 95.99)\tAcc@5 100.00 ( 99.62)\n","Epoch: [130][210/391]\tTime  0.065 ( 0.076)\tLoss 1.2435e-01 (1.4111e-01)\tAcc@1  96.09 ( 96.04)\tAcc@5  99.22 ( 99.59)\n","Epoch: [130][240/391]\tTime  0.074 ( 0.076)\tLoss 1.0585e-01 (1.4098e-01)\tAcc@1  96.88 ( 96.01)\tAcc@5  99.22 ( 99.59)\n","Epoch: [130][270/391]\tTime  0.064 ( 0.076)\tLoss 1.0555e-01 (1.4163e-01)\tAcc@1  98.44 ( 95.97)\tAcc@5 100.00 ( 99.59)\n","Epoch: [130][300/391]\tTime  0.046 ( 0.075)\tLoss 1.2931e-01 (1.4327e-01)\tAcc@1  97.66 ( 95.90)\tAcc@5  99.22 ( 99.58)\n","Epoch: [130][330/391]\tTime  0.065 ( 0.075)\tLoss 1.1182e-01 (1.4319e-01)\tAcc@1  96.09 ( 95.91)\tAcc@5 100.00 ( 99.58)\n","Epoch: [130][360/391]\tTime  0.086 ( 0.075)\tLoss 1.0527e-01 (1.4216e-01)\tAcc@1  97.66 ( 95.95)\tAcc@5 100.00 ( 99.58)\n","Epoch: [130][390/391]\tTime  0.047 ( 0.075)\tLoss 1.3616e-01 (1.4232e-01)\tAcc@1  96.25 ( 95.95)\tAcc@5 100.00 ( 99.58)\n","==> Train Accuracy: Acc@1 95.952 || Acc@5 99.584\n","==> Test Accuracy:  Acc@1 78.010 || Acc@5 94.320\n","==> 31.45 seconds to train this epoch\n","\n","\n","----- epoch: 131, lr: 0.0008000000000000003 -----\n","Epoch: [131][  0/391]\tTime  0.258 ( 0.258)\tLoss 1.0491e-01 (1.0491e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n","Epoch: [131][ 30/391]\tTime  0.073 ( 0.078)\tLoss 1.0729e-01 (1.2834e-01)\tAcc@1  96.88 ( 96.47)\tAcc@5 100.00 ( 99.70)\n","Epoch: [131][ 60/391]\tTime  0.062 ( 0.075)\tLoss 8.8162e-02 (1.2985e-01)\tAcc@1  96.09 ( 96.48)\tAcc@5 100.00 ( 99.71)\n","Epoch: [131][ 90/391]\tTime  0.072 ( 0.074)\tLoss 1.9689e-01 (1.3664e-01)\tAcc@1  92.97 ( 96.21)\tAcc@5  99.22 ( 99.67)\n","Epoch: [131][120/391]\tTime  0.073 ( 0.074)\tLoss 1.0448e-01 (1.3338e-01)\tAcc@1  96.09 ( 96.42)\tAcc@5 100.00 ( 99.64)\n","Epoch: [131][150/391]\tTime  0.065 ( 0.074)\tLoss 9.4398e-02 (1.3185e-01)\tAcc@1  98.44 ( 96.47)\tAcc@5 100.00 ( 99.67)\n","Epoch: [131][180/391]\tTime  0.081 ( 0.074)\tLoss 1.7138e-01 (1.3491e-01)\tAcc@1  95.31 ( 96.33)\tAcc@5 100.00 ( 99.68)\n","Epoch: [131][210/391]\tTime  0.061 ( 0.073)\tLoss 1.9684e-01 (1.3641e-01)\tAcc@1  93.75 ( 96.26)\tAcc@5  99.22 ( 99.68)\n","Epoch: [131][240/391]\tTime  0.087 ( 0.073)\tLoss 7.2515e-02 (1.3605e-01)\tAcc@1  97.66 ( 96.29)\tAcc@5 100.00 ( 99.68)\n","Epoch: [131][270/391]\tTime  0.053 ( 0.073)\tLoss 1.2247e-01 (1.3599e-01)\tAcc@1  98.44 ( 96.29)\tAcc@5  99.22 ( 99.67)\n","Epoch: [131][300/391]\tTime  0.078 ( 0.073)\tLoss 1.9623e-01 (1.3760e-01)\tAcc@1  92.97 ( 96.22)\tAcc@5 100.00 ( 99.65)\n","Epoch: [131][330/391]\tTime  0.058 ( 0.073)\tLoss 1.4819e-01 (1.3767e-01)\tAcc@1  96.88 ( 96.21)\tAcc@5  98.44 ( 99.63)\n","Epoch: [131][360/391]\tTime  0.062 ( 0.073)\tLoss 1.1844e-01 (1.3698e-01)\tAcc@1  97.66 ( 96.21)\tAcc@5 100.00 ( 99.64)\n","Epoch: [131][390/391]\tTime  0.048 ( 0.073)\tLoss 1.4433e-01 (1.3656e-01)\tAcc@1  96.25 ( 96.22)\tAcc@5 100.00 ( 99.65)\n","==> Train Accuracy: Acc@1 96.218 || Acc@5 99.648\n","==> Test Accuracy:  Acc@1 78.020 || Acc@5 94.130\n","==> 30.85 seconds to train this epoch\n","\n","\n","----- epoch: 132, lr: 0.0008000000000000003 -----\n","Epoch: [132][  0/391]\tTime  0.291 ( 0.291)\tLoss 2.2476e-01 (2.2476e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n","Epoch: [132][ 30/391]\tTime  0.069 ( 0.079)\tLoss 1.3976e-01 (1.3504e-01)\tAcc@1  96.88 ( 96.50)\tAcc@5  98.44 ( 99.60)\n","Epoch: [132][ 60/391]\tTime  0.057 ( 0.076)\tLoss 1.7331e-01 (1.4208e-01)\tAcc@1  94.53 ( 96.20)\tAcc@5  99.22 ( 99.55)\n","Epoch: [132][ 90/391]\tTime  0.066 ( 0.076)\tLoss 1.4280e-01 (1.4361e-01)\tAcc@1  97.66 ( 96.08)\tAcc@5 100.00 ( 99.54)\n","Epoch: [132][120/391]\tTime  0.066 ( 0.075)\tLoss 1.7286e-01 (1.4128e-01)\tAcc@1  97.66 ( 96.20)\tAcc@5  98.44 ( 99.57)\n","Epoch: [132][150/391]\tTime  0.081 ( 0.074)\tLoss 1.6117e-01 (1.4065e-01)\tAcc@1  97.66 ( 96.15)\tAcc@5  98.44 ( 99.59)\n","Epoch: [132][180/391]\tTime  0.062 ( 0.074)\tLoss 1.8382e-01 (1.3821e-01)\tAcc@1  95.31 ( 96.18)\tAcc@5  99.22 ( 99.59)\n","Epoch: [132][210/391]\tTime  0.077 ( 0.074)\tLoss 5.0455e-02 (1.3853e-01)\tAcc@1  99.22 ( 96.19)\tAcc@5 100.00 ( 99.60)\n","Epoch: [132][240/391]\tTime  0.073 ( 0.073)\tLoss 2.6748e-01 (1.3924e-01)\tAcc@1  92.19 ( 96.17)\tAcc@5  98.44 ( 99.62)\n","Epoch: [132][270/391]\tTime  0.068 ( 0.073)\tLoss 2.1311e-01 (1.3944e-01)\tAcc@1  92.97 ( 96.17)\tAcc@5  99.22 ( 99.60)\n","Epoch: [132][300/391]\tTime  0.069 ( 0.073)\tLoss 2.2278e-01 (1.3976e-01)\tAcc@1  92.19 ( 96.16)\tAcc@5  99.22 ( 99.61)\n","Epoch: [132][330/391]\tTime  0.077 ( 0.073)\tLoss 1.8749e-01 (1.4034e-01)\tAcc@1  95.31 ( 96.14)\tAcc@5  98.44 ( 99.60)\n","Epoch: [132][360/391]\tTime  0.091 ( 0.073)\tLoss 9.8454e-02 (1.3955e-01)\tAcc@1  97.66 ( 96.17)\tAcc@5 100.00 ( 99.61)\n","Epoch: [132][390/391]\tTime  0.039 ( 0.073)\tLoss 2.1040e-01 (1.3799e-01)\tAcc@1  95.00 ( 96.22)\tAcc@5 100.00 ( 99.61)\n","==> Train Accuracy: Acc@1 96.224 || Acc@5 99.614\n","==> Test Accuracy:  Acc@1 77.620 || Acc@5 94.120\n","==> 30.84 seconds to train this epoch\n","\n","\n","----- epoch: 133, lr: 0.0008000000000000003 -----\n","Epoch: [133][  0/391]\tTime  0.260 ( 0.260)\tLoss 2.6186e-01 (2.6186e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  97.66 ( 97.66)\n","Epoch: [133][ 30/391]\tTime  0.055 ( 0.081)\tLoss 1.1891e-01 (1.4570e-01)\tAcc@1  96.09 ( 96.07)\tAcc@5  99.22 ( 99.37)\n","Epoch: [133][ 60/391]\tTime  0.071 ( 0.078)\tLoss 1.1358e-01 (1.3586e-01)\tAcc@1  97.66 ( 96.40)\tAcc@5 100.00 ( 99.49)\n","Epoch: [133][ 90/391]\tTime  0.061 ( 0.076)\tLoss 1.1841e-01 (1.3522e-01)\tAcc@1  96.88 ( 96.46)\tAcc@5 100.00 ( 99.52)\n","Epoch: [133][120/391]\tTime  0.061 ( 0.075)\tLoss 1.1029e-01 (1.3562e-01)\tAcc@1  96.88 ( 96.38)\tAcc@5 100.00 ( 99.52)\n","Epoch: [133][150/391]\tTime  0.063 ( 0.075)\tLoss 1.1363e-01 (1.3512e-01)\tAcc@1  97.66 ( 96.37)\tAcc@5  99.22 ( 99.55)\n","Epoch: [133][180/391]\tTime  0.091 ( 0.075)\tLoss 1.5766e-01 (1.3363e-01)\tAcc@1  96.88 ( 96.41)\tAcc@5  99.22 ( 99.56)\n","Epoch: [133][210/391]\tTime  0.092 ( 0.075)\tLoss 2.0662e-01 (1.3338e-01)\tAcc@1  96.88 ( 96.41)\tAcc@5  99.22 ( 99.56)\n","Epoch: [133][240/391]\tTime  0.060 ( 0.074)\tLoss 1.9393e-01 (1.3222e-01)\tAcc@1  94.53 ( 96.45)\tAcc@5 100.00 ( 99.58)\n","Epoch: [133][270/391]\tTime  0.065 ( 0.074)\tLoss 1.9072e-01 (1.3417e-01)\tAcc@1  96.09 ( 96.41)\tAcc@5  96.88 ( 99.54)\n","Epoch: [133][300/391]\tTime  0.101 ( 0.074)\tLoss 1.5054e-01 (1.3408e-01)\tAcc@1  97.66 ( 96.38)\tAcc@5  99.22 ( 99.55)\n","Epoch: [133][330/391]\tTime  0.062 ( 0.074)\tLoss 1.6367e-01 (1.3605e-01)\tAcc@1  95.31 ( 96.33)\tAcc@5 100.00 ( 99.54)\n","Epoch: [133][360/391]\tTime  0.065 ( 0.074)\tLoss 1.4161e-01 (1.3595e-01)\tAcc@1  96.09 ( 96.34)\tAcc@5  99.22 ( 99.55)\n","Epoch: [133][390/391]\tTime  0.048 ( 0.074)\tLoss 3.2239e-01 (1.3616e-01)\tAcc@1  90.00 ( 96.31)\tAcc@5 100.00 ( 99.55)\n","==> Train Accuracy: Acc@1 96.310 || Acc@5 99.548\n","==> Test Accuracy:  Acc@1 77.880 || Acc@5 94.110\n","==> 31.12 seconds to train this epoch\n","\n","\n","----- epoch: 134, lr: 0.0008000000000000003 -----\n","Epoch: [134][  0/391]\tTime  0.267 ( 0.267)\tLoss 9.2069e-02 (9.2069e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [134][ 30/391]\tTime  0.051 ( 0.080)\tLoss 1.3673e-01 (1.3399e-01)\tAcc@1  96.88 ( 96.45)\tAcc@5  99.22 ( 99.70)\n","Epoch: [134][ 60/391]\tTime  0.070 ( 0.076)\tLoss 9.8724e-02 (1.3620e-01)\tAcc@1  96.09 ( 96.32)\tAcc@5 100.00 ( 99.59)\n","Epoch: [134][ 90/391]\tTime  0.088 ( 0.075)\tLoss 3.2960e-02 (1.3605e-01)\tAcc@1  99.22 ( 96.37)\tAcc@5 100.00 ( 99.62)\n","Epoch: [134][120/391]\tTime  0.073 ( 0.074)\tLoss 8.7108e-02 (1.3663e-01)\tAcc@1  96.88 ( 96.33)\tAcc@5  99.22 ( 99.62)\n","Epoch: [134][150/391]\tTime  0.112 ( 0.075)\tLoss 1.0535e-01 (1.3589e-01)\tAcc@1  96.88 ( 96.31)\tAcc@5 100.00 ( 99.63)\n","Epoch: [134][180/391]\tTime  0.064 ( 0.074)\tLoss 1.2776e-01 (1.3626e-01)\tAcc@1  96.88 ( 96.31)\tAcc@5  99.22 ( 99.63)\n","Epoch: [134][210/391]\tTime  0.065 ( 0.074)\tLoss 1.4099e-01 (1.3557e-01)\tAcc@1  96.09 ( 96.32)\tAcc@5  99.22 ( 99.62)\n","Epoch: [134][240/391]\tTime  0.072 ( 0.074)\tLoss 8.6619e-02 (1.3465e-01)\tAcc@1  96.09 ( 96.30)\tAcc@5 100.00 ( 99.63)\n","Epoch: [134][270/391]\tTime  0.069 ( 0.074)\tLoss 1.4939e-01 (1.3479e-01)\tAcc@1  96.09 ( 96.31)\tAcc@5  99.22 ( 99.62)\n","Epoch: [134][300/391]\tTime  0.055 ( 0.074)\tLoss 1.2591e-01 (1.3316e-01)\tAcc@1  97.66 ( 96.38)\tAcc@5  99.22 ( 99.63)\n","Epoch: [134][330/391]\tTime  0.057 ( 0.074)\tLoss 1.3883e-01 (1.3183e-01)\tAcc@1  94.53 ( 96.43)\tAcc@5 100.00 ( 99.63)\n","Epoch: [134][360/391]\tTime  0.071 ( 0.074)\tLoss 1.9883e-01 (1.3251e-01)\tAcc@1  93.75 ( 96.38)\tAcc@5  98.44 ( 99.62)\n","Epoch: [134][390/391]\tTime  0.048 ( 0.074)\tLoss 1.1151e-01 (1.3292e-01)\tAcc@1  96.25 ( 96.35)\tAcc@5 100.00 ( 99.62)\n","==> Train Accuracy: Acc@1 96.354 || Acc@5 99.618\n","==> Test Accuracy:  Acc@1 78.080 || Acc@5 94.130\n","==> 31.11 seconds to train this epoch\n","\n","\n","----- epoch: 135, lr: 0.0008000000000000003 -----\n","Epoch: [135][  0/391]\tTime  0.265 ( 0.265)\tLoss 5.2914e-02 (5.2914e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n","Epoch: [135][ 30/391]\tTime  0.075 ( 0.079)\tLoss 1.0227e-01 (1.2850e-01)\tAcc@1  96.09 ( 96.47)\tAcc@5 100.00 ( 99.77)\n","Epoch: [135][ 60/391]\tTime  0.076 ( 0.076)\tLoss 1.4450e-01 (1.3126e-01)\tAcc@1  95.31 ( 96.35)\tAcc@5 100.00 ( 99.74)\n","Epoch: [135][ 90/391]\tTime  0.101 ( 0.075)\tLoss 2.1216e-01 (1.3269e-01)\tAcc@1  92.19 ( 96.32)\tAcc@5 100.00 ( 99.70)\n","Epoch: [135][120/391]\tTime  0.052 ( 0.075)\tLoss 8.7556e-02 (1.3393e-01)\tAcc@1  98.44 ( 96.20)\tAcc@5 100.00 ( 99.72)\n","Epoch: [135][150/391]\tTime  0.100 ( 0.075)\tLoss 1.1525e-01 (1.3462e-01)\tAcc@1  96.88 ( 96.20)\tAcc@5  99.22 ( 99.66)\n","Epoch: [135][180/391]\tTime  0.066 ( 0.074)\tLoss 1.1036e-01 (1.3503e-01)\tAcc@1  95.31 ( 96.13)\tAcc@5 100.00 ( 99.66)\n","Epoch: [135][210/391]\tTime  0.102 ( 0.074)\tLoss 1.3276e-01 (1.3468e-01)\tAcc@1  94.53 ( 96.13)\tAcc@5 100.00 ( 99.65)\n","Epoch: [135][240/391]\tTime  0.070 ( 0.074)\tLoss 1.1367e-01 (1.3330e-01)\tAcc@1  96.88 ( 96.15)\tAcc@5 100.00 ( 99.67)\n","Epoch: [135][270/391]\tTime  0.069 ( 0.074)\tLoss 9.9509e-02 (1.3253e-01)\tAcc@1  96.88 ( 96.18)\tAcc@5 100.00 ( 99.68)\n","Epoch: [135][300/391]\tTime  0.084 ( 0.073)\tLoss 1.6408e-01 (1.3333e-01)\tAcc@1  94.53 ( 96.19)\tAcc@5 100.00 ( 99.66)\n","Epoch: [135][330/391]\tTime  0.056 ( 0.073)\tLoss 1.3868e-01 (1.3377e-01)\tAcc@1  96.09 ( 96.20)\tAcc@5  99.22 ( 99.64)\n","Epoch: [135][360/391]\tTime  0.075 ( 0.073)\tLoss 1.3026e-01 (1.3350e-01)\tAcc@1  98.44 ( 96.23)\tAcc@5 100.00 ( 99.65)\n","Epoch: [135][390/391]\tTime  0.048 ( 0.073)\tLoss 2.0062e-01 (1.3359e-01)\tAcc@1  93.75 ( 96.23)\tAcc@5 100.00 ( 99.65)\n","==> Train Accuracy: Acc@1 96.234 || Acc@5 99.650\n","==> Test Accuracy:  Acc@1 78.180 || Acc@5 94.120\n","==> 30.76 seconds to train this epoch\n","\n","\n","----- epoch: 136, lr: 0.0008000000000000003 -----\n","Epoch: [136][  0/391]\tTime  0.273 ( 0.273)\tLoss 1.2400e-01 (1.2400e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [136][ 30/391]\tTime  0.078 ( 0.077)\tLoss 9.3413e-02 (1.2527e-01)\tAcc@1  97.66 ( 96.65)\tAcc@5 100.00 ( 99.60)\n","Epoch: [136][ 60/391]\tTime  0.060 ( 0.076)\tLoss 1.4937e-01 (1.2711e-01)\tAcc@1  94.53 ( 96.62)\tAcc@5 100.00 ( 99.53)\n","Epoch: [136][ 90/391]\tTime  0.059 ( 0.075)\tLoss 7.7964e-02 (1.2778e-01)\tAcc@1  98.44 ( 96.57)\tAcc@5 100.00 ( 99.57)\n","Epoch: [136][120/391]\tTime  0.061 ( 0.074)\tLoss 2.3811e-01 (1.2910e-01)\tAcc@1  93.75 ( 96.47)\tAcc@5  99.22 ( 99.61)\n","Epoch: [136][150/391]\tTime  0.054 ( 0.073)\tLoss 9.0333e-02 (1.2951e-01)\tAcc@1  97.66 ( 96.48)\tAcc@5 100.00 ( 99.60)\n","Epoch: [136][180/391]\tTime  0.071 ( 0.073)\tLoss 7.8984e-02 (1.3064e-01)\tAcc@1  99.22 ( 96.47)\tAcc@5 100.00 ( 99.62)\n","Epoch: [136][210/391]\tTime  0.058 ( 0.073)\tLoss 1.2890e-01 (1.2988e-01)\tAcc@1  95.31 ( 96.47)\tAcc@5 100.00 ( 99.62)\n","Epoch: [136][240/391]\tTime  0.067 ( 0.073)\tLoss 1.5107e-01 (1.3036e-01)\tAcc@1  95.31 ( 96.47)\tAcc@5 100.00 ( 99.63)\n","Epoch: [136][270/391]\tTime  0.101 ( 0.073)\tLoss 1.3035e-01 (1.3034e-01)\tAcc@1  96.88 ( 96.48)\tAcc@5 100.00 ( 99.64)\n","Epoch: [136][300/391]\tTime  0.084 ( 0.073)\tLoss 2.1212e-01 (1.3212e-01)\tAcc@1  94.53 ( 96.39)\tAcc@5 100.00 ( 99.64)\n","Epoch: [136][330/391]\tTime  0.061 ( 0.073)\tLoss 6.7088e-02 (1.3142e-01)\tAcc@1  98.44 ( 96.40)\tAcc@5 100.00 ( 99.65)\n","Epoch: [136][360/391]\tTime  0.065 ( 0.073)\tLoss 1.3222e-01 (1.3217e-01)\tAcc@1  95.31 ( 96.36)\tAcc@5 100.00 ( 99.64)\n","Epoch: [136][390/391]\tTime  0.047 ( 0.073)\tLoss 1.7745e-01 (1.3269e-01)\tAcc@1  96.25 ( 96.36)\tAcc@5  98.75 ( 99.63)\n","==> Train Accuracy: Acc@1 96.356 || Acc@5 99.634\n","==> Test Accuracy:  Acc@1 78.080 || Acc@5 94.230\n","==> 30.58 seconds to train this epoch\n","\n","\n","----- epoch: 137, lr: 0.0008000000000000003 -----\n","Epoch: [137][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.0108e-01 (1.0108e-01)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [137][ 30/391]\tTime  0.059 ( 0.078)\tLoss 6.0867e-02 (1.3156e-01)\tAcc@1  98.44 ( 96.24)\tAcc@5 100.00 ( 99.67)\n","Epoch: [137][ 60/391]\tTime  0.055 ( 0.075)\tLoss 1.3462e-01 (1.3190e-01)\tAcc@1  95.31 ( 96.29)\tAcc@5 100.00 ( 99.64)\n","Epoch: [137][ 90/391]\tTime  0.064 ( 0.074)\tLoss 7.0188e-02 (1.2923e-01)\tAcc@1  96.88 ( 96.46)\tAcc@5 100.00 ( 99.63)\n","Epoch: [137][120/391]\tTime  0.072 ( 0.073)\tLoss 1.6111e-01 (1.3162e-01)\tAcc@1  95.31 ( 96.36)\tAcc@5 100.00 ( 99.63)\n","Epoch: [137][150/391]\tTime  0.082 ( 0.074)\tLoss 1.8889e-01 (1.3638e-01)\tAcc@1  96.88 ( 96.25)\tAcc@5  99.22 ( 99.57)\n","Epoch: [137][180/391]\tTime  0.080 ( 0.073)\tLoss 1.8258e-01 (1.3766e-01)\tAcc@1  93.75 ( 96.20)\tAcc@5  99.22 ( 99.56)\n","Epoch: [137][210/391]\tTime  0.073 ( 0.073)\tLoss 1.0239e-01 (1.3561e-01)\tAcc@1  97.66 ( 96.25)\tAcc@5  99.22 ( 99.57)\n","Epoch: [137][240/391]\tTime  0.060 ( 0.073)\tLoss 7.9784e-02 (1.3630e-01)\tAcc@1  98.44 ( 96.23)\tAcc@5 100.00 ( 99.56)\n","Epoch: [137][270/391]\tTime  0.064 ( 0.073)\tLoss 1.8741e-01 (1.3624e-01)\tAcc@1  96.88 ( 96.24)\tAcc@5 100.00 ( 99.57)\n","Epoch: [137][300/391]\tTime  0.078 ( 0.073)\tLoss 1.2822e-01 (1.3693e-01)\tAcc@1  96.88 ( 96.22)\tAcc@5  99.22 ( 99.57)\n","Epoch: [137][330/391]\tTime  0.067 ( 0.073)\tLoss 1.4474e-01 (1.3580e-01)\tAcc@1  96.09 ( 96.22)\tAcc@5 100.00 ( 99.59)\n","Epoch: [137][360/391]\tTime  0.063 ( 0.073)\tLoss 1.4670e-01 (1.3631e-01)\tAcc@1  96.88 ( 96.22)\tAcc@5 100.00 ( 99.60)\n","Epoch: [137][390/391]\tTime  0.047 ( 0.073)\tLoss 2.0070e-01 (1.3684e-01)\tAcc@1  93.75 ( 96.20)\tAcc@5 100.00 ( 99.60)\n","==> Train Accuracy: Acc@1 96.196 || Acc@5 99.604\n","==> Test Accuracy:  Acc@1 77.770 || Acc@5 94.290\n","==> 30.64 seconds to train this epoch\n","\n","\n","----- epoch: 138, lr: 0.0008000000000000003 -----\n","Epoch: [138][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.7051e-01 (1.7051e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [138][ 30/391]\tTime  0.075 ( 0.076)\tLoss 1.8846e-01 (1.2757e-01)\tAcc@1  92.97 ( 96.35)\tAcc@5 100.00 ( 99.70)\n","Epoch: [138][ 60/391]\tTime  0.077 ( 0.073)\tLoss 9.3576e-02 (1.3008e-01)\tAcc@1  96.88 ( 96.43)\tAcc@5 100.00 ( 99.60)\n","Epoch: [138][ 90/391]\tTime  0.061 ( 0.073)\tLoss 1.0413e-01 (1.2988e-01)\tAcc@1  96.88 ( 96.37)\tAcc@5 100.00 ( 99.61)\n","Epoch: [138][120/391]\tTime  0.055 ( 0.072)\tLoss 3.7937e-02 (1.3068e-01)\tAcc@1  99.22 ( 96.38)\tAcc@5 100.00 ( 99.61)\n","Epoch: [138][150/391]\tTime  0.050 ( 0.072)\tLoss 2.3886e-01 (1.3132e-01)\tAcc@1  92.97 ( 96.36)\tAcc@5  98.44 ( 99.61)\n","Epoch: [138][180/391]\tTime  0.068 ( 0.072)\tLoss 6.7196e-02 (1.2841e-01)\tAcc@1  98.44 ( 96.49)\tAcc@5 100.00 ( 99.64)\n","Epoch: [138][210/391]\tTime  0.099 ( 0.072)\tLoss 1.3504e-01 (1.2913e-01)\tAcc@1  95.31 ( 96.44)\tAcc@5 100.00 ( 99.64)\n","Epoch: [138][240/391]\tTime  0.067 ( 0.072)\tLoss 2.0006e-01 (1.2903e-01)\tAcc@1  92.97 ( 96.45)\tAcc@5  98.44 ( 99.63)\n","Epoch: [138][270/391]\tTime  0.054 ( 0.072)\tLoss 8.8682e-02 (1.2902e-01)\tAcc@1  97.66 ( 96.44)\tAcc@5  99.22 ( 99.63)\n","Epoch: [138][300/391]\tTime  0.070 ( 0.072)\tLoss 1.2334e-01 (1.2929e-01)\tAcc@1  96.88 ( 96.42)\tAcc@5  99.22 ( 99.63)\n","Epoch: [138][330/391]\tTime  0.117 ( 0.072)\tLoss 1.0775e-01 (1.2906e-01)\tAcc@1  96.88 ( 96.44)\tAcc@5 100.00 ( 99.62)\n","Epoch: [138][360/391]\tTime  0.078 ( 0.072)\tLoss 1.4498e-01 (1.2942e-01)\tAcc@1  96.09 ( 96.42)\tAcc@5  99.22 ( 99.62)\n","Epoch: [138][390/391]\tTime  0.048 ( 0.072)\tLoss 1.1815e-01 (1.2954e-01)\tAcc@1  98.75 ( 96.44)\tAcc@5 100.00 ( 99.62)\n","==> Train Accuracy: Acc@1 96.438 || Acc@5 99.622\n","==> Test Accuracy:  Acc@1 77.850 || Acc@5 94.210\n","==> 30.34 seconds to train this epoch\n","\n","\n","----- epoch: 139, lr: 0.0008000000000000003 -----\n","Epoch: [139][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.7171e-01 (1.7171e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [139][ 30/391]\tTime  0.063 ( 0.077)\tLoss 1.6555e-01 (1.2278e-01)\tAcc@1  96.09 ( 96.52)\tAcc@5  99.22 ( 99.67)\n","Epoch: [139][ 60/391]\tTime  0.058 ( 0.075)\tLoss 3.7503e-02 (1.2117e-01)\tAcc@1 100.00 ( 96.59)\tAcc@5 100.00 ( 99.73)\n","Epoch: [139][ 90/391]\tTime  0.082 ( 0.073)\tLoss 9.4532e-02 (1.2495e-01)\tAcc@1  98.44 ( 96.51)\tAcc@5 100.00 ( 99.72)\n","Epoch: [139][120/391]\tTime  0.055 ( 0.073)\tLoss 8.3413e-02 (1.2655e-01)\tAcc@1  97.66 ( 96.50)\tAcc@5 100.00 ( 99.66)\n","Epoch: [139][150/391]\tTime  0.081 ( 0.073)\tLoss 1.5478e-01 (1.2591e-01)\tAcc@1  96.09 ( 96.52)\tAcc@5 100.00 ( 99.68)\n","Epoch: [139][180/391]\tTime  0.069 ( 0.073)\tLoss 1.9490e-01 (1.2477e-01)\tAcc@1  94.53 ( 96.54)\tAcc@5  99.22 ( 99.69)\n","Epoch: [139][210/391]\tTime  0.061 ( 0.073)\tLoss 4.5089e-02 (1.2494e-01)\tAcc@1 100.00 ( 96.56)\tAcc@5 100.00 ( 99.69)\n","Epoch: [139][240/391]\tTime  0.063 ( 0.073)\tLoss 8.6029e-02 (1.2568e-01)\tAcc@1  98.44 ( 96.56)\tAcc@5 100.00 ( 99.66)\n","Epoch: [139][270/391]\tTime  0.075 ( 0.073)\tLoss 1.2568e-01 (1.2655e-01)\tAcc@1  97.66 ( 96.54)\tAcc@5 100.00 ( 99.65)\n","Epoch: [139][300/391]\tTime  0.073 ( 0.073)\tLoss 1.2962e-01 (1.2674e-01)\tAcc@1  96.09 ( 96.53)\tAcc@5  99.22 ( 99.65)\n","Epoch: [139][330/391]\tTime  0.064 ( 0.073)\tLoss 1.0056e-01 (1.2662e-01)\tAcc@1  98.44 ( 96.53)\tAcc@5 100.00 ( 99.65)\n","Epoch: [139][360/391]\tTime  0.075 ( 0.073)\tLoss 1.9600e-01 (1.2662e-01)\tAcc@1  95.31 ( 96.53)\tAcc@5  99.22 ( 99.64)\n","Epoch: [139][390/391]\tTime  0.048 ( 0.073)\tLoss 9.8271e-02 (1.2641e-01)\tAcc@1  98.75 ( 96.56)\tAcc@5 100.00 ( 99.64)\n","==> Train Accuracy: Acc@1 96.556 || Acc@5 99.644\n","==> Test Accuracy:  Acc@1 77.970 || Acc@5 94.130\n","==> 30.74 seconds to train this epoch\n","\n","\n","----- epoch: 140, lr: 0.0008000000000000003 -----\n","Epoch: [140][  0/391]\tTime  0.279 ( 0.279)\tLoss 6.7370e-02 (6.7370e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [140][ 30/391]\tTime  0.046 ( 0.078)\tLoss 1.1305e-01 (1.2372e-01)\tAcc@1  96.88 ( 96.65)\tAcc@5  99.22 ( 99.57)\n","Epoch: [140][ 60/391]\tTime  0.080 ( 0.075)\tLoss 1.2112e-01 (1.2679e-01)\tAcc@1  95.31 ( 96.50)\tAcc@5 100.00 ( 99.63)\n","Epoch: [140][ 90/391]\tTime  0.078 ( 0.074)\tLoss 6.9543e-02 (1.2265e-01)\tAcc@1  98.44 ( 96.57)\tAcc@5 100.00 ( 99.67)\n","Epoch: [140][120/391]\tTime  0.053 ( 0.074)\tLoss 9.4830e-02 (1.2137e-01)\tAcc@1  96.88 ( 96.60)\tAcc@5 100.00 ( 99.70)\n","Epoch: [140][150/391]\tTime  0.071 ( 0.074)\tLoss 1.4792e-01 (1.2401e-01)\tAcc@1  95.31 ( 96.55)\tAcc@5  99.22 ( 99.68)\n","Epoch: [140][180/391]\tTime  0.069 ( 0.073)\tLoss 1.8914e-01 (1.2317e-01)\tAcc@1  95.31 ( 96.61)\tAcc@5  99.22 ( 99.69)\n","Epoch: [140][210/391]\tTime  0.068 ( 0.073)\tLoss 1.6294e-01 (1.2356e-01)\tAcc@1  96.09 ( 96.60)\tAcc@5  99.22 ( 99.67)\n","Epoch: [140][240/391]\tTime  0.064 ( 0.073)\tLoss 4.3606e-02 (1.2251e-01)\tAcc@1 100.00 ( 96.60)\tAcc@5 100.00 ( 99.69)\n","Epoch: [140][270/391]\tTime  0.067 ( 0.073)\tLoss 1.3919e-01 (1.2306e-01)\tAcc@1  98.44 ( 96.59)\tAcc@5  98.44 ( 99.69)\n","Epoch: [140][300/391]\tTime  0.107 ( 0.073)\tLoss 1.4777e-01 (1.2404e-01)\tAcc@1  96.88 ( 96.54)\tAcc@5  98.44 ( 99.68)\n","Epoch: [140][330/391]\tTime  0.100 ( 0.073)\tLoss 1.5651e-01 (1.2416e-01)\tAcc@1  95.31 ( 96.52)\tAcc@5  99.22 ( 99.68)\n","Epoch: [140][360/391]\tTime  0.097 ( 0.073)\tLoss 1.2177e-01 (1.2357e-01)\tAcc@1  96.09 ( 96.53)\tAcc@5 100.00 ( 99.69)\n","Epoch: [140][390/391]\tTime  0.048 ( 0.073)\tLoss 8.4139e-02 (1.2418e-01)\tAcc@1  97.50 ( 96.50)\tAcc@5 100.00 ( 99.69)\n","==> Train Accuracy: Acc@1 96.502 || Acc@5 99.686\n","==> Test Accuracy:  Acc@1 78.100 || Acc@5 94.130\n","==> 30.79 seconds to train this epoch\n","\n","\n","----- epoch: 141, lr: 0.0008000000000000003 -----\n","Epoch: [141][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.1333e-01 (1.1333e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [141][ 30/391]\tTime  0.059 ( 0.079)\tLoss 9.1896e-02 (1.1099e-01)\tAcc@1  96.88 ( 97.20)\tAcc@5 100.00 ( 99.77)\n","Epoch: [141][ 60/391]\tTime  0.062 ( 0.076)\tLoss 1.0753e-01 (1.1722e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 ( 99.72)\n","Epoch: [141][ 90/391]\tTime  0.088 ( 0.075)\tLoss 1.3086e-01 (1.2402e-01)\tAcc@1  96.88 ( 96.67)\tAcc@5 100.00 ( 99.69)\n","Epoch: [141][120/391]\tTime  0.065 ( 0.074)\tLoss 2.2264e-01 (1.2486e-01)\tAcc@1  92.97 ( 96.63)\tAcc@5 100.00 ( 99.70)\n","Epoch: [141][150/391]\tTime  0.123 ( 0.075)\tLoss 1.9710e-01 (1.2383e-01)\tAcc@1  94.53 ( 96.66)\tAcc@5  98.44 ( 99.71)\n","Epoch: [141][180/391]\tTime  0.071 ( 0.074)\tLoss 1.1238e-01 (1.2208e-01)\tAcc@1  98.44 ( 96.73)\tAcc@5  99.22 ( 99.71)\n","Epoch: [141][210/391]\tTime  0.064 ( 0.074)\tLoss 1.5150e-01 (1.2247e-01)\tAcc@1  96.88 ( 96.67)\tAcc@5  99.22 ( 99.69)\n","Epoch: [141][240/391]\tTime  0.081 ( 0.074)\tLoss 1.4592e-01 (1.2183e-01)\tAcc@1  96.09 ( 96.70)\tAcc@5  99.22 ( 99.68)\n","Epoch: [141][270/391]\tTime  0.049 ( 0.074)\tLoss 1.0584e-01 (1.2332e-01)\tAcc@1  97.66 ( 96.67)\tAcc@5 100.00 ( 99.67)\n","Epoch: [141][300/391]\tTime  0.060 ( 0.074)\tLoss 5.6555e-02 (1.2379e-01)\tAcc@1  99.22 ( 96.65)\tAcc@5 100.00 ( 99.66)\n","Epoch: [141][330/391]\tTime  0.096 ( 0.074)\tLoss 1.7983e-01 (1.2422e-01)\tAcc@1  96.09 ( 96.63)\tAcc@5 100.00 ( 99.66)\n","Epoch: [141][360/391]\tTime  0.076 ( 0.073)\tLoss 1.4838e-01 (1.2507e-01)\tAcc@1  96.09 ( 96.59)\tAcc@5 100.00 ( 99.66)\n","Epoch: [141][390/391]\tTime  0.048 ( 0.073)\tLoss 1.7715e-01 (1.2584e-01)\tAcc@1  95.00 ( 96.57)\tAcc@5 100.00 ( 99.66)\n","==> Train Accuracy: Acc@1 96.570 || Acc@5 99.656\n","==> Test Accuracy:  Acc@1 77.900 || Acc@5 94.040\n","==> 30.87 seconds to train this epoch\n","\n","\n","----- epoch: 142, lr: 0.0008000000000000003 -----\n","Epoch: [142][  0/391]\tTime  0.270 ( 0.270)\tLoss 8.4365e-02 (8.4365e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5  99.22 ( 99.22)\n","Epoch: [142][ 30/391]\tTime  0.075 ( 0.079)\tLoss 1.5961e-01 (1.3397e-01)\tAcc@1  96.88 ( 96.12)\tAcc@5 100.00 ( 99.57)\n","Epoch: [142][ 60/391]\tTime  0.072 ( 0.077)\tLoss 1.7095e-01 (1.2852e-01)\tAcc@1  96.09 ( 96.41)\tAcc@5  98.44 ( 99.56)\n","Epoch: [142][ 90/391]\tTime  0.065 ( 0.076)\tLoss 1.2775e-01 (1.2800e-01)\tAcc@1  96.88 ( 96.45)\tAcc@5 100.00 ( 99.58)\n","Epoch: [142][120/391]\tTime  0.075 ( 0.075)\tLoss 9.5126e-02 (1.2768e-01)\tAcc@1  96.88 ( 96.50)\tAcc@5 100.00 ( 99.59)\n","Epoch: [142][150/391]\tTime  0.089 ( 0.075)\tLoss 1.7163e-01 (1.2776e-01)\tAcc@1  96.88 ( 96.46)\tAcc@5 100.00 ( 99.59)\n","Epoch: [142][180/391]\tTime  0.068 ( 0.075)\tLoss 1.7083e-01 (1.2846e-01)\tAcc@1  93.75 ( 96.41)\tAcc@5 100.00 ( 99.59)\n","Epoch: [142][210/391]\tTime  0.080 ( 0.075)\tLoss 1.7045e-01 (1.3037e-01)\tAcc@1  96.09 ( 96.36)\tAcc@5 100.00 ( 99.59)\n","Epoch: [142][240/391]\tTime  0.067 ( 0.075)\tLoss 1.6653e-01 (1.3026e-01)\tAcc@1  96.09 ( 96.40)\tAcc@5 100.00 ( 99.59)\n","Epoch: [142][270/391]\tTime  0.096 ( 0.075)\tLoss 1.2450e-01 (1.2884e-01)\tAcc@1  96.88 ( 96.42)\tAcc@5 100.00 ( 99.60)\n","Epoch: [142][300/391]\tTime  0.076 ( 0.075)\tLoss 8.2006e-02 (1.2836e-01)\tAcc@1  97.66 ( 96.40)\tAcc@5 100.00 ( 99.61)\n","Epoch: [142][330/391]\tTime  0.075 ( 0.075)\tLoss 9.7937e-02 (1.2919e-01)\tAcc@1  97.66 ( 96.39)\tAcc@5 100.00 ( 99.60)\n","Epoch: [142][360/391]\tTime  0.081 ( 0.075)\tLoss 1.7559e-01 (1.2993e-01)\tAcc@1  96.09 ( 96.38)\tAcc@5  98.44 ( 99.59)\n","Epoch: [142][390/391]\tTime  0.048 ( 0.075)\tLoss 2.2086e-01 (1.2967e-01)\tAcc@1  93.75 ( 96.39)\tAcc@5  98.75 ( 99.60)\n","==> Train Accuracy: Acc@1 96.386 || Acc@5 99.596\n","==> Test Accuracy:  Acc@1 77.550 || Acc@5 94.050\n","==> 31.46 seconds to train this epoch\n","\n","\n","----- epoch: 143, lr: 0.0008000000000000003 -----\n","Epoch: [143][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.0251e-01 (1.0251e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [143][ 30/391]\tTime  0.078 ( 0.080)\tLoss 1.6364e-01 (1.3027e-01)\tAcc@1  96.09 ( 96.60)\tAcc@5  99.22 ( 99.52)\n","Epoch: [143][ 60/391]\tTime  0.051 ( 0.076)\tLoss 1.0453e-01 (1.2683e-01)\tAcc@1  96.88 ( 96.47)\tAcc@5 100.00 ( 99.64)\n","Epoch: [143][ 90/391]\tTime  0.057 ( 0.076)\tLoss 2.0208e-01 (1.2797e-01)\tAcc@1  95.31 ( 96.40)\tAcc@5  99.22 ( 99.61)\n","Epoch: [143][120/391]\tTime  0.063 ( 0.075)\tLoss 8.2689e-02 (1.2197e-01)\tAcc@1  97.66 ( 96.59)\tAcc@5  99.22 ( 99.66)\n","Epoch: [143][150/391]\tTime  0.053 ( 0.075)\tLoss 1.0365e-01 (1.2204e-01)\tAcc@1  97.66 ( 96.59)\tAcc@5 100.00 ( 99.67)\n","Epoch: [143][180/391]\tTime  0.053 ( 0.074)\tLoss 1.0866e-01 (1.2217e-01)\tAcc@1  98.44 ( 96.59)\tAcc@5 100.00 ( 99.66)\n","Epoch: [143][210/391]\tTime  0.059 ( 0.074)\tLoss 9.5583e-02 (1.2125e-01)\tAcc@1  96.88 ( 96.61)\tAcc@5 100.00 ( 99.67)\n","Epoch: [143][240/391]\tTime  0.069 ( 0.074)\tLoss 1.3928e-01 (1.2190e-01)\tAcc@1  97.66 ( 96.60)\tAcc@5  99.22 ( 99.66)\n","Epoch: [143][270/391]\tTime  0.091 ( 0.074)\tLoss 1.7254e-01 (1.2161e-01)\tAcc@1  95.31 ( 96.59)\tAcc@5 100.00 ( 99.68)\n","Epoch: [143][300/391]\tTime  0.075 ( 0.074)\tLoss 8.4020e-02 (1.2209e-01)\tAcc@1  99.22 ( 96.61)\tAcc@5 100.00 ( 99.68)\n","Epoch: [143][330/391]\tTime  0.092 ( 0.074)\tLoss 2.8372e-01 (1.2272e-01)\tAcc@1  91.41 ( 96.60)\tAcc@5  99.22 ( 99.66)\n","Epoch: [143][360/391]\tTime  0.062 ( 0.074)\tLoss 1.4982e-01 (1.2339e-01)\tAcc@1  96.09 ( 96.58)\tAcc@5  99.22 ( 99.67)\n","Epoch: [143][390/391]\tTime  0.048 ( 0.074)\tLoss 1.2545e-01 (1.2501e-01)\tAcc@1  96.25 ( 96.52)\tAcc@5 100.00 ( 99.66)\n","==> Train Accuracy: Acc@1 96.518 || Acc@5 99.660\n","==> Test Accuracy:  Acc@1 77.860 || Acc@5 94.270\n","==> 31.22 seconds to train this epoch\n","\n","\n","----- epoch: 144, lr: 0.0008000000000000003 -----\n","Epoch: [144][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.2049e-01 (1.2049e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n","Epoch: [144][ 30/391]\tTime  0.067 ( 0.080)\tLoss 7.2472e-02 (1.2010e-01)\tAcc@1  99.22 ( 96.52)\tAcc@5 100.00 ( 99.65)\n","Epoch: [144][ 60/391]\tTime  0.102 ( 0.078)\tLoss 2.0038e-01 (1.1910e-01)\tAcc@1  93.75 ( 96.66)\tAcc@5 100.00 ( 99.69)\n","Epoch: [144][ 90/391]\tTime  0.104 ( 0.076)\tLoss 8.5842e-02 (1.2218e-01)\tAcc@1  98.44 ( 96.55)\tAcc@5  99.22 ( 99.67)\n","Epoch: [144][120/391]\tTime  0.090 ( 0.076)\tLoss 1.2456e-01 (1.2100e-01)\tAcc@1  95.31 ( 96.60)\tAcc@5 100.00 ( 99.68)\n","Epoch: [144][150/391]\tTime  0.066 ( 0.075)\tLoss 1.7201e-01 (1.2028e-01)\tAcc@1  94.53 ( 96.62)\tAcc@5 100.00 ( 99.70)\n","Epoch: [144][180/391]\tTime  0.074 ( 0.075)\tLoss 5.8891e-02 (1.1960e-01)\tAcc@1  99.22 ( 96.65)\tAcc@5 100.00 ( 99.70)\n","Epoch: [144][210/391]\tTime  0.069 ( 0.074)\tLoss 1.3207e-01 (1.2025e-01)\tAcc@1  96.88 ( 96.66)\tAcc@5 100.00 ( 99.69)\n","Epoch: [144][240/391]\tTime  0.072 ( 0.074)\tLoss 1.2644e-01 (1.2066e-01)\tAcc@1  96.88 ( 96.61)\tAcc@5  99.22 ( 99.71)\n","Epoch: [144][270/391]\tTime  0.077 ( 0.074)\tLoss 1.8023e-01 (1.2324e-01)\tAcc@1  96.88 ( 96.57)\tAcc@5  99.22 ( 99.70)\n","Epoch: [144][300/391]\tTime  0.072 ( 0.074)\tLoss 1.2592e-01 (1.2418e-01)\tAcc@1  96.88 ( 96.55)\tAcc@5  99.22 ( 99.70)\n","Epoch: [144][330/391]\tTime  0.050 ( 0.074)\tLoss 2.1931e-01 (1.2410e-01)\tAcc@1  92.97 ( 96.56)\tAcc@5  99.22 ( 99.68)\n","Epoch: [144][360/391]\tTime  0.049 ( 0.073)\tLoss 2.4619e-01 (1.2484e-01)\tAcc@1  93.75 ( 96.54)\tAcc@5  97.66 ( 99.67)\n","Epoch: [144][390/391]\tTime  0.048 ( 0.073)\tLoss 1.8595e-01 (1.2567e-01)\tAcc@1  93.75 ( 96.52)\tAcc@5 100.00 ( 99.67)\n","==> Train Accuracy: Acc@1 96.520 || Acc@5 99.672\n","==> Test Accuracy:  Acc@1 77.820 || Acc@5 94.010\n","==> 30.98 seconds to train this epoch\n","\n","\n","----- epoch: 145, lr: 0.0008000000000000003 -----\n","Epoch: [145][  0/391]\tTime  0.289 ( 0.289)\tLoss 1.3201e-01 (1.3201e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [145][ 30/391]\tTime  0.074 ( 0.080)\tLoss 1.0126e-01 (1.2098e-01)\tAcc@1  96.88 ( 96.70)\tAcc@5 100.00 ( 99.60)\n","Epoch: [145][ 60/391]\tTime  0.064 ( 0.078)\tLoss 2.3494e-01 (1.2200e-01)\tAcc@1  96.09 ( 96.61)\tAcc@5  98.44 ( 99.63)\n","Epoch: [145][ 90/391]\tTime  0.111 ( 0.077)\tLoss 1.7603e-01 (1.2627e-01)\tAcc@1  96.88 ( 96.55)\tAcc@5  99.22 ( 99.62)\n","Epoch: [145][120/391]\tTime  0.089 ( 0.076)\tLoss 1.4207e-01 (1.2728e-01)\tAcc@1  96.88 ( 96.49)\tAcc@5  99.22 ( 99.63)\n","Epoch: [145][150/391]\tTime  0.076 ( 0.076)\tLoss 1.3296e-01 (1.2891e-01)\tAcc@1  96.88 ( 96.40)\tAcc@5 100.00 ( 99.63)\n","Epoch: [145][180/391]\tTime  0.074 ( 0.075)\tLoss 1.6010e-01 (1.2691e-01)\tAcc@1  96.88 ( 96.41)\tAcc@5  98.44 ( 99.64)\n","Epoch: [145][210/391]\tTime  0.083 ( 0.075)\tLoss 1.0017e-01 (1.2670e-01)\tAcc@1  96.88 ( 96.42)\tAcc@5 100.00 ( 99.61)\n","Epoch: [145][240/391]\tTime  0.054 ( 0.075)\tLoss 9.8380e-02 (1.2578e-01)\tAcc@1  97.66 ( 96.44)\tAcc@5 100.00 ( 99.62)\n","Epoch: [145][270/391]\tTime  0.105 ( 0.075)\tLoss 9.2340e-02 (1.2541e-01)\tAcc@1  97.66 ( 96.48)\tAcc@5 100.00 ( 99.63)\n","Epoch: [145][300/391]\tTime  0.074 ( 0.075)\tLoss 1.2511e-01 (1.2370e-01)\tAcc@1  96.09 ( 96.54)\tAcc@5 100.00 ( 99.65)\n","Epoch: [145][330/391]\tTime  0.102 ( 0.075)\tLoss 1.5150e-01 (1.2400e-01)\tAcc@1  96.09 ( 96.54)\tAcc@5  99.22 ( 99.65)\n","Epoch: [145][360/391]\tTime  0.043 ( 0.075)\tLoss 1.1703e-01 (1.2417e-01)\tAcc@1  98.44 ( 96.53)\tAcc@5  99.22 ( 99.64)\n","Epoch: [145][390/391]\tTime  0.048 ( 0.074)\tLoss 1.4781e-01 (1.2420e-01)\tAcc@1  97.50 ( 96.55)\tAcc@5  98.75 ( 99.63)\n","==> Train Accuracy: Acc@1 96.554 || Acc@5 99.634\n","==> Test Accuracy:  Acc@1 77.810 || Acc@5 93.960\n","==> 31.40 seconds to train this epoch\n","\n","\n","----- epoch: 146, lr: 0.0008000000000000003 -----\n","Epoch: [146][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.7783e-01 (1.7783e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [146][ 30/391]\tTime  0.066 ( 0.080)\tLoss 1.0663e-01 (1.1412e-01)\tAcc@1  96.88 ( 97.03)\tAcc@5 100.00 ( 99.67)\n","Epoch: [146][ 60/391]\tTime  0.067 ( 0.076)\tLoss 1.9379e-01 (1.1585e-01)\tAcc@1  94.53 ( 96.95)\tAcc@5  99.22 ( 99.71)\n","Epoch: [146][ 90/391]\tTime  0.073 ( 0.075)\tLoss 1.6390e-01 (1.1575e-01)\tAcc@1  93.75 ( 96.92)\tAcc@5 100.00 ( 99.75)\n","Epoch: [146][120/391]\tTime  0.072 ( 0.074)\tLoss 1.4020e-01 (1.1735e-01)\tAcc@1  96.09 ( 96.90)\tAcc@5  99.22 ( 99.71)\n","Epoch: [146][150/391]\tTime  0.083 ( 0.074)\tLoss 8.4097e-02 (1.1743e-01)\tAcc@1  98.44 ( 96.88)\tAcc@5 100.00 ( 99.72)\n","Epoch: [146][180/391]\tTime  0.124 ( 0.074)\tLoss 8.9315e-02 (1.1978e-01)\tAcc@1  97.66 ( 96.79)\tAcc@5 100.00 ( 99.69)\n","Epoch: [146][210/391]\tTime  0.054 ( 0.074)\tLoss 1.6040e-01 (1.1963e-01)\tAcc@1  96.88 ( 96.79)\tAcc@5  98.44 ( 99.67)\n","Epoch: [146][240/391]\tTime  0.064 ( 0.074)\tLoss 1.7434e-01 (1.1982e-01)\tAcc@1  93.75 ( 96.80)\tAcc@5  99.22 ( 99.67)\n","Epoch: [146][270/391]\tTime  0.074 ( 0.074)\tLoss 1.1823e-01 (1.1920e-01)\tAcc@1  97.66 ( 96.85)\tAcc@5 100.00 ( 99.66)\n","Epoch: [146][300/391]\tTime  0.106 ( 0.074)\tLoss 1.6744e-01 (1.1948e-01)\tAcc@1  95.31 ( 96.80)\tAcc@5  98.44 ( 99.66)\n","Epoch: [146][330/391]\tTime  0.095 ( 0.074)\tLoss 8.9199e-02 (1.1928e-01)\tAcc@1  97.66 ( 96.81)\tAcc@5 100.00 ( 99.65)\n","Epoch: [146][360/391]\tTime  0.059 ( 0.074)\tLoss 7.2211e-02 (1.1903e-01)\tAcc@1  97.66 ( 96.83)\tAcc@5 100.00 ( 99.65)\n","Epoch: [146][390/391]\tTime  0.048 ( 0.074)\tLoss 8.0492e-02 (1.2076e-01)\tAcc@1  97.50 ( 96.77)\tAcc@5 100.00 ( 99.66)\n","==> Train Accuracy: Acc@1 96.766 || Acc@5 99.658\n","==> Test Accuracy:  Acc@1 77.910 || Acc@5 94.010\n","==> 31.03 seconds to train this epoch\n","\n","\n","----- epoch: 147, lr: 0.0008000000000000003 -----\n","Epoch: [147][  0/391]\tTime  0.295 ( 0.295)\tLoss 1.1616e-01 (1.1616e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [147][ 30/391]\tTime  0.052 ( 0.078)\tLoss 7.0095e-02 (1.2173e-01)\tAcc@1  96.88 ( 96.70)\tAcc@5 100.00 ( 99.65)\n","Epoch: [147][ 60/391]\tTime  0.111 ( 0.075)\tLoss 1.4281e-01 (1.1895e-01)\tAcc@1  96.09 ( 96.73)\tAcc@5 100.00 ( 99.72)\n","Epoch: [147][ 90/391]\tTime  0.062 ( 0.074)\tLoss 1.6127e-01 (1.2158e-01)\tAcc@1  96.09 ( 96.65)\tAcc@5  97.66 ( 99.65)\n","Epoch: [147][120/391]\tTime  0.085 ( 0.074)\tLoss 2.8108e-01 (1.2747e-01)\tAcc@1  91.41 ( 96.50)\tAcc@5  97.66 ( 99.58)\n","Epoch: [147][150/391]\tTime  0.071 ( 0.073)\tLoss 1.6376e-01 (1.2613e-01)\tAcc@1  96.09 ( 96.50)\tAcc@5 100.00 ( 99.58)\n","Epoch: [147][180/391]\tTime  0.090 ( 0.073)\tLoss 4.6760e-02 (1.2487e-01)\tAcc@1 100.00 ( 96.56)\tAcc@5 100.00 ( 99.56)\n","Epoch: [147][210/391]\tTime  0.054 ( 0.073)\tLoss 2.0133e-01 (1.2365e-01)\tAcc@1  93.75 ( 96.58)\tAcc@5 100.00 ( 99.58)\n","Epoch: [147][240/391]\tTime  0.073 ( 0.073)\tLoss 1.5132e-01 (1.2125e-01)\tAcc@1  95.31 ( 96.66)\tAcc@5  99.22 ( 99.60)\n","Epoch: [147][270/391]\tTime  0.060 ( 0.073)\tLoss 8.7120e-02 (1.2071e-01)\tAcc@1  97.66 ( 96.66)\tAcc@5 100.00 ( 99.61)\n","Epoch: [147][300/391]\tTime  0.068 ( 0.073)\tLoss 8.4413e-02 (1.2208e-01)\tAcc@1  96.09 ( 96.62)\tAcc@5 100.00 ( 99.60)\n","Epoch: [147][330/391]\tTime  0.097 ( 0.073)\tLoss 1.0993e-01 (1.2175e-01)\tAcc@1  96.09 ( 96.62)\tAcc@5 100.00 ( 99.61)\n","Epoch: [147][360/391]\tTime  0.061 ( 0.073)\tLoss 1.2603e-01 (1.2105e-01)\tAcc@1  94.53 ( 96.64)\tAcc@5 100.00 ( 99.62)\n","Epoch: [147][390/391]\tTime  0.049 ( 0.073)\tLoss 1.5682e-01 (1.2055e-01)\tAcc@1  97.50 ( 96.66)\tAcc@5 100.00 ( 99.63)\n","==> Train Accuracy: Acc@1 96.662 || Acc@5 99.632\n","==> Test Accuracy:  Acc@1 77.900 || Acc@5 94.070\n","==> 30.70 seconds to train this epoch\n","\n","\n","----- epoch: 148, lr: 0.0008000000000000003 -----\n","Epoch: [148][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.1319e-01 (1.1319e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [148][ 30/391]\tTime  0.088 ( 0.081)\tLoss 1.2189e-01 (1.1450e-01)\tAcc@1  96.09 ( 96.93)\tAcc@5 100.00 ( 99.70)\n","Epoch: [148][ 60/391]\tTime  0.060 ( 0.076)\tLoss 1.0805e-01 (1.1529e-01)\tAcc@1  96.88 ( 96.76)\tAcc@5 100.00 ( 99.72)\n","Epoch: [148][ 90/391]\tTime  0.083 ( 0.075)\tLoss 1.1180e-01 (1.1616e-01)\tAcc@1  97.66 ( 96.82)\tAcc@5 100.00 ( 99.68)\n","Epoch: [148][120/391]\tTime  0.069 ( 0.075)\tLoss 8.6959e-02 (1.1818e-01)\tAcc@1  97.66 ( 96.77)\tAcc@5 100.00 ( 99.67)\n","Epoch: [148][150/391]\tTime  0.055 ( 0.074)\tLoss 1.0194e-01 (1.2122e-01)\tAcc@1  97.66 ( 96.67)\tAcc@5 100.00 ( 99.68)\n","Epoch: [148][180/391]\tTime  0.067 ( 0.074)\tLoss 1.1673e-01 (1.2082e-01)\tAcc@1  97.66 ( 96.71)\tAcc@5 100.00 ( 99.65)\n","Epoch: [148][210/391]\tTime  0.097 ( 0.073)\tLoss 1.1628e-01 (1.1889e-01)\tAcc@1  96.88 ( 96.80)\tAcc@5 100.00 ( 99.66)\n","Epoch: [148][240/391]\tTime  0.078 ( 0.073)\tLoss 1.3855e-01 (1.1826e-01)\tAcc@1  96.09 ( 96.80)\tAcc@5 100.00 ( 99.68)\n","Epoch: [148][270/391]\tTime  0.088 ( 0.073)\tLoss 9.6436e-02 (1.1865e-01)\tAcc@1  98.44 ( 96.75)\tAcc@5 100.00 ( 99.69)\n","Epoch: [148][300/391]\tTime  0.084 ( 0.073)\tLoss 6.9661e-02 (1.1828e-01)\tAcc@1  98.44 ( 96.77)\tAcc@5 100.00 ( 99.70)\n","Epoch: [148][330/391]\tTime  0.069 ( 0.073)\tLoss 7.3609e-02 (1.1925e-01)\tAcc@1  97.66 ( 96.74)\tAcc@5 100.00 ( 99.67)\n","Epoch: [148][360/391]\tTime  0.077 ( 0.073)\tLoss 5.1872e-02 (1.1915e-01)\tAcc@1  99.22 ( 96.76)\tAcc@5 100.00 ( 99.67)\n","Epoch: [148][390/391]\tTime  0.048 ( 0.073)\tLoss 2.7193e-01 (1.1918e-01)\tAcc@1  93.75 ( 96.78)\tAcc@5  98.75 ( 99.67)\n","==> Train Accuracy: Acc@1 96.782 || Acc@5 99.672\n","==> Test Accuracy:  Acc@1 77.720 || Acc@5 94.180\n","==> 30.65 seconds to train this epoch\n","\n","\n","----- epoch: 149, lr: 0.0008000000000000003 -----\n","Epoch: [149][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.9845e-01 (1.9845e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n","Epoch: [149][ 30/391]\tTime  0.070 ( 0.080)\tLoss 1.6545e-01 (1.1747e-01)\tAcc@1  95.31 ( 96.82)\tAcc@5 100.00 ( 99.75)\n","Epoch: [149][ 60/391]\tTime  0.092 ( 0.075)\tLoss 1.4234e-01 (1.2031e-01)\tAcc@1  96.09 ( 96.76)\tAcc@5  99.22 ( 99.58)\n","Epoch: [149][ 90/391]\tTime  0.099 ( 0.074)\tLoss 1.1595e-01 (1.1691e-01)\tAcc@1  97.66 ( 96.91)\tAcc@5  99.22 ( 99.64)\n","Epoch: [149][120/391]\tTime  0.104 ( 0.074)\tLoss 7.5114e-02 (1.1823e-01)\tAcc@1  97.66 ( 96.79)\tAcc@5 100.00 ( 99.64)\n","Epoch: [149][150/391]\tTime  0.056 ( 0.073)\tLoss 1.5655e-01 (1.1781e-01)\tAcc@1  96.09 ( 96.80)\tAcc@5 100.00 ( 99.65)\n","Epoch: [149][180/391]\tTime  0.099 ( 0.073)\tLoss 1.2154e-01 (1.1918e-01)\tAcc@1  96.88 ( 96.73)\tAcc@5  99.22 ( 99.65)\n","Epoch: [149][210/391]\tTime  0.085 ( 0.073)\tLoss 6.2143e-02 (1.2017e-01)\tAcc@1  96.88 ( 96.65)\tAcc@5 100.00 ( 99.67)\n","Epoch: [149][240/391]\tTime  0.074 ( 0.073)\tLoss 1.5563e-01 (1.2193e-01)\tAcc@1  95.31 ( 96.63)\tAcc@5  98.44 ( 99.65)\n","Epoch: [149][270/391]\tTime  0.076 ( 0.073)\tLoss 1.6889e-01 (1.2128e-01)\tAcc@1  94.53 ( 96.69)\tAcc@5  99.22 ( 99.65)\n","Epoch: [149][300/391]\tTime  0.074 ( 0.073)\tLoss 1.5786e-01 (1.2148e-01)\tAcc@1  93.75 ( 96.66)\tAcc@5 100.00 ( 99.66)\n","Epoch: [149][330/391]\tTime  0.057 ( 0.073)\tLoss 1.0934e-01 (1.2158e-01)\tAcc@1  96.09 ( 96.68)\tAcc@5 100.00 ( 99.66)\n","Epoch: [149][360/391]\tTime  0.056 ( 0.073)\tLoss 7.8541e-02 (1.2182e-01)\tAcc@1  98.44 ( 96.65)\tAcc@5  99.22 ( 99.66)\n","Epoch: [149][390/391]\tTime  0.048 ( 0.073)\tLoss 2.9306e-01 (1.2179e-01)\tAcc@1  91.25 ( 96.67)\tAcc@5  97.50 ( 99.66)\n","==> Train Accuracy: Acc@1 96.666 || Acc@5 99.660\n","==> Test Accuracy:  Acc@1 77.770 || Acc@5 94.150\n","==> 30.66 seconds to train this epoch\n","\n","Best Top-1 Accuracy: 78.22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hgRvZCczCbYv"},"source":[""],"execution_count":null,"outputs":[]}]}