{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0512_Cutmix+1randomchanging_1st.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"152b210a5a374d65bc5c73f7d410a643":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_464f0aef23e34c20b88da742414249ed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_59a38c37d8ed4382960557d208adcea3","IPY_MODEL_a3882f6651d24dd2ac78bc9c1be1b342"]}},"464f0aef23e34c20b88da742414249ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59a38c37d8ed4382960557d208adcea3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8706c8f31e524517bb1f9d5028052b25","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":169001437,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":169001437,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75ef5ebe0f2845aba45dfbe470c08dea"}},"a3882f6651d24dd2ac78bc9c1be1b342":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_839921cb963f4d3abb525e596603add8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 169001984/? [04:52&lt;00:00, 577734.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b5710db700b6473d80d4bf66fc74ea48"}},"8706c8f31e524517bb1f9d5028052b25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75ef5ebe0f2845aba45dfbe470c08dea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"839921cb963f4d3abb525e596603add8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b5710db700b6473d80d4bf66fc74ea48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OSFGYaIDG6f0"},"source":["Cutout Data Augmentation.\n","\n","This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"]},{"cell_type":"markdown","metadata":{"id":"vCVSE5-UboYl"},"source":["##**Import all neceassary packages**"]},{"cell_type":"code","metadata":{"id":"5YBMwPsubsbX","executionInfo":{"status":"ok","timestamp":1620792255633,"user_tz":-540,"elapsed":4224,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["import numpy as np\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.backends.cudnn as cudnn\n","from torch.optim.lr_scheduler import MultiStepLR\n","from torchvision import datasets, transforms\n","from tqdm.notebook import tqdm as tqdm\n","import random\n","import math"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L88afYXKMSdL"},"source":["##**Model - Define ResNet Model**"]},{"cell_type":"code","metadata":{"id":"eMFSLTnkMQdq","executionInfo":{"status":"ok","timestamp":1620792255635,"user_tz":-540,"elapsed":4223,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["'''ResNet18/34/50/101/152 in Pytorch.'''\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = conv3x3(3,64)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18(num_classes=10):\n","    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n","\n","def ResNet34(num_classes=10):\n","    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n","\n","def ResNet50(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n","\n","def ResNet101(num_classes=10):\n","    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n","\n","def ResNet152(num_classes=10):\n","    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n","\n","def test_resnet():\n","    net = ResNet50()\n","    y = net(Variable(torch.randn(1,3,32,32)))\n","    print(y.size())\n","\n","# test_resnet()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjM3cl279Lvg"},"source":["##**Utils**"]},{"cell_type":"code","metadata":{"id":"gIvuSgE49Kvu","executionInfo":{"status":"ok","timestamp":1620792255636,"user_tz":-540,"elapsed":4222,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMQI2K4AMopg","executionInfo":{"status":"ok","timestamp":1620792255636,"user_tz":-540,"elapsed":1423,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["class Randomchanging(object):\n","    '''\n","    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n","    -------------------------------------------------------------------------------------\n","    probability: The probability that the operation will be performed.\n","    sl: min erasing area\n","    sh: max erasing area\n","    r1: min aspect ratio\n","    mean: erasing value\n","    -------------------------------------------------------------------------------------\n","    '''\n","    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3):\n","        self.probability = probability\n","        self.sl = sl\n","        self.sh = sh\n","        self.r1 = r1\n","       \n","    def __call__(self, img):\n","\n","        if random.uniform(0, 1) > self.probability:\n","            return img\n","\n","        for attempt in range(100):\n","            area = img.size()[1] * img.size()[2]\n","       \n","            target_area = random.uniform(self.sl, self.sh) * area\n","            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n","\n","            h = int(round(math.sqrt(target_area * aspect_ratio)))\n","            w = int(round(math.sqrt(target_area / aspect_ratio)))\n","\n","            if w < img.size()[2] and h < img.size()[1]:\n","                x1 = random.randint(0, img.size()[1] - h)\n","                y1 = random.randint(0, img.size()[2] - w)\n","                change_x1 = random.randint(0, img.size()[1] - h) # 새로운 위치 정의\n","                change_y1 = random.randint(0, img.size()[2] - w) # 새로운 위치 정의\n","                if img.size()[0] == 3:\n","                    img[0, x1:x1+h, y1:y1+w] = img[0, change_x1:change_x1+h, change_y1:change_y1+w] # 새로운 위치의 값으로 변경\n","                    img[1, x1:x1+h, y1:y1+w] = img[1,change_x1:change_x1+h, change_y1:change_y1+w] # 새로운 위치의 값으로 변경\n","                    img[2, x1:x1+h, y1:y1+w] = img[2, change_x1:change_x1+h, change_y1:change_y1+w] # 새로운 위치의 값으로 변경\n","                else:\n","                    img[0, x1:x1+h, y1:y1+w] = img[0, change_x1:change_x1+h, change_y1:change_y1+w] # 새로운 위치의 값으로 변경\n","                return img\n","\n","        return img"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwswzxa-iWHB","executionInfo":{"status":"ok","timestamp":1620792257606,"user_tz":-540,"elapsed":1213,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["#cutmix시킬 bbox의 각 꼭짓점들과 lambda값을 반환\n","def rand_bbox(size):\n","    W = size[2] # 512\n","    H = size[3] # 384\n","\n","    # uniform\n","    rx = np.random.randint(0, W)\n","    ry = np.random.randint(0, H)\n","    cm_lambda = np.random.rand()\n","    rw = W * (1-cm_lambda) ** 0.5\n","    rh = H * (1-cm_lambda) ** 0.5\n","\n","    x_min = max(0, rx - rw//2)\n","    y_min = max(0, ry - rh//2)\n","    x_max = min(W, rx + rw//2)\n","    y_max = min(H, ry + rh//2)\n","    cm_lambda = 1 - (x_max - x_min) * (y_max - y_min) / (W*H)\n","\n","    return cm_lambda, x_min, x_max, y_min, y_max"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s8oXpzdMvol"},"source":["##**Parameter Settings**"]},{"cell_type":"code","metadata":{"id":"CE_6GKltjfco","executionInfo":{"status":"ok","timestamp":1620792291192,"user_tz":-540,"elapsed":804,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["dataset = 'cifar100' # cifar10 or cifar100\n","model = 'resnet34' # resnet18, resnet50, resnet101\n","batch_size = 128  # Input batch size for training (default: 128)\n","epochs = 150 # Number of epochs to train (default: 200)\n","learning_rate = 0.1 # Learning rate\n","data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n","# cutout = True # Apply Cutout?\n","cutmix=True\n","seed = 0 # Random seed (default: 0)\n","print_freq = 30\n","cuda = torch.cuda.is_available()\n","cudnn.benchmark = True  # Should make training should go faster for large models\n","\n","\n","\n","\n","torch.manual_seed(seed)\n","if cuda:\n","    torch.cuda.manual_seed(seed)\n","\n","test_id = dataset + '_' + model\n","\n","random.seed(0)\n","np.random.seed(0)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eXL_PBj6cVoe"},"source":["##**Load and preprocess data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["152b210a5a374d65bc5c73f7d410a643","464f0aef23e34c20b88da742414249ed","59a38c37d8ed4382960557d208adcea3","a3882f6651d24dd2ac78bc9c1be1b342","8706c8f31e524517bb1f9d5028052b25","75ef5ebe0f2845aba45dfbe470c08dea","839921cb963f4d3abb525e596603add8","b5710db700b6473d80d4bf66fc74ea48"]},"id":"dvQjH3T9caYs","executionInfo":{"status":"ok","timestamp":1620792311770,"user_tz":-540,"elapsed":16920,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}},"outputId":"e5b22f05-4674-424e-8e55-fb6fb61a4383"},"source":["# Image Preprocessing\n","normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n","                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n","\n","train_transform = transforms.Compose([])\n","if data_augmentation:\n","    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n","    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n","train_transform.transforms.append(transforms.ToTensor())\n","train_transform.transforms.append(normalize)\n","train_transform.transforms.append(Randomchanging(probability = 0.2, sh = 0.4, r1 = 0.5))\n","\n","test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize])\n","\n","if dataset == 'cifar10':\n","    num_classes = 10\n","    train_dataset = datasets.CIFAR10(root='data/',\n","                                     train=True,\n","                                     transform=train_transform,\n","                                     download=True)\n","\n","    test_dataset = datasets.CIFAR10(root='data/',\n","                                    train=False,\n","                                    transform=test_transform,\n","                                    download=True)\n","elif dataset == 'cifar100':\n","    num_classes = 100\n","    train_dataset = datasets.CIFAR100(root='data/',\n","                                      train=True,\n","                                      transform=train_transform,\n","                                      download=True)\n","\n","    test_dataset = datasets.CIFAR100(root='data/',\n","                                     train=False,\n","                                     transform=test_transform,\n","                                     download=True)\n","\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           pin_memory=True,\n","                                           num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          pin_memory=True,\n","                                          num_workers=2)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"152b210a5a374d65bc5c73f7d410a643","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting data/cifar-100-python.tar.gz to data/\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n3xieRZ6iOLI","executionInfo":{"status":"ok","timestamp":1620792351796,"user_tz":-540,"elapsed":19569,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}},"outputId":"66fe87f9-9126-42c1-a356-8b1be984e397"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VKc1jOryiPFQ","executionInfo":{"status":"ok","timestamp":1620792357963,"user_tz":-540,"elapsed":814,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["path = '/content/drive/MyDrive/4-1 실전기계학습/mid_project'\n","augmentation_method = '0512cutmix+1randomchange_1st'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnlPy0TkiWOO","executionInfo":{"status":"ok","timestamp":1620792364757,"user_tz":-540,"elapsed":910,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["def load_model(model, path, method) :\n","\n","    dir_ckpt = pathlib.Path(path)\n","    dir_path = dir_ckpt / method / 'checkpoint'\n","    ckpt_file = dir_path / 'model_best.pth'\n","\n","    if cuda:\n","        checkpoint = torch.load(ckpt_file, map_location=lambda storage, loc: storage.cuda(0))\n","        try:\n","            model.load_state_dict(checkpoint['model'])\n","        except:\n","            model.module.load_state_dict(checkpoint['model'])\n","    else:\n","        checkpoint = torch.load(ckpt_file, map_location=lambda storage, loc: storage)\n","        try:\n","            model.load_state_dict(checkpoint['model'])\n","        except:\n","            # create new OrderedDict that does not contain `module.`\n","            new_state_dict = OrderedDict()\n","            for k, v in checkpoint['model'].items():\n","                if k[:7] == 'module.':\n","                    name = k[7:] # remove `module.`\n","                else:\n","                    name = k[:]\n","                new_state_dict[name] = v\n","\n","            model.load_state_dict(new_state_dict)\n","\n","    return checkpoint"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xC3RWxmiXa3","executionInfo":{"status":"ok","timestamp":1620792366282,"user_tz":-540,"elapsed":570,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}}},"source":["import pathlib\n","\n","def save_model(state, path, method):\n","    dir_ckpt = pathlib.Path(path)\n","    dir_path = dir_ckpt / method / 'checkpoint'\n","    dir_path.mkdir(parents=True, exist_ok=True)\n","\n","    model_file = dir_path / 'model_best.pth'\n","    \n","    torch.save(state, model_file)\n","\n","def save_values(epoch, acc1_train, acc5_train, acc1_valid, acc5_valid, path, method):\n","    dir_ckpt = pathlib.Path(path)\n","    dir_path = dir_ckpt / method / 'values'\n","    dir_path.mkdir(parents=True, exist_ok=True)\n","\n","    acc1_train_file = dir_path / 'acc1_train.txt'\n","    acc5_train_file = dir_path / 'acc5_train.txt'\n","\n","    acc1_valid_file = dir_path / 'acc1_valid.txt'\n","    acc5_valid_file = dir_path / 'acc5_valid.txt'\n","\n","    with open(acc1_train_file, \"a\") as f :\n","        f.write(epoch + \", \" + acc1_train + '\\n')\n","\n","    with open(acc5_train_file, \"a\") as f :\n","        f.write(epoch + \", \" + acc5_train + '\\n')\n","\n","    with open(acc1_valid_file, \"a\") as f :\n","        f.write(epoch + \", \" + acc1_valid + '\\n')\n","\n","    with open(acc5_valid_file, \"a\") as f :\n","        f.write(epoch + \", \" + acc5_valid + '\\n')"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gITLQIAr9lAZ"},"source":["##**Main Training**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1sBYsEoszM4","executionInfo":{"status":"ok","timestamp":1620798382907,"user_tz":-540,"elapsed":5711943,"user":{"displayName":"김효준","photoUrl":"","userId":"12098101409760390036"}},"outputId":"26dc0354-fea2-45d4-8098-fc6dd39c91ab"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        input = input.cuda()\n","        target = target.cuda()\n","        if cutmix == True:\n","            rand_indices = torch.randperm(input.size()[0]).cuda()\n","            target_a = target\n","            target_b = target[rand_indices]\n","            l, x_min, x_max, y_min, y_max = rand_bbox(input.size())\n","            input[:,:,int(x_min):int(x_max), int(y_min):int(y_max)] = input[rand_indices,:,int(x_min):int(x_max), int(y_min):int(y_max)]\n","            output = model(input)\n","            loss = criterion(output, target_a)*l + criterion(output, target_b)*(1-l)\n","\n","        else:\n","            # compute output\n","            output = model(input)\n","            loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            progress.print(i)\n","\n","    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg, top5.avg\n","\n","def test(test_loader,epoch, model):\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    model.eval()\n","    for i,(input,target) in enumerate(test_loader):\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        output = model(input)\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg, top5.avg\n","\n","model = ResNet34(num_classes=num_classes).cuda()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n","\n","scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n","\n","criterion = torch.nn.CrossEntropyLoss().cuda()\n","###########################################################\n","best_acc = 0\n","for epoch in range(epochs):\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    # train for one epoch\n","    start_time = time.time()\n","    train_acc1, train_acc5 = train(train_loader, epoch, model, optimizer, criterion)\n","    test_acc1, test_acc5 = test(test_loader,epoch,model)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","    # learning rate scheduling\n","    scheduler.step()\n","    \n","    # Save model for best accuracy\n","    # if best_acc < test_acc:\n","    #     best_acc = test_acc\n","    #     torch.save(model.state_dict(), 'model_best.pt')\n","    # Save model for best accuracy\n","    if best_acc < test_acc1:\n","        best_acc = test_acc1\n","        state = {'epoch': epoch + 1,\n","                 'model': model.state_dict(),\n","                 'optimizer': optimizer.state_dict(),\n","                 'scheduler' : scheduler.state_dict()\n","                 }\n","        save_model(state, path, augmentation_method)\n","    save_values(str(epoch + 1), str(train_acc1), str(train_acc5), str(test_acc1), str(test_acc5), path, augmentation_method)\n","        \n","torch.save(model.state_dict(),'model_latest.pt')\n","print(f\"Best Top-1 Accuracy: {best_acc}\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["\n","----- epoch: 0, lr: 0.1 -----\n","Epoch: [0][  0/391]\tTime  0.193 ( 0.193)\tLoss 4.7552e+00 (4.7552e+00)\tAcc@1   2.34 (  2.34)\tAcc@5   4.69 (  4.69)\n","Epoch: [0][ 30/391]\tTime  0.090 ( 0.094)\tLoss 4.6533e+00 (5.4123e+00)\tAcc@1   0.78 (  1.41)\tAcc@5   4.69 (  6.07)\n","Epoch: [0][ 60/391]\tTime  0.090 ( 0.092)\tLoss 4.5568e+00 (5.0059e+00)\tAcc@1   0.78 (  1.60)\tAcc@5  11.72 (  7.31)\n","Epoch: [0][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.3696e+00 (4.8375e+00)\tAcc@1   0.78 (  2.02)\tAcc@5  13.28 (  8.93)\n","Epoch: [0][120/391]\tTime  0.091 ( 0.091)\tLoss 4.4327e+00 (4.7340e+00)\tAcc@1   3.12 (  2.24)\tAcc@5  10.94 (  9.92)\n","Epoch: [0][150/391]\tTime  0.090 ( 0.091)\tLoss 4.3621e+00 (4.6675e+00)\tAcc@1   7.03 (  2.42)\tAcc@5  17.97 ( 10.69)\n","Epoch: [0][180/391]\tTime  0.090 ( 0.091)\tLoss 4.4152e+00 (4.6201e+00)\tAcc@1   5.47 (  2.66)\tAcc@5  15.62 ( 11.39)\n","Epoch: [0][210/391]\tTime  0.090 ( 0.091)\tLoss 4.3659e+00 (4.5830e+00)\tAcc@1   3.12 (  2.85)\tAcc@5  16.41 ( 11.99)\n","Epoch: [0][240/391]\tTime  0.090 ( 0.091)\tLoss 4.2591e+00 (4.5537e+00)\tAcc@1   2.34 (  2.96)\tAcc@5  18.75 ( 12.38)\n","Epoch: [0][270/391]\tTime  0.090 ( 0.091)\tLoss 4.4149e+00 (4.5326e+00)\tAcc@1   3.91 (  3.06)\tAcc@5  13.28 ( 12.79)\n","Epoch: [0][300/391]\tTime  0.090 ( 0.091)\tLoss 4.1942e+00 (4.5106e+00)\tAcc@1   3.91 (  3.21)\tAcc@5  22.66 ( 13.17)\n","Epoch: [0][330/391]\tTime  0.090 ( 0.091)\tLoss 4.4240e+00 (4.4924e+00)\tAcc@1   4.69 (  3.34)\tAcc@5  15.62 ( 13.53)\n","Epoch: [0][360/391]\tTime  0.092 ( 0.091)\tLoss 4.2874e+00 (4.4750e+00)\tAcc@1   7.03 (  3.46)\tAcc@5  21.88 ( 13.98)\n","Epoch: [0][390/391]\tTime  0.081 ( 0.091)\tLoss 4.2324e+00 (4.4583e+00)\tAcc@1   3.75 (  3.62)\tAcc@5  18.75 ( 14.52)\n","==> Train Accuracy: Acc@1 3.620 || Acc@5 14.520\n","==> Test Accuracy:  Acc@1 7.900 || Acc@5 26.200\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 1, lr: 0.1 -----\n","Epoch: [1][  0/391]\tTime  0.226 ( 0.226)\tLoss 4.3115e+00 (4.3115e+00)\tAcc@1  10.16 ( 10.16)\tAcc@5  24.22 ( 24.22)\n","Epoch: [1][ 30/391]\tTime  0.090 ( 0.094)\tLoss 4.1702e+00 (4.2708e+00)\tAcc@1   4.69 (  5.14)\tAcc@5  26.56 ( 19.28)\n","Epoch: [1][ 60/391]\tTime  0.091 ( 0.092)\tLoss 4.1978e+00 (4.2454e+00)\tAcc@1   7.03 (  5.61)\tAcc@5  23.44 ( 20.27)\n","Epoch: [1][ 90/391]\tTime  0.094 ( 0.092)\tLoss 4.3050e+00 (4.2473e+00)\tAcc@1   6.25 (  5.64)\tAcc@5  14.06 ( 20.52)\n","Epoch: [1][120/391]\tTime  0.090 ( 0.092)\tLoss 4.3052e+00 (4.2409e+00)\tAcc@1   5.47 (  5.86)\tAcc@5  22.66 ( 20.97)\n","Epoch: [1][150/391]\tTime  0.090 ( 0.091)\tLoss 4.2829e+00 (4.2340e+00)\tAcc@1   5.47 (  6.06)\tAcc@5  19.53 ( 21.44)\n","Epoch: [1][180/391]\tTime  0.092 ( 0.091)\tLoss 4.1883e+00 (4.2340e+00)\tAcc@1   7.81 (  6.00)\tAcc@5  25.78 ( 21.26)\n","Epoch: [1][210/391]\tTime  0.090 ( 0.091)\tLoss 4.0905e+00 (4.2326e+00)\tAcc@1  12.50 (  5.87)\tAcc@5  30.47 ( 21.23)\n","Epoch: [1][240/391]\tTime  0.090 ( 0.091)\tLoss 4.3564e+00 (4.2293e+00)\tAcc@1   2.34 (  5.91)\tAcc@5  15.62 ( 21.40)\n","Epoch: [1][270/391]\tTime  0.090 ( 0.091)\tLoss 3.8094e+00 (4.2179e+00)\tAcc@1   8.59 (  6.10)\tAcc@5  32.03 ( 21.97)\n","Epoch: [1][300/391]\tTime  0.091 ( 0.091)\tLoss 4.2941e+00 (4.2126e+00)\tAcc@1   3.12 (  6.21)\tAcc@5   7.03 ( 22.20)\n","Epoch: [1][330/391]\tTime  0.090 ( 0.091)\tLoss 4.2847e+00 (4.2040e+00)\tAcc@1   3.12 (  6.39)\tAcc@5  13.28 ( 22.51)\n","Epoch: [1][360/391]\tTime  0.091 ( 0.091)\tLoss 4.1117e+00 (4.2012e+00)\tAcc@1  14.06 (  6.49)\tAcc@5  30.47 ( 22.61)\n","Epoch: [1][390/391]\tTime  0.082 ( 0.091)\tLoss 4.2022e+00 (4.1964e+00)\tAcc@1   7.50 (  6.54)\tAcc@5  25.00 ( 22.73)\n","==> Train Accuracy: Acc@1 6.536 || Acc@5 22.726\n","==> Test Accuracy:  Acc@1 11.190 || Acc@5 34.360\n","==> 37.95 seconds to train this epoch\n","\n","\n","----- epoch: 2, lr: 0.1 -----\n","Epoch: [2][  0/391]\tTime  0.225 ( 0.225)\tLoss 4.0872e+00 (4.0872e+00)\tAcc@1  10.94 ( 10.94)\tAcc@5  32.81 ( 32.81)\n","Epoch: [2][ 30/391]\tTime  0.090 ( 0.094)\tLoss 4.0798e+00 (4.1038e+00)\tAcc@1   5.47 (  7.71)\tAcc@5   9.38 ( 25.13)\n","Epoch: [2][ 60/391]\tTime  0.090 ( 0.092)\tLoss 4.2391e+00 (4.1011e+00)\tAcc@1   5.47 (  8.47)\tAcc@5  15.62 ( 26.27)\n","Epoch: [2][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.1949e+00 (4.0971e+00)\tAcc@1  11.72 (  8.35)\tAcc@5  27.34 ( 26.39)\n","Epoch: [2][120/391]\tTime  0.094 ( 0.092)\tLoss 3.9351e+00 (4.0934e+00)\tAcc@1  10.94 (  8.32)\tAcc@5  35.94 ( 26.21)\n","Epoch: [2][150/391]\tTime  0.091 ( 0.091)\tLoss 4.1066e+00 (4.0919e+00)\tAcc@1  10.94 (  8.32)\tAcc@5  28.91 ( 26.56)\n","Epoch: [2][180/391]\tTime  0.090 ( 0.091)\tLoss 4.2420e+00 (4.0943e+00)\tAcc@1   3.91 (  8.30)\tAcc@5  16.41 ( 26.52)\n","Epoch: [2][210/391]\tTime  0.090 ( 0.091)\tLoss 4.2016e+00 (4.0943e+00)\tAcc@1   1.56 (  8.42)\tAcc@5   5.47 ( 26.61)\n","Epoch: [2][240/391]\tTime  0.090 ( 0.091)\tLoss 4.0970e+00 (4.0888e+00)\tAcc@1  11.72 (  8.54)\tAcc@5  27.34 ( 26.68)\n","Epoch: [2][270/391]\tTime  0.090 ( 0.091)\tLoss 4.0438e+00 (4.0844e+00)\tAcc@1   6.25 (  8.73)\tAcc@5  33.59 ( 27.08)\n","Epoch: [2][300/391]\tTime  0.091 ( 0.091)\tLoss 3.9167e+00 (4.0827e+00)\tAcc@1  14.06 (  8.77)\tAcc@5  34.38 ( 27.07)\n","Epoch: [2][330/391]\tTime  0.091 ( 0.091)\tLoss 4.2999e+00 (4.0752e+00)\tAcc@1   6.25 (  8.89)\tAcc@5  25.00 ( 27.43)\n","Epoch: [2][360/391]\tTime  0.091 ( 0.091)\tLoss 3.9300e+00 (4.0716e+00)\tAcc@1  10.94 (  8.93)\tAcc@5  37.50 ( 27.56)\n","Epoch: [2][390/391]\tTime  0.082 ( 0.091)\tLoss 4.1371e+00 (4.0722e+00)\tAcc@1  11.25 (  8.92)\tAcc@5  27.50 ( 27.57)\n","==> Train Accuracy: Acc@1 8.922 || Acc@5 27.572\n","==> Test Accuracy:  Acc@1 15.270 || Acc@5 40.960\n","==> 38.00 seconds to train this epoch\n","\n","\n","----- epoch: 3, lr: 0.1 -----\n","Epoch: [3][  0/391]\tTime  0.228 ( 0.228)\tLoss 3.7990e+00 (3.7990e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  35.94 ( 35.94)\n","Epoch: [3][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.5946e+00 (4.0103e+00)\tAcc@1  14.84 ( 10.16)\tAcc@5  42.97 ( 30.22)\n","Epoch: [3][ 60/391]\tTime  0.092 ( 0.093)\tLoss 4.0320e+00 (3.9979e+00)\tAcc@1  13.28 ( 10.31)\tAcc@5  32.03 ( 30.55)\n","Epoch: [3][ 90/391]\tTime  0.093 ( 0.092)\tLoss 4.0867e+00 (3.9899e+00)\tAcc@1  13.28 (  9.96)\tAcc@5  25.78 ( 29.92)\n","Epoch: [3][120/391]\tTime  0.098 ( 0.092)\tLoss 3.8555e+00 (3.9825e+00)\tAcc@1  12.50 ( 10.23)\tAcc@5  34.38 ( 30.44)\n","Epoch: [3][150/391]\tTime  0.091 ( 0.092)\tLoss 3.4515e+00 (3.9869e+00)\tAcc@1  24.22 ( 10.08)\tAcc@5  48.44 ( 30.20)\n","Epoch: [3][180/391]\tTime  0.088 ( 0.092)\tLoss 3.9472e+00 (3.9812e+00)\tAcc@1   2.34 ( 10.34)\tAcc@5   8.59 ( 30.46)\n","Epoch: [3][210/391]\tTime  0.091 ( 0.091)\tLoss 4.1217e+00 (3.9881e+00)\tAcc@1  12.50 ( 10.13)\tAcc@5  34.38 ( 29.91)\n","Epoch: [3][240/391]\tTime  0.090 ( 0.091)\tLoss 4.0176e+00 (3.9730e+00)\tAcc@1  11.72 ( 10.56)\tAcc@5  32.03 ( 30.71)\n","Epoch: [3][270/391]\tTime  0.091 ( 0.091)\tLoss 4.1131e+00 (3.9646e+00)\tAcc@1   9.38 ( 10.81)\tAcc@5  25.00 ( 31.20)\n","Epoch: [3][300/391]\tTime  0.091 ( 0.091)\tLoss 3.9535e+00 (3.9647e+00)\tAcc@1  11.72 ( 10.87)\tAcc@5  31.25 ( 31.34)\n","Epoch: [3][330/391]\tTime  0.091 ( 0.091)\tLoss 3.9057e+00 (3.9633e+00)\tAcc@1  20.31 ( 11.08)\tAcc@5  42.97 ( 31.61)\n","Epoch: [3][360/391]\tTime  0.091 ( 0.091)\tLoss 3.4807e+00 (3.9575e+00)\tAcc@1  17.19 ( 11.16)\tAcc@5  46.09 ( 31.84)\n","Epoch: [3][390/391]\tTime  0.083 ( 0.091)\tLoss 3.8583e+00 (3.9557e+00)\tAcc@1  17.50 ( 11.28)\tAcc@5  40.00 ( 32.01)\n","==> Train Accuracy: Acc@1 11.282 || Acc@5 32.014\n","==> Test Accuracy:  Acc@1 20.160 || Acc@5 47.700\n","==> 38.10 seconds to train this epoch\n","\n","\n","----- epoch: 4, lr: 0.1 -----\n","Epoch: [4][  0/391]\tTime  0.203 ( 0.203)\tLoss 4.1349e+00 (4.1349e+00)\tAcc@1  11.72 ( 11.72)\tAcc@5  28.12 ( 28.12)\n","Epoch: [4][ 30/391]\tTime  0.092 ( 0.094)\tLoss 4.0202e+00 (3.9793e+00)\tAcc@1  14.84 ( 11.39)\tAcc@5  32.03 ( 31.68)\n","Epoch: [4][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.9157e+00 (3.9262e+00)\tAcc@1  15.62 ( 12.31)\tAcc@5  35.94 ( 34.50)\n","Epoch: [4][ 90/391]\tTime  0.091 ( 0.092)\tLoss 4.0094e+00 (3.9196e+00)\tAcc@1  13.28 ( 12.06)\tAcc@5  35.94 ( 33.86)\n","Epoch: [4][120/391]\tTime  0.092 ( 0.091)\tLoss 3.9180e+00 (3.8908e+00)\tAcc@1  17.19 ( 12.67)\tAcc@5  39.06 ( 35.11)\n","Epoch: [4][150/391]\tTime  0.091 ( 0.091)\tLoss 4.0983e+00 (3.8859e+00)\tAcc@1   5.47 ( 12.77)\tAcc@5  16.41 ( 35.19)\n","Epoch: [4][180/391]\tTime  0.090 ( 0.091)\tLoss 3.8170e+00 (3.8840e+00)\tAcc@1  17.19 ( 12.88)\tAcc@5  40.62 ( 35.66)\n","Epoch: [4][210/391]\tTime  0.088 ( 0.091)\tLoss 3.7769e+00 (3.8692e+00)\tAcc@1  17.97 ( 13.20)\tAcc@5  42.19 ( 36.20)\n","Epoch: [4][240/391]\tTime  0.090 ( 0.091)\tLoss 4.0942e+00 (3.8738e+00)\tAcc@1   7.81 ( 12.80)\tAcc@5  27.34 ( 35.40)\n","Epoch: [4][270/391]\tTime  0.091 ( 0.091)\tLoss 4.0256e+00 (3.8754e+00)\tAcc@1   7.03 ( 12.76)\tAcc@5  27.34 ( 35.38)\n","Epoch: [4][300/391]\tTime  0.090 ( 0.091)\tLoss 3.8057e+00 (3.8659e+00)\tAcc@1  13.28 ( 12.97)\tAcc@5  39.06 ( 35.76)\n","Epoch: [4][330/391]\tTime  0.091 ( 0.091)\tLoss 3.5287e+00 (3.8651e+00)\tAcc@1  21.88 ( 12.96)\tAcc@5  46.88 ( 35.66)\n","Epoch: [4][360/391]\tTime  0.090 ( 0.091)\tLoss 3.2618e+00 (3.8583e+00)\tAcc@1  21.09 ( 13.07)\tAcc@5  50.00 ( 35.65)\n","Epoch: [4][390/391]\tTime  0.083 ( 0.091)\tLoss 3.2571e+00 (3.8489e+00)\tAcc@1  17.50 ( 13.23)\tAcc@5  57.50 ( 35.96)\n","==> Train Accuracy: Acc@1 13.234 || Acc@5 35.956\n","==> Test Accuracy:  Acc@1 21.370 || Acc@5 50.370\n","==> 38.00 seconds to train this epoch\n","\n","\n","----- epoch: 5, lr: 0.1 -----\n","Epoch: [5][  0/391]\tTime  0.227 ( 0.227)\tLoss 3.8961e+00 (3.8961e+00)\tAcc@1  10.94 ( 10.94)\tAcc@5  39.84 ( 39.84)\n","Epoch: [5][ 30/391]\tTime  0.095 ( 0.095)\tLoss 3.9993e+00 (3.7721e+00)\tAcc@1   7.03 ( 15.95)\tAcc@5  22.66 ( 40.12)\n","Epoch: [5][ 60/391]\tTime  0.090 ( 0.093)\tLoss 4.0361e+00 (3.7287e+00)\tAcc@1   9.38 ( 16.02)\tAcc@5  29.69 ( 41.01)\n","Epoch: [5][ 90/391]\tTime  0.093 ( 0.092)\tLoss 3.4440e+00 (3.7447e+00)\tAcc@1  21.09 ( 15.52)\tAcc@5  46.88 ( 39.69)\n","Epoch: [5][120/391]\tTime  0.092 ( 0.092)\tLoss 3.9982e+00 (3.7400e+00)\tAcc@1  11.72 ( 15.72)\tAcc@5  35.94 ( 39.79)\n","Epoch: [5][150/391]\tTime  0.090 ( 0.092)\tLoss 3.9309e+00 (3.7455e+00)\tAcc@1   7.81 ( 15.53)\tAcc@5  25.00 ( 39.21)\n","Epoch: [5][180/391]\tTime  0.091 ( 0.092)\tLoss 3.3185e+00 (3.7496e+00)\tAcc@1  25.78 ( 15.53)\tAcc@5  54.69 ( 39.00)\n","Epoch: [5][210/391]\tTime  0.088 ( 0.091)\tLoss 3.8996e+00 (3.7547e+00)\tAcc@1   3.12 ( 15.36)\tAcc@5  10.94 ( 38.68)\n","Epoch: [5][240/391]\tTime  0.090 ( 0.091)\tLoss 3.5983e+00 (3.7416e+00)\tAcc@1  17.97 ( 15.64)\tAcc@5  53.12 ( 39.30)\n","Epoch: [5][270/391]\tTime  0.090 ( 0.091)\tLoss 3.3156e+00 (3.7366e+00)\tAcc@1  21.09 ( 15.62)\tAcc@5  45.31 ( 39.22)\n","Epoch: [5][300/391]\tTime  0.091 ( 0.091)\tLoss 3.8957e+00 (3.7389e+00)\tAcc@1  17.97 ( 15.58)\tAcc@5  38.28 ( 39.26)\n","Epoch: [5][330/391]\tTime  0.090 ( 0.091)\tLoss 3.6106e+00 (3.7397e+00)\tAcc@1  22.66 ( 15.62)\tAcc@5  54.69 ( 39.32)\n","Epoch: [5][360/391]\tTime  0.092 ( 0.091)\tLoss 3.6625e+00 (3.7366e+00)\tAcc@1  20.31 ( 15.68)\tAcc@5  40.62 ( 39.29)\n","Epoch: [5][390/391]\tTime  0.082 ( 0.091)\tLoss 4.0795e+00 (3.7285e+00)\tAcc@1   5.00 ( 15.91)\tAcc@5  22.50 ( 39.66)\n","==> Train Accuracy: Acc@1 15.912 || Acc@5 39.660\n","==> Test Accuracy:  Acc@1 22.670 || Acc@5 52.820\n","==> 38.20 seconds to train this epoch\n","\n","\n","----- epoch: 6, lr: 0.1 -----\n","Epoch: [6][  0/391]\tTime  0.232 ( 0.232)\tLoss 3.4768e+00 (3.4768e+00)\tAcc@1  24.22 ( 24.22)\tAcc@5  50.78 ( 50.78)\n","Epoch: [6][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.8501e+00 (3.6526e+00)\tAcc@1   1.56 ( 17.69)\tAcc@5   4.69 ( 41.51)\n","Epoch: [6][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.8928e+00 (3.7165e+00)\tAcc@1  12.50 ( 16.64)\tAcc@5  35.94 ( 40.05)\n","Epoch: [6][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.6541e+00 (3.7041e+00)\tAcc@1  21.88 ( 16.72)\tAcc@5  46.09 ( 40.72)\n","Epoch: [6][120/391]\tTime  0.094 ( 0.092)\tLoss 3.9993e+00 (3.6946e+00)\tAcc@1   6.25 ( 16.84)\tAcc@5  24.22 ( 40.81)\n","Epoch: [6][150/391]\tTime  0.086 ( 0.092)\tLoss 4.0149e+00 (3.6860e+00)\tAcc@1   8.59 ( 16.83)\tAcc@5  30.47 ( 40.91)\n","Epoch: [6][180/391]\tTime  0.092 ( 0.092)\tLoss 3.8693e+00 (3.6989e+00)\tAcc@1   1.56 ( 16.57)\tAcc@5  10.16 ( 40.37)\n","Epoch: [6][210/391]\tTime  0.090 ( 0.091)\tLoss 3.2874e+00 (3.6810e+00)\tAcc@1  22.66 ( 16.86)\tAcc@5  57.03 ( 40.88)\n","Epoch: [6][240/391]\tTime  0.090 ( 0.091)\tLoss 3.8485e+00 (3.6770e+00)\tAcc@1   7.03 ( 16.75)\tAcc@5  22.66 ( 40.65)\n","Epoch: [6][270/391]\tTime  0.090 ( 0.091)\tLoss 3.7999e+00 (3.6659e+00)\tAcc@1  15.62 ( 16.91)\tAcc@5  34.38 ( 41.01)\n","Epoch: [6][300/391]\tTime  0.090 ( 0.091)\tLoss 3.8882e+00 (3.6599e+00)\tAcc@1   6.25 ( 16.87)\tAcc@5  16.41 ( 41.00)\n","Epoch: [6][330/391]\tTime  0.090 ( 0.091)\tLoss 3.7981e+00 (3.6497e+00)\tAcc@1  10.94 ( 17.16)\tAcc@5  43.75 ( 41.68)\n","Epoch: [6][360/391]\tTime  0.091 ( 0.091)\tLoss 3.7025e+00 (3.6514e+00)\tAcc@1  21.88 ( 17.14)\tAcc@5  49.22 ( 41.64)\n","Epoch: [6][390/391]\tTime  0.082 ( 0.091)\tLoss 3.5805e+00 (3.6443e+00)\tAcc@1  23.75 ( 17.38)\tAcc@5  50.00 ( 42.15)\n","==> Train Accuracy: Acc@1 17.378 || Acc@5 42.154\n","==> Test Accuracy:  Acc@1 26.100 || Acc@5 55.650\n","==> 38.01 seconds to train this epoch\n","\n","\n","----- epoch: 7, lr: 0.1 -----\n","Epoch: [7][  0/391]\tTime  0.230 ( 0.230)\tLoss 2.8753e+00 (2.8753e+00)\tAcc@1  32.03 ( 32.03)\tAcc@5  62.50 ( 62.50)\n","Epoch: [7][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.7094e+00 (3.6010e+00)\tAcc@1  19.53 ( 16.94)\tAcc@5  49.22 ( 41.15)\n","Epoch: [7][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.8791e+00 (3.5696e+00)\tAcc@1   5.47 ( 17.29)\tAcc@5  25.00 ( 40.84)\n","Epoch: [7][ 90/391]\tTime  0.093 ( 0.092)\tLoss 3.8371e+00 (3.5409e+00)\tAcc@1   4.69 ( 18.29)\tAcc@5  10.94 ( 42.68)\n","Epoch: [7][120/391]\tTime  0.089 ( 0.092)\tLoss 3.6960e+00 (3.5502e+00)\tAcc@1  24.22 ( 18.25)\tAcc@5  50.78 ( 42.56)\n","Epoch: [7][150/391]\tTime  0.091 ( 0.092)\tLoss 2.7916e+00 (3.5421e+00)\tAcc@1  30.47 ( 18.74)\tAcc@5  60.94 ( 43.84)\n","Epoch: [7][180/391]\tTime  0.091 ( 0.092)\tLoss 3.1557e+00 (3.5194e+00)\tAcc@1  35.94 ( 19.20)\tAcc@5  64.06 ( 44.44)\n","Epoch: [7][210/391]\tTime  0.090 ( 0.091)\tLoss 3.4999e+00 (3.5132e+00)\tAcc@1  22.66 ( 19.19)\tAcc@5  57.81 ( 44.45)\n","Epoch: [7][240/391]\tTime  0.092 ( 0.091)\tLoss 3.6147e+00 (3.5070e+00)\tAcc@1   2.34 ( 19.26)\tAcc@5  16.41 ( 44.35)\n","Epoch: [7][270/391]\tTime  0.094 ( 0.091)\tLoss 2.8096e+00 (3.4953e+00)\tAcc@1  30.47 ( 19.41)\tAcc@5  64.06 ( 44.61)\n","Epoch: [7][300/391]\tTime  0.091 ( 0.091)\tLoss 3.0820e+00 (3.4918e+00)\tAcc@1  32.81 ( 19.75)\tAcc@5  58.59 ( 45.21)\n","Epoch: [7][330/391]\tTime  0.090 ( 0.091)\tLoss 2.8795e+00 (3.4971e+00)\tAcc@1  32.81 ( 19.65)\tAcc@5  65.62 ( 45.12)\n","Epoch: [7][360/391]\tTime  0.090 ( 0.091)\tLoss 2.9004e+00 (3.4942e+00)\tAcc@1  25.78 ( 19.51)\tAcc@5  53.91 ( 44.80)\n","Epoch: [7][390/391]\tTime  0.083 ( 0.091)\tLoss 3.7673e+00 (3.4887e+00)\tAcc@1  20.00 ( 19.73)\tAcc@5  47.50 ( 45.14)\n","==> Train Accuracy: Acc@1 19.734 || Acc@5 45.140\n","==> Test Accuracy:  Acc@1 32.640 || Acc@5 66.190\n","==> 38.04 seconds to train this epoch\n","\n","\n","----- epoch: 8, lr: 0.1 -----\n","Epoch: [8][  0/391]\tTime  0.220 ( 0.220)\tLoss 2.9186e+00 (2.9186e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  61.72 ( 61.72)\n","Epoch: [8][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.2714e+00 (3.4923e+00)\tAcc@1   2.34 ( 20.21)\tAcc@5   9.38 ( 47.33)\n","Epoch: [8][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.7021e+00 (3.5188e+00)\tAcc@1  18.75 ( 18.97)\tAcc@5  45.31 ( 44.85)\n","Epoch: [8][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.6537e+00 (3.4721e+00)\tAcc@1  14.84 ( 20.68)\tAcc@5  40.62 ( 46.91)\n","Epoch: [8][120/391]\tTime  0.096 ( 0.092)\tLoss 3.4996e+00 (3.4595e+00)\tAcc@1  26.56 ( 20.82)\tAcc@5  57.03 ( 47.19)\n","Epoch: [8][150/391]\tTime  0.091 ( 0.092)\tLoss 3.6091e+00 (3.4395e+00)\tAcc@1  18.75 ( 21.31)\tAcc@5  47.66 ( 47.80)\n","Epoch: [8][180/391]\tTime  0.091 ( 0.091)\tLoss 2.8661e+00 (3.4307e+00)\tAcc@1  30.47 ( 21.64)\tAcc@5  65.62 ( 48.43)\n","Epoch: [8][210/391]\tTime  0.091 ( 0.091)\tLoss 4.0239e+00 (3.4199e+00)\tAcc@1   3.91 ( 22.07)\tAcc@5  20.31 ( 48.93)\n","Epoch: [8][240/391]\tTime  0.090 ( 0.091)\tLoss 2.7998e+00 (3.4197e+00)\tAcc@1  32.03 ( 21.78)\tAcc@5  64.06 ( 48.13)\n","Epoch: [8][270/391]\tTime  0.090 ( 0.091)\tLoss 3.6044e+00 (3.4217e+00)\tAcc@1  22.66 ( 21.78)\tAcc@5  48.44 ( 48.09)\n","Epoch: [8][300/391]\tTime  0.090 ( 0.091)\tLoss 2.8136e+00 (3.4165e+00)\tAcc@1  26.56 ( 22.14)\tAcc@5  62.50 ( 48.54)\n","Epoch: [8][330/391]\tTime  0.090 ( 0.091)\tLoss 3.7583e+00 (3.3990e+00)\tAcc@1  17.97 ( 22.64)\tAcc@5  42.97 ( 49.37)\n","Epoch: [8][360/391]\tTime  0.091 ( 0.091)\tLoss 3.4848e+00 (3.3990e+00)\tAcc@1  28.91 ( 22.71)\tAcc@5  58.59 ( 49.44)\n","Epoch: [8][390/391]\tTime  0.082 ( 0.091)\tLoss 3.7435e+00 (3.3933e+00)\tAcc@1  20.00 ( 22.84)\tAcc@5  37.50 ( 49.58)\n","==> Train Accuracy: Acc@1 22.844 || Acc@5 49.584\n","==> Test Accuracy:  Acc@1 26.760 || Acc@5 57.050\n","==> 38.03 seconds to train this epoch\n","\n","\n","----- epoch: 9, lr: 0.1 -----\n","Epoch: [9][  0/391]\tTime  0.194 ( 0.194)\tLoss 3.4734e+00 (3.4734e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  55.47 ( 55.47)\n","Epoch: [9][ 30/391]\tTime  0.091 ( 0.094)\tLoss 2.8798e+00 (3.2697e+00)\tAcc@1  34.38 ( 28.18)\tAcc@5  73.44 ( 58.92)\n","Epoch: [9][ 60/391]\tTime  0.089 ( 0.092)\tLoss 3.5855e+00 (3.2856e+00)\tAcc@1  17.19 ( 26.70)\tAcc@5  46.88 ( 56.12)\n","Epoch: [9][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.6555e+00 (3.3141e+00)\tAcc@1   6.25 ( 25.15)\tAcc@5  20.31 ( 53.76)\n","Epoch: [9][120/391]\tTime  0.090 ( 0.091)\tLoss 3.1937e+00 (3.3092e+00)\tAcc@1  30.47 ( 25.01)\tAcc@5  57.81 ( 52.89)\n","Epoch: [9][150/391]\tTime  0.090 ( 0.091)\tLoss 3.2514e+00 (3.3121e+00)\tAcc@1  32.81 ( 24.96)\tAcc@5  64.84 ( 52.65)\n","Epoch: [9][180/391]\tTime  0.090 ( 0.091)\tLoss 3.2197e+00 (3.3255e+00)\tAcc@1  27.34 ( 24.87)\tAcc@5  66.41 ( 52.51)\n","Epoch: [9][210/391]\tTime  0.091 ( 0.091)\tLoss 2.6624e+00 (3.3031e+00)\tAcc@1  43.75 ( 25.33)\tAcc@5  65.62 ( 52.91)\n","Epoch: [9][240/391]\tTime  0.091 ( 0.091)\tLoss 3.1445e+00 (3.2975e+00)\tAcc@1  34.38 ( 25.64)\tAcc@5  58.59 ( 53.36)\n","Epoch: [9][270/391]\tTime  0.090 ( 0.091)\tLoss 2.5158e+00 (3.3013e+00)\tAcc@1  39.84 ( 25.28)\tAcc@5  74.22 ( 52.84)\n","Epoch: [9][300/391]\tTime  0.091 ( 0.091)\tLoss 3.6446e+00 (3.2960e+00)\tAcc@1  13.28 ( 25.45)\tAcc@5  44.53 ( 52.89)\n","Epoch: [9][330/391]\tTime  0.090 ( 0.091)\tLoss 3.5832e+00 (3.3019e+00)\tAcc@1  16.41 ( 25.23)\tAcc@5  43.75 ( 52.69)\n","Epoch: [9][360/391]\tTime  0.090 ( 0.091)\tLoss 3.6383e+00 (3.2922e+00)\tAcc@1   9.38 ( 25.48)\tAcc@5  25.00 ( 53.06)\n","Epoch: [9][390/391]\tTime  0.078 ( 0.091)\tLoss 3.5167e+00 (3.2946e+00)\tAcc@1   1.25 ( 25.44)\tAcc@5   6.25 ( 53.09)\n","==> Train Accuracy: Acc@1 25.440 || Acc@5 53.090\n","==> Test Accuracy:  Acc@1 33.160 || Acc@5 64.750\n","==> 37.99 seconds to train this epoch\n","\n","\n","----- epoch: 10, lr: 0.1 -----\n","Epoch: [10][  0/391]\tTime  0.243 ( 0.243)\tLoss 3.1591e+00 (3.1591e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  63.28 ( 63.28)\n","Epoch: [10][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.5464e+00 (3.2557e+00)\tAcc@1  20.31 ( 27.47)\tAcc@5  53.12 ( 56.38)\n","Epoch: [10][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.3119e+00 (3.2436e+00)\tAcc@1  23.44 ( 26.42)\tAcc@5  54.69 ( 54.70)\n","Epoch: [10][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.6343e+00 (3.2266e+00)\tAcc@1  21.88 ( 27.31)\tAcc@5  44.53 ( 55.51)\n","Epoch: [10][120/391]\tTime  0.099 ( 0.092)\tLoss 3.7166e+00 (3.2313e+00)\tAcc@1   3.91 ( 27.18)\tAcc@5  16.41 ( 54.90)\n","Epoch: [10][150/391]\tTime  0.089 ( 0.091)\tLoss 3.2586e+00 (3.2388e+00)\tAcc@1  26.56 ( 26.99)\tAcc@5  63.28 ( 54.61)\n","Epoch: [10][180/391]\tTime  0.091 ( 0.091)\tLoss 2.4643e+00 (3.2360e+00)\tAcc@1  39.84 ( 26.91)\tAcc@5  70.31 ( 54.38)\n","Epoch: [10][210/391]\tTime  0.090 ( 0.091)\tLoss 3.7086e+00 (3.2233e+00)\tAcc@1  19.53 ( 27.29)\tAcc@5  46.09 ( 54.94)\n","Epoch: [10][240/391]\tTime  0.091 ( 0.091)\tLoss 3.3334e+00 (3.2035e+00)\tAcc@1  32.03 ( 27.73)\tAcc@5  60.16 ( 55.15)\n","Epoch: [10][270/391]\tTime  0.090 ( 0.091)\tLoss 2.3872e+00 (3.2005e+00)\tAcc@1  41.41 ( 27.53)\tAcc@5  73.44 ( 54.94)\n","Epoch: [10][300/391]\tTime  0.091 ( 0.091)\tLoss 3.6515e+00 (3.2007e+00)\tAcc@1   6.25 ( 27.49)\tAcc@5  16.41 ( 54.73)\n","Epoch: [10][330/391]\tTime  0.091 ( 0.091)\tLoss 3.4107e+00 (3.1886e+00)\tAcc@1  28.91 ( 27.90)\tAcc@5  59.38 ( 55.38)\n","Epoch: [10][360/391]\tTime  0.090 ( 0.091)\tLoss 3.5464e+00 (3.1942e+00)\tAcc@1  22.66 ( 27.81)\tAcc@5  50.00 ( 55.29)\n","Epoch: [10][390/391]\tTime  0.078 ( 0.091)\tLoss 3.5639e+00 (3.1938e+00)\tAcc@1  10.00 ( 27.76)\tAcc@5  35.00 ( 55.43)\n","==> Train Accuracy: Acc@1 27.762 || Acc@5 55.428\n","==> Test Accuracy:  Acc@1 40.630 || Acc@5 72.570\n","==> 37.98 seconds to train this epoch\n","\n","\n","----- epoch: 11, lr: 0.1 -----\n","Epoch: [11][  0/391]\tTime  0.222 ( 0.222)\tLoss 3.2236e+00 (3.2236e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   8.59 (  8.59)\n","Epoch: [11][ 30/391]\tTime  0.093 ( 0.094)\tLoss 3.2655e+00 (3.1082e+00)\tAcc@1  32.03 ( 27.80)\tAcc@5  62.50 ( 53.15)\n","Epoch: [11][ 60/391]\tTime  0.091 ( 0.092)\tLoss 3.5839e+00 (3.1562e+00)\tAcc@1  12.50 ( 26.92)\tAcc@5  39.06 ( 53.04)\n","Epoch: [11][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.2182e+00 (3.1723e+00)\tAcc@1  32.81 ( 26.88)\tAcc@5  63.28 ( 52.91)\n","Epoch: [11][120/391]\tTime  0.088 ( 0.092)\tLoss 2.8450e+00 (3.1799e+00)\tAcc@1  39.84 ( 26.85)\tAcc@5  71.09 ( 53.00)\n","Epoch: [11][150/391]\tTime  0.090 ( 0.091)\tLoss 3.2365e+00 (3.1653e+00)\tAcc@1   3.91 ( 27.20)\tAcc@5  11.72 ( 53.50)\n","Epoch: [11][180/391]\tTime  0.090 ( 0.091)\tLoss 2.9630e+00 (3.1557e+00)\tAcc@1  37.50 ( 27.55)\tAcc@5  68.75 ( 54.28)\n","Epoch: [11][210/391]\tTime  0.091 ( 0.091)\tLoss 3.5180e+00 (3.1670e+00)\tAcc@1  17.19 ( 27.34)\tAcc@5  41.41 ( 54.04)\n","Epoch: [11][240/391]\tTime  0.090 ( 0.091)\tLoss 3.4205e+00 (3.1604e+00)\tAcc@1  27.34 ( 27.46)\tAcc@5  48.44 ( 54.17)\n","Epoch: [11][270/391]\tTime  0.090 ( 0.091)\tLoss 3.5322e+00 (3.1773e+00)\tAcc@1  14.84 ( 27.18)\tAcc@5  42.19 ( 53.91)\n","Epoch: [11][300/391]\tTime  0.090 ( 0.091)\tLoss 3.2724e+00 (3.1760e+00)\tAcc@1  34.38 ( 27.41)\tAcc@5  60.94 ( 54.17)\n","Epoch: [11][330/391]\tTime  0.090 ( 0.091)\tLoss 2.8973e+00 (3.1774e+00)\tAcc@1  38.28 ( 27.56)\tAcc@5  75.00 ( 54.41)\n","Epoch: [11][360/391]\tTime  0.090 ( 0.091)\tLoss 2.4181e+00 (3.1728e+00)\tAcc@1  55.47 ( 27.80)\tAcc@5  81.25 ( 54.88)\n","Epoch: [11][390/391]\tTime  0.082 ( 0.091)\tLoss 2.9508e+00 (3.1715e+00)\tAcc@1  38.75 ( 27.82)\tAcc@5  73.75 ( 54.97)\n","==> Train Accuracy: Acc@1 27.824 || Acc@5 54.972\n","==> Test Accuracy:  Acc@1 44.110 || Acc@5 75.400\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 12, lr: 0.1 -----\n","Epoch: [12][  0/391]\tTime  0.193 ( 0.193)\tLoss 3.4720e+00 (3.4720e+00)\tAcc@1  17.97 ( 17.97)\tAcc@5  35.16 ( 35.16)\n","Epoch: [12][ 30/391]\tTime  0.091 ( 0.093)\tLoss 3.1556e+00 (3.1736e+00)\tAcc@1  35.94 ( 29.99)\tAcc@5  65.62 ( 56.22)\n","Epoch: [12][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.1278e+00 (3.1533e+00)\tAcc@1  40.62 ( 30.16)\tAcc@5  69.53 ( 57.27)\n","Epoch: [12][ 90/391]\tTime  0.090 ( 0.091)\tLoss 3.4911e+00 (3.1288e+00)\tAcc@1  25.00 ( 29.65)\tAcc@5  54.69 ( 56.89)\n","Epoch: [12][120/391]\tTime  0.094 ( 0.091)\tLoss 3.6082e+00 (3.1544e+00)\tAcc@1  17.19 ( 28.82)\tAcc@5  45.31 ( 56.20)\n","Epoch: [12][150/391]\tTime  0.092 ( 0.091)\tLoss 3.2294e+00 (3.1372e+00)\tAcc@1   0.78 ( 28.40)\tAcc@5   7.81 ( 55.25)\n","Epoch: [12][180/391]\tTime  0.090 ( 0.091)\tLoss 3.3682e+00 (3.1133e+00)\tAcc@1  25.00 ( 28.55)\tAcc@5  60.16 ( 55.87)\n","Epoch: [12][210/391]\tTime  0.091 ( 0.091)\tLoss 2.4124e+00 (3.1017e+00)\tAcc@1  38.28 ( 28.36)\tAcc@5  69.53 ( 55.65)\n","Epoch: [12][240/391]\tTime  0.092 ( 0.091)\tLoss 2.7242e+00 (3.1026e+00)\tAcc@1  48.44 ( 28.77)\tAcc@5  75.78 ( 56.26)\n","Epoch: [12][270/391]\tTime  0.090 ( 0.091)\tLoss 3.4144e+00 (3.1127e+00)\tAcc@1  25.78 ( 28.52)\tAcc@5  57.81 ( 56.06)\n","Epoch: [12][300/391]\tTime  0.091 ( 0.091)\tLoss 3.0397e+00 (3.1044e+00)\tAcc@1  38.28 ( 28.77)\tAcc@5  69.53 ( 56.49)\n","Epoch: [12][330/391]\tTime  0.091 ( 0.091)\tLoss 3.5265e+00 (3.1028e+00)\tAcc@1   5.47 ( 28.76)\tAcc@5  25.00 ( 56.54)\n","Epoch: [12][360/391]\tTime  0.090 ( 0.091)\tLoss 3.3053e+00 (3.1026e+00)\tAcc@1  21.09 ( 28.62)\tAcc@5  50.78 ( 56.29)\n","Epoch: [12][390/391]\tTime  0.082 ( 0.091)\tLoss 3.3400e+00 (3.1043e+00)\tAcc@1  35.00 ( 28.78)\tAcc@5  63.75 ( 56.54)\n","==> Train Accuracy: Acc@1 28.778 || Acc@5 56.544\n","==> Test Accuracy:  Acc@1 43.520 || Acc@5 75.790\n","==> 38.00 seconds to train this epoch\n","\n","\n","----- epoch: 13, lr: 0.1 -----\n","Epoch: [13][  0/391]\tTime  0.198 ( 0.198)\tLoss 1.9828e+00 (1.9828e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  80.47 ( 80.47)\n","Epoch: [13][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.7660e+00 (2.9655e+00)\tAcc@1   4.69 ( 30.04)\tAcc@5  10.16 ( 56.96)\n","Epoch: [13][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.4181e+00 (3.0386e+00)\tAcc@1  26.56 ( 29.76)\tAcc@5  50.00 ( 57.58)\n","Epoch: [13][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.3849e+00 (3.0032e+00)\tAcc@1  46.88 ( 31.77)\tAcc@5  82.81 ( 60.31)\n","Epoch: [13][120/391]\tTime  0.091 ( 0.091)\tLoss 2.7760e+00 (3.0049e+00)\tAcc@1  46.88 ( 32.47)\tAcc@5  78.12 ( 61.62)\n","Epoch: [13][150/391]\tTime  0.091 ( 0.091)\tLoss 2.4850e+00 (2.9699e+00)\tAcc@1  53.91 ( 33.11)\tAcc@5  84.38 ( 62.17)\n","Epoch: [13][180/391]\tTime  0.091 ( 0.091)\tLoss 3.5082e+00 (2.9727e+00)\tAcc@1  21.88 ( 32.39)\tAcc@5  52.34 ( 61.02)\n","Epoch: [13][210/391]\tTime  0.087 ( 0.091)\tLoss 3.5216e+00 (2.9938e+00)\tAcc@1  20.31 ( 31.56)\tAcc@5  42.97 ( 59.93)\n","Epoch: [13][240/391]\tTime  0.090 ( 0.091)\tLoss 2.7894e+00 (2.9861e+00)\tAcc@1  45.31 ( 31.28)\tAcc@5  75.00 ( 59.30)\n","Epoch: [13][270/391]\tTime  0.090 ( 0.091)\tLoss 1.9847e+00 (2.9889e+00)\tAcc@1  50.00 ( 31.38)\tAcc@5  77.34 ( 59.46)\n","Epoch: [13][300/391]\tTime  0.090 ( 0.091)\tLoss 3.2416e+00 (3.0011e+00)\tAcc@1  33.59 ( 31.20)\tAcc@5  59.38 ( 59.47)\n","Epoch: [13][330/391]\tTime  0.090 ( 0.091)\tLoss 3.1897e+00 (3.0075e+00)\tAcc@1  32.03 ( 31.16)\tAcc@5  61.72 ( 59.40)\n","Epoch: [13][360/391]\tTime  0.090 ( 0.091)\tLoss 2.5971e+00 (3.0018e+00)\tAcc@1  38.28 ( 31.33)\tAcc@5  67.97 ( 59.63)\n","Epoch: [13][390/391]\tTime  0.081 ( 0.091)\tLoss 3.5200e+00 (3.0067e+00)\tAcc@1  18.75 ( 31.31)\tAcc@5  47.50 ( 59.57)\n","==> Train Accuracy: Acc@1 31.310 || Acc@5 59.570\n","==> Test Accuracy:  Acc@1 43.500 || Acc@5 74.930\n","==> 37.99 seconds to train this epoch\n","\n","\n","----- epoch: 14, lr: 0.1 -----\n","Epoch: [14][  0/391]\tTime  0.208 ( 0.208)\tLoss 2.3314e+00 (2.3314e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  79.69 ( 79.69)\n","Epoch: [14][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.2258e+00 (3.0256e+00)\tAcc@1   5.47 ( 29.26)\tAcc@5  22.66 ( 55.92)\n","Epoch: [14][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.5789e+00 (2.9871e+00)\tAcc@1   8.59 ( 32.16)\tAcc@5  28.12 ( 59.76)\n","Epoch: [14][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.5115e+00 (3.0450e+00)\tAcc@1   3.91 ( 31.05)\tAcc@5  23.44 ( 58.73)\n","Epoch: [14][120/391]\tTime  0.090 ( 0.091)\tLoss 3.3216e+00 (3.0404e+00)\tAcc@1  28.12 ( 31.26)\tAcc@5  56.25 ( 58.60)\n","Epoch: [14][150/391]\tTime  0.090 ( 0.091)\tLoss 2.3412e+00 (3.0093e+00)\tAcc@1  45.31 ( 32.02)\tAcc@5  71.88 ( 59.22)\n","Epoch: [14][180/391]\tTime  0.091 ( 0.091)\tLoss 2.7888e+00 (3.0045e+00)\tAcc@1  49.22 ( 32.22)\tAcc@5  76.56 ( 59.66)\n","Epoch: [14][210/391]\tTime  0.091 ( 0.091)\tLoss 2.3139e+00 (2.9698e+00)\tAcc@1  46.09 ( 33.09)\tAcc@5  75.00 ( 61.23)\n","Epoch: [14][240/391]\tTime  0.091 ( 0.091)\tLoss 2.2505e+00 (2.9739e+00)\tAcc@1  46.88 ( 32.76)\tAcc@5  81.25 ( 60.71)\n","Epoch: [14][270/391]\tTime  0.091 ( 0.091)\tLoss 3.2370e+00 (2.9736e+00)\tAcc@1   4.69 ( 32.77)\tAcc@5  17.19 ( 60.81)\n","Epoch: [14][300/391]\tTime  0.090 ( 0.091)\tLoss 3.0766e+00 (2.9765e+00)\tAcc@1  33.59 ( 32.53)\tAcc@5  70.31 ( 60.60)\n","Epoch: [14][330/391]\tTime  0.090 ( 0.091)\tLoss 3.0726e+00 (2.9834e+00)\tAcc@1  39.06 ( 32.42)\tAcc@5  68.75 ( 60.51)\n","Epoch: [14][360/391]\tTime  0.091 ( 0.091)\tLoss 3.3867e+00 (2.9813e+00)\tAcc@1  10.94 ( 32.63)\tAcc@5  29.69 ( 60.72)\n","Epoch: [14][390/391]\tTime  0.082 ( 0.091)\tLoss 3.5105e+00 (2.9873e+00)\tAcc@1  28.75 ( 32.47)\tAcc@5  50.00 ( 60.50)\n","==> Train Accuracy: Acc@1 32.466 || Acc@5 60.498\n","==> Test Accuracy:  Acc@1 48.260 || Acc@5 79.590\n","==> 38.04 seconds to train this epoch\n","\n","\n","----- epoch: 15, lr: 0.1 -----\n","Epoch: [15][  0/391]\tTime  0.228 ( 0.228)\tLoss 3.3102e+00 (3.3102e+00)\tAcc@1  21.09 ( 21.09)\tAcc@5  47.66 ( 47.66)\n","Epoch: [15][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.3370e+00 (2.8427e+00)\tAcc@1  35.94 ( 35.53)\tAcc@5  60.16 ( 64.36)\n","Epoch: [15][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.3546e+00 (2.9355e+00)\tAcc@1  57.03 ( 32.67)\tAcc@5  82.03 ( 60.30)\n","Epoch: [15][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.7939e+00 (2.9142e+00)\tAcc@1  38.28 ( 33.70)\tAcc@5  71.09 ( 61.23)\n","Epoch: [15][120/391]\tTime  0.090 ( 0.092)\tLoss 2.9929e+00 (2.9360e+00)\tAcc@1  41.41 ( 33.40)\tAcc@5  71.09 ( 61.04)\n","Epoch: [15][150/391]\tTime  0.090 ( 0.092)\tLoss 3.1945e+00 (2.9570e+00)\tAcc@1   0.78 ( 32.12)\tAcc@5  15.62 ( 59.20)\n","Epoch: [15][180/391]\tTime  0.092 ( 0.091)\tLoss 2.7464e+00 (2.9340e+00)\tAcc@1  39.84 ( 33.36)\tAcc@5  74.22 ( 61.10)\n","Epoch: [15][210/391]\tTime  0.091 ( 0.091)\tLoss 2.6569e+00 (2.9454e+00)\tAcc@1  46.09 ( 32.92)\tAcc@5  79.69 ( 60.69)\n","Epoch: [15][240/391]\tTime  0.090 ( 0.091)\tLoss 3.1933e+00 (2.9371e+00)\tAcc@1   3.12 ( 33.10)\tAcc@5  11.72 ( 60.84)\n","Epoch: [15][270/391]\tTime  0.095 ( 0.091)\tLoss 3.2282e+00 (2.9429e+00)\tAcc@1  22.66 ( 33.19)\tAcc@5  52.34 ( 60.82)\n","Epoch: [15][300/391]\tTime  0.090 ( 0.091)\tLoss 2.8289e+00 (2.9460e+00)\tAcc@1  50.78 ( 33.07)\tAcc@5  78.12 ( 60.46)\n","Epoch: [15][330/391]\tTime  0.088 ( 0.091)\tLoss 3.1765e+00 (2.9468e+00)\tAcc@1  35.16 ( 33.43)\tAcc@5  70.31 ( 61.02)\n","Epoch: [15][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8972e+00 (2.9353e+00)\tAcc@1  50.00 ( 33.70)\tAcc@5  78.91 ( 61.33)\n","Epoch: [15][390/391]\tTime  0.082 ( 0.091)\tLoss 3.3997e+00 (2.9401e+00)\tAcc@1   5.00 ( 33.32)\tAcc@5  22.50 ( 60.91)\n","==> Train Accuracy: Acc@1 33.324 || Acc@5 60.906\n","==> Test Accuracy:  Acc@1 43.960 || Acc@5 76.230\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 16, lr: 0.1 -----\n","Epoch: [16][  0/391]\tTime  0.210 ( 0.210)\tLoss 3.2110e+00 (3.2110e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  57.81 ( 57.81)\n","Epoch: [16][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.8417e+00 (3.0427e+00)\tAcc@1   3.12 ( 30.59)\tAcc@5  10.94 ( 58.74)\n","Epoch: [16][ 60/391]\tTime  0.092 ( 0.092)\tLoss 3.2710e+00 (2.9359e+00)\tAcc@1  14.84 ( 33.27)\tAcc@5  51.56 ( 62.01)\n","Epoch: [16][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.8452e+00 (2.9509e+00)\tAcc@1  44.53 ( 32.59)\tAcc@5  73.44 ( 61.45)\n","Epoch: [16][120/391]\tTime  0.095 ( 0.091)\tLoss 2.6952e+00 (2.9562e+00)\tAcc@1  42.97 ( 32.94)\tAcc@5  82.81 ( 61.89)\n","Epoch: [16][150/391]\tTime  0.090 ( 0.091)\tLoss 3.3822e+00 (2.9812e+00)\tAcc@1  21.09 ( 31.68)\tAcc@5  45.31 ( 59.97)\n","Epoch: [16][180/391]\tTime  0.090 ( 0.091)\tLoss 2.5282e+00 (2.9733e+00)\tAcc@1  54.69 ( 32.11)\tAcc@5  84.38 ( 60.25)\n","Epoch: [16][210/391]\tTime  0.092 ( 0.091)\tLoss 2.9346e+00 (2.9796e+00)\tAcc@1  43.75 ( 32.15)\tAcc@5  75.00 ( 60.33)\n","Epoch: [16][240/391]\tTime  0.091 ( 0.091)\tLoss 3.1668e+00 (2.9818e+00)\tAcc@1  32.81 ( 31.90)\tAcc@5  62.50 ( 60.01)\n","Epoch: [16][270/391]\tTime  0.091 ( 0.091)\tLoss 3.4307e+00 (2.9720e+00)\tAcc@1  26.56 ( 32.30)\tAcc@5  46.88 ( 60.44)\n","Epoch: [16][300/391]\tTime  0.089 ( 0.091)\tLoss 3.4761e+00 (2.9639e+00)\tAcc@1  14.06 ( 32.41)\tAcc@5  46.09 ( 60.55)\n","Epoch: [16][330/391]\tTime  0.090 ( 0.091)\tLoss 3.3129e+00 (2.9644e+00)\tAcc@1  16.41 ( 32.19)\tAcc@5  37.50 ( 60.28)\n","Epoch: [16][360/391]\tTime  0.091 ( 0.091)\tLoss 3.4292e+00 (2.9638e+00)\tAcc@1  17.97 ( 32.39)\tAcc@5  40.62 ( 60.44)\n","Epoch: [16][390/391]\tTime  0.080 ( 0.091)\tLoss 2.6369e+00 (2.9599e+00)\tAcc@1  46.25 ( 32.51)\tAcc@5  75.00 ( 60.54)\n","==> Train Accuracy: Acc@1 32.508 || Acc@5 60.536\n","==> Test Accuracy:  Acc@1 43.230 || Acc@5 75.060\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 17, lr: 0.1 -----\n","Epoch: [17][  0/391]\tTime  0.209 ( 0.209)\tLoss 2.5598e+00 (2.5598e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  79.69 ( 79.69)\n","Epoch: [17][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.3537e+00 (2.8584e+00)\tAcc@1  17.19 ( 34.43)\tAcc@5  51.56 ( 62.68)\n","Epoch: [17][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.4941e+00 (2.8621e+00)\tAcc@1  16.41 ( 33.62)\tAcc@5  42.19 ( 61.01)\n","Epoch: [17][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.0428e+00 (2.8967e+00)\tAcc@1  35.94 ( 33.53)\tAcc@5  64.06 ( 61.09)\n","Epoch: [17][120/391]\tTime  0.091 ( 0.092)\tLoss 2.6142e+00 (2.8987e+00)\tAcc@1  50.00 ( 33.29)\tAcc@5  78.91 ( 61.11)\n","Epoch: [17][150/391]\tTime  0.090 ( 0.091)\tLoss 3.1119e+00 (2.8902e+00)\tAcc@1  31.25 ( 33.74)\tAcc@5  60.16 ( 61.58)\n","Epoch: [17][180/391]\tTime  0.091 ( 0.091)\tLoss 2.3343e+00 (2.8777e+00)\tAcc@1   1.56 ( 33.73)\tAcc@5   4.69 ( 61.56)\n","Epoch: [17][210/391]\tTime  0.091 ( 0.091)\tLoss 2.8237e+00 (2.8633e+00)\tAcc@1  44.53 ( 34.20)\tAcc@5  71.88 ( 61.95)\n","Epoch: [17][240/391]\tTime  0.090 ( 0.091)\tLoss 2.8385e+00 (2.8761e+00)\tAcc@1  41.41 ( 34.00)\tAcc@5  76.56 ( 61.74)\n","Epoch: [17][270/391]\tTime  0.091 ( 0.091)\tLoss 3.0700e+00 (2.8758e+00)\tAcc@1  42.97 ( 33.83)\tAcc@5  67.19 ( 61.59)\n","Epoch: [17][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6070e+00 (2.8741e+00)\tAcc@1  59.38 ( 33.89)\tAcc@5  88.28 ( 61.60)\n","Epoch: [17][330/391]\tTime  0.090 ( 0.091)\tLoss 2.9718e+00 (2.8783e+00)\tAcc@1  35.16 ( 33.82)\tAcc@5  67.19 ( 61.57)\n","Epoch: [17][360/391]\tTime  0.091 ( 0.091)\tLoss 2.8858e+00 (2.8669e+00)\tAcc@1  50.78 ( 34.26)\tAcc@5  75.78 ( 62.15)\n","Epoch: [17][390/391]\tTime  0.082 ( 0.091)\tLoss 3.2070e+00 (2.8625e+00)\tAcc@1   7.50 ( 34.34)\tAcc@5  33.75 ( 62.13)\n","==> Train Accuracy: Acc@1 34.338 || Acc@5 62.128\n","==> Test Accuracy:  Acc@1 48.630 || Acc@5 80.400\n","==> 37.99 seconds to train this epoch\n","\n","\n","----- epoch: 18, lr: 0.1 -----\n","Epoch: [18][  0/391]\tTime  0.242 ( 0.242)\tLoss 3.4564e+00 (3.4564e+00)\tAcc@1  13.28 ( 13.28)\tAcc@5  35.94 ( 35.94)\n","Epoch: [18][ 30/391]\tTime  0.088 ( 0.095)\tLoss 3.0403e+00 (2.9742e+00)\tAcc@1  40.62 ( 28.00)\tAcc@5  71.09 ( 56.07)\n","Epoch: [18][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.9502e+00 (2.9152e+00)\tAcc@1  46.09 ( 32.48)\tAcc@5  71.88 ( 60.13)\n","Epoch: [18][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.1540e+00 (2.9580e+00)\tAcc@1  35.16 ( 32.96)\tAcc@5  68.75 ( 60.78)\n","Epoch: [18][120/391]\tTime  0.086 ( 0.092)\tLoss 3.0788e+00 (2.9470e+00)\tAcc@1   5.47 ( 32.74)\tAcc@5  26.56 ( 60.35)\n","Epoch: [18][150/391]\tTime  0.090 ( 0.092)\tLoss 2.6760e+00 (2.9349e+00)\tAcc@1  48.44 ( 33.13)\tAcc@5  78.12 ( 61.04)\n","Epoch: [18][180/391]\tTime  0.090 ( 0.091)\tLoss 2.2745e+00 (2.9171e+00)\tAcc@1  47.66 ( 33.95)\tAcc@5  84.38 ( 62.08)\n","Epoch: [18][210/391]\tTime  0.090 ( 0.091)\tLoss 2.6764e+00 (2.9005e+00)\tAcc@1  51.56 ( 34.37)\tAcc@5  78.91 ( 62.23)\n","Epoch: [18][240/391]\tTime  0.090 ( 0.091)\tLoss 3.0333e+00 (2.9002e+00)\tAcc@1   1.56 ( 34.40)\tAcc@5   5.47 ( 62.18)\n","Epoch: [18][270/391]\tTime  0.090 ( 0.091)\tLoss 3.0410e+00 (2.8922e+00)\tAcc@1  35.94 ( 34.84)\tAcc@5  67.97 ( 62.82)\n","Epoch: [18][300/391]\tTime  0.090 ( 0.091)\tLoss 3.4790e+00 (2.8726e+00)\tAcc@1  21.09 ( 35.46)\tAcc@5  43.75 ( 63.53)\n","Epoch: [18][330/391]\tTime  0.091 ( 0.091)\tLoss 3.0224e+00 (2.8819e+00)\tAcc@1  42.97 ( 34.89)\tAcc@5  71.88 ( 62.88)\n","Epoch: [18][360/391]\tTime  0.094 ( 0.091)\tLoss 2.5644e+00 (2.8603e+00)\tAcc@1  50.78 ( 35.55)\tAcc@5  79.69 ( 63.55)\n","Epoch: [18][390/391]\tTime  0.081 ( 0.091)\tLoss 3.3577e+00 (2.8639e+00)\tAcc@1  31.25 ( 35.24)\tAcc@5  57.50 ( 63.18)\n","==> Train Accuracy: Acc@1 35.240 || Acc@5 63.178\n","==> Test Accuracy:  Acc@1 51.330 || Acc@5 80.680\n","==> 37.99 seconds to train this epoch\n","\n","\n","----- epoch: 19, lr: 0.1 -----\n","Epoch: [19][  0/391]\tTime  0.210 ( 0.210)\tLoss 3.0271e+00 (3.0271e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  71.88 ( 71.88)\n","Epoch: [19][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.3582e+00 (2.7695e+00)\tAcc@1  23.44 ( 37.63)\tAcc@5  46.09 ( 65.05)\n","Epoch: [19][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.3482e+00 (2.8114e+00)\tAcc@1  44.53 ( 36.68)\tAcc@5  78.12 ( 64.45)\n","Epoch: [19][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.2081e+00 (2.8162e+00)\tAcc@1  34.38 ( 36.50)\tAcc@5  64.84 ( 64.65)\n","Epoch: [19][120/391]\tTime  0.085 ( 0.092)\tLoss 3.0852e+00 (2.7751e+00)\tAcc@1  32.03 ( 37.76)\tAcc@5  63.28 ( 66.14)\n","Epoch: [19][150/391]\tTime  0.091 ( 0.091)\tLoss 3.2621e+00 (2.7710e+00)\tAcc@1   3.12 ( 37.90)\tAcc@5   9.38 ( 66.34)\n","Epoch: [19][180/391]\tTime  0.090 ( 0.091)\tLoss 1.8959e+00 (2.7680e+00)\tAcc@1  57.81 ( 38.07)\tAcc@5  84.38 ( 66.17)\n","Epoch: [19][210/391]\tTime  0.092 ( 0.091)\tLoss 3.2718e+00 (2.7978e+00)\tAcc@1  18.75 ( 36.83)\tAcc@5  43.75 ( 64.53)\n","Epoch: [19][240/391]\tTime  0.090 ( 0.091)\tLoss 3.2202e+00 (2.8058e+00)\tAcc@1  35.94 ( 36.67)\tAcc@5  61.72 ( 64.56)\n","Epoch: [19][270/391]\tTime  0.091 ( 0.091)\tLoss 3.1522e+00 (2.7968e+00)\tAcc@1  42.19 ( 36.61)\tAcc@5  67.19 ( 64.51)\n","Epoch: [19][300/391]\tTime  0.091 ( 0.091)\tLoss 2.3117e+00 (2.7987e+00)\tAcc@1  55.47 ( 36.88)\tAcc@5  83.59 ( 64.85)\n","Epoch: [19][330/391]\tTime  0.090 ( 0.091)\tLoss 3.0889e+00 (2.8051e+00)\tAcc@1  37.50 ( 36.79)\tAcc@5  70.31 ( 64.79)\n","Epoch: [19][360/391]\tTime  0.094 ( 0.091)\tLoss 2.9137e+00 (2.7996e+00)\tAcc@1  46.09 ( 37.06)\tAcc@5  75.78 ( 65.00)\n","Epoch: [19][390/391]\tTime  0.082 ( 0.091)\tLoss 2.9770e+00 (2.8031e+00)\tAcc@1   6.25 ( 36.92)\tAcc@5  15.00 ( 64.84)\n","==> Train Accuracy: Acc@1 36.916 || Acc@5 64.842\n","==> Test Accuracy:  Acc@1 50.450 || Acc@5 80.830\n","==> 38.01 seconds to train this epoch\n","\n","\n","----- epoch: 20, lr: 0.1 -----\n","Epoch: [20][  0/391]\tTime  0.203 ( 0.203)\tLoss 3.2223e+00 (3.2223e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  46.88 ( 46.88)\n","Epoch: [20][ 30/391]\tTime  0.091 ( 0.094)\tLoss 3.1344e+00 (2.6718e+00)\tAcc@1  31.25 ( 41.23)\tAcc@5  64.84 ( 71.22)\n","Epoch: [20][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.0815e+00 (2.7056e+00)\tAcc@1  55.47 ( 39.77)\tAcc@5  80.47 ( 68.80)\n","Epoch: [20][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.1128e+00 (2.7222e+00)\tAcc@1  48.44 ( 39.68)\tAcc@5  82.81 ( 68.14)\n","Epoch: [20][120/391]\tTime  0.091 ( 0.091)\tLoss 3.0457e+00 (2.7280e+00)\tAcc@1  39.06 ( 39.47)\tAcc@5  68.75 ( 67.86)\n","Epoch: [20][150/391]\tTime  0.090 ( 0.091)\tLoss 2.5358e+00 (2.7134e+00)\tAcc@1  47.66 ( 40.39)\tAcc@5  75.78 ( 68.86)\n","Epoch: [20][180/391]\tTime  0.091 ( 0.091)\tLoss 3.3000e+00 (2.7525e+00)\tAcc@1  17.19 ( 39.26)\tAcc@5  38.28 ( 67.38)\n","Epoch: [20][210/391]\tTime  0.086 ( 0.091)\tLoss 2.9766e+00 (2.7514e+00)\tAcc@1  32.03 ( 39.13)\tAcc@5  74.22 ( 67.28)\n","Epoch: [20][240/391]\tTime  0.090 ( 0.091)\tLoss 3.0932e+00 (2.7424e+00)\tAcc@1  39.84 ( 39.26)\tAcc@5  73.44 ( 67.63)\n","Epoch: [20][270/391]\tTime  0.090 ( 0.091)\tLoss 3.2348e+00 (2.7596e+00)\tAcc@1  20.31 ( 38.59)\tAcc@5  46.09 ( 66.80)\n","Epoch: [20][300/391]\tTime  0.090 ( 0.091)\tLoss 3.1793e+00 (2.7514e+00)\tAcc@1  34.38 ( 38.63)\tAcc@5  65.62 ( 66.75)\n","Epoch: [20][330/391]\tTime  0.087 ( 0.091)\tLoss 2.1810e+00 (2.7369e+00)\tAcc@1  51.56 ( 39.03)\tAcc@5  85.16 ( 67.22)\n","Epoch: [20][360/391]\tTime  0.091 ( 0.091)\tLoss 2.5580e+00 (2.7535e+00)\tAcc@1  55.47 ( 38.63)\tAcc@5  82.81 ( 66.97)\n","Epoch: [20][390/391]\tTime  0.082 ( 0.091)\tLoss 2.8890e+00 (2.7604e+00)\tAcc@1  40.00 ( 38.18)\tAcc@5  70.00 ( 66.37)\n","==> Train Accuracy: Acc@1 38.180 || Acc@5 66.374\n","==> Test Accuracy:  Acc@1 51.100 || Acc@5 81.100\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 21, lr: 0.1 -----\n","Epoch: [21][  0/391]\tTime  0.197 ( 0.197)\tLoss 2.3424e+00 (2.3424e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.16 ( 85.16)\n","Epoch: [21][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.1714e+00 (2.7186e+00)\tAcc@1  14.06 ( 39.72)\tAcc@5  38.28 ( 68.30)\n","Epoch: [21][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.2882e+00 (2.8097e+00)\tAcc@1  53.12 ( 36.64)\tAcc@5  82.81 ( 64.82)\n","Epoch: [21][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.9118e+00 (2.8222e+00)\tAcc@1  42.97 ( 36.50)\tAcc@5  70.31 ( 64.84)\n","Epoch: [21][120/391]\tTime  0.091 ( 0.091)\tLoss 2.7330e+00 (2.8289e+00)\tAcc@1  52.34 ( 36.35)\tAcc@5  74.22 ( 65.06)\n","Epoch: [21][150/391]\tTime  0.090 ( 0.091)\tLoss 3.2744e+00 (2.8209e+00)\tAcc@1  11.72 ( 36.06)\tAcc@5  35.16 ( 64.44)\n","Epoch: [21][180/391]\tTime  0.090 ( 0.091)\tLoss 3.2144e+00 (2.7862e+00)\tAcc@1  35.16 ( 37.47)\tAcc@5  67.97 ( 66.08)\n","Epoch: [21][210/391]\tTime  0.090 ( 0.091)\tLoss 3.1329e+00 (2.7976e+00)\tAcc@1  28.12 ( 37.18)\tAcc@5  60.94 ( 65.69)\n","Epoch: [21][240/391]\tTime  0.090 ( 0.091)\tLoss 3.1755e+00 (2.8106e+00)\tAcc@1  18.75 ( 36.71)\tAcc@5  46.09 ( 65.06)\n","Epoch: [21][270/391]\tTime  0.090 ( 0.091)\tLoss 3.1005e+00 (2.7929e+00)\tAcc@1  33.59 ( 37.09)\tAcc@5  64.06 ( 65.55)\n","Epoch: [21][300/391]\tTime  0.090 ( 0.091)\tLoss 3.3043e+00 (2.7802e+00)\tAcc@1  17.97 ( 36.91)\tAcc@5  45.31 ( 65.23)\n","Epoch: [21][330/391]\tTime  0.092 ( 0.091)\tLoss 1.7548e+00 (2.7646e+00)\tAcc@1  53.91 ( 37.46)\tAcc@5  80.47 ( 65.78)\n","Epoch: [21][360/391]\tTime  0.091 ( 0.091)\tLoss 3.1878e+00 (2.7597e+00)\tAcc@1   9.38 ( 37.55)\tAcc@5  28.12 ( 65.90)\n","Epoch: [21][390/391]\tTime  0.083 ( 0.091)\tLoss 2.4302e+00 (2.7512e+00)\tAcc@1  51.25 ( 37.84)\tAcc@5  78.75 ( 66.19)\n","==> Train Accuracy: Acc@1 37.838 || Acc@5 66.192\n","==> Test Accuracy:  Acc@1 49.300 || Acc@5 79.720\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 22, lr: 0.1 -----\n","Epoch: [22][  0/391]\tTime  0.192 ( 0.192)\tLoss 1.6532e+00 (1.6532e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  85.94 ( 85.94)\n","Epoch: [22][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.3715e+00 (2.7009e+00)\tAcc@1  11.72 ( 37.12)\tAcc@5  34.38 ( 63.23)\n","Epoch: [22][ 60/391]\tTime  0.091 ( 0.092)\tLoss 3.1865e+00 (2.6881e+00)\tAcc@1   9.38 ( 39.78)\tAcc@5  26.56 ( 67.74)\n","Epoch: [22][ 90/391]\tTime  0.095 ( 0.092)\tLoss 2.7287e+00 (2.7612e+00)\tAcc@1  50.00 ( 38.67)\tAcc@5  73.44 ( 66.83)\n","Epoch: [22][120/391]\tTime  0.094 ( 0.091)\tLoss 2.7833e+00 (2.7594e+00)\tAcc@1  44.53 ( 39.05)\tAcc@5  79.69 ( 67.25)\n","Epoch: [22][150/391]\tTime  0.090 ( 0.091)\tLoss 2.2074e+00 (2.7383e+00)\tAcc@1  55.47 ( 39.69)\tAcc@5  84.38 ( 68.11)\n","Epoch: [22][180/391]\tTime  0.091 ( 0.091)\tLoss 2.6550e+00 (2.7536e+00)\tAcc@1  43.75 ( 38.86)\tAcc@5  79.69 ( 67.49)\n","Epoch: [22][210/391]\tTime  0.090 ( 0.091)\tLoss 1.9350e+00 (2.7526e+00)\tAcc@1  50.00 ( 38.61)\tAcc@5  81.25 ( 67.18)\n","Epoch: [22][240/391]\tTime  0.090 ( 0.091)\tLoss 2.8529e+00 (2.7542e+00)\tAcc@1  42.97 ( 38.56)\tAcc@5  77.34 ( 66.94)\n","Epoch: [22][270/391]\tTime  0.091 ( 0.091)\tLoss 3.2233e+00 (2.7555e+00)\tAcc@1   2.34 ( 38.56)\tAcc@5  18.75 ( 66.92)\n","Epoch: [22][300/391]\tTime  0.091 ( 0.091)\tLoss 1.9295e+00 (2.7569e+00)\tAcc@1  57.81 ( 38.49)\tAcc@5  86.72 ( 66.74)\n","Epoch: [22][330/391]\tTime  0.091 ( 0.091)\tLoss 3.1329e+00 (2.7698e+00)\tAcc@1  35.16 ( 38.32)\tAcc@5  63.28 ( 66.54)\n","Epoch: [22][360/391]\tTime  0.091 ( 0.091)\tLoss 2.8721e+00 (2.7663e+00)\tAcc@1  47.66 ( 38.37)\tAcc@5  71.88 ( 66.53)\n","Epoch: [22][390/391]\tTime  0.084 ( 0.091)\tLoss 2.8853e+00 (2.7526e+00)\tAcc@1  46.25 ( 38.73)\tAcc@5  72.50 ( 66.94)\n","==> Train Accuracy: Acc@1 38.728 || Acc@5 66.936\n","==> Test Accuracy:  Acc@1 50.950 || Acc@5 80.330\n","==> 37.95 seconds to train this epoch\n","\n","\n","----- epoch: 23, lr: 0.1 -----\n","Epoch: [23][  0/391]\tTime  0.218 ( 0.218)\tLoss 2.6409e+00 (2.6409e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  75.78 ( 75.78)\n","Epoch: [23][ 30/391]\tTime  0.091 ( 0.094)\tLoss 3.0413e+00 (2.6787e+00)\tAcc@1  25.78 ( 37.45)\tAcc@5  60.94 ( 66.00)\n","Epoch: [23][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.9660e+00 (2.8215e+00)\tAcc@1   3.91 ( 35.30)\tAcc@5  17.97 ( 63.82)\n","Epoch: [23][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.7430e+00 (2.8547e+00)\tAcc@1   2.34 ( 33.08)\tAcc@5  13.28 ( 61.13)\n","Epoch: [23][120/391]\tTime  0.089 ( 0.092)\tLoss 2.5531e+00 (2.8262e+00)\tAcc@1  53.91 ( 33.57)\tAcc@5  82.03 ( 61.51)\n","Epoch: [23][150/391]\tTime  0.090 ( 0.091)\tLoss 2.2284e+00 (2.8166e+00)\tAcc@1  53.12 ( 35.01)\tAcc@5  82.81 ( 63.21)\n","Epoch: [23][180/391]\tTime  0.091 ( 0.091)\tLoss 3.2200e+00 (2.7990e+00)\tAcc@1  28.91 ( 35.83)\tAcc@5  57.81 ( 63.99)\n","Epoch: [23][210/391]\tTime  0.088 ( 0.091)\tLoss 1.7750e+00 (2.8028e+00)\tAcc@1  60.94 ( 35.93)\tAcc@5  89.06 ( 64.23)\n","Epoch: [23][240/391]\tTime  0.091 ( 0.091)\tLoss 2.2776e+00 (2.7985e+00)\tAcc@1  55.47 ( 35.99)\tAcc@5  84.38 ( 64.16)\n","Epoch: [23][270/391]\tTime  0.090 ( 0.091)\tLoss 2.3112e+00 (2.7823e+00)\tAcc@1  57.03 ( 36.43)\tAcc@5  81.25 ( 64.58)\n","Epoch: [23][300/391]\tTime  0.091 ( 0.091)\tLoss 2.0850e+00 (2.7556e+00)\tAcc@1  64.84 ( 37.45)\tAcc@5  86.72 ( 65.60)\n","Epoch: [23][330/391]\tTime  0.091 ( 0.091)\tLoss 2.4069e+00 (2.7689e+00)\tAcc@1  52.34 ( 37.08)\tAcc@5  75.78 ( 65.01)\n","Epoch: [23][360/391]\tTime  0.091 ( 0.091)\tLoss 3.1284e+00 (2.7721e+00)\tAcc@1  32.81 ( 37.27)\tAcc@5  57.03 ( 65.30)\n","Epoch: [23][390/391]\tTime  0.081 ( 0.091)\tLoss 2.1469e+00 (2.7671e+00)\tAcc@1  53.75 ( 37.44)\tAcc@5  81.25 ( 65.62)\n","==> Train Accuracy: Acc@1 37.442 || Acc@5 65.618\n","==> Test Accuracy:  Acc@1 52.830 || Acc@5 82.720\n","==> 37.96 seconds to train this epoch\n","\n","\n","----- epoch: 24, lr: 0.1 -----\n","Epoch: [24][  0/391]\tTime  0.228 ( 0.228)\tLoss 2.7781e+00 (2.7781e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  81.25 ( 81.25)\n","Epoch: [24][ 30/391]\tTime  0.090 ( 0.095)\tLoss 2.6149e+00 (2.5756e+00)\tAcc@1  57.81 ( 42.52)\tAcc@5  76.56 ( 71.37)\n","Epoch: [24][ 60/391]\tTime  0.094 ( 0.093)\tLoss 2.2743e+00 (2.6742e+00)\tAcc@1  55.47 ( 40.42)\tAcc@5  84.38 ( 68.95)\n","Epoch: [24][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.6386e+00 (2.6717e+00)\tAcc@1  63.28 ( 41.17)\tAcc@5  90.62 ( 69.72)\n","Epoch: [24][120/391]\tTime  0.089 ( 0.092)\tLoss 2.7707e+00 (2.6901e+00)\tAcc@1  44.53 ( 39.84)\tAcc@5  75.78 ( 68.47)\n","Epoch: [24][150/391]\tTime  0.091 ( 0.092)\tLoss 3.0266e+00 (2.6969e+00)\tAcc@1  25.78 ( 39.26)\tAcc@5  57.03 ( 67.94)\n","Epoch: [24][180/391]\tTime  0.090 ( 0.091)\tLoss 3.1680e+00 (2.6907e+00)\tAcc@1  24.22 ( 39.12)\tAcc@5  54.69 ( 67.71)\n","Epoch: [24][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6994e+00 (2.7027e+00)\tAcc@1  50.00 ( 38.94)\tAcc@5  85.16 ( 67.71)\n","Epoch: [24][240/391]\tTime  0.088 ( 0.091)\tLoss 3.0650e+00 (2.7107e+00)\tAcc@1  35.94 ( 39.25)\tAcc@5  66.41 ( 67.89)\n","Epoch: [24][270/391]\tTime  0.090 ( 0.091)\tLoss 3.0917e+00 (2.7027e+00)\tAcc@1  28.91 ( 39.45)\tAcc@5  59.38 ( 68.02)\n","Epoch: [24][300/391]\tTime  0.091 ( 0.091)\tLoss 3.2706e+00 (2.6989e+00)\tAcc@1  14.84 ( 39.20)\tAcc@5  42.97 ( 67.67)\n","Epoch: [24][330/391]\tTime  0.090 ( 0.091)\tLoss 2.1838e+00 (2.6999e+00)\tAcc@1  57.81 ( 39.25)\tAcc@5  86.72 ( 67.65)\n","Epoch: [24][360/391]\tTime  0.091 ( 0.091)\tLoss 3.2417e+00 (2.6974e+00)\tAcc@1  10.16 ( 39.24)\tAcc@5  31.25 ( 67.61)\n","Epoch: [24][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5071e+00 (2.7038e+00)\tAcc@1  61.25 ( 39.26)\tAcc@5  87.50 ( 67.59)\n","==> Train Accuracy: Acc@1 39.264 || Acc@5 67.590\n","==> Test Accuracy:  Acc@1 54.760 || Acc@5 82.820\n","==> 37.98 seconds to train this epoch\n","\n","\n","----- epoch: 25, lr: 0.1 -----\n","Epoch: [25][  0/391]\tTime  0.229 ( 0.229)\tLoss 3.2083e+00 (3.2083e+00)\tAcc@1  33.59 ( 33.59)\tAcc@5  62.50 ( 62.50)\n","Epoch: [25][ 30/391]\tTime  0.090 ( 0.095)\tLoss 2.6135e+00 (2.6649e+00)\tAcc@1  51.56 ( 36.67)\tAcc@5  80.47 ( 63.99)\n","Epoch: [25][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.0006e+00 (2.6624e+00)\tAcc@1  26.56 ( 38.76)\tAcc@5  64.06 ( 66.64)\n","Epoch: [25][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.0873e+00 (2.6684e+00)\tAcc@1  32.03 ( 38.46)\tAcc@5  60.94 ( 66.53)\n","Epoch: [25][120/391]\tTime  0.090 ( 0.092)\tLoss 2.8066e+00 (2.6258e+00)\tAcc@1  36.72 ( 39.81)\tAcc@5  74.22 ( 67.65)\n","Epoch: [25][150/391]\tTime  0.086 ( 0.092)\tLoss 3.2267e+00 (2.6612e+00)\tAcc@1  12.50 ( 39.42)\tAcc@5  28.91 ( 67.06)\n","Epoch: [25][180/391]\tTime  0.090 ( 0.091)\tLoss 2.3987e+00 (2.6909e+00)\tAcc@1  52.34 ( 38.87)\tAcc@5  78.12 ( 66.72)\n","Epoch: [25][210/391]\tTime  0.090 ( 0.091)\tLoss 3.3119e+00 (2.6901e+00)\tAcc@1  23.44 ( 39.18)\tAcc@5  47.66 ( 67.03)\n","Epoch: [25][240/391]\tTime  0.090 ( 0.091)\tLoss 3.3320e+00 (2.7064e+00)\tAcc@1  21.88 ( 38.82)\tAcc@5  49.22 ( 66.64)\n","Epoch: [25][270/391]\tTime  0.091 ( 0.091)\tLoss 2.8955e+00 (2.7082e+00)\tAcc@1  44.53 ( 38.98)\tAcc@5  75.78 ( 66.79)\n","Epoch: [25][300/391]\tTime  0.091 ( 0.091)\tLoss 2.7052e+00 (2.7060e+00)\tAcc@1  43.75 ( 39.28)\tAcc@5  78.12 ( 67.07)\n","Epoch: [25][330/391]\tTime  0.090 ( 0.091)\tLoss 2.1836e+00 (2.7182e+00)\tAcc@1  60.94 ( 39.07)\tAcc@5  84.38 ( 66.83)\n","Epoch: [25][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7888e+00 (2.7171e+00)\tAcc@1  57.81 ( 39.08)\tAcc@5  85.94 ( 66.80)\n","Epoch: [25][390/391]\tTime  0.082 ( 0.091)\tLoss 2.0291e+00 (2.7180e+00)\tAcc@1  52.50 ( 38.84)\tAcc@5  88.75 ( 66.57)\n","==> Train Accuracy: Acc@1 38.840 || Acc@5 66.566\n","==> Test Accuracy:  Acc@1 48.820 || Acc@5 79.150\n","==> 38.00 seconds to train this epoch\n","\n","\n","----- epoch: 26, lr: 0.1 -----\n","Epoch: [26][  0/391]\tTime  0.203 ( 0.203)\tLoss 3.2181e+00 (3.2181e+00)\tAcc@1   3.12 (  3.12)\tAcc@5  15.62 ( 15.62)\n","Epoch: [26][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.4836e+00 (2.6458e+00)\tAcc@1  65.62 ( 39.97)\tAcc@5  85.16 ( 66.00)\n","Epoch: [26][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.5958e+00 (2.7149e+00)\tAcc@1  57.81 ( 38.27)\tAcc@5  79.69 ( 65.34)\n","Epoch: [26][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.9964e+00 (2.7377e+00)\tAcc@1  36.72 ( 38.24)\tAcc@5  73.44 ( 65.70)\n","Epoch: [26][120/391]\tTime  0.090 ( 0.091)\tLoss 3.0388e+00 (2.7285e+00)\tAcc@1  41.41 ( 38.34)\tAcc@5  69.53 ( 66.25)\n","Epoch: [26][150/391]\tTime  0.091 ( 0.091)\tLoss 2.8816e+00 (2.7069e+00)\tAcc@1  40.62 ( 38.13)\tAcc@5  67.97 ( 65.93)\n","Epoch: [26][180/391]\tTime  0.091 ( 0.091)\tLoss 3.0052e+00 (2.7053e+00)\tAcc@1  38.28 ( 38.48)\tAcc@5  70.31 ( 66.04)\n","Epoch: [26][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2523e+00 (2.7057e+00)\tAcc@1  57.03 ( 38.81)\tAcc@5  85.16 ( 66.73)\n","Epoch: [26][240/391]\tTime  0.091 ( 0.091)\tLoss 2.7547e+00 (2.7029e+00)\tAcc@1  44.53 ( 39.10)\tAcc@5  78.91 ( 67.05)\n","Epoch: [26][270/391]\tTime  0.091 ( 0.091)\tLoss 3.0381e+00 (2.7222e+00)\tAcc@1  36.72 ( 38.65)\tAcc@5  70.31 ( 66.82)\n","Epoch: [26][300/391]\tTime  0.092 ( 0.091)\tLoss 3.3216e+00 (2.7154e+00)\tAcc@1  13.28 ( 38.81)\tAcc@5  35.94 ( 67.09)\n","Epoch: [26][330/391]\tTime  0.090 ( 0.091)\tLoss 1.7745e+00 (2.7145e+00)\tAcc@1  57.81 ( 38.96)\tAcc@5  83.59 ( 67.35)\n","Epoch: [26][360/391]\tTime  0.091 ( 0.091)\tLoss 2.3521e+00 (2.7190e+00)\tAcc@1  42.19 ( 38.82)\tAcc@5  78.91 ( 67.11)\n","Epoch: [26][390/391]\tTime  0.081 ( 0.091)\tLoss 2.8193e+00 (2.7198e+00)\tAcc@1  43.75 ( 39.11)\tAcc@5  68.75 ( 67.43)\n","==> Train Accuracy: Acc@1 39.108 || Acc@5 67.432\n","==> Test Accuracy:  Acc@1 52.390 || Acc@5 80.670\n","==> 37.96 seconds to train this epoch\n","\n","\n","----- epoch: 27, lr: 0.1 -----\n","Epoch: [27][  0/391]\tTime  0.208 ( 0.208)\tLoss 2.7556e+00 (2.7556e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  75.00 ( 75.00)\n","Epoch: [27][ 30/391]\tTime  0.091 ( 0.094)\tLoss 2.4559e+00 (2.6549e+00)\tAcc@1  50.78 ( 37.27)\tAcc@5  83.59 ( 66.20)\n","Epoch: [27][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.9087e+00 (2.6811e+00)\tAcc@1  44.53 ( 37.96)\tAcc@5  71.09 ( 67.06)\n","Epoch: [27][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.0023e+00 (2.7106e+00)\tAcc@1  41.41 ( 38.47)\tAcc@5  66.41 ( 67.58)\n","Epoch: [27][120/391]\tTime  0.090 ( 0.091)\tLoss 2.7721e+00 (2.7087e+00)\tAcc@1  47.66 ( 37.83)\tAcc@5  78.12 ( 66.44)\n","Epoch: [27][150/391]\tTime  0.091 ( 0.091)\tLoss 2.5678e+00 (2.7176e+00)\tAcc@1  53.12 ( 37.99)\tAcc@5  75.00 ( 66.48)\n","Epoch: [27][180/391]\tTime  0.090 ( 0.091)\tLoss 2.4146e+00 (2.7168e+00)\tAcc@1  49.22 ( 38.46)\tAcc@5  80.47 ( 66.70)\n","Epoch: [27][210/391]\tTime  0.091 ( 0.091)\tLoss 3.1514e+00 (2.7073e+00)\tAcc@1  12.50 ( 38.61)\tAcc@5  42.19 ( 66.76)\n","Epoch: [27][240/391]\tTime  0.090 ( 0.091)\tLoss 3.1824e+00 (2.7086e+00)\tAcc@1   5.47 ( 38.09)\tAcc@5  30.47 ( 66.15)\n","Epoch: [27][270/391]\tTime  0.090 ( 0.091)\tLoss 3.1200e+00 (2.7020e+00)\tAcc@1  32.81 ( 38.30)\tAcc@5  60.16 ( 66.46)\n","Epoch: [27][300/391]\tTime  0.090 ( 0.091)\tLoss 2.2692e+00 (2.7047e+00)\tAcc@1  50.78 ( 38.32)\tAcc@5  80.47 ( 66.39)\n","Epoch: [27][330/391]\tTime  0.090 ( 0.091)\tLoss 2.9669e+00 (2.7209e+00)\tAcc@1  32.03 ( 38.17)\tAcc@5  67.19 ( 66.33)\n","Epoch: [27][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8760e+00 (2.7183e+00)\tAcc@1  61.72 ( 38.07)\tAcc@5  88.28 ( 66.27)\n","Epoch: [27][390/391]\tTime  0.082 ( 0.091)\tLoss 3.0435e+00 (2.7201e+00)\tAcc@1  31.25 ( 38.03)\tAcc@5  65.00 ( 66.27)\n","==> Train Accuracy: Acc@1 38.034 || Acc@5 66.266\n","==> Test Accuracy:  Acc@1 53.000 || Acc@5 81.290\n","==> 37.97 seconds to train this epoch\n","\n","\n","----- epoch: 28, lr: 0.1 -----\n","Epoch: [28][  0/391]\tTime  0.211 ( 0.211)\tLoss 3.0597e+00 (3.0597e+00)\tAcc@1  21.09 ( 21.09)\tAcc@5  55.47 ( 55.47)\n","Epoch: [28][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.7973e+00 (2.6421e+00)\tAcc@1  42.97 ( 41.68)\tAcc@5  75.78 ( 70.77)\n","Epoch: [28][ 60/391]\tTime  0.091 ( 0.092)\tLoss 3.1686e+00 (2.7036e+00)\tAcc@1  21.09 ( 40.11)\tAcc@5  55.47 ( 69.36)\n","Epoch: [28][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.0044e+00 (2.7250e+00)\tAcc@1  10.16 ( 38.02)\tAcc@5  41.41 ( 66.53)\n","Epoch: [28][120/391]\tTime  0.090 ( 0.091)\tLoss 2.1554e+00 (2.7256e+00)\tAcc@1  53.91 ( 37.33)\tAcc@5  79.69 ( 65.18)\n","Epoch: [28][150/391]\tTime  0.090 ( 0.091)\tLoss 3.0042e+00 (2.7361e+00)\tAcc@1  18.75 ( 36.51)\tAcc@5  44.53 ( 63.70)\n","Epoch: [28][180/391]\tTime  0.091 ( 0.091)\tLoss 3.2208e+00 (2.7086e+00)\tAcc@1  18.75 ( 37.43)\tAcc@5  44.53 ( 64.57)\n","Epoch: [28][210/391]\tTime  0.090 ( 0.091)\tLoss 2.9433e+00 (2.7050e+00)\tAcc@1  42.97 ( 37.66)\tAcc@5  72.66 ( 65.07)\n","Epoch: [28][240/391]\tTime  0.090 ( 0.091)\tLoss 2.7645e+00 (2.7072e+00)\tAcc@1  47.66 ( 38.07)\tAcc@5  77.34 ( 65.52)\n","Epoch: [28][270/391]\tTime  0.090 ( 0.091)\tLoss 3.1066e+00 (2.7078e+00)\tAcc@1  29.69 ( 38.30)\tAcc@5  58.59 ( 65.87)\n","Epoch: [28][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4470e+00 (2.6979e+00)\tAcc@1  64.06 ( 38.58)\tAcc@5  86.72 ( 66.26)\n","Epoch: [28][330/391]\tTime  0.090 ( 0.091)\tLoss 3.0672e+00 (2.7092e+00)\tAcc@1  31.25 ( 38.18)\tAcc@5  64.84 ( 65.87)\n","Epoch: [28][360/391]\tTime  0.089 ( 0.091)\tLoss 1.6397e+00 (2.7037e+00)\tAcc@1  62.50 ( 38.45)\tAcc@5  87.50 ( 66.23)\n","Epoch: [28][390/391]\tTime  0.082 ( 0.091)\tLoss 2.4313e+00 (2.7043e+00)\tAcc@1  56.25 ( 38.62)\tAcc@5  85.00 ( 66.47)\n","==> Train Accuracy: Acc@1 38.618 || Acc@5 66.472\n","==> Test Accuracy:  Acc@1 41.910 || Acc@5 71.720\n","==> 37.88 seconds to train this epoch\n","\n","\n","----- epoch: 29, lr: 0.1 -----\n","Epoch: [29][  0/391]\tTime  0.220 ( 0.220)\tLoss 1.8174e+00 (1.8174e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  84.38 ( 84.38)\n","Epoch: [29][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.0917e+00 (2.6610e+00)\tAcc@1   8.59 ( 41.13)\tAcc@5  28.12 ( 69.00)\n","Epoch: [29][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.2614e+00 (2.6154e+00)\tAcc@1  57.81 ( 43.25)\tAcc@5  84.38 ( 71.47)\n","Epoch: [29][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.9230e+00 (2.5954e+00)\tAcc@1  57.81 ( 44.69)\tAcc@5  88.28 ( 72.97)\n","Epoch: [29][120/391]\tTime  0.090 ( 0.091)\tLoss 2.5208e+00 (2.6320e+00)\tAcc@1  52.34 ( 43.78)\tAcc@5  82.03 ( 72.40)\n","Epoch: [29][150/391]\tTime  0.091 ( 0.091)\tLoss 2.7432e+00 (2.6777e+00)\tAcc@1  50.00 ( 41.50)\tAcc@5  75.00 ( 69.75)\n","Epoch: [29][180/391]\tTime  0.090 ( 0.091)\tLoss 1.5261e+00 (2.6544e+00)\tAcc@1  67.19 ( 42.04)\tAcc@5  91.41 ( 70.47)\n","Epoch: [29][210/391]\tTime  0.091 ( 0.091)\tLoss 2.5965e+00 (2.6478e+00)\tAcc@1  49.22 ( 42.09)\tAcc@5  79.69 ( 70.57)\n","Epoch: [29][240/391]\tTime  0.090 ( 0.091)\tLoss 2.0198e+00 (2.6408e+00)\tAcc@1  60.94 ( 42.26)\tAcc@5  84.38 ( 70.61)\n","Epoch: [29][270/391]\tTime  0.090 ( 0.091)\tLoss 2.7103e+00 (2.6404e+00)\tAcc@1   2.34 ( 41.67)\tAcc@5   4.69 ( 69.77)\n","Epoch: [29][300/391]\tTime  0.091 ( 0.091)\tLoss 2.4439e+00 (2.6480e+00)\tAcc@1  57.81 ( 41.31)\tAcc@5  82.81 ( 69.28)\n","Epoch: [29][330/391]\tTime  0.090 ( 0.091)\tLoss 3.1849e+00 (2.6537e+00)\tAcc@1   2.34 ( 41.03)\tAcc@5  25.00 ( 68.88)\n","Epoch: [29][360/391]\tTime  0.091 ( 0.091)\tLoss 2.9873e+00 (2.6632e+00)\tAcc@1  28.12 ( 40.87)\tAcc@5  73.44 ( 68.84)\n","Epoch: [29][390/391]\tTime  0.082 ( 0.091)\tLoss 2.9440e+00 (2.6702e+00)\tAcc@1  41.25 ( 40.64)\tAcc@5  68.75 ( 68.67)\n","==> Train Accuracy: Acc@1 40.642 || Acc@5 68.672\n","==> Test Accuracy:  Acc@1 56.720 || Acc@5 84.560\n","==> 37.86 seconds to train this epoch\n","\n","\n","----- epoch: 30, lr: 0.1 -----\n","Epoch: [30][  0/391]\tTime  0.224 ( 0.224)\tLoss 2.0682e+00 (2.0682e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  90.62 ( 90.62)\n","Epoch: [30][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.2601e+00 (2.5826e+00)\tAcc@1  21.09 ( 43.67)\tAcc@5  53.12 ( 72.33)\n","Epoch: [30][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.0327e+00 (2.6423e+00)\tAcc@1  26.56 ( 39.73)\tAcc@5  57.03 ( 68.29)\n","Epoch: [30][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.8400e+00 (2.6317e+00)\tAcc@1  67.97 ( 39.47)\tAcc@5  89.84 ( 67.29)\n","Epoch: [30][120/391]\tTime  0.090 ( 0.091)\tLoss 2.1688e+00 (2.6333e+00)\tAcc@1  59.38 ( 40.03)\tAcc@5  85.94 ( 67.43)\n","Epoch: [30][150/391]\tTime  0.090 ( 0.091)\tLoss 2.7362e+00 (2.6128e+00)\tAcc@1  42.19 ( 40.73)\tAcc@5  77.34 ( 68.03)\n","Epoch: [30][180/391]\tTime  0.090 ( 0.091)\tLoss 2.3694e+00 (2.6139e+00)\tAcc@1  57.81 ( 40.85)\tAcc@5  79.69 ( 68.04)\n","Epoch: [30][210/391]\tTime  0.090 ( 0.091)\tLoss 3.1031e+00 (2.6340e+00)\tAcc@1  29.69 ( 40.47)\tAcc@5  61.72 ( 68.01)\n","Epoch: [30][240/391]\tTime  0.091 ( 0.091)\tLoss 1.2974e+00 (2.6424e+00)\tAcc@1  64.06 ( 39.89)\tAcc@5  90.62 ( 67.50)\n","Epoch: [30][270/391]\tTime  0.090 ( 0.091)\tLoss 3.1847e+00 (2.6421e+00)\tAcc@1  19.53 ( 39.87)\tAcc@5  42.97 ( 67.31)\n","Epoch: [30][300/391]\tTime  0.090 ( 0.091)\tLoss 2.9895e+00 (2.6288e+00)\tAcc@1  29.69 ( 40.21)\tAcc@5  56.25 ( 67.53)\n","Epoch: [30][330/391]\tTime  0.090 ( 0.091)\tLoss 2.0956e+00 (2.6267e+00)\tAcc@1  57.03 ( 40.59)\tAcc@5  82.03 ( 68.05)\n","Epoch: [30][360/391]\tTime  0.090 ( 0.091)\tLoss 2.4380e+00 (2.6245e+00)\tAcc@1  52.34 ( 40.86)\tAcc@5  86.72 ( 68.50)\n","Epoch: [30][390/391]\tTime  0.081 ( 0.091)\tLoss 3.1555e+00 (2.6326e+00)\tAcc@1  22.50 ( 40.63)\tAcc@5  51.25 ( 68.29)\n","==> Train Accuracy: Acc@1 40.628 || Acc@5 68.286\n","==> Test Accuracy:  Acc@1 52.720 || Acc@5 81.640\n","==> 37.95 seconds to train this epoch\n","\n","\n","----- epoch: 31, lr: 0.1 -----\n","Epoch: [31][  0/391]\tTime  0.209 ( 0.209)\tLoss 2.9923e+00 (2.9923e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  68.75 ( 68.75)\n","Epoch: [31][ 30/391]\tTime  0.092 ( 0.094)\tLoss 2.3704e+00 (2.7118e+00)\tAcc@1  53.91 ( 40.20)\tAcc@5  82.81 ( 69.68)\n","Epoch: [31][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.5020e+00 (2.6473e+00)\tAcc@1  50.00 ( 42.80)\tAcc@5  85.16 ( 71.39)\n","Epoch: [31][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.9527e+00 (2.6462e+00)\tAcc@1  39.06 ( 41.05)\tAcc@5  71.09 ( 68.91)\n","Epoch: [31][120/391]\tTime  0.090 ( 0.091)\tLoss 2.0707e+00 (2.6276e+00)\tAcc@1  57.03 ( 41.56)\tAcc@5  86.72 ( 69.53)\n","Epoch: [31][150/391]\tTime  0.090 ( 0.091)\tLoss 1.4452e+00 (2.6200e+00)\tAcc@1  64.06 ( 41.29)\tAcc@5  89.84 ( 69.28)\n","Epoch: [31][180/391]\tTime  0.090 ( 0.091)\tLoss 1.9662e+00 (2.6299e+00)\tAcc@1  60.94 ( 40.51)\tAcc@5  87.50 ( 68.34)\n","Epoch: [31][210/391]\tTime  0.091 ( 0.091)\tLoss 2.2635e+00 (2.6426e+00)\tAcc@1  53.91 ( 40.61)\tAcc@5  85.16 ( 68.33)\n","Epoch: [31][240/391]\tTime  0.095 ( 0.091)\tLoss 3.1923e+00 (2.6660e+00)\tAcc@1   8.59 ( 40.20)\tAcc@5  28.91 ( 67.95)\n","Epoch: [31][270/391]\tTime  0.090 ( 0.091)\tLoss 2.9032e+00 (2.6859e+00)\tAcc@1  47.66 ( 40.04)\tAcc@5  79.69 ( 67.92)\n","Epoch: [31][300/391]\tTime  0.091 ( 0.091)\tLoss 2.9469e+00 (2.6703e+00)\tAcc@1  38.28 ( 40.38)\tAcc@5  69.53 ( 68.06)\n","Epoch: [31][330/391]\tTime  0.091 ( 0.091)\tLoss 1.7644e+00 (2.6641e+00)\tAcc@1  60.16 ( 40.47)\tAcc@5  85.16 ( 68.31)\n","Epoch: [31][360/391]\tTime  0.090 ( 0.091)\tLoss 2.9982e+00 (2.6582e+00)\tAcc@1  43.75 ( 40.87)\tAcc@5  67.19 ( 68.85)\n","Epoch: [31][390/391]\tTime  0.081 ( 0.091)\tLoss 3.2164e+00 (2.6649e+00)\tAcc@1   7.50 ( 40.61)\tAcc@5  23.75 ( 68.55)\n","==> Train Accuracy: Acc@1 40.608 || Acc@5 68.554\n","==> Test Accuracy:  Acc@1 52.790 || Acc@5 82.410\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 32, lr: 0.1 -----\n","Epoch: [32][  0/391]\tTime  0.215 ( 0.215)\tLoss 3.2269e+00 (3.2269e+00)\tAcc@1   4.69 (  4.69)\tAcc@5  23.44 ( 23.44)\n","Epoch: [32][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.8936e+00 (2.4770e+00)\tAcc@1  39.06 ( 44.13)\tAcc@5  73.44 ( 70.94)\n","Epoch: [32][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.3067e+00 (2.6046e+00)\tAcc@1  21.88 ( 43.03)\tAcc@5  55.47 ( 70.58)\n","Epoch: [32][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.0613e+00 (2.6010e+00)\tAcc@1  17.97 ( 42.70)\tAcc@5  52.34 ( 70.23)\n","Epoch: [32][120/391]\tTime  0.090 ( 0.091)\tLoss 2.2573e+00 (2.6028e+00)\tAcc@1  58.59 ( 42.57)\tAcc@5  87.50 ( 69.94)\n","Epoch: [32][150/391]\tTime  0.091 ( 0.091)\tLoss 1.7198e+00 (2.6079e+00)\tAcc@1  56.25 ( 42.42)\tAcc@5  82.81 ( 70.05)\n","Epoch: [32][180/391]\tTime  0.090 ( 0.091)\tLoss 2.4165e+00 (2.6018e+00)\tAcc@1  59.38 ( 41.96)\tAcc@5  85.16 ( 69.31)\n","Epoch: [32][210/391]\tTime  0.090 ( 0.091)\tLoss 2.8022e+00 (2.6142e+00)\tAcc@1  43.75 ( 41.07)\tAcc@5  71.88 ( 68.39)\n","Epoch: [32][240/391]\tTime  0.090 ( 0.091)\tLoss 2.0821e+00 (2.6214e+00)\tAcc@1  51.56 ( 41.03)\tAcc@5  78.91 ( 68.35)\n","Epoch: [32][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0244e+00 (2.6352e+00)\tAcc@1  57.03 ( 40.16)\tAcc@5  82.81 ( 67.32)\n","Epoch: [32][300/391]\tTime  0.090 ( 0.091)\tLoss 2.7487e+00 (2.6389e+00)\tAcc@1  46.09 ( 39.99)\tAcc@5  77.34 ( 67.34)\n","Epoch: [32][330/391]\tTime  0.091 ( 0.091)\tLoss 2.4168e+00 (2.6364e+00)\tAcc@1  54.69 ( 40.08)\tAcc@5  78.12 ( 67.45)\n","Epoch: [32][360/391]\tTime  0.090 ( 0.091)\tLoss 2.8083e+00 (2.6469e+00)\tAcc@1  44.53 ( 40.08)\tAcc@5  78.12 ( 67.69)\n","Epoch: [32][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7965e+00 (2.6457e+00)\tAcc@1  56.25 ( 40.19)\tAcc@5  83.75 ( 67.84)\n","==> Train Accuracy: Acc@1 40.194 || Acc@5 67.840\n","==> Test Accuracy:  Acc@1 53.150 || Acc@5 82.730\n","==> 37.97 seconds to train this epoch\n","\n","\n","----- epoch: 33, lr: 0.1 -----\n","Epoch: [33][  0/391]\tTime  0.207 ( 0.207)\tLoss 2.7355e+00 (2.7355e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  77.34 ( 77.34)\n","Epoch: [33][ 30/391]\tTime  0.091 ( 0.094)\tLoss 3.1404e+00 (2.6712e+00)\tAcc@1  24.22 ( 38.73)\tAcc@5  57.03 ( 66.78)\n","Epoch: [33][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.6744e+00 (2.6575e+00)\tAcc@1   0.78 ( 39.04)\tAcc@5  12.50 ( 65.97)\n","Epoch: [33][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.1265e+00 (2.6239e+00)\tAcc@1  58.59 ( 39.95)\tAcc@5  87.50 ( 66.96)\n","Epoch: [33][120/391]\tTime  0.090 ( 0.092)\tLoss 1.9263e+00 (2.6562e+00)\tAcc@1  60.94 ( 39.71)\tAcc@5  89.06 ( 66.86)\n","Epoch: [33][150/391]\tTime  0.093 ( 0.091)\tLoss 3.0839e+00 (2.6579e+00)\tAcc@1  25.00 ( 39.28)\tAcc@5  60.16 ( 66.24)\n","Epoch: [33][180/391]\tTime  0.090 ( 0.091)\tLoss 2.9528e+00 (2.6667e+00)\tAcc@1  41.41 ( 39.47)\tAcc@5  69.53 ( 66.50)\n","Epoch: [33][210/391]\tTime  0.090 ( 0.091)\tLoss 2.8630e+00 (2.6646e+00)\tAcc@1  41.41 ( 39.74)\tAcc@5  69.53 ( 67.01)\n","Epoch: [33][240/391]\tTime  0.091 ( 0.091)\tLoss 3.1773e+00 (2.6618e+00)\tAcc@1  32.03 ( 40.37)\tAcc@5  58.59 ( 67.76)\n","Epoch: [33][270/391]\tTime  0.091 ( 0.091)\tLoss 2.8282e+00 (2.6636e+00)\tAcc@1  45.31 ( 40.39)\tAcc@5  71.88 ( 67.88)\n","Epoch: [33][300/391]\tTime  0.090 ( 0.091)\tLoss 3.2351e+00 (2.6588e+00)\tAcc@1  25.78 ( 40.59)\tAcc@5  53.12 ( 68.14)\n","Epoch: [33][330/391]\tTime  0.090 ( 0.091)\tLoss 2.4927e+00 (2.6538e+00)\tAcc@1  50.00 ( 40.56)\tAcc@5  77.34 ( 68.18)\n","Epoch: [33][360/391]\tTime  0.090 ( 0.091)\tLoss 3.2634e+00 (2.6612e+00)\tAcc@1  31.25 ( 40.29)\tAcc@5  50.78 ( 67.98)\n","Epoch: [33][390/391]\tTime  0.081 ( 0.091)\tLoss 3.0555e+00 (2.6627e+00)\tAcc@1  25.00 ( 40.36)\tAcc@5  62.50 ( 68.13)\n","==> Train Accuracy: Acc@1 40.362 || Acc@5 68.132\n","==> Test Accuracy:  Acc@1 53.000 || Acc@5 81.410\n","==> 37.97 seconds to train this epoch\n","\n","\n","----- epoch: 34, lr: 0.1 -----\n","Epoch: [34][  0/391]\tTime  0.186 ( 0.186)\tLoss 2.7338e+00 (2.7338e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  78.91 ( 78.91)\n","Epoch: [34][ 30/391]\tTime  0.090 ( 0.093)\tLoss 2.3796e+00 (2.5171e+00)\tAcc@1  55.47 ( 41.94)\tAcc@5  82.03 ( 70.69)\n","Epoch: [34][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.6963e+00 (2.5768e+00)\tAcc@1  48.44 ( 42.51)\tAcc@5  75.78 ( 71.98)\n","Epoch: [34][ 90/391]\tTime  0.090 ( 0.091)\tLoss 3.1927e+00 (2.5841e+00)\tAcc@1  29.69 ( 43.17)\tAcc@5  57.81 ( 72.17)\n","Epoch: [34][120/391]\tTime  0.090 ( 0.091)\tLoss 2.9562e+00 (2.5875e+00)\tAcc@1  27.34 ( 43.56)\tAcc@5  57.81 ( 72.44)\n","Epoch: [34][150/391]\tTime  0.090 ( 0.091)\tLoss 3.1939e+00 (2.5922e+00)\tAcc@1  17.19 ( 43.02)\tAcc@5  43.75 ( 71.62)\n","Epoch: [34][180/391]\tTime  0.090 ( 0.091)\tLoss 3.1739e+00 (2.6031e+00)\tAcc@1   2.34 ( 42.80)\tAcc@5  16.41 ( 71.24)\n","Epoch: [34][210/391]\tTime  0.090 ( 0.091)\tLoss 3.1255e+00 (2.6214e+00)\tAcc@1  31.25 ( 42.69)\tAcc@5  61.72 ( 71.17)\n","Epoch: [34][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7586e+00 (2.6248e+00)\tAcc@1  60.94 ( 42.83)\tAcc@5  89.84 ( 71.34)\n","Epoch: [34][270/391]\tTime  0.090 ( 0.091)\tLoss 3.0628e+00 (2.6434e+00)\tAcc@1  29.69 ( 42.37)\tAcc@5  61.72 ( 70.87)\n","Epoch: [34][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9396e+00 (2.6535e+00)\tAcc@1  63.28 ( 41.93)\tAcc@5  85.94 ( 70.46)\n","Epoch: [34][330/391]\tTime  0.091 ( 0.091)\tLoss 2.6056e+00 (2.6596e+00)\tAcc@1  50.78 ( 41.79)\tAcc@5  79.69 ( 70.39)\n","Epoch: [34][360/391]\tTime  0.090 ( 0.091)\tLoss 2.8219e+00 (2.6528e+00)\tAcc@1  41.41 ( 41.73)\tAcc@5  73.44 ( 70.31)\n","Epoch: [34][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5402e+00 (2.6627e+00)\tAcc@1  68.75 ( 41.40)\tAcc@5  87.50 ( 69.94)\n","==> Train Accuracy: Acc@1 41.400 || Acc@5 69.936\n","==> Test Accuracy:  Acc@1 56.270 || Acc@5 84.540\n","==> 37.86 seconds to train this epoch\n","\n","\n","----- epoch: 35, lr: 0.1 -----\n","Epoch: [35][  0/391]\tTime  0.197 ( 0.197)\tLoss 1.3080e+00 (1.3080e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  91.41 ( 91.41)\n","Epoch: [35][ 30/391]\tTime  0.090 ( 0.093)\tLoss 2.6652e+00 (2.6453e+00)\tAcc@1  45.31 ( 38.94)\tAcc@5  80.47 ( 67.49)\n","Epoch: [35][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.6119e+00 (2.6042e+00)\tAcc@1  51.56 ( 39.73)\tAcc@5  78.91 ( 68.17)\n","Epoch: [35][ 90/391]\tTime  0.089 ( 0.091)\tLoss 2.9134e+00 (2.6214e+00)\tAcc@1   3.91 ( 38.96)\tAcc@5  28.91 ( 66.67)\n","Epoch: [35][120/391]\tTime  0.090 ( 0.091)\tLoss 3.0522e+00 (2.6211e+00)\tAcc@1  32.03 ( 40.15)\tAcc@5  65.62 ( 68.27)\n","Epoch: [35][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7896e+00 (2.6331e+00)\tAcc@1  60.94 ( 39.62)\tAcc@5  90.62 ( 67.61)\n","Epoch: [35][180/391]\tTime  0.090 ( 0.091)\tLoss 3.1240e+00 (2.6491e+00)\tAcc@1  32.81 ( 38.83)\tAcc@5  64.84 ( 66.59)\n","Epoch: [35][210/391]\tTime  0.090 ( 0.091)\tLoss 1.4023e+00 (2.6214e+00)\tAcc@1  63.28 ( 39.84)\tAcc@5  86.72 ( 67.88)\n","Epoch: [35][240/391]\tTime  0.090 ( 0.091)\tLoss 3.0362e+00 (2.6018e+00)\tAcc@1  39.84 ( 40.77)\tAcc@5  67.97 ( 68.78)\n","Epoch: [35][270/391]\tTime  0.091 ( 0.091)\tLoss 2.9897e+00 (2.6223e+00)\tAcc@1  33.59 ( 40.52)\tAcc@5  64.06 ( 68.51)\n","Epoch: [35][300/391]\tTime  0.092 ( 0.091)\tLoss 1.7619e+00 (2.6189e+00)\tAcc@1  61.72 ( 40.65)\tAcc@5  93.75 ( 68.74)\n","Epoch: [35][330/391]\tTime  0.090 ( 0.091)\tLoss 1.8956e+00 (2.6059e+00)\tAcc@1  63.28 ( 41.11)\tAcc@5  78.91 ( 68.98)\n","Epoch: [35][360/391]\tTime  0.090 ( 0.091)\tLoss 3.4703e+00 (2.5981e+00)\tAcc@1   3.91 ( 41.33)\tAcc@5  17.97 ( 69.25)\n","Epoch: [35][390/391]\tTime  0.083 ( 0.091)\tLoss 2.7663e+00 (2.6043e+00)\tAcc@1  47.50 ( 41.17)\tAcc@5  71.25 ( 69.18)\n","==> Train Accuracy: Acc@1 41.174 || Acc@5 69.184\n","==> Test Accuracy:  Acc@1 55.830 || Acc@5 84.200\n","==> 37.98 seconds to train this epoch\n","\n","\n","----- epoch: 36, lr: 0.1 -----\n","Epoch: [36][  0/391]\tTime  0.216 ( 0.216)\tLoss 2.5844e+00 (2.5844e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  82.03 ( 82.03)\n","Epoch: [36][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.5671e+00 (2.6621e+00)\tAcc@1  57.03 ( 38.51)\tAcc@5  87.50 ( 66.56)\n","Epoch: [36][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.5760e+00 (2.5877e+00)\tAcc@1  62.50 ( 42.10)\tAcc@5  94.53 ( 69.92)\n","Epoch: [36][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.7640e+00 (2.5791e+00)\tAcc@1   2.34 ( 41.60)\tAcc@5  10.94 ( 69.33)\n","Epoch: [36][120/391]\tTime  0.091 ( 0.092)\tLoss 2.4043e+00 (2.5642e+00)\tAcc@1  49.22 ( 42.39)\tAcc@5  81.25 ( 70.39)\n","Epoch: [36][150/391]\tTime  0.091 ( 0.091)\tLoss 3.0779e+00 (2.5761e+00)\tAcc@1  32.03 ( 42.89)\tAcc@5  62.50 ( 70.93)\n","Epoch: [36][180/391]\tTime  0.091 ( 0.091)\tLoss 2.8490e+00 (2.5950e+00)\tAcc@1  38.28 ( 42.37)\tAcc@5  75.78 ( 70.51)\n","Epoch: [36][210/391]\tTime  0.091 ( 0.091)\tLoss 2.7059e+00 (2.6028e+00)\tAcc@1  46.88 ( 42.14)\tAcc@5  77.34 ( 70.26)\n","Epoch: [36][240/391]\tTime  0.091 ( 0.091)\tLoss 2.2853e+00 (2.6114e+00)\tAcc@1  57.03 ( 42.17)\tAcc@5  83.59 ( 70.41)\n","Epoch: [36][270/391]\tTime  0.090 ( 0.091)\tLoss 2.2157e+00 (2.6031e+00)\tAcc@1  60.94 ( 42.11)\tAcc@5  85.16 ( 70.47)\n","Epoch: [36][300/391]\tTime  0.090 ( 0.091)\tLoss 2.1907e+00 (2.5972e+00)\tAcc@1  57.03 ( 42.24)\tAcc@5  84.38 ( 70.60)\n","Epoch: [36][330/391]\tTime  0.089 ( 0.091)\tLoss 2.6249e+00 (2.6032e+00)\tAcc@1  53.91 ( 42.07)\tAcc@5  82.81 ( 70.40)\n","Epoch: [36][360/391]\tTime  0.090 ( 0.091)\tLoss 2.9162e+00 (2.6165e+00)\tAcc@1   0.78 ( 41.77)\tAcc@5  14.84 ( 70.11)\n","Epoch: [36][390/391]\tTime  0.081 ( 0.091)\tLoss 2.7534e+00 (2.6111e+00)\tAcc@1  50.00 ( 41.82)\tAcc@5  76.25 ( 70.15)\n","==> Train Accuracy: Acc@1 41.818 || Acc@5 70.154\n","==> Test Accuracy:  Acc@1 54.800 || Acc@5 83.080\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 37, lr: 0.1 -----\n","Epoch: [37][  0/391]\tTime  0.193 ( 0.193)\tLoss 2.9663e+00 (2.9663e+00)\tAcc@1  14.06 ( 14.06)\tAcc@5  39.06 ( 39.06)\n","Epoch: [37][ 30/391]\tTime  0.090 ( 0.093)\tLoss 2.8469e+00 (2.7337e+00)\tAcc@1  34.38 ( 37.40)\tAcc@5  67.19 ( 66.36)\n","Epoch: [37][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.1833e+00 (2.7144e+00)\tAcc@1  15.62 ( 37.87)\tAcc@5  39.06 ( 66.27)\n","Epoch: [37][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.8989e+00 (2.6461e+00)\tAcc@1  58.59 ( 39.66)\tAcc@5  84.38 ( 67.93)\n","Epoch: [37][120/391]\tTime  0.090 ( 0.091)\tLoss 1.7524e+00 (2.5754e+00)\tAcc@1  56.25 ( 42.19)\tAcc@5  89.06 ( 69.93)\n","Epoch: [37][150/391]\tTime  0.090 ( 0.091)\tLoss 2.4446e+00 (2.5565e+00)\tAcc@1  56.25 ( 43.07)\tAcc@5  85.94 ( 71.07)\n","Epoch: [37][180/391]\tTime  0.090 ( 0.091)\tLoss 2.8885e+00 (2.5657e+00)\tAcc@1  37.50 ( 43.03)\tAcc@5  75.00 ( 71.12)\n","Epoch: [37][210/391]\tTime  0.090 ( 0.091)\tLoss 2.8299e+00 (2.5681e+00)\tAcc@1  50.00 ( 42.47)\tAcc@5  77.34 ( 70.42)\n","Epoch: [37][240/391]\tTime  0.090 ( 0.091)\tLoss 1.9206e+00 (2.5792e+00)\tAcc@1  61.72 ( 41.62)\tAcc@5  78.12 ( 69.55)\n","Epoch: [37][270/391]\tTime  0.091 ( 0.091)\tLoss 2.4733e+00 (2.5808e+00)\tAcc@1  51.56 ( 41.53)\tAcc@5  82.81 ( 69.67)\n","Epoch: [37][300/391]\tTime  0.090 ( 0.091)\tLoss 3.0844e+00 (2.5843e+00)\tAcc@1  31.25 ( 41.46)\tAcc@5  64.06 ( 69.66)\n","Epoch: [37][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8239e+00 (2.5857e+00)\tAcc@1  60.16 ( 41.63)\tAcc@5  89.06 ( 69.78)\n","Epoch: [37][360/391]\tTime  0.090 ( 0.091)\tLoss 2.3793e+00 (2.5870e+00)\tAcc@1  54.69 ( 41.31)\tAcc@5  91.41 ( 69.43)\n","Epoch: [37][390/391]\tTime  0.082 ( 0.091)\tLoss 2.7454e+00 (2.5810e+00)\tAcc@1  46.25 ( 41.49)\tAcc@5  72.50 ( 69.51)\n","==> Train Accuracy: Acc@1 41.494 || Acc@5 69.510\n","==> Test Accuracy:  Acc@1 53.020 || Acc@5 81.970\n","==> 37.86 seconds to train this epoch\n","\n","\n","----- epoch: 38, lr: 0.1 -----\n","Epoch: [38][  0/391]\tTime  0.200 ( 0.200)\tLoss 3.0356e+00 (3.0356e+00)\tAcc@1   8.59 (  8.59)\tAcc@5  30.47 ( 30.47)\n","Epoch: [38][ 30/391]\tTime  0.091 ( 0.094)\tLoss 3.0314e+00 (2.5709e+00)\tAcc@1  34.38 ( 42.16)\tAcc@5  60.16 ( 70.14)\n","Epoch: [38][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.1506e+00 (2.5910e+00)\tAcc@1  32.03 ( 42.12)\tAcc@5  64.84 ( 70.33)\n","Epoch: [38][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.8345e+00 (2.6019e+00)\tAcc@1  42.19 ( 42.41)\tAcc@5  75.00 ( 70.87)\n","Epoch: [38][120/391]\tTime  0.090 ( 0.091)\tLoss 2.5390e+00 (2.5773e+00)\tAcc@1  52.34 ( 43.21)\tAcc@5  85.94 ( 71.56)\n","Epoch: [38][150/391]\tTime  0.090 ( 0.091)\tLoss 2.9205e+00 (2.5803e+00)\tAcc@1  49.22 ( 42.42)\tAcc@5  71.88 ( 71.07)\n","Epoch: [38][180/391]\tTime  0.090 ( 0.091)\tLoss 2.7544e+00 (2.5997e+00)\tAcc@1  51.56 ( 42.01)\tAcc@5  75.78 ( 70.49)\n","Epoch: [38][210/391]\tTime  0.090 ( 0.091)\tLoss 2.9413e+00 (2.6143e+00)\tAcc@1  27.34 ( 41.84)\tAcc@5  62.50 ( 70.54)\n","Epoch: [38][240/391]\tTime  0.090 ( 0.091)\tLoss 2.6688e+00 (2.6095e+00)\tAcc@1  49.22 ( 41.49)\tAcc@5  82.81 ( 70.18)\n","Epoch: [38][270/391]\tTime  0.090 ( 0.091)\tLoss 2.8014e+00 (2.6111e+00)\tAcc@1   1.56 ( 41.40)\tAcc@5   7.81 ( 69.89)\n","Epoch: [38][300/391]\tTime  0.091 ( 0.091)\tLoss 2.4502e+00 (2.6153e+00)\tAcc@1  54.69 ( 41.29)\tAcc@5  83.59 ( 69.75)\n","Epoch: [38][330/391]\tTime  0.090 ( 0.091)\tLoss 3.0185e+00 (2.6147e+00)\tAcc@1  39.06 ( 41.42)\tAcc@5  70.31 ( 69.84)\n","Epoch: [38][360/391]\tTime  0.090 ( 0.091)\tLoss 3.1483e+00 (2.6205e+00)\tAcc@1  26.56 ( 41.33)\tAcc@5  54.69 ( 69.60)\n","Epoch: [38][390/391]\tTime  0.078 ( 0.091)\tLoss 2.9964e+00 (2.6270e+00)\tAcc@1  21.25 ( 41.22)\tAcc@5  52.50 ( 69.52)\n","==> Train Accuracy: Acc@1 41.220 || Acc@5 69.522\n","==> Test Accuracy:  Acc@1 56.200 || Acc@5 84.570\n","==> 37.84 seconds to train this epoch\n","\n","\n","----- epoch: 39, lr: 0.1 -----\n","Epoch: [39][  0/391]\tTime  0.196 ( 0.196)\tLoss 3.0119e+00 (3.0119e+00)\tAcc@1  13.28 ( 13.28)\tAcc@5  42.19 ( 42.19)\n","Epoch: [39][ 30/391]\tTime  0.091 ( 0.093)\tLoss 2.7121e+00 (2.5785e+00)\tAcc@1  50.00 ( 40.60)\tAcc@5  81.25 ( 70.16)\n","Epoch: [39][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.3480e+00 (2.6117e+00)\tAcc@1  53.91 ( 40.64)\tAcc@5  83.59 ( 69.17)\n","Epoch: [39][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.4379e+00 (2.6005e+00)\tAcc@1  67.19 ( 40.94)\tAcc@5  85.16 ( 68.55)\n","Epoch: [39][120/391]\tTime  0.090 ( 0.091)\tLoss 2.9224e+00 (2.6006e+00)\tAcc@1  32.03 ( 41.41)\tAcc@5  67.97 ( 69.32)\n","Epoch: [39][150/391]\tTime  0.090 ( 0.091)\tLoss 2.1015e+00 (2.5794e+00)\tAcc@1  63.28 ( 42.22)\tAcc@5  87.50 ( 69.99)\n","Epoch: [39][180/391]\tTime  0.090 ( 0.091)\tLoss 3.0046e+00 (2.5701e+00)\tAcc@1   3.12 ( 42.39)\tAcc@5  17.19 ( 70.18)\n","Epoch: [39][210/391]\tTime  0.090 ( 0.091)\tLoss 2.4220e+00 (2.5802e+00)\tAcc@1  56.25 ( 42.08)\tAcc@5  85.16 ( 69.96)\n","Epoch: [39][240/391]\tTime  0.090 ( 0.091)\tLoss 2.0471e+00 (2.5753e+00)\tAcc@1  56.25 ( 41.99)\tAcc@5  87.50 ( 69.89)\n","Epoch: [39][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0030e+00 (2.5827e+00)\tAcc@1  60.16 ( 41.95)\tAcc@5  85.94 ( 69.89)\n","Epoch: [39][300/391]\tTime  0.088 ( 0.091)\tLoss 3.0147e+00 (2.5814e+00)\tAcc@1  27.34 ( 42.31)\tAcc@5  57.81 ( 70.29)\n","Epoch: [39][330/391]\tTime  0.090 ( 0.091)\tLoss 2.7475e+00 (2.5809e+00)\tAcc@1  45.31 ( 42.47)\tAcc@5  77.34 ( 70.48)\n","Epoch: [39][360/391]\tTime  0.091 ( 0.091)\tLoss 3.1291e+00 (2.5967e+00)\tAcc@1  30.47 ( 42.14)\tAcc@5  53.91 ( 70.34)\n","Epoch: [39][390/391]\tTime  0.082 ( 0.091)\tLoss 2.8906e+00 (2.6044e+00)\tAcc@1  43.75 ( 41.87)\tAcc@5  70.00 ( 70.13)\n","==> Train Accuracy: Acc@1 41.866 || Acc@5 70.128\n","==> Test Accuracy:  Acc@1 56.080 || Acc@5 83.840\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 40, lr: 0.1 -----\n","Epoch: [40][  0/391]\tTime  0.201 ( 0.201)\tLoss 2.5697e+00 (2.5697e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  81.25 ( 81.25)\n","Epoch: [40][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.5498e+00 (2.7235e+00)\tAcc@1  64.84 ( 40.10)\tAcc@5  90.62 ( 67.14)\n","Epoch: [40][ 60/391]\tTime  0.092 ( 0.092)\tLoss 3.1203e+00 (2.6707e+00)\tAcc@1  28.12 ( 39.34)\tAcc@5  57.81 ( 65.91)\n","Epoch: [40][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.3391e+00 (2.6661e+00)\tAcc@1  56.25 ( 39.65)\tAcc@5  84.38 ( 66.55)\n","Epoch: [40][120/391]\tTime  0.091 ( 0.091)\tLoss 1.7186e+00 (2.6328e+00)\tAcc@1  62.50 ( 40.52)\tAcc@5  86.72 ( 67.68)\n","Epoch: [40][150/391]\tTime  0.090 ( 0.091)\tLoss 2.5942e+00 (2.6445e+00)\tAcc@1  51.56 ( 39.35)\tAcc@5  81.25 ( 66.77)\n","Epoch: [40][180/391]\tTime  0.086 ( 0.091)\tLoss 1.5559e+00 (2.6606e+00)\tAcc@1  67.97 ( 38.41)\tAcc@5  92.97 ( 65.85)\n","Epoch: [40][210/391]\tTime  0.090 ( 0.091)\tLoss 1.7011e+00 (2.6121e+00)\tAcc@1  61.72 ( 40.03)\tAcc@5  89.84 ( 67.45)\n","Epoch: [40][240/391]\tTime  0.091 ( 0.091)\tLoss 3.0190e+00 (2.6243e+00)\tAcc@1  28.12 ( 39.95)\tAcc@5  58.59 ( 67.48)\n","Epoch: [40][270/391]\tTime  0.092 ( 0.091)\tLoss 1.7739e+00 (2.6258e+00)\tAcc@1  61.72 ( 39.94)\tAcc@5  85.94 ( 67.63)\n","Epoch: [40][300/391]\tTime  0.090 ( 0.091)\tLoss 2.9806e+00 (2.6419e+00)\tAcc@1  32.03 ( 39.54)\tAcc@5  66.41 ( 67.40)\n","Epoch: [40][330/391]\tTime  0.090 ( 0.091)\tLoss 2.2849e+00 (2.6487e+00)\tAcc@1  60.16 ( 39.43)\tAcc@5  85.94 ( 67.43)\n","Epoch: [40][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7729e+00 (2.6375e+00)\tAcc@1  60.16 ( 39.80)\tAcc@5  88.28 ( 67.87)\n","Epoch: [40][390/391]\tTime  0.083 ( 0.091)\tLoss 2.9154e+00 (2.6314e+00)\tAcc@1  50.00 ( 39.96)\tAcc@5  72.50 ( 68.04)\n","==> Train Accuracy: Acc@1 39.960 || Acc@5 68.042\n","==> Test Accuracy:  Acc@1 56.060 || Acc@5 84.040\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 41, lr: 0.1 -----\n","Epoch: [41][  0/391]\tTime  0.217 ( 0.217)\tLoss 2.6554e+00 (2.6554e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  78.91 ( 78.91)\n","Epoch: [41][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.4378e+00 (2.5147e+00)\tAcc@1  61.72 ( 41.86)\tAcc@5  88.28 ( 70.82)\n","Epoch: [41][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.9755e+00 (2.5147e+00)\tAcc@1  64.06 ( 42.42)\tAcc@5  85.94 ( 71.39)\n","Epoch: [41][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3778e+00 (2.5156e+00)\tAcc@1  60.94 ( 43.36)\tAcc@5  89.84 ( 71.84)\n","Epoch: [41][120/391]\tTime  0.089 ( 0.091)\tLoss 3.0049e+00 (2.5124e+00)\tAcc@1  36.72 ( 43.89)\tAcc@5  67.19 ( 72.36)\n","Epoch: [41][150/391]\tTime  0.090 ( 0.091)\tLoss 2.9774e+00 (2.5417e+00)\tAcc@1   4.69 ( 42.90)\tAcc@5  31.25 ( 71.31)\n","Epoch: [41][180/391]\tTime  0.089 ( 0.091)\tLoss 2.8551e+00 (2.5563e+00)\tAcc@1  42.19 ( 42.47)\tAcc@5  69.53 ( 70.54)\n","Epoch: [41][210/391]\tTime  0.090 ( 0.091)\tLoss 2.3327e+00 (2.5457e+00)\tAcc@1   3.91 ( 42.51)\tAcc@5   7.81 ( 70.69)\n","Epoch: [41][240/391]\tTime  0.090 ( 0.091)\tLoss 2.3187e+00 (2.5544e+00)\tAcc@1  53.91 ( 42.26)\tAcc@5  80.47 ( 70.30)\n","Epoch: [41][270/391]\tTime  0.090 ( 0.091)\tLoss 2.4235e+00 (2.5710e+00)\tAcc@1  58.59 ( 41.98)\tAcc@5  88.28 ( 70.13)\n","Epoch: [41][300/391]\tTime  0.090 ( 0.091)\tLoss 2.7271e+00 (2.5763e+00)\tAcc@1  53.12 ( 41.46)\tAcc@5  77.34 ( 69.44)\n","Epoch: [41][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9957e+00 (2.5750e+00)\tAcc@1  60.16 ( 41.61)\tAcc@5  87.50 ( 69.69)\n","Epoch: [41][360/391]\tTime  0.090 ( 0.091)\tLoss 3.2008e+00 (2.5737e+00)\tAcc@1  15.62 ( 41.93)\tAcc@5  47.66 ( 69.89)\n","Epoch: [41][390/391]\tTime  0.081 ( 0.091)\tLoss 2.5896e+00 (2.5701e+00)\tAcc@1  51.25 ( 42.01)\tAcc@5  76.25 ( 69.87)\n","==> Train Accuracy: Acc@1 42.006 || Acc@5 69.866\n","==> Test Accuracy:  Acc@1 55.980 || Acc@5 84.380\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 42, lr: 0.1 -----\n","Epoch: [42][  0/391]\tTime  0.210 ( 0.210)\tLoss 3.2344e+00 (3.2344e+00)\tAcc@1  18.75 ( 18.75)\tAcc@5  53.12 ( 53.12)\n","Epoch: [42][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.5223e+00 (2.5950e+00)\tAcc@1   1.56 ( 38.51)\tAcc@5  16.41 ( 65.62)\n","Epoch: [42][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.7732e+00 (2.5646e+00)\tAcc@1  40.62 ( 39.88)\tAcc@5  74.22 ( 67.17)\n","Epoch: [42][ 90/391]\tTime  0.089 ( 0.091)\tLoss 3.0697e+00 (2.6055e+00)\tAcc@1  25.78 ( 39.96)\tAcc@5  56.25 ( 67.80)\n","Epoch: [42][120/391]\tTime  0.090 ( 0.091)\tLoss 3.0597e+00 (2.6108e+00)\tAcc@1  33.59 ( 40.38)\tAcc@5  66.41 ( 68.22)\n","Epoch: [42][150/391]\tTime  0.089 ( 0.091)\tLoss 2.2789e+00 (2.5985e+00)\tAcc@1  57.81 ( 41.13)\tAcc@5  82.03 ( 68.89)\n","Epoch: [42][180/391]\tTime  0.090 ( 0.091)\tLoss 2.3082e+00 (2.6058e+00)\tAcc@1  51.56 ( 41.67)\tAcc@5  85.16 ( 69.60)\n","Epoch: [42][210/391]\tTime  0.090 ( 0.091)\tLoss 1.7684e+00 (2.5975e+00)\tAcc@1  57.81 ( 42.43)\tAcc@5  87.50 ( 70.43)\n","Epoch: [42][240/391]\tTime  0.090 ( 0.091)\tLoss 2.7625e+00 (2.6060e+00)\tAcc@1  44.53 ( 42.33)\tAcc@5  74.22 ( 70.56)\n","Epoch: [42][270/391]\tTime  0.089 ( 0.091)\tLoss 2.5493e+00 (2.6139e+00)\tAcc@1  58.59 ( 42.12)\tAcc@5  82.81 ( 70.30)\n","Epoch: [42][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7695e+00 (2.6064e+00)\tAcc@1  60.16 ( 42.26)\tAcc@5  85.94 ( 70.43)\n","Epoch: [42][330/391]\tTime  0.090 ( 0.091)\tLoss 3.2283e+00 (2.5884e+00)\tAcc@1  15.62 ( 42.69)\tAcc@5  36.72 ( 70.92)\n","Epoch: [42][360/391]\tTime  0.090 ( 0.091)\tLoss 2.3303e+00 (2.5874e+00)\tAcc@1  53.12 ( 42.84)\tAcc@5  85.16 ( 71.11)\n","Epoch: [42][390/391]\tTime  0.082 ( 0.091)\tLoss 3.0618e+00 (2.5896e+00)\tAcc@1  15.00 ( 42.92)\tAcc@5  45.00 ( 71.13)\n","==> Train Accuracy: Acc@1 42.920 || Acc@5 71.128\n","==> Test Accuracy:  Acc@1 56.310 || Acc@5 84.730\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 43, lr: 0.1 -----\n","Epoch: [43][  0/391]\tTime  0.201 ( 0.201)\tLoss 2.8842e+00 (2.8842e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  70.31 ( 70.31)\n","Epoch: [43][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.0810e+00 (2.6238e+00)\tAcc@1  17.19 ( 39.52)\tAcc@5  39.06 ( 69.08)\n","Epoch: [43][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.5121e+00 (2.5224e+00)\tAcc@1  48.44 ( 43.58)\tAcc@5  73.44 ( 72.86)\n","Epoch: [43][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.4457e+00 (2.5721e+00)\tAcc@1  56.25 ( 41.84)\tAcc@5  86.72 ( 70.09)\n","Epoch: [43][120/391]\tTime  0.088 ( 0.091)\tLoss 3.0892e+00 (2.5540e+00)\tAcc@1  25.78 ( 42.50)\tAcc@5  55.47 ( 70.55)\n","Epoch: [43][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7938e+00 (2.5619e+00)\tAcc@1  61.72 ( 42.52)\tAcc@5  84.38 ( 70.72)\n","Epoch: [43][180/391]\tTime  0.090 ( 0.091)\tLoss 1.8384e+00 (2.5721e+00)\tAcc@1  67.19 ( 43.02)\tAcc@5  94.53 ( 71.16)\n","Epoch: [43][210/391]\tTime  0.090 ( 0.091)\tLoss 2.9419e+00 (2.5848e+00)\tAcc@1  12.50 ( 42.58)\tAcc@5  45.31 ( 70.98)\n","Epoch: [43][240/391]\tTime  0.090 ( 0.091)\tLoss 2.8889e+00 (2.5898e+00)\tAcc@1  42.97 ( 42.93)\tAcc@5  72.66 ( 71.33)\n","Epoch: [43][270/391]\tTime  0.090 ( 0.091)\tLoss 2.7814e+00 (2.5813e+00)\tAcc@1  39.06 ( 42.91)\tAcc@5  78.12 ( 71.37)\n","Epoch: [43][300/391]\tTime  0.090 ( 0.091)\tLoss 2.3764e+00 (2.5673e+00)\tAcc@1  49.22 ( 43.03)\tAcc@5  82.81 ( 71.42)\n","Epoch: [43][330/391]\tTime  0.090 ( 0.091)\tLoss 2.6437e+00 (2.5810e+00)\tAcc@1  55.47 ( 42.82)\tAcc@5  78.91 ( 71.24)\n","Epoch: [43][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4251e+00 (2.5707e+00)\tAcc@1  63.28 ( 43.19)\tAcc@5  91.41 ( 71.67)\n","Epoch: [43][390/391]\tTime  0.082 ( 0.091)\tLoss 2.8794e+00 (2.5723e+00)\tAcc@1  18.75 ( 42.83)\tAcc@5  50.00 ( 71.19)\n","==> Train Accuracy: Acc@1 42.834 || Acc@5 71.186\n","==> Test Accuracy:  Acc@1 56.550 || Acc@5 84.870\n","==> 37.88 seconds to train this epoch\n","\n","\n","----- epoch: 44, lr: 0.1 -----\n","Epoch: [44][  0/391]\tTime  0.201 ( 0.201)\tLoss 2.1509e+00 (2.1509e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  87.50 ( 87.50)\n","Epoch: [44][ 30/391]\tTime  0.089 ( 0.093)\tLoss 2.7626e+00 (2.6982e+00)\tAcc@1  50.78 ( 37.37)\tAcc@5  78.91 ( 66.31)\n","Epoch: [44][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.8074e+00 (2.5202e+00)\tAcc@1  10.94 ( 43.40)\tAcc@5  30.47 ( 71.66)\n","Epoch: [44][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.3310e+00 (2.5553e+00)\tAcc@1  58.59 ( 40.79)\tAcc@5  78.91 ( 68.28)\n","Epoch: [44][120/391]\tTime  0.088 ( 0.091)\tLoss 3.0233e+00 (2.5597e+00)\tAcc@1  39.06 ( 41.28)\tAcc@5  66.41 ( 69.07)\n","Epoch: [44][150/391]\tTime  0.090 ( 0.091)\tLoss 2.4929e+00 (2.5549e+00)\tAcc@1  50.00 ( 41.51)\tAcc@5  86.72 ( 69.54)\n","Epoch: [44][180/391]\tTime  0.090 ( 0.091)\tLoss 2.8487e+00 (2.5837e+00)\tAcc@1  37.50 ( 41.52)\tAcc@5  75.78 ( 69.75)\n","Epoch: [44][210/391]\tTime  0.091 ( 0.091)\tLoss 2.9476e+00 (2.5760e+00)\tAcc@1  42.19 ( 41.73)\tAcc@5  68.75 ( 69.84)\n","Epoch: [44][240/391]\tTime  0.091 ( 0.091)\tLoss 3.1837e+00 (2.5660e+00)\tAcc@1  24.22 ( 41.92)\tAcc@5  46.88 ( 69.83)\n","Epoch: [44][270/391]\tTime  0.090 ( 0.091)\tLoss 1.5381e+00 (2.5546e+00)\tAcc@1  58.59 ( 42.03)\tAcc@5  89.84 ( 69.80)\n","Epoch: [44][300/391]\tTime  0.090 ( 0.091)\tLoss 2.0356e+00 (2.5597e+00)\tAcc@1  57.81 ( 41.83)\tAcc@5  85.94 ( 69.55)\n","Epoch: [44][330/391]\tTime  0.090 ( 0.091)\tLoss 2.6185e+00 (2.5526e+00)\tAcc@1  58.59 ( 42.07)\tAcc@5  79.69 ( 69.81)\n","Epoch: [44][360/391]\tTime  0.090 ( 0.091)\tLoss 2.2712e+00 (2.5592e+00)\tAcc@1   1.56 ( 41.88)\tAcc@5   6.25 ( 69.46)\n","Epoch: [44][390/391]\tTime  0.081 ( 0.091)\tLoss 2.0284e+00 (2.5495e+00)\tAcc@1  60.00 ( 42.14)\tAcc@5  86.25 ( 69.72)\n","==> Train Accuracy: Acc@1 42.136 || Acc@5 69.720\n","==> Test Accuracy:  Acc@1 55.630 || Acc@5 83.390\n","==> 37.83 seconds to train this epoch\n","\n","\n","----- epoch: 45, lr: 0.1 -----\n","Epoch: [45][  0/391]\tTime  0.190 ( 0.190)\tLoss 2.9853e+00 (2.9853e+00)\tAcc@1  31.25 ( 31.25)\tAcc@5  63.28 ( 63.28)\n","Epoch: [45][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.0434e+00 (2.5388e+00)\tAcc@1  16.41 ( 39.59)\tAcc@5  50.78 ( 67.99)\n","Epoch: [45][ 60/391]\tTime  0.089 ( 0.092)\tLoss 3.1954e+00 (2.5247e+00)\tAcc@1  25.00 ( 43.93)\tAcc@5  50.78 ( 72.35)\n","Epoch: [45][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.5994e+00 (2.5139e+00)\tAcc@1  51.56 ( 45.36)\tAcc@5  84.38 ( 73.60)\n","Epoch: [45][120/391]\tTime  0.090 ( 0.091)\tLoss 2.9453e+00 (2.5518e+00)\tAcc@1  34.38 ( 44.19)\tAcc@5  67.97 ( 72.41)\n","Epoch: [45][150/391]\tTime  0.093 ( 0.091)\tLoss 2.1615e+00 (2.5652e+00)\tAcc@1  63.28 ( 43.69)\tAcc@5  91.41 ( 71.68)\n","Epoch: [45][180/391]\tTime  0.090 ( 0.091)\tLoss 2.2796e+00 (2.5861e+00)\tAcc@1  60.16 ( 42.89)\tAcc@5  88.28 ( 70.87)\n","Epoch: [45][210/391]\tTime  0.091 ( 0.091)\tLoss 2.0999e+00 (2.5824e+00)\tAcc@1  59.38 ( 42.58)\tAcc@5  93.75 ( 70.51)\n","Epoch: [45][240/391]\tTime  0.091 ( 0.091)\tLoss 2.7458e+00 (2.5870e+00)\tAcc@1  45.31 ( 42.05)\tAcc@5  75.00 ( 69.89)\n","Epoch: [45][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0636e+00 (2.5900e+00)\tAcc@1  62.50 ( 41.69)\tAcc@5  89.84 ( 69.38)\n","Epoch: [45][300/391]\tTime  0.090 ( 0.091)\tLoss 3.0583e+00 (2.6017e+00)\tAcc@1  35.16 ( 41.13)\tAcc@5  67.97 ( 68.88)\n","Epoch: [45][330/391]\tTime  0.091 ( 0.091)\tLoss 3.2006e+00 (2.6129e+00)\tAcc@1  21.09 ( 40.64)\tAcc@5  48.44 ( 68.57)\n","Epoch: [45][360/391]\tTime  0.091 ( 0.091)\tLoss 2.9788e+00 (2.6230e+00)\tAcc@1  32.81 ( 40.36)\tAcc@5  67.19 ( 68.19)\n","Epoch: [45][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5371e+00 (2.6227e+00)\tAcc@1  56.25 ( 40.34)\tAcc@5  80.00 ( 68.23)\n","==> Train Accuracy: Acc@1 40.344 || Acc@5 68.226\n","==> Test Accuracy:  Acc@1 58.780 || Acc@5 86.590\n","==> 37.99 seconds to train this epoch\n","\n","\n","----- epoch: 46, lr: 0.1 -----\n","Epoch: [46][  0/391]\tTime  0.221 ( 0.221)\tLoss 2.7178e+00 (2.7178e+00)\tAcc@1  39.84 ( 39.84)\tAcc@5  77.34 ( 77.34)\n","Epoch: [46][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.5371e+00 (2.4783e+00)\tAcc@1  64.06 ( 43.09)\tAcc@5  91.41 ( 72.30)\n","Epoch: [46][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.0530e+00 (2.5181e+00)\tAcc@1   7.03 ( 40.95)\tAcc@5  27.34 ( 69.11)\n","Epoch: [46][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.8981e+00 (2.5206e+00)\tAcc@1  42.19 ( 43.02)\tAcc@5  75.00 ( 71.28)\n","Epoch: [46][120/391]\tTime  0.091 ( 0.092)\tLoss 1.7884e+00 (2.5396e+00)\tAcc@1  71.09 ( 42.79)\tAcc@5  89.06 ( 70.75)\n","Epoch: [46][150/391]\tTime  0.090 ( 0.091)\tLoss 2.2148e+00 (2.5679e+00)\tAcc@1  65.62 ( 42.50)\tAcc@5  87.50 ( 70.64)\n","Epoch: [46][180/391]\tTime  0.090 ( 0.091)\tLoss 2.9590e+00 (2.5853e+00)\tAcc@1  34.38 ( 42.12)\tAcc@5  64.06 ( 70.31)\n","Epoch: [46][210/391]\tTime  0.090 ( 0.091)\tLoss 3.1393e+00 (2.5814e+00)\tAcc@1  20.31 ( 42.68)\tAcc@5  50.78 ( 70.85)\n","Epoch: [46][240/391]\tTime  0.090 ( 0.091)\tLoss 2.9357e+00 (2.5748e+00)\tAcc@1  35.94 ( 42.90)\tAcc@5  72.66 ( 70.93)\n","Epoch: [46][270/391]\tTime  0.090 ( 0.091)\tLoss 2.7501e+00 (2.5785e+00)\tAcc@1  51.56 ( 42.91)\tAcc@5  76.56 ( 70.90)\n","Epoch: [46][300/391]\tTime  0.090 ( 0.091)\tLoss 2.8985e+00 (2.5929e+00)\tAcc@1  29.69 ( 42.71)\tAcc@5  65.62 ( 70.73)\n","Epoch: [46][330/391]\tTime  0.090 ( 0.091)\tLoss 3.1918e+00 (2.5979e+00)\tAcc@1  10.16 ( 42.68)\tAcc@5  33.59 ( 70.85)\n","Epoch: [46][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4802e+00 (2.5872e+00)\tAcc@1  62.50 ( 42.98)\tAcc@5  88.28 ( 71.17)\n","Epoch: [46][390/391]\tTime  0.082 ( 0.091)\tLoss 3.2113e+00 (2.5932e+00)\tAcc@1  33.75 ( 42.59)\tAcc@5  58.75 ( 70.66)\n","==> Train Accuracy: Acc@1 42.590 || Acc@5 70.662\n","==> Test Accuracy:  Acc@1 54.580 || Acc@5 81.840\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 47, lr: 0.1 -----\n","Epoch: [47][  0/391]\tTime  0.198 ( 0.198)\tLoss 2.4320e+00 (2.4320e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  90.62 ( 90.62)\n","Epoch: [47][ 30/391]\tTime  0.090 ( 0.093)\tLoss 2.4997e+00 (2.4062e+00)\tAcc@1  55.47 ( 48.26)\tAcc@5  81.25 ( 76.21)\n","Epoch: [47][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.5398e+00 (2.4990e+00)\tAcc@1  57.03 ( 44.92)\tAcc@5  85.94 ( 71.98)\n","Epoch: [47][ 90/391]\tTime  0.096 ( 0.092)\tLoss 2.3660e+00 (2.5218e+00)\tAcc@1  52.34 ( 43.15)\tAcc@5  80.47 ( 70.30)\n","Epoch: [47][120/391]\tTime  0.091 ( 0.091)\tLoss 2.2266e+00 (2.5030e+00)\tAcc@1  61.72 ( 44.25)\tAcc@5  87.50 ( 72.06)\n","Epoch: [47][150/391]\tTime  0.091 ( 0.091)\tLoss 3.0594e+00 (2.4853e+00)\tAcc@1  34.38 ( 45.08)\tAcc@5  67.97 ( 72.85)\n","Epoch: [47][180/391]\tTime  0.091 ( 0.091)\tLoss 3.0940e+00 (2.4982e+00)\tAcc@1  29.69 ( 44.42)\tAcc@5  60.94 ( 71.94)\n","Epoch: [47][210/391]\tTime  0.093 ( 0.091)\tLoss 2.9488e+00 (2.4881e+00)\tAcc@1  32.81 ( 44.81)\tAcc@5  64.84 ( 72.51)\n","Epoch: [47][240/391]\tTime  0.090 ( 0.091)\tLoss 2.9961e+00 (2.5035e+00)\tAcc@1  33.59 ( 45.00)\tAcc@5  67.19 ( 72.92)\n","Epoch: [47][270/391]\tTime  0.091 ( 0.091)\tLoss 2.6571e+00 (2.5260e+00)\tAcc@1  53.12 ( 44.25)\tAcc@5  80.47 ( 72.32)\n","Epoch: [47][300/391]\tTime  0.091 ( 0.091)\tLoss 2.3028e+00 (2.5371e+00)\tAcc@1  56.25 ( 44.14)\tAcc@5  89.06 ( 72.31)\n","Epoch: [47][330/391]\tTime  0.090 ( 0.091)\tLoss 2.6176e+00 (2.5562e+00)\tAcc@1  51.56 ( 43.36)\tAcc@5  78.91 ( 71.63)\n","Epoch: [47][360/391]\tTime  0.091 ( 0.091)\tLoss 3.1134e+00 (2.5576e+00)\tAcc@1  22.66 ( 43.33)\tAcc@5  48.44 ( 71.57)\n","Epoch: [47][390/391]\tTime  0.085 ( 0.091)\tLoss 2.8640e+00 (2.5625e+00)\tAcc@1  41.25 ( 43.33)\tAcc@5  72.50 ( 71.60)\n","==> Train Accuracy: Acc@1 43.334 || Acc@5 71.596\n","==> Test Accuracy:  Acc@1 56.800 || Acc@5 85.340\n","==> 38.05 seconds to train this epoch\n","\n","\n","----- epoch: 48, lr: 0.1 -----\n","Epoch: [48][  0/391]\tTime  0.194 ( 0.194)\tLoss 2.9684e+00 (2.9684e+00)\tAcc@1  32.03 ( 32.03)\tAcc@5  66.41 ( 66.41)\n","Epoch: [48][ 30/391]\tTime  0.091 ( 0.094)\tLoss 2.9344e+00 (2.6092e+00)\tAcc@1  15.62 ( 40.83)\tAcc@5  45.31 ( 69.78)\n","Epoch: [48][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.9725e+00 (2.5157e+00)\tAcc@1  54.69 ( 44.25)\tAcc@5  85.94 ( 73.17)\n","Epoch: [48][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.4152e+00 (2.5163e+00)\tAcc@1  52.34 ( 44.51)\tAcc@5  78.91 ( 73.15)\n","Epoch: [48][120/391]\tTime  0.090 ( 0.092)\tLoss 2.9858e+00 (2.5154e+00)\tAcc@1   7.03 ( 44.73)\tAcc@5  24.22 ( 73.17)\n","Epoch: [48][150/391]\tTime  0.090 ( 0.091)\tLoss 2.5288e+00 (2.5201e+00)\tAcc@1  56.25 ( 44.14)\tAcc@5  81.25 ( 72.66)\n","Epoch: [48][180/391]\tTime  0.091 ( 0.091)\tLoss 2.5943e+00 (2.5272e+00)\tAcc@1  50.78 ( 43.95)\tAcc@5  82.03 ( 72.48)\n","Epoch: [48][210/391]\tTime  0.090 ( 0.091)\tLoss 2.6908e+00 (2.5447e+00)\tAcc@1  47.66 ( 43.34)\tAcc@5  77.34 ( 71.80)\n","Epoch: [48][240/391]\tTime  0.090 ( 0.091)\tLoss 2.8096e+00 (2.5552e+00)\tAcc@1  42.19 ( 42.51)\tAcc@5  77.34 ( 70.90)\n","Epoch: [48][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9322e+00 (2.5398e+00)\tAcc@1  59.38 ( 43.15)\tAcc@5  89.84 ( 71.58)\n","Epoch: [48][300/391]\tTime  0.091 ( 0.091)\tLoss 1.3364e+00 (2.5344e+00)\tAcc@1  68.75 ( 43.06)\tAcc@5  92.97 ( 71.56)\n","Epoch: [48][330/391]\tTime  0.090 ( 0.091)\tLoss 3.1772e+00 (2.5520e+00)\tAcc@1  11.72 ( 42.04)\tAcc@5  32.81 ( 70.43)\n","Epoch: [48][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5065e+00 (2.5638e+00)\tAcc@1  55.47 ( 41.76)\tAcc@5  88.28 ( 70.18)\n","Epoch: [48][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5940e+00 (2.5554e+00)\tAcc@1  48.75 ( 41.96)\tAcc@5  82.50 ( 70.31)\n","==> Train Accuracy: Acc@1 41.960 || Acc@5 70.310\n","==> Test Accuracy:  Acc@1 57.650 || Acc@5 86.510\n","==> 38.08 seconds to train this epoch\n","\n","\n","----- epoch: 49, lr: 0.1 -----\n","Epoch: [49][  0/391]\tTime  0.210 ( 0.210)\tLoss 2.3260e+00 (2.3260e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  89.06 ( 89.06)\n","Epoch: [49][ 30/391]\tTime  0.091 ( 0.095)\tLoss 2.8422e+00 (2.6614e+00)\tAcc@1  42.97 ( 41.20)\tAcc@5  71.88 ( 69.83)\n","Epoch: [49][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.6817e+00 (2.5076e+00)\tAcc@1   6.25 ( 44.33)\tAcc@5  23.44 ( 72.07)\n","Epoch: [49][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.0202e+00 (2.6195e+00)\tAcc@1  28.91 ( 41.22)\tAcc@5  60.94 ( 69.66)\n","Epoch: [49][120/391]\tTime  0.091 ( 0.092)\tLoss 3.1340e+00 (2.6085e+00)\tAcc@1  31.25 ( 41.85)\tAcc@5  64.06 ( 69.89)\n","Epoch: [49][150/391]\tTime  0.091 ( 0.091)\tLoss 2.8015e+00 (2.6147e+00)\tAcc@1  42.97 ( 41.93)\tAcc@5  69.53 ( 70.05)\n","Epoch: [49][180/391]\tTime  0.091 ( 0.091)\tLoss 2.7864e+00 (2.5738e+00)\tAcc@1  42.19 ( 43.18)\tAcc@5  75.78 ( 71.25)\n","Epoch: [49][210/391]\tTime  0.090 ( 0.091)\tLoss 2.9886e+00 (2.5700e+00)\tAcc@1  36.72 ( 42.82)\tAcc@5  66.41 ( 70.87)\n","Epoch: [49][240/391]\tTime  0.090 ( 0.091)\tLoss 2.7217e+00 (2.5724e+00)\tAcc@1  42.19 ( 42.57)\tAcc@5  79.69 ( 70.55)\n","Epoch: [49][270/391]\tTime  0.091 ( 0.091)\tLoss 3.0436e+00 (2.5576e+00)\tAcc@1  11.72 ( 42.63)\tAcc@5  41.41 ( 70.41)\n","Epoch: [49][300/391]\tTime  0.090 ( 0.091)\tLoss 2.5736e+00 (2.5626e+00)\tAcc@1  51.56 ( 42.85)\tAcc@5  83.59 ( 70.78)\n","Epoch: [49][330/391]\tTime  0.091 ( 0.091)\tLoss 1.7980e+00 (2.5462e+00)\tAcc@1  63.28 ( 43.33)\tAcc@5  88.28 ( 71.16)\n","Epoch: [49][360/391]\tTime  0.090 ( 0.091)\tLoss 2.7146e+00 (2.5537e+00)\tAcc@1  44.53 ( 43.35)\tAcc@5  77.34 ( 71.38)\n","Epoch: [49][390/391]\tTime  0.080 ( 0.091)\tLoss 2.5007e+00 (2.5654e+00)\tAcc@1  47.50 ( 43.08)\tAcc@5  78.75 ( 71.03)\n","==> Train Accuracy: Acc@1 43.076 || Acc@5 71.034\n","==> Test Accuracy:  Acc@1 57.120 || Acc@5 85.140\n","==> 38.06 seconds to train this epoch\n","\n","\n","----- epoch: 50, lr: 0.1 -----\n","Epoch: [50][  0/391]\tTime  0.202 ( 0.202)\tLoss 2.3762e+00 (2.3762e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  86.72 ( 86.72)\n","Epoch: [50][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.6599e+00 (2.5379e+00)\tAcc@1  48.44 ( 42.19)\tAcc@5  75.78 ( 69.48)\n","Epoch: [50][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.8432e+00 (2.5801e+00)\tAcc@1  40.62 ( 41.38)\tAcc@5  76.56 ( 69.54)\n","Epoch: [50][ 90/391]\tTime  0.089 ( 0.092)\tLoss 2.4798e+00 (2.5754e+00)\tAcc@1  53.12 ( 41.43)\tAcc@5  82.81 ( 69.52)\n","Epoch: [50][120/391]\tTime  0.091 ( 0.092)\tLoss 2.6978e+00 (2.5883e+00)\tAcc@1  45.31 ( 41.92)\tAcc@5  75.78 ( 70.24)\n","Epoch: [50][150/391]\tTime  0.090 ( 0.091)\tLoss 1.9126e+00 (2.5701e+00)\tAcc@1  53.91 ( 42.31)\tAcc@5  84.38 ( 70.66)\n","Epoch: [50][180/391]\tTime  0.089 ( 0.091)\tLoss 2.2829e+00 (2.5569e+00)\tAcc@1  60.16 ( 43.40)\tAcc@5  81.25 ( 71.59)\n","Epoch: [50][210/391]\tTime  0.090 ( 0.091)\tLoss 2.9903e+00 (2.5551e+00)\tAcc@1  28.12 ( 42.89)\tAcc@5  61.72 ( 70.87)\n","Epoch: [50][240/391]\tTime  0.090 ( 0.091)\tLoss 2.1239e+00 (2.5678e+00)\tAcc@1  60.16 ( 42.17)\tAcc@5  82.81 ( 70.12)\n","Epoch: [50][270/391]\tTime  0.091 ( 0.091)\tLoss 2.1347e+00 (2.5576e+00)\tAcc@1  64.06 ( 42.73)\tAcc@5  89.06 ( 70.78)\n","Epoch: [50][300/391]\tTime  0.091 ( 0.091)\tLoss 2.0054e+00 (2.5523e+00)\tAcc@1  58.59 ( 43.15)\tAcc@5  81.25 ( 71.20)\n","Epoch: [50][330/391]\tTime  0.090 ( 0.091)\tLoss 2.9879e+00 (2.5708e+00)\tAcc@1  27.34 ( 42.45)\tAcc@5  60.16 ( 70.48)\n","Epoch: [50][360/391]\tTime  0.091 ( 0.091)\tLoss 2.4955e+00 (2.5804e+00)\tAcc@1  53.91 ( 42.17)\tAcc@5  82.03 ( 70.14)\n","Epoch: [50][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5586e+00 (2.5813e+00)\tAcc@1  66.25 ( 42.26)\tAcc@5  90.00 ( 70.24)\n","==> Train Accuracy: Acc@1 42.256 || Acc@5 70.242\n","==> Test Accuracy:  Acc@1 56.110 || Acc@5 84.150\n","==> 38.06 seconds to train this epoch\n","\n","\n","----- epoch: 51, lr: 0.1 -----\n","Epoch: [51][  0/391]\tTime  0.206 ( 0.206)\tLoss 2.5398e+00 (2.5398e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  86.72 ( 86.72)\n","Epoch: [51][ 30/391]\tTime  0.091 ( 0.094)\tLoss 3.0213e+00 (2.4850e+00)\tAcc@1  32.81 ( 44.00)\tAcc@5  62.50 ( 72.88)\n","Epoch: [51][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.9691e+00 (2.5216e+00)\tAcc@1  61.72 ( 42.33)\tAcc@5  87.50 ( 71.08)\n","Epoch: [51][ 90/391]\tTime  0.092 ( 0.092)\tLoss 2.6171e+00 (2.6077e+00)\tAcc@1  48.44 ( 40.11)\tAcc@5  78.91 ( 68.87)\n","Epoch: [51][120/391]\tTime  0.090 ( 0.092)\tLoss 2.5773e+00 (2.5627e+00)\tAcc@1  50.00 ( 41.52)\tAcc@5  85.16 ( 70.22)\n","Epoch: [51][150/391]\tTime  0.091 ( 0.091)\tLoss 3.0901e+00 (2.5603e+00)\tAcc@1  19.53 ( 41.69)\tAcc@5  49.22 ( 70.36)\n","Epoch: [51][180/391]\tTime  0.091 ( 0.091)\tLoss 2.8390e+00 (2.5291e+00)\tAcc@1  43.75 ( 42.70)\tAcc@5  78.12 ( 71.51)\n","Epoch: [51][210/391]\tTime  0.090 ( 0.091)\tLoss 3.2276e+00 (2.5294e+00)\tAcc@1  15.62 ( 43.05)\tAcc@5  42.19 ( 71.51)\n","Epoch: [51][240/391]\tTime  0.090 ( 0.091)\tLoss 2.7559e+00 (2.5176e+00)\tAcc@1  47.66 ( 43.73)\tAcc@5  74.22 ( 72.12)\n","Epoch: [51][270/391]\tTime  0.091 ( 0.091)\tLoss 2.8517e+00 (2.5418e+00)\tAcc@1   4.69 ( 42.82)\tAcc@5  25.78 ( 71.02)\n","Epoch: [51][300/391]\tTime  0.091 ( 0.091)\tLoss 3.2090e+00 (2.5546e+00)\tAcc@1  23.44 ( 42.61)\tAcc@5  58.59 ( 70.98)\n","Epoch: [51][330/391]\tTime  0.090 ( 0.091)\tLoss 2.2818e+00 (2.5598e+00)\tAcc@1  53.91 ( 42.45)\tAcc@5  84.38 ( 70.82)\n","Epoch: [51][360/391]\tTime  0.091 ( 0.091)\tLoss 2.5601e+00 (2.5662e+00)\tAcc@1  57.81 ( 42.24)\tAcc@5  78.12 ( 70.57)\n","Epoch: [51][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5556e+00 (2.5742e+00)\tAcc@1  60.00 ( 41.89)\tAcc@5  87.50 ( 70.14)\n","==> Train Accuracy: Acc@1 41.892 || Acc@5 70.144\n","==> Test Accuracy:  Acc@1 54.720 || Acc@5 82.330\n","==> 37.97 seconds to train this epoch\n","\n","\n","----- epoch: 52, lr: 0.1 -----\n","Epoch: [52][  0/391]\tTime  0.197 ( 0.197)\tLoss 2.0982e+00 (2.0982e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  87.50 ( 87.50)\n","Epoch: [52][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.6162e+00 (2.4677e+00)\tAcc@1  61.72 ( 46.82)\tAcc@5  85.16 ( 74.92)\n","Epoch: [52][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.8841e+00 (2.5190e+00)\tAcc@1   8.59 ( 44.28)\tAcc@5  32.81 ( 72.21)\n","Epoch: [52][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.8821e+00 (2.5306e+00)\tAcc@1  13.28 ( 41.94)\tAcc@5  39.84 ( 70.54)\n","Epoch: [52][120/391]\tTime  0.091 ( 0.092)\tLoss 2.5984e+00 (2.4866e+00)\tAcc@1  50.00 ( 43.79)\tAcc@5  75.78 ( 72.11)\n","Epoch: [52][150/391]\tTime  0.091 ( 0.091)\tLoss 2.8022e+00 (2.4973e+00)\tAcc@1  47.66 ( 44.09)\tAcc@5  77.34 ( 72.70)\n","Epoch: [52][180/391]\tTime  0.091 ( 0.091)\tLoss 2.8422e+00 (2.5319e+00)\tAcc@1  43.75 ( 42.26)\tAcc@5  69.53 ( 70.78)\n","Epoch: [52][210/391]\tTime  0.091 ( 0.091)\tLoss 2.9672e+00 (2.5510e+00)\tAcc@1  45.31 ( 42.18)\tAcc@5  66.41 ( 70.59)\n","Epoch: [52][240/391]\tTime  0.091 ( 0.091)\tLoss 2.2598e+00 (2.5690e+00)\tAcc@1  57.81 ( 42.04)\tAcc@5  87.50 ( 70.22)\n","Epoch: [52][270/391]\tTime  0.091 ( 0.091)\tLoss 3.1545e+00 (2.5915e+00)\tAcc@1  12.50 ( 40.99)\tAcc@5  33.59 ( 69.23)\n","Epoch: [52][300/391]\tTime  0.091 ( 0.091)\tLoss 3.0336e+00 (2.6030e+00)\tAcc@1   3.12 ( 40.39)\tAcc@5  28.91 ( 68.60)\n","Epoch: [52][330/391]\tTime  0.091 ( 0.091)\tLoss 3.0833e+00 (2.6082e+00)\tAcc@1  23.44 ( 40.14)\tAcc@5  48.44 ( 68.28)\n","Epoch: [52][360/391]\tTime  0.091 ( 0.091)\tLoss 1.7763e+00 (2.6114e+00)\tAcc@1  60.94 ( 40.30)\tAcc@5  89.06 ( 68.57)\n","Epoch: [52][390/391]\tTime  0.082 ( 0.091)\tLoss 2.9742e+00 (2.6034e+00)\tAcc@1  36.25 ( 40.52)\tAcc@5  57.50 ( 68.80)\n","==> Train Accuracy: Acc@1 40.524 || Acc@5 68.796\n","==> Test Accuracy:  Acc@1 58.290 || Acc@5 86.350\n","==> 38.06 seconds to train this epoch\n","\n","\n","----- epoch: 53, lr: 0.1 -----\n","Epoch: [53][  0/391]\tTime  0.205 ( 0.205)\tLoss 3.0679e+00 (3.0679e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  58.59 ( 58.59)\n","Epoch: [53][ 30/391]\tTime  0.091 ( 0.094)\tLoss 2.8618e+00 (2.5182e+00)\tAcc@1  43.75 ( 42.67)\tAcc@5  76.56 ( 69.63)\n","Epoch: [53][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.6923e+00 (2.5544e+00)\tAcc@1  46.88 ( 41.70)\tAcc@5  76.56 ( 69.67)\n","Epoch: [53][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.3715e+00 (2.5631e+00)\tAcc@1   0.78 ( 42.18)\tAcc@5  13.28 ( 69.92)\n","Epoch: [53][120/391]\tTime  0.090 ( 0.092)\tLoss 2.6664e+00 (2.5339e+00)\tAcc@1  50.78 ( 42.26)\tAcc@5  79.69 ( 69.73)\n","Epoch: [53][150/391]\tTime  0.090 ( 0.091)\tLoss 2.6456e+00 (2.5450e+00)\tAcc@1  49.22 ( 41.84)\tAcc@5  83.59 ( 69.22)\n","Epoch: [53][180/391]\tTime  0.091 ( 0.091)\tLoss 3.0069e+00 (2.5358e+00)\tAcc@1  32.03 ( 42.41)\tAcc@5  60.94 ( 69.90)\n","Epoch: [53][210/391]\tTime  0.087 ( 0.091)\tLoss 2.7720e+00 (2.5248e+00)\tAcc@1  47.66 ( 42.89)\tAcc@5  75.00 ( 70.53)\n","Epoch: [53][240/391]\tTime  0.090 ( 0.091)\tLoss 3.2193e+00 (2.5469e+00)\tAcc@1  26.56 ( 41.75)\tAcc@5  55.47 ( 69.54)\n","Epoch: [53][270/391]\tTime  0.091 ( 0.091)\tLoss 2.4106e+00 (2.5267e+00)\tAcc@1  53.91 ( 42.27)\tAcc@5  82.81 ( 70.06)\n","Epoch: [53][300/391]\tTime  0.091 ( 0.091)\tLoss 2.6169e+00 (2.5409e+00)\tAcc@1  46.88 ( 41.95)\tAcc@5  76.56 ( 69.72)\n","Epoch: [53][330/391]\tTime  0.092 ( 0.091)\tLoss 2.3595e+00 (2.5377e+00)\tAcc@1  57.81 ( 42.18)\tAcc@5  82.81 ( 70.03)\n","Epoch: [53][360/391]\tTime  0.090 ( 0.091)\tLoss 2.9744e+00 (2.5398e+00)\tAcc@1  39.84 ( 42.42)\tAcc@5  66.41 ( 70.37)\n","Epoch: [53][390/391]\tTime  0.082 ( 0.091)\tLoss 2.3662e+00 (2.5467e+00)\tAcc@1  63.75 ( 42.19)\tAcc@5  85.00 ( 70.09)\n","==> Train Accuracy: Acc@1 42.192 || Acc@5 70.092\n","==> Test Accuracy:  Acc@1 55.590 || Acc@5 82.930\n","==> 38.02 seconds to train this epoch\n","\n","\n","----- epoch: 54, lr: 0.1 -----\n","Epoch: [54][  0/391]\tTime  0.199 ( 0.199)\tLoss 1.7413e+00 (1.7413e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  92.97 ( 92.97)\n","Epoch: [54][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.8382e+00 (2.3739e+00)\tAcc@1  67.19 ( 48.41)\tAcc@5  92.19 ( 75.38)\n","Epoch: [54][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.4795e+00 (2.4844e+00)\tAcc@1  60.16 ( 45.36)\tAcc@5  87.50 ( 73.17)\n","Epoch: [54][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.3736e+00 (2.5050e+00)\tAcc@1  61.72 ( 44.79)\tAcc@5  86.72 ( 72.56)\n","Epoch: [54][120/391]\tTime  0.090 ( 0.092)\tLoss 2.8720e+00 (2.5239e+00)\tAcc@1   7.81 ( 44.38)\tAcc@5  36.72 ( 72.49)\n","Epoch: [54][150/391]\tTime  0.090 ( 0.091)\tLoss 2.4848e+00 (2.5408e+00)\tAcc@1  55.47 ( 43.57)\tAcc@5  85.16 ( 71.88)\n","Epoch: [54][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6186e+00 (2.5168e+00)\tAcc@1  64.06 ( 44.07)\tAcc@5  89.06 ( 72.11)\n","Epoch: [54][210/391]\tTime  0.090 ( 0.091)\tLoss 2.0930e+00 (2.5232e+00)\tAcc@1  61.72 ( 43.84)\tAcc@5  90.62 ( 72.19)\n","Epoch: [54][240/391]\tTime  0.090 ( 0.091)\tLoss 3.0588e+00 (2.5283e+00)\tAcc@1  35.94 ( 43.46)\tAcc@5  66.41 ( 71.88)\n","Epoch: [54][270/391]\tTime  0.090 ( 0.091)\tLoss 2.4244e+00 (2.5287e+00)\tAcc@1  58.59 ( 43.42)\tAcc@5  85.16 ( 71.80)\n","Epoch: [54][300/391]\tTime  0.090 ( 0.091)\tLoss 3.1023e+00 (2.5325e+00)\tAcc@1  21.88 ( 43.39)\tAcc@5  52.34 ( 71.73)\n","Epoch: [54][330/391]\tTime  0.090 ( 0.091)\tLoss 3.0440e+00 (2.5365e+00)\tAcc@1   2.34 ( 43.40)\tAcc@5  21.88 ( 71.71)\n","Epoch: [54][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8641e+00 (2.5464e+00)\tAcc@1  59.38 ( 43.15)\tAcc@5  85.16 ( 71.53)\n","Epoch: [54][390/391]\tTime  0.081 ( 0.091)\tLoss 3.4529e+00 (2.5499e+00)\tAcc@1  15.00 ( 42.85)\tAcc@5  41.25 ( 71.17)\n","==> Train Accuracy: Acc@1 42.852 || Acc@5 71.166\n","==> Test Accuracy:  Acc@1 48.010 || Acc@5 78.330\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 55, lr: 0.1 -----\n","Epoch: [55][  0/391]\tTime  0.197 ( 0.197)\tLoss 2.5460e+00 (2.5460e+00)\tAcc@1  45.31 ( 45.31)\tAcc@5  86.72 ( 86.72)\n","Epoch: [55][ 30/391]\tTime  0.093 ( 0.094)\tLoss 2.6943e+00 (2.5537e+00)\tAcc@1  50.78 ( 44.20)\tAcc@5  83.59 ( 73.56)\n","Epoch: [55][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.6337e+00 (2.5111e+00)\tAcc@1  48.44 ( 44.30)\tAcc@5  79.69 ( 72.58)\n","Epoch: [55][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.7964e+00 (2.5260e+00)\tAcc@1  46.09 ( 44.21)\tAcc@5  74.22 ( 72.93)\n","Epoch: [55][120/391]\tTime  0.090 ( 0.091)\tLoss 2.7422e+00 (2.5430e+00)\tAcc@1  51.56 ( 44.41)\tAcc@5  77.34 ( 73.13)\n","Epoch: [55][150/391]\tTime  0.091 ( 0.091)\tLoss 2.9539e+00 (2.5543e+00)\tAcc@1  31.25 ( 43.18)\tAcc@5  64.06 ( 71.78)\n","Epoch: [55][180/391]\tTime  0.090 ( 0.091)\tLoss 1.5303e+00 (2.5716e+00)\tAcc@1  66.41 ( 42.36)\tAcc@5  86.72 ( 70.71)\n","Epoch: [55][210/391]\tTime  0.090 ( 0.091)\tLoss 2.9689e+00 (2.5766e+00)\tAcc@1  35.16 ( 42.09)\tAcc@5  64.84 ( 70.31)\n","Epoch: [55][240/391]\tTime  0.090 ( 0.091)\tLoss 2.4847e+00 (2.5863e+00)\tAcc@1  51.56 ( 41.70)\tAcc@5  83.59 ( 69.89)\n","Epoch: [55][270/391]\tTime  0.090 ( 0.091)\tLoss 2.9745e+00 (2.5947e+00)\tAcc@1  23.44 ( 41.51)\tAcc@5  55.47 ( 69.68)\n","Epoch: [55][300/391]\tTime  0.090 ( 0.091)\tLoss 2.9326e+00 (2.5813e+00)\tAcc@1  33.59 ( 41.90)\tAcc@5  60.16 ( 69.85)\n","Epoch: [55][330/391]\tTime  0.091 ( 0.091)\tLoss 2.0671e+00 (2.5801e+00)\tAcc@1  56.25 ( 41.83)\tAcc@5  85.16 ( 69.71)\n","Epoch: [55][360/391]\tTime  0.090 ( 0.091)\tLoss 2.8026e+00 (2.5725e+00)\tAcc@1  43.75 ( 42.39)\tAcc@5  72.66 ( 70.29)\n","Epoch: [55][390/391]\tTime  0.082 ( 0.091)\tLoss 2.6916e+00 (2.5801e+00)\tAcc@1  46.25 ( 41.95)\tAcc@5  77.50 ( 69.88)\n","==> Train Accuracy: Acc@1 41.952 || Acc@5 69.884\n","==> Test Accuracy:  Acc@1 59.250 || Acc@5 86.150\n","==> 37.92 seconds to train this epoch\n","\n","\n","----- epoch: 56, lr: 0.1 -----\n","Epoch: [56][  0/391]\tTime  0.218 ( 0.218)\tLoss 1.9832e+00 (1.9832e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  92.19 ( 92.19)\n","Epoch: [56][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.6157e+00 (2.3533e+00)\tAcc@1   4.69 ( 49.55)\tAcc@5  24.22 ( 78.12)\n","Epoch: [56][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.4942e+00 (2.4258e+00)\tAcc@1  51.56 ( 48.31)\tAcc@5  78.12 ( 76.43)\n","Epoch: [56][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.7866e+00 (2.4495e+00)\tAcc@1  47.66 ( 46.41)\tAcc@5  72.66 ( 74.24)\n","Epoch: [56][120/391]\tTime  0.093 ( 0.091)\tLoss 2.0562e+00 (2.4668e+00)\tAcc@1  62.50 ( 46.29)\tAcc@5  88.28 ( 74.06)\n","Epoch: [56][150/391]\tTime  0.090 ( 0.091)\tLoss 3.1387e+00 (2.4550e+00)\tAcc@1  27.34 ( 46.68)\tAcc@5  57.03 ( 74.51)\n","Epoch: [56][180/391]\tTime  0.090 ( 0.091)\tLoss 2.8150e+00 (2.4967e+00)\tAcc@1  11.72 ( 45.46)\tAcc@5  39.84 ( 73.32)\n","Epoch: [56][210/391]\tTime  0.090 ( 0.091)\tLoss 2.6415e+00 (2.4996e+00)\tAcc@1  54.69 ( 44.72)\tAcc@5  78.91 ( 72.49)\n","Epoch: [56][240/391]\tTime  0.090 ( 0.091)\tLoss 3.3562e+00 (2.5112e+00)\tAcc@1   6.25 ( 44.40)\tAcc@5  25.78 ( 72.37)\n","Epoch: [56][270/391]\tTime  0.090 ( 0.091)\tLoss 2.9659e+00 (2.5299e+00)\tAcc@1  34.38 ( 43.91)\tAcc@5  64.84 ( 71.99)\n","Epoch: [56][300/391]\tTime  0.090 ( 0.091)\tLoss 2.8788e+00 (2.5309e+00)\tAcc@1  39.84 ( 43.90)\tAcc@5  67.97 ( 72.05)\n","Epoch: [56][330/391]\tTime  0.090 ( 0.091)\tLoss 2.6616e+00 (2.5457e+00)\tAcc@1  51.56 ( 43.14)\tAcc@5  77.34 ( 71.41)\n","Epoch: [56][360/391]\tTime  0.091 ( 0.091)\tLoss 2.3815e+00 (2.5350e+00)\tAcc@1  57.81 ( 43.49)\tAcc@5  85.16 ( 71.78)\n","Epoch: [56][390/391]\tTime  0.080 ( 0.091)\tLoss 3.1725e+00 (2.5468e+00)\tAcc@1  27.50 ( 43.18)\tAcc@5  57.50 ( 71.31)\n","==> Train Accuracy: Acc@1 43.180 || Acc@5 71.306\n","==> Test Accuracy:  Acc@1 57.620 || Acc@5 84.860\n","==> 37.90 seconds to train this epoch\n","\n","\n","----- epoch: 57, lr: 0.1 -----\n","Epoch: [57][  0/391]\tTime  0.202 ( 0.202)\tLoss 1.2621e+00 (1.2621e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  91.41 ( 91.41)\n","Epoch: [57][ 30/391]\tTime  0.090 ( 0.093)\tLoss 1.4248e+00 (2.5537e+00)\tAcc@1  61.72 ( 41.73)\tAcc@5  89.06 ( 69.61)\n","Epoch: [57][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.3643e+00 (2.6156e+00)\tAcc@1  58.59 ( 40.89)\tAcc@5  78.91 ( 69.66)\n","Epoch: [57][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.7188e+00 (2.6214e+00)\tAcc@1  46.09 ( 40.10)\tAcc@5  75.78 ( 68.60)\n","Epoch: [57][120/391]\tTime  0.090 ( 0.091)\tLoss 2.2041e+00 (2.6220e+00)\tAcc@1  65.62 ( 40.95)\tAcc@5  85.94 ( 69.49)\n","Epoch: [57][150/391]\tTime  0.090 ( 0.091)\tLoss 2.7691e+00 (2.6152e+00)\tAcc@1   2.34 ( 41.04)\tAcc@5   9.38 ( 69.55)\n","Epoch: [57][180/391]\tTime  0.090 ( 0.091)\tLoss 2.9686e+00 (2.6234e+00)\tAcc@1  32.03 ( 41.57)\tAcc@5  62.50 ( 70.25)\n","Epoch: [57][210/391]\tTime  0.090 ( 0.091)\tLoss 2.6546e+00 (2.6255e+00)\tAcc@1  53.91 ( 41.62)\tAcc@5  82.03 ( 70.29)\n","Epoch: [57][240/391]\tTime  0.091 ( 0.091)\tLoss 2.8681e+00 (2.6311e+00)\tAcc@1  33.59 ( 41.35)\tAcc@5  64.06 ( 69.93)\n","Epoch: [57][270/391]\tTime  0.092 ( 0.091)\tLoss 2.0876e+00 (2.6252e+00)\tAcc@1  54.69 ( 41.47)\tAcc@5  87.50 ( 70.08)\n","Epoch: [57][300/391]\tTime  0.092 ( 0.091)\tLoss 2.9663e+00 (2.6139e+00)\tAcc@1  31.25 ( 41.36)\tAcc@5  63.28 ( 69.92)\n","Epoch: [57][330/391]\tTime  0.090 ( 0.091)\tLoss 2.8566e+00 (2.6190e+00)\tAcc@1  23.44 ( 40.86)\tAcc@5  55.47 ( 69.36)\n","Epoch: [57][360/391]\tTime  0.090 ( 0.091)\tLoss 2.9649e+00 (2.6079e+00)\tAcc@1   5.47 ( 41.19)\tAcc@5  26.56 ( 69.74)\n","Epoch: [57][390/391]\tTime  0.081 ( 0.091)\tLoss 2.9202e+00 (2.6056e+00)\tAcc@1  35.00 ( 41.48)\tAcc@5  76.25 ( 70.05)\n","==> Train Accuracy: Acc@1 41.482 || Acc@5 70.048\n","==> Test Accuracy:  Acc@1 58.660 || Acc@5 86.890\n","==> 37.83 seconds to train this epoch\n","\n","\n","----- epoch: 58, lr: 0.1 -----\n","Epoch: [58][  0/391]\tTime  0.184 ( 0.184)\tLoss 1.4498e+00 (1.4498e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  90.62 ( 90.62)\n","Epoch: [58][ 30/391]\tTime  0.090 ( 0.093)\tLoss 3.0686e+00 (2.3880e+00)\tAcc@1   4.69 ( 45.89)\tAcc@5  18.75 ( 70.99)\n","Epoch: [58][ 60/391]\tTime  0.090 ( 0.092)\tLoss 3.0676e+00 (2.5297e+00)\tAcc@1  21.88 ( 42.25)\tAcc@5  54.69 ( 69.34)\n","Epoch: [58][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.7140e+00 (2.5335e+00)\tAcc@1  50.00 ( 42.62)\tAcc@5  76.56 ( 70.03)\n","Epoch: [58][120/391]\tTime  0.090 ( 0.091)\tLoss 2.7431e+00 (2.5179e+00)\tAcc@1   3.91 ( 43.53)\tAcc@5  15.62 ( 70.98)\n","Epoch: [58][150/391]\tTime  0.084 ( 0.091)\tLoss 1.7128e+00 (2.5279e+00)\tAcc@1  70.31 ( 44.13)\tAcc@5  90.62 ( 71.76)\n","Epoch: [58][180/391]\tTime  0.091 ( 0.091)\tLoss 2.8534e+00 (2.5230e+00)\tAcc@1  39.06 ( 43.69)\tAcc@5  67.97 ( 71.06)\n","Epoch: [58][210/391]\tTime  0.090 ( 0.091)\tLoss 2.3602e+00 (2.5285e+00)\tAcc@1  54.69 ( 43.86)\tAcc@5  82.03 ( 71.17)\n","Epoch: [58][240/391]\tTime  0.090 ( 0.091)\tLoss 2.9791e+00 (2.5293e+00)\tAcc@1  26.56 ( 43.80)\tAcc@5  57.03 ( 71.02)\n","Epoch: [58][270/391]\tTime  0.090 ( 0.091)\tLoss 2.1828e+00 (2.5307e+00)\tAcc@1  54.69 ( 43.70)\tAcc@5  87.50 ( 70.92)\n","Epoch: [58][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4980e+00 (2.5257e+00)\tAcc@1  64.06 ( 43.74)\tAcc@5  91.41 ( 71.10)\n","Epoch: [58][330/391]\tTime  0.087 ( 0.091)\tLoss 1.6484e+00 (2.5256e+00)\tAcc@1  67.19 ( 43.55)\tAcc@5  88.28 ( 71.01)\n","Epoch: [58][360/391]\tTime  0.092 ( 0.091)\tLoss 3.2441e+00 (2.5425e+00)\tAcc@1   8.59 ( 43.12)\tAcc@5  32.81 ( 70.62)\n","Epoch: [58][390/391]\tTime  0.082 ( 0.091)\tLoss 2.9738e+00 (2.5500e+00)\tAcc@1  36.25 ( 42.84)\tAcc@5  66.25 ( 70.52)\n","==> Train Accuracy: Acc@1 42.844 || Acc@5 70.516\n","==> Test Accuracy:  Acc@1 58.900 || Acc@5 86.300\n","==> 37.82 seconds to train this epoch\n","\n","\n","----- epoch: 59, lr: 0.1 -----\n","Epoch: [59][  0/391]\tTime  0.209 ( 0.209)\tLoss 2.9813e+00 (2.9813e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  67.97 ( 67.97)\n","Epoch: [59][ 30/391]\tTime  0.090 ( 0.093)\tLoss 2.0527e+00 (2.5235e+00)\tAcc@1  67.19 ( 44.43)\tAcc@5  91.41 ( 72.20)\n","Epoch: [59][ 60/391]\tTime  0.089 ( 0.092)\tLoss 2.6325e+00 (2.5152e+00)\tAcc@1  53.91 ( 44.52)\tAcc@5  80.47 ( 72.91)\n","Epoch: [59][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.5574e+00 (2.5064e+00)\tAcc@1  51.56 ( 45.77)\tAcc@5  82.81 ( 74.06)\n","Epoch: [59][120/391]\tTime  0.090 ( 0.091)\tLoss 1.8072e+00 (2.5518e+00)\tAcc@1  64.06 ( 44.17)\tAcc@5  89.84 ( 72.77)\n","Epoch: [59][150/391]\tTime  0.090 ( 0.091)\tLoss 2.4008e+00 (2.5537e+00)\tAcc@1  56.25 ( 43.29)\tAcc@5  89.06 ( 71.86)\n","Epoch: [59][180/391]\tTime  0.093 ( 0.091)\tLoss 1.7139e+00 (2.5609e+00)\tAcc@1  70.31 ( 43.28)\tAcc@5  91.41 ( 71.81)\n","Epoch: [59][210/391]\tTime  0.090 ( 0.091)\tLoss 2.9578e+00 (2.5644e+00)\tAcc@1  31.25 ( 42.65)\tAcc@5  60.16 ( 71.41)\n","Epoch: [59][240/391]\tTime  0.091 ( 0.091)\tLoss 2.8557e+00 (2.5316e+00)\tAcc@1  39.84 ( 43.62)\tAcc@5  70.31 ( 72.29)\n","Epoch: [59][270/391]\tTime  0.091 ( 0.091)\tLoss 3.1080e+00 (2.5396e+00)\tAcc@1  20.31 ( 43.46)\tAcc@5  45.31 ( 72.06)\n","Epoch: [59][300/391]\tTime  0.091 ( 0.091)\tLoss 2.4990e+00 (2.5496e+00)\tAcc@1  63.28 ( 43.23)\tAcc@5  85.16 ( 71.88)\n","Epoch: [59][330/391]\tTime  0.090 ( 0.091)\tLoss 2.3850e+00 (2.5584e+00)\tAcc@1  59.38 ( 43.13)\tAcc@5  87.50 ( 71.76)\n","Epoch: [59][360/391]\tTime  0.090 ( 0.091)\tLoss 2.5730e+00 (2.5536e+00)\tAcc@1  53.12 ( 43.10)\tAcc@5  82.03 ( 71.73)\n","Epoch: [59][390/391]\tTime  0.081 ( 0.091)\tLoss 2.9810e+00 (2.5733e+00)\tAcc@1  23.75 ( 42.37)\tAcc@5  56.25 ( 71.03)\n","==> Train Accuracy: Acc@1 42.366 || Acc@5 71.030\n","==> Test Accuracy:  Acc@1 53.930 || Acc@5 83.330\n","==> 37.86 seconds to train this epoch\n","\n","\n","----- epoch: 60, lr: 0.020000000000000004 -----\n","Epoch: [60][  0/391]\tTime  0.188 ( 0.188)\tLoss 2.4089e+00 (2.4089e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  84.38 ( 84.38)\n","Epoch: [60][ 30/391]\tTime  0.090 ( 0.093)\tLoss 2.2238e+00 (2.4360e+00)\tAcc@1  65.62 ( 42.79)\tAcc@5  88.28 ( 68.32)\n","Epoch: [60][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.5856e+00 (2.4046e+00)\tAcc@1   9.38 ( 44.06)\tAcc@5  37.50 ( 69.97)\n","Epoch: [60][ 90/391]\tTime  0.090 ( 0.091)\tLoss 9.5591e-01 (2.3465e+00)\tAcc@1  78.12 ( 47.36)\tAcc@5  96.88 ( 73.33)\n","Epoch: [60][120/391]\tTime  0.090 ( 0.091)\tLoss 2.6082e+00 (2.3171e+00)\tAcc@1  37.50 ( 47.91)\tAcc@5  75.00 ( 74.28)\n","Epoch: [60][150/391]\tTime  0.090 ( 0.091)\tLoss 1.0065e+00 (2.2931e+00)\tAcc@1  75.00 ( 48.88)\tAcc@5  92.19 ( 75.31)\n","Epoch: [60][180/391]\tTime  0.091 ( 0.091)\tLoss 1.7208e+00 (2.2736e+00)\tAcc@1  72.66 ( 49.34)\tAcc@5  93.75 ( 75.86)\n","Epoch: [60][210/391]\tTime  0.094 ( 0.091)\tLoss 2.1629e+00 (2.2429e+00)\tAcc@1  57.81 ( 50.51)\tAcc@5  85.16 ( 76.78)\n","Epoch: [60][240/391]\tTime  0.090 ( 0.091)\tLoss 2.1360e+00 (2.2201e+00)\tAcc@1  71.09 ( 51.04)\tAcc@5  89.06 ( 77.23)\n","Epoch: [60][270/391]\tTime  0.090 ( 0.091)\tLoss 2.3321e+00 (2.2209e+00)\tAcc@1   4.69 ( 50.69)\tAcc@5  19.53 ( 76.92)\n","Epoch: [60][300/391]\tTime  0.092 ( 0.091)\tLoss 2.3029e+00 (2.2192e+00)\tAcc@1  53.12 ( 50.33)\tAcc@5  83.59 ( 76.79)\n","Epoch: [60][330/391]\tTime  0.090 ( 0.091)\tLoss 2.3117e+00 (2.2285e+00)\tAcc@1  63.28 ( 50.21)\tAcc@5  85.16 ( 76.92)\n","Epoch: [60][360/391]\tTime  0.090 ( 0.091)\tLoss 2.0655e+00 (2.2036e+00)\tAcc@1  57.81 ( 50.98)\tAcc@5  88.28 ( 77.54)\n","Epoch: [60][390/391]\tTime  0.082 ( 0.091)\tLoss 2.3740e+00 (2.2033e+00)\tAcc@1  57.50 ( 51.00)\tAcc@5  81.25 ( 77.44)\n","==> Train Accuracy: Acc@1 50.998 || Acc@5 77.436\n","==> Test Accuracy:  Acc@1 71.840 || Acc@5 93.340\n","==> 37.83 seconds to train this epoch\n","\n","\n","----- epoch: 61, lr: 0.020000000000000004 -----\n","Epoch: [61][  0/391]\tTime  0.212 ( 0.212)\tLoss 2.7391e+00 (2.7391e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5  75.00 ( 75.00)\n","Epoch: [61][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.6308e+00 (2.2370e+00)\tAcc@1  20.31 ( 51.08)\tAcc@5  51.56 ( 79.01)\n","Epoch: [61][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.6485e+00 (2.1705e+00)\tAcc@1  19.53 ( 51.09)\tAcc@5  62.50 ( 77.50)\n","Epoch: [61][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.6109e+00 (2.1540e+00)\tAcc@1  71.09 ( 52.49)\tAcc@5  91.41 ( 78.82)\n","Epoch: [61][120/391]\tTime  0.088 ( 0.091)\tLoss 2.5637e+00 (2.0999e+00)\tAcc@1  43.75 ( 53.33)\tAcc@5  74.22 ( 78.58)\n","Epoch: [61][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3616e+00 (2.1128e+00)\tAcc@1  72.66 ( 52.73)\tAcc@5  94.53 ( 78.49)\n","Epoch: [61][180/391]\tTime  0.090 ( 0.091)\tLoss 2.6851e+00 (2.1006e+00)\tAcc@1  30.47 ( 53.20)\tAcc@5  67.19 ( 79.20)\n","Epoch: [61][210/391]\tTime  0.090 ( 0.091)\tLoss 2.3108e+00 (2.1031e+00)\tAcc@1  61.72 ( 53.07)\tAcc@5  86.72 ( 79.31)\n","Epoch: [61][240/391]\tTime  0.090 ( 0.091)\tLoss 1.2076e+00 (2.1113e+00)\tAcc@1  75.78 ( 52.66)\tAcc@5  96.09 ( 78.84)\n","Epoch: [61][270/391]\tTime  0.090 ( 0.091)\tLoss 2.7033e+00 (2.0991e+00)\tAcc@1  29.69 ( 53.02)\tAcc@5  60.16 ( 79.13)\n","Epoch: [61][300/391]\tTime  0.094 ( 0.091)\tLoss 2.6406e+00 (2.1056e+00)\tAcc@1  14.84 ( 52.48)\tAcc@5  46.09 ( 78.61)\n","Epoch: [61][330/391]\tTime  0.090 ( 0.091)\tLoss 2.0935e+00 (2.1016e+00)\tAcc@1  66.41 ( 52.72)\tAcc@5  85.94 ( 78.85)\n","Epoch: [61][360/391]\tTime  0.091 ( 0.091)\tLoss 2.5334e+00 (2.1109e+00)\tAcc@1   4.69 ( 52.21)\tAcc@5  31.25 ( 78.50)\n","Epoch: [61][390/391]\tTime  0.082 ( 0.091)\tLoss 2.6082e+00 (2.1141e+00)\tAcc@1  26.25 ( 52.06)\tAcc@5  63.75 ( 78.36)\n","==> Train Accuracy: Acc@1 52.062 || Acc@5 78.364\n","==> Test Accuracy:  Acc@1 72.260 || Acc@5 93.520\n","==> 37.97 seconds to train this epoch\n","\n","\n","----- epoch: 62, lr: 0.020000000000000004 -----\n","Epoch: [62][  0/391]\tTime  0.221 ( 0.221)\tLoss 2.5981e+00 (2.5981e+00)\tAcc@1  25.78 ( 25.78)\tAcc@5  57.81 ( 57.81)\n","Epoch: [62][ 30/391]\tTime  0.096 ( 0.095)\tLoss 1.9477e+00 (2.0436e+00)\tAcc@1  71.09 ( 58.49)\tAcc@5  92.97 ( 83.54)\n","Epoch: [62][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.4780e+00 (2.0702e+00)\tAcc@1  16.41 ( 53.19)\tAcc@5  57.03 ( 78.97)\n","Epoch: [62][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.2532e+00 (2.0676e+00)\tAcc@1  56.25 ( 51.98)\tAcc@5  82.81 ( 77.68)\n","Epoch: [62][120/391]\tTime  0.090 ( 0.092)\tLoss 1.8812e+00 (2.1003e+00)\tAcc@1  71.88 ( 51.52)\tAcc@5  90.62 ( 77.80)\n","Epoch: [62][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3881e+00 (2.0961e+00)\tAcc@1  79.69 ( 52.25)\tAcc@5  95.31 ( 78.76)\n","Epoch: [62][180/391]\tTime  0.090 ( 0.091)\tLoss 2.5856e+00 (2.0997e+00)\tAcc@1  46.09 ( 51.93)\tAcc@5  76.56 ( 78.57)\n","Epoch: [62][210/391]\tTime  0.091 ( 0.091)\tLoss 2.5627e+00 (2.0950e+00)\tAcc@1  25.00 ( 51.92)\tAcc@5  63.28 ( 78.70)\n","Epoch: [62][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5446e+00 (2.0735e+00)\tAcc@1  67.97 ( 53.00)\tAcc@5  93.75 ( 79.43)\n","Epoch: [62][270/391]\tTime  0.090 ( 0.091)\tLoss 2.2592e+00 (2.0446e+00)\tAcc@1  60.16 ( 53.77)\tAcc@5  86.72 ( 79.95)\n","Epoch: [62][300/391]\tTime  0.090 ( 0.091)\tLoss 2.5925e+00 (2.0551e+00)\tAcc@1  13.28 ( 53.28)\tAcc@5  56.25 ( 79.49)\n","Epoch: [62][330/391]\tTime  0.090 ( 0.091)\tLoss 1.8068e+00 (2.0551e+00)\tAcc@1  69.53 ( 53.41)\tAcc@5  92.19 ( 79.60)\n","Epoch: [62][360/391]\tTime  0.090 ( 0.091)\tLoss 2.4604e+00 (2.0579e+00)\tAcc@1  48.44 ( 53.53)\tAcc@5  77.34 ( 79.64)\n","Epoch: [62][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5394e+00 (2.0631e+00)\tAcc@1  26.25 ( 53.35)\tAcc@5  57.50 ( 79.63)\n","==> Train Accuracy: Acc@1 53.350 || Acc@5 79.634\n","==> Test Accuracy:  Acc@1 72.910 || Acc@5 93.450\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 63, lr: 0.020000000000000004 -----\n","Epoch: [63][  0/391]\tTime  0.191 ( 0.191)\tLoss 2.4062e+00 (2.4062e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  77.34 ( 77.34)\n","Epoch: [63][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.2830e+00 (1.9367e+00)\tAcc@1  53.91 ( 57.28)\tAcc@5  83.59 ( 82.76)\n","Epoch: [63][ 60/391]\tTime  0.090 ( 0.092)\tLoss 7.4326e-01 (1.9638e+00)\tAcc@1  82.03 ( 54.97)\tAcc@5  97.66 ( 81.33)\n","Epoch: [63][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.0161e+00 (1.9387e+00)\tAcc@1  67.97 ( 55.30)\tAcc@5  89.06 ( 81.49)\n","Epoch: [63][120/391]\tTime  0.090 ( 0.091)\tLoss 1.2673e+00 (1.9514e+00)\tAcc@1  73.44 ( 56.60)\tAcc@5  96.88 ( 82.89)\n","Epoch: [63][150/391]\tTime  0.090 ( 0.091)\tLoss 2.3652e+00 (1.9659e+00)\tAcc@1  22.66 ( 55.01)\tAcc@5  65.62 ( 81.29)\n","Epoch: [63][180/391]\tTime  0.090 ( 0.091)\tLoss 2.1695e+00 (1.9640e+00)\tAcc@1  17.97 ( 54.55)\tAcc@5  67.19 ( 81.03)\n","Epoch: [63][210/391]\tTime  0.092 ( 0.091)\tLoss 2.6459e+00 (1.9933e+00)\tAcc@1  17.19 ( 53.90)\tAcc@5  52.34 ( 80.72)\n","Epoch: [63][240/391]\tTime  0.091 ( 0.091)\tLoss 2.7013e+00 (2.0135e+00)\tAcc@1  17.19 ( 53.43)\tAcc@5  47.66 ( 80.40)\n","Epoch: [63][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0593e+00 (1.9964e+00)\tAcc@1  60.16 ( 54.35)\tAcc@5  92.19 ( 81.01)\n","Epoch: [63][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7166e+00 (2.0146e+00)\tAcc@1  71.88 ( 53.89)\tAcc@5  94.53 ( 80.74)\n","Epoch: [63][330/391]\tTime  0.090 ( 0.091)\tLoss 2.5647e+00 (2.0229e+00)\tAcc@1  35.94 ( 53.30)\tAcc@5  67.19 ( 80.23)\n","Epoch: [63][360/391]\tTime  0.090 ( 0.091)\tLoss 1.0146e+00 (2.0185e+00)\tAcc@1  78.91 ( 53.67)\tAcc@5  96.09 ( 80.29)\n","Epoch: [63][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5231e+00 (2.0268e+00)\tAcc@1  47.50 ( 53.23)\tAcc@5  78.75 ( 79.97)\n","==> Train Accuracy: Acc@1 53.226 || Acc@5 79.966\n","==> Test Accuracy:  Acc@1 72.210 || Acc@5 93.440\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 64, lr: 0.020000000000000004 -----\n","Epoch: [64][  0/391]\tTime  0.210 ( 0.210)\tLoss 1.5207e+00 (1.5207e+00)\tAcc@1  80.47 ( 80.47)\tAcc@5  95.31 ( 95.31)\n","Epoch: [64][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.2988e+00 (1.9212e+00)\tAcc@1  40.62 ( 57.74)\tAcc@5  75.78 ( 81.88)\n","Epoch: [64][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.0977e+00 (2.0307e+00)\tAcc@1  64.84 ( 53.79)\tAcc@5  90.62 ( 80.29)\n","Epoch: [64][ 90/391]\tTime  0.090 ( 0.091)\tLoss 7.6806e-01 (2.0040e+00)\tAcc@1  82.03 ( 55.09)\tAcc@5  96.09 ( 81.55)\n","Epoch: [64][120/391]\tTime  0.090 ( 0.091)\tLoss 2.2232e+00 (2.0094e+00)\tAcc@1  53.91 ( 54.75)\tAcc@5  82.03 ( 81.40)\n","Epoch: [64][150/391]\tTime  0.091 ( 0.091)\tLoss 1.5480e+00 (2.0328e+00)\tAcc@1  79.69 ( 53.86)\tAcc@5  94.53 ( 80.68)\n","Epoch: [64][180/391]\tTime  0.090 ( 0.091)\tLoss 2.2007e+00 (2.0168e+00)\tAcc@1  58.59 ( 54.76)\tAcc@5  86.72 ( 81.12)\n","Epoch: [64][210/391]\tTime  0.090 ( 0.091)\tLoss 1.4683e+00 (2.0179e+00)\tAcc@1  79.69 ( 54.42)\tAcc@5  93.75 ( 80.75)\n","Epoch: [64][240/391]\tTime  0.090 ( 0.091)\tLoss 2.5115e+00 (2.0209e+00)\tAcc@1  44.53 ( 53.92)\tAcc@5  80.47 ( 80.12)\n","Epoch: [64][270/391]\tTime  0.090 ( 0.091)\tLoss 2.4688e+00 (2.0261e+00)\tAcc@1  25.78 ( 53.93)\tAcc@5  64.06 ( 80.12)\n","Epoch: [64][300/391]\tTime  0.090 ( 0.091)\tLoss 9.4473e-01 (2.0233e+00)\tAcc@1  79.69 ( 54.57)\tAcc@5  91.41 ( 80.61)\n","Epoch: [64][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9195e+00 (2.0183e+00)\tAcc@1  61.72 ( 54.92)\tAcc@5  92.19 ( 80.90)\n","Epoch: [64][360/391]\tTime  0.090 ( 0.091)\tLoss 2.5216e+00 (2.0245e+00)\tAcc@1  45.31 ( 54.87)\tAcc@5  75.78 ( 80.87)\n","Epoch: [64][390/391]\tTime  0.081 ( 0.091)\tLoss 2.3776e+00 (2.0296e+00)\tAcc@1  51.25 ( 54.61)\tAcc@5  83.75 ( 80.70)\n","==> Train Accuracy: Acc@1 54.614 || Acc@5 80.696\n","==> Test Accuracy:  Acc@1 73.310 || Acc@5 93.530\n","==> 37.82 seconds to train this epoch\n","\n","\n","----- epoch: 65, lr: 0.020000000000000004 -----\n","Epoch: [65][  0/391]\tTime  0.204 ( 0.204)\tLoss 1.4208e+00 (1.4208e+00)\tAcc@1  82.81 ( 82.81)\tAcc@5  92.19 ( 92.19)\n","Epoch: [65][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.1165e+00 (1.8183e+00)\tAcc@1  64.06 ( 59.80)\tAcc@5  87.50 ( 86.16)\n","Epoch: [65][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.2700e+00 (1.8546e+00)\tAcc@1  75.78 ( 58.03)\tAcc@5  94.53 ( 84.21)\n","Epoch: [65][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.4230e+00 (1.9093e+00)\tAcc@1  52.34 ( 56.23)\tAcc@5  78.12 ( 83.53)\n","Epoch: [65][120/391]\tTime  0.090 ( 0.091)\tLoss 2.5478e+00 (1.9395e+00)\tAcc@1  33.59 ( 55.71)\tAcc@5  68.75 ( 82.36)\n","Epoch: [65][150/391]\tTime  0.091 ( 0.091)\tLoss 1.5319e+00 (1.9476e+00)\tAcc@1  75.00 ( 55.99)\tAcc@5  93.75 ( 82.41)\n","Epoch: [65][180/391]\tTime  0.090 ( 0.091)\tLoss 1.7080e+00 (1.9729e+00)\tAcc@1  74.22 ( 55.48)\tAcc@5  95.31 ( 82.11)\n","Epoch: [65][210/391]\tTime  0.093 ( 0.091)\tLoss 2.3072e+00 (1.9696e+00)\tAcc@1  55.47 ( 56.38)\tAcc@5  85.94 ( 82.84)\n","Epoch: [65][240/391]\tTime  0.090 ( 0.091)\tLoss 2.4489e+00 (1.9806e+00)\tAcc@1  17.19 ( 55.72)\tAcc@5  50.78 ( 82.32)\n","Epoch: [65][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6515e+00 (1.9768e+00)\tAcc@1  74.22 ( 55.92)\tAcc@5  90.62 ( 82.26)\n","Epoch: [65][300/391]\tTime  0.091 ( 0.091)\tLoss 2.2496e+00 (1.9693e+00)\tAcc@1  61.72 ( 56.41)\tAcc@5  86.72 ( 82.65)\n","Epoch: [65][330/391]\tTime  0.090 ( 0.091)\tLoss 1.8030e+00 (1.9677e+00)\tAcc@1  64.84 ( 56.33)\tAcc@5  92.19 ( 82.55)\n","Epoch: [65][360/391]\tTime  0.091 ( 0.091)\tLoss 1.9640e+00 (1.9787e+00)\tAcc@1  72.66 ( 56.07)\tAcc@5  92.19 ( 82.44)\n","Epoch: [65][390/391]\tTime  0.082 ( 0.091)\tLoss 2.1500e+00 (1.9745e+00)\tAcc@1  66.25 ( 56.08)\tAcc@5  88.75 ( 82.56)\n","==> Train Accuracy: Acc@1 56.076 || Acc@5 82.558\n","==> Test Accuracy:  Acc@1 72.530 || Acc@5 92.930\n","==> 37.84 seconds to train this epoch\n","\n","\n","----- epoch: 66, lr: 0.020000000000000004 -----\n","Epoch: [66][  0/391]\tTime  0.198 ( 0.198)\tLoss 1.9203e+00 (1.9203e+00)\tAcc@1  74.22 ( 74.22)\tAcc@5  92.97 ( 92.97)\n","Epoch: [66][ 30/391]\tTime  0.091 ( 0.093)\tLoss 1.0230e+00 (1.8405e+00)\tAcc@1  78.12 ( 61.84)\tAcc@5  97.66 ( 85.33)\n","Epoch: [66][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.1539e+00 (1.8991e+00)\tAcc@1  80.47 ( 57.51)\tAcc@5  95.31 ( 81.67)\n","Epoch: [66][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.1845e+00 (1.9097e+00)\tAcc@1  59.38 ( 58.22)\tAcc@5  85.94 ( 82.76)\n","Epoch: [66][120/391]\tTime  0.096 ( 0.091)\tLoss 1.1505e+00 (1.9369e+00)\tAcc@1  81.25 ( 58.06)\tAcc@5  94.53 ( 82.69)\n","Epoch: [66][150/391]\tTime  0.090 ( 0.091)\tLoss 2.1624e+00 (1.9457e+00)\tAcc@1  59.38 ( 57.81)\tAcc@5  90.62 ( 82.95)\n","Epoch: [66][180/391]\tTime  0.090 ( 0.091)\tLoss 2.4242e+00 (1.9548e+00)\tAcc@1  11.72 ( 56.96)\tAcc@5  53.91 ( 82.61)\n","Epoch: [66][210/391]\tTime  0.090 ( 0.091)\tLoss 2.0538e+00 (1.9530e+00)\tAcc@1  65.62 ( 57.19)\tAcc@5  87.50 ( 82.91)\n","Epoch: [66][240/391]\tTime  0.090 ( 0.091)\tLoss 1.2385e+00 (1.9371e+00)\tAcc@1  78.12 ( 57.69)\tAcc@5  97.66 ( 83.15)\n","Epoch: [66][270/391]\tTime  0.090 ( 0.091)\tLoss 1.9734e+00 (1.9700e+00)\tAcc@1  71.88 ( 56.38)\tAcc@5  95.31 ( 82.24)\n","Epoch: [66][300/391]\tTime  0.093 ( 0.091)\tLoss 1.8133e+00 (1.9687e+00)\tAcc@1  78.12 ( 56.94)\tAcc@5  95.31 ( 82.73)\n","Epoch: [66][330/391]\tTime  0.090 ( 0.091)\tLoss 2.2182e+00 (1.9850e+00)\tAcc@1  53.91 ( 56.29)\tAcc@5  82.81 ( 82.48)\n","Epoch: [66][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7364e+00 (1.9920e+00)\tAcc@1  71.09 ( 56.12)\tAcc@5  94.53 ( 82.47)\n","Epoch: [66][390/391]\tTime  0.081 ( 0.090)\tLoss 1.9277e+00 (1.9955e+00)\tAcc@1  68.75 ( 55.91)\tAcc@5  93.75 ( 82.31)\n","==> Train Accuracy: Acc@1 55.912 || Acc@5 82.306\n","==> Test Accuracy:  Acc@1 72.960 || Acc@5 93.290\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 67, lr: 0.020000000000000004 -----\n","Epoch: [67][  0/391]\tTime  0.209 ( 0.209)\tLoss 2.3829e+00 (2.3829e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  82.81 ( 82.81)\n","Epoch: [67][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.7182e+00 (2.0208e+00)\tAcc@1  76.56 ( 51.16)\tAcc@5  92.97 ( 77.19)\n","Epoch: [67][ 60/391]\tTime  0.092 ( 0.092)\tLoss 1.8368e+00 (1.9949e+00)\tAcc@1  70.31 ( 53.59)\tAcc@5  90.62 ( 79.19)\n","Epoch: [67][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.4743e+00 (2.0244e+00)\tAcc@1  22.66 ( 53.98)\tAcc@5  63.28 ( 80.15)\n","Epoch: [67][120/391]\tTime  0.090 ( 0.091)\tLoss 1.7498e+00 (2.0000e+00)\tAcc@1  75.00 ( 55.02)\tAcc@5  96.88 ( 81.07)\n","Epoch: [67][150/391]\tTime  0.091 ( 0.091)\tLoss 1.6286e+00 (1.9935e+00)\tAcc@1  76.56 ( 54.82)\tAcc@5  94.53 ( 80.46)\n","Epoch: [67][180/391]\tTime  0.090 ( 0.091)\tLoss 1.8902e+00 (2.0158e+00)\tAcc@1  75.78 ( 54.86)\tAcc@5  89.84 ( 80.68)\n","Epoch: [67][210/391]\tTime  0.090 ( 0.091)\tLoss 2.1964e+00 (1.9991e+00)\tAcc@1  54.69 ( 55.12)\tAcc@5  87.50 ( 80.81)\n","Epoch: [67][240/391]\tTime  0.090 ( 0.091)\tLoss 1.3979e+00 (2.0072e+00)\tAcc@1  83.59 ( 55.00)\tAcc@5  94.53 ( 80.85)\n","Epoch: [67][270/391]\tTime  0.091 ( 0.091)\tLoss 2.5016e+00 (2.0080e+00)\tAcc@1   0.78 ( 54.98)\tAcc@5  28.91 ( 80.95)\n","Epoch: [67][300/391]\tTime  0.089 ( 0.091)\tLoss 1.5238e+00 (2.0057e+00)\tAcc@1  75.78 ( 55.04)\tAcc@5  92.19 ( 80.95)\n","Epoch: [67][330/391]\tTime  0.087 ( 0.091)\tLoss 1.8349e+00 (1.9738e+00)\tAcc@1  74.22 ( 56.25)\tAcc@5  92.19 ( 81.83)\n","Epoch: [67][360/391]\tTime  0.090 ( 0.091)\tLoss 2.4621e+00 (1.9856e+00)\tAcc@1  35.94 ( 55.49)\tAcc@5  72.66 ( 81.48)\n","Epoch: [67][390/391]\tTime  0.082 ( 0.091)\tLoss 2.2163e+00 (1.9805e+00)\tAcc@1  62.50 ( 55.03)\tAcc@5  81.25 ( 80.94)\n","==> Train Accuracy: Acc@1 55.034 || Acc@5 80.940\n","==> Test Accuracy:  Acc@1 73.420 || Acc@5 93.530\n","==> 37.92 seconds to train this epoch\n","\n","\n","----- epoch: 68, lr: 0.020000000000000004 -----\n","Epoch: [68][  0/391]\tTime  0.211 ( 0.211)\tLoss 2.6172e+00 (2.6172e+00)\tAcc@1  26.56 ( 26.56)\tAcc@5  61.72 ( 61.72)\n","Epoch: [68][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.5536e+00 (2.0220e+00)\tAcc@1  11.72 ( 53.33)\tAcc@5  50.00 ( 80.17)\n","Epoch: [68][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.2790e+00 (1.9727e+00)\tAcc@1  78.91 ( 56.20)\tAcc@5  96.09 ( 82.49)\n","Epoch: [68][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.5905e+00 (1.9720e+00)\tAcc@1  34.38 ( 55.70)\tAcc@5  75.00 ( 82.09)\n","Epoch: [68][120/391]\tTime  0.095 ( 0.091)\tLoss 1.2309e+00 (1.9913e+00)\tAcc@1  75.78 ( 55.55)\tAcc@5  93.75 ( 81.69)\n","Epoch: [68][150/391]\tTime  0.090 ( 0.091)\tLoss 2.1279e+00 (2.0147e+00)\tAcc@1  60.94 ( 54.75)\tAcc@5  86.72 ( 81.31)\n","Epoch: [68][180/391]\tTime  0.091 ( 0.091)\tLoss 1.4250e+00 (2.0099e+00)\tAcc@1  75.78 ( 55.15)\tAcc@5  94.53 ( 81.67)\n","Epoch: [68][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2043e+00 (1.9932e+00)\tAcc@1  57.03 ( 55.93)\tAcc@5  85.16 ( 82.38)\n","Epoch: [68][240/391]\tTime  0.086 ( 0.091)\tLoss 2.0981e+00 (1.9830e+00)\tAcc@1  65.62 ( 55.91)\tAcc@5  87.50 ( 82.17)\n","Epoch: [68][270/391]\tTime  0.089 ( 0.091)\tLoss 1.2802e+00 (1.9941e+00)\tAcc@1  72.66 ( 55.27)\tAcc@5  95.31 ( 81.47)\n","Epoch: [68][300/391]\tTime  0.090 ( 0.091)\tLoss 1.1613e+00 (1.9846e+00)\tAcc@1  82.81 ( 55.86)\tAcc@5  96.88 ( 81.93)\n","Epoch: [68][330/391]\tTime  0.086 ( 0.091)\tLoss 1.6548e+00 (1.9713e+00)\tAcc@1  79.69 ( 56.44)\tAcc@5  94.53 ( 82.29)\n","Epoch: [68][360/391]\tTime  0.090 ( 0.091)\tLoss 2.2123e+00 (1.9651e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  85.16 ( 82.14)\n","Epoch: [68][390/391]\tTime  0.082 ( 0.091)\tLoss 2.3839e+00 (1.9773e+00)\tAcc@1  46.25 ( 55.94)\tAcc@5  76.25 ( 81.85)\n","==> Train Accuracy: Acc@1 55.938 || Acc@5 81.854\n","==> Test Accuracy:  Acc@1 72.880 || Acc@5 93.220\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 69, lr: 0.020000000000000004 -----\n","Epoch: [69][  0/391]\tTime  0.209 ( 0.209)\tLoss 2.3631e+00 (2.3631e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  72.66 ( 72.66)\n","Epoch: [69][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.2683e+00 (1.9776e+00)\tAcc@1  50.78 ( 52.90)\tAcc@5  83.59 ( 78.78)\n","Epoch: [69][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.7147e+00 (2.0568e+00)\tAcc@1  76.56 ( 52.29)\tAcc@5  94.53 ( 77.82)\n","Epoch: [69][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.8643e+00 (1.9962e+00)\tAcc@1  69.53 ( 54.00)\tAcc@5  92.19 ( 79.23)\n","Epoch: [69][120/391]\tTime  0.090 ( 0.091)\tLoss 1.6649e+00 (1.9740e+00)\tAcc@1  75.00 ( 55.53)\tAcc@5  93.75 ( 80.99)\n","Epoch: [69][150/391]\tTime  0.090 ( 0.091)\tLoss 1.8383e+00 (1.9804e+00)\tAcc@1  68.75 ( 56.20)\tAcc@5  90.62 ( 81.76)\n","Epoch: [69][180/391]\tTime  0.090 ( 0.091)\tLoss 1.9334e+00 (1.9911e+00)\tAcc@1  76.56 ( 55.96)\tAcc@5  89.06 ( 81.68)\n","Epoch: [69][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8176e+00 (1.9838e+00)\tAcc@1  70.31 ( 55.96)\tAcc@5  89.06 ( 81.64)\n","Epoch: [69][240/391]\tTime  0.091 ( 0.091)\tLoss 1.8635e+00 (1.9920e+00)\tAcc@1  71.09 ( 55.17)\tAcc@5  92.97 ( 80.90)\n","Epoch: [69][270/391]\tTime  0.091 ( 0.091)\tLoss 8.5425e-01 (2.0043e+00)\tAcc@1  81.25 ( 54.83)\tAcc@5  96.09 ( 80.78)\n","Epoch: [69][300/391]\tTime  0.091 ( 0.091)\tLoss 1.9127e+00 (2.0003e+00)\tAcc@1  67.19 ( 54.77)\tAcc@5  85.16 ( 80.79)\n","Epoch: [69][330/391]\tTime  0.091 ( 0.091)\tLoss 1.9096e+00 (1.9994e+00)\tAcc@1  67.97 ( 54.80)\tAcc@5  93.75 ( 80.85)\n","Epoch: [69][360/391]\tTime  0.090 ( 0.091)\tLoss 2.2126e+00 (2.0017e+00)\tAcc@1  44.53 ( 54.66)\tAcc@5  82.81 ( 80.99)\n","Epoch: [69][390/391]\tTime  0.081 ( 0.091)\tLoss 2.5320e+00 (2.0049e+00)\tAcc@1  48.75 ( 54.44)\tAcc@5  73.75 ( 80.61)\n","==> Train Accuracy: Acc@1 54.442 || Acc@5 80.606\n","==> Test Accuracy:  Acc@1 71.390 || Acc@5 92.690\n","==> 37.83 seconds to train this epoch\n","\n","\n","----- epoch: 70, lr: 0.020000000000000004 -----\n","Epoch: [70][  0/391]\tTime  0.200 ( 0.200)\tLoss 2.1426e+00 (2.1426e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  90.62 ( 90.62)\n","Epoch: [70][ 30/391]\tTime  0.095 ( 0.094)\tLoss 2.2267e+00 (2.0225e+00)\tAcc@1  49.22 ( 57.31)\tAcc@5  84.38 ( 84.12)\n","Epoch: [70][ 60/391]\tTime  0.090 ( 0.092)\tLoss 6.6594e-01 (1.8658e+00)\tAcc@1  85.94 ( 60.68)\tAcc@5  96.09 ( 86.31)\n","Epoch: [70][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.3250e+00 (1.9191e+00)\tAcc@1  53.91 ( 58.51)\tAcc@5  81.25 ( 83.89)\n","Epoch: [70][120/391]\tTime  0.093 ( 0.091)\tLoss 2.4375e+00 (1.9381e+00)\tAcc@1  28.12 ( 57.26)\tAcc@5  65.62 ( 82.90)\n","Epoch: [70][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2298e+00 (1.9525e+00)\tAcc@1  79.69 ( 56.82)\tAcc@5  95.31 ( 82.43)\n","Epoch: [70][180/391]\tTime  0.090 ( 0.091)\tLoss 2.3648e+00 (1.9691e+00)\tAcc@1  14.06 ( 55.85)\tAcc@5  56.25 ( 82.03)\n","Epoch: [70][210/391]\tTime  0.091 ( 0.091)\tLoss 2.0459e+00 (1.9445e+00)\tAcc@1  64.84 ( 56.31)\tAcc@5  89.06 ( 82.11)\n","Epoch: [70][240/391]\tTime  0.090 ( 0.091)\tLoss 1.4032e+00 (1.9627e+00)\tAcc@1  75.00 ( 55.38)\tAcc@5  93.75 ( 81.25)\n","Epoch: [70][270/391]\tTime  0.090 ( 0.091)\tLoss 2.2220e+00 (1.9554e+00)\tAcc@1   3.12 ( 56.11)\tAcc@5  15.62 ( 81.68)\n","Epoch: [70][300/391]\tTime  0.091 ( 0.091)\tLoss 2.3411e+00 (1.9687e+00)\tAcc@1  50.78 ( 55.72)\tAcc@5  79.69 ( 81.47)\n","Epoch: [70][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5376e+00 (1.9805e+00)\tAcc@1  78.91 ( 55.45)\tAcc@5  96.09 ( 81.41)\n","Epoch: [70][360/391]\tTime  0.090 ( 0.091)\tLoss 9.2972e-01 (1.9783e+00)\tAcc@1  85.16 ( 55.68)\tAcc@5  96.09 ( 81.63)\n","Epoch: [70][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5686e+00 (1.9791e+00)\tAcc@1  17.50 ( 55.71)\tAcc@5  52.50 ( 81.67)\n","==> Train Accuracy: Acc@1 55.706 || Acc@5 81.674\n","==> Test Accuracy:  Acc@1 71.470 || Acc@5 92.370\n","==> 37.83 seconds to train this epoch\n","\n","\n","----- epoch: 71, lr: 0.020000000000000004 -----\n","Epoch: [71][  0/391]\tTime  0.209 ( 0.209)\tLoss 1.6164e+00 (1.6164e+00)\tAcc@1  75.78 ( 75.78)\tAcc@5  98.44 ( 98.44)\n","Epoch: [71][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.1852e+00 (2.0476e+00)\tAcc@1  55.47 ( 55.27)\tAcc@5  84.38 ( 82.84)\n","Epoch: [71][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.8760e+00 (1.9091e+00)\tAcc@1  71.88 ( 60.78)\tAcc@5  94.53 ( 85.76)\n","Epoch: [71][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.3707e+00 (1.9741e+00)\tAcc@1  44.53 ( 58.31)\tAcc@5  80.47 ( 84.51)\n","Epoch: [71][120/391]\tTime  0.090 ( 0.091)\tLoss 1.6821e+00 (1.9468e+00)\tAcc@1  76.56 ( 59.75)\tAcc@5  95.31 ( 85.30)\n","Epoch: [71][150/391]\tTime  0.093 ( 0.091)\tLoss 1.7367e+00 (1.9493e+00)\tAcc@1  72.66 ( 58.54)\tAcc@5  92.97 ( 84.34)\n","Epoch: [71][180/391]\tTime  0.091 ( 0.091)\tLoss 2.3730e+00 (1.9390e+00)\tAcc@1  42.19 ( 59.83)\tAcc@5  76.56 ( 85.22)\n","Epoch: [71][210/391]\tTime  0.091 ( 0.091)\tLoss 2.3099e+00 (1.9387e+00)\tAcc@1  57.81 ( 59.65)\tAcc@5  87.50 ( 85.07)\n","Epoch: [71][240/391]\tTime  0.091 ( 0.091)\tLoss 1.7269e+00 (1.9414e+00)\tAcc@1  78.12 ( 59.15)\tAcc@5  95.31 ( 84.63)\n","Epoch: [71][270/391]\tTime  0.091 ( 0.091)\tLoss 2.8058e+00 (1.9477e+00)\tAcc@1  10.16 ( 58.42)\tAcc@5  38.28 ( 84.04)\n","Epoch: [71][300/391]\tTime  0.090 ( 0.091)\tLoss 2.3920e+00 (1.9633e+00)\tAcc@1  19.53 ( 57.41)\tAcc@5  52.34 ( 83.29)\n","Epoch: [71][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8433e+00 (1.9621e+00)\tAcc@1  70.31 ( 57.29)\tAcc@5  90.62 ( 83.08)\n","Epoch: [71][360/391]\tTime  0.090 ( 0.091)\tLoss 2.2185e+00 (1.9642e+00)\tAcc@1  60.16 ( 56.78)\tAcc@5  88.28 ( 82.69)\n","Epoch: [71][390/391]\tTime  0.082 ( 0.091)\tLoss 2.1231e+00 (1.9788e+00)\tAcc@1  57.50 ( 56.08)\tAcc@5  86.25 ( 82.32)\n","==> Train Accuracy: Acc@1 56.084 || Acc@5 82.324\n","==> Test Accuracy:  Acc@1 72.620 || Acc@5 93.200\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 72, lr: 0.020000000000000004 -----\n","Epoch: [72][  0/391]\tTime  0.195 ( 0.195)\tLoss 2.3979e+00 (2.3979e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  79.69 ( 79.69)\n","Epoch: [72][ 30/391]\tTime  0.090 ( 0.093)\tLoss 1.9108e+00 (1.8345e+00)\tAcc@1  72.66 ( 59.80)\tAcc@5  94.53 ( 85.69)\n","Epoch: [72][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.2701e+00 (1.9475e+00)\tAcc@1  32.81 ( 55.83)\tAcc@5  78.12 ( 82.80)\n","Epoch: [72][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.3450e+00 (1.9410e+00)\tAcc@1  46.09 ( 56.15)\tAcc@5  79.69 ( 83.21)\n","Epoch: [72][120/391]\tTime  0.090 ( 0.091)\tLoss 1.6667e+00 (1.9084e+00)\tAcc@1  77.34 ( 58.04)\tAcc@5  94.53 ( 84.04)\n","Epoch: [72][150/391]\tTime  0.090 ( 0.091)\tLoss 2.4322e+00 (1.9335e+00)\tAcc@1  22.66 ( 56.55)\tAcc@5  57.03 ( 82.82)\n","Epoch: [72][180/391]\tTime  0.091 ( 0.091)\tLoss 1.0138e+00 (1.9315e+00)\tAcc@1  79.69 ( 56.59)\tAcc@5  96.09 ( 82.91)\n","Epoch: [72][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2304e+00 (1.9402e+00)\tAcc@1  59.38 ( 56.19)\tAcc@5  85.16 ( 82.79)\n","Epoch: [72][240/391]\tTime  0.090 ( 0.091)\tLoss 2.0049e+00 (1.9467e+00)\tAcc@1  69.53 ( 56.02)\tAcc@5  88.28 ( 82.52)\n","Epoch: [72][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8427e+00 (1.9572e+00)\tAcc@1  80.47 ( 56.30)\tAcc@5  94.53 ( 82.72)\n","Epoch: [72][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8799e+00 (1.9548e+00)\tAcc@1  67.97 ( 56.34)\tAcc@5  92.19 ( 82.78)\n","Epoch: [72][330/391]\tTime  0.090 ( 0.091)\tLoss 2.5693e+00 (1.9520e+00)\tAcc@1  25.78 ( 56.50)\tAcc@5  60.16 ( 82.71)\n","Epoch: [72][360/391]\tTime  0.090 ( 0.091)\tLoss 2.5506e+00 (1.9534e+00)\tAcc@1  55.47 ( 56.46)\tAcc@5  78.12 ( 82.56)\n","Epoch: [72][390/391]\tTime  0.081 ( 0.090)\tLoss 2.3611e+00 (1.9613e+00)\tAcc@1  27.50 ( 56.22)\tAcc@5  68.75 ( 82.29)\n","==> Train Accuracy: Acc@1 56.224 || Acc@5 82.294\n","==> Test Accuracy:  Acc@1 72.050 || Acc@5 92.690\n","==> 37.80 seconds to train this epoch\n","\n","\n","----- epoch: 73, lr: 0.020000000000000004 -----\n","Epoch: [73][  0/391]\tTime  0.207 ( 0.207)\tLoss 2.1541e+00 (2.1541e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  87.50 ( 87.50)\n","Epoch: [73][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.5246e+00 (1.9596e+00)\tAcc@1  31.25 ( 57.48)\tAcc@5  75.78 ( 83.77)\n","Epoch: [73][ 60/391]\tTime  0.089 ( 0.092)\tLoss 2.4678e+00 (1.9638e+00)\tAcc@1  32.81 ( 57.63)\tAcc@5  68.75 ( 83.70)\n","Epoch: [73][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.4981e+00 (1.9788e+00)\tAcc@1  83.59 ( 55.98)\tAcc@5  97.66 ( 82.12)\n","Epoch: [73][120/391]\tTime  0.090 ( 0.091)\tLoss 2.1713e+00 (1.9663e+00)\tAcc@1   3.12 ( 56.92)\tAcc@5  21.09 ( 82.97)\n","Epoch: [73][150/391]\tTime  0.090 ( 0.091)\tLoss 2.3424e+00 (1.9554e+00)\tAcc@1  36.72 ( 56.97)\tAcc@5  73.44 ( 83.27)\n","Epoch: [73][180/391]\tTime  0.090 ( 0.091)\tLoss 2.5786e+00 (1.9505e+00)\tAcc@1  30.47 ( 56.88)\tAcc@5  70.31 ( 82.99)\n","Epoch: [73][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8927e+00 (1.9831e+00)\tAcc@1  72.66 ( 56.23)\tAcc@5  96.09 ( 82.63)\n","Epoch: [73][240/391]\tTime  0.090 ( 0.091)\tLoss 1.9838e+00 (1.9735e+00)\tAcc@1  67.97 ( 55.80)\tAcc@5  89.84 ( 82.05)\n","Epoch: [73][270/391]\tTime  0.090 ( 0.091)\tLoss 7.7783e-01 (1.9816e+00)\tAcc@1  75.78 ( 54.98)\tAcc@5  94.53 ( 81.47)\n","Epoch: [73][300/391]\tTime  0.090 ( 0.091)\tLoss 9.9072e-01 (1.9790e+00)\tAcc@1  78.91 ( 54.99)\tAcc@5  92.97 ( 81.46)\n","Epoch: [73][330/391]\tTime  0.092 ( 0.091)\tLoss 2.1843e+00 (1.9764e+00)\tAcc@1  64.84 ( 55.58)\tAcc@5  89.06 ( 81.87)\n","Epoch: [73][360/391]\tTime  0.090 ( 0.091)\tLoss 1.2338e+00 (1.9783e+00)\tAcc@1  72.66 ( 55.35)\tAcc@5  97.66 ( 81.70)\n","Epoch: [73][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7558e+00 (1.9732e+00)\tAcc@1  63.75 ( 55.54)\tAcc@5  91.25 ( 81.93)\n","==> Train Accuracy: Acc@1 55.542 || Acc@5 81.928\n","==> Test Accuracy:  Acc@1 71.570 || Acc@5 93.310\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 74, lr: 0.020000000000000004 -----\n","Epoch: [74][  0/391]\tTime  0.215 ( 0.215)\tLoss 2.2567e+00 (2.2567e+00)\tAcc@1   7.03 (  7.03)\tAcc@5  32.81 ( 32.81)\n","Epoch: [74][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.2062e+00 (1.8657e+00)\tAcc@1  74.22 ( 61.09)\tAcc@5  96.88 ( 86.39)\n","Epoch: [74][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.2398e+00 (1.8576e+00)\tAcc@1  47.66 ( 63.09)\tAcc@5  80.47 ( 87.40)\n","Epoch: [74][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.6922e+00 (1.8836e+00)\tAcc@1  23.44 ( 60.42)\tAcc@5  64.06 ( 85.53)\n","Epoch: [74][120/391]\tTime  0.090 ( 0.091)\tLoss 2.0539e+00 (1.8922e+00)\tAcc@1  67.97 ( 59.86)\tAcc@5  88.28 ( 85.08)\n","Epoch: [74][150/391]\tTime  0.090 ( 0.091)\tLoss 2.1523e+00 (1.9254e+00)\tAcc@1  60.16 ( 58.73)\tAcc@5  82.81 ( 84.63)\n","Epoch: [74][180/391]\tTime  0.091 ( 0.091)\tLoss 1.3498e+00 (1.9426e+00)\tAcc@1  77.34 ( 57.25)\tAcc@5  97.66 ( 83.38)\n","Epoch: [74][210/391]\tTime  0.090 ( 0.091)\tLoss 2.1619e+00 (1.9356e+00)\tAcc@1  57.03 ( 57.75)\tAcc@5  79.69 ( 83.52)\n","Epoch: [74][240/391]\tTime  0.090 ( 0.091)\tLoss 1.2897e+00 (1.9299e+00)\tAcc@1  76.56 ( 58.10)\tAcc@5  92.97 ( 83.75)\n","Epoch: [74][270/391]\tTime  0.090 ( 0.091)\tLoss 1.9972e+00 (1.9272e+00)\tAcc@1  64.06 ( 58.74)\tAcc@5  86.72 ( 84.16)\n","Epoch: [74][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9606e+00 (1.9243e+00)\tAcc@1  73.44 ( 58.86)\tAcc@5  92.97 ( 84.31)\n","Epoch: [74][330/391]\tTime  0.090 ( 0.091)\tLoss 2.2495e+00 (1.9264e+00)\tAcc@1  54.69 ( 58.48)\tAcc@5  83.59 ( 84.04)\n","Epoch: [74][360/391]\tTime  0.090 ( 0.091)\tLoss 8.1693e-01 (1.9303e+00)\tAcc@1  82.81 ( 58.02)\tAcc@5  96.88 ( 83.76)\n","Epoch: [74][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5423e+00 (1.9281e+00)\tAcc@1  41.25 ( 58.11)\tAcc@5  73.75 ( 83.79)\n","==> Train Accuracy: Acc@1 58.114 || Acc@5 83.786\n","==> Test Accuracy:  Acc@1 71.470 || Acc@5 92.620\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 75, lr: 0.020000000000000004 -----\n","Epoch: [75][  0/391]\tTime  0.196 ( 0.196)\tLoss 2.1608e+00 (2.1608e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.06 ( 89.06)\n","Epoch: [75][ 30/391]\tTime  0.091 ( 0.093)\tLoss 7.4280e-01 (1.9284e+00)\tAcc@1  82.03 ( 56.78)\tAcc@5  96.88 ( 81.96)\n","Epoch: [75][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.3968e+00 (1.9586e+00)\tAcc@1  29.69 ( 54.78)\tAcc@5  67.97 ( 80.93)\n","Epoch: [75][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.4072e+00 (1.9252e+00)\tAcc@1  81.25 ( 55.69)\tAcc@5  95.31 ( 81.53)\n","Epoch: [75][120/391]\tTime  0.090 ( 0.091)\tLoss 2.4160e+00 (1.9531e+00)\tAcc@1  21.88 ( 55.48)\tAcc@5  66.41 ( 81.79)\n","Epoch: [75][150/391]\tTime  0.090 ( 0.091)\tLoss 2.5476e+00 (1.9404e+00)\tAcc@1  18.75 ( 56.36)\tAcc@5  49.22 ( 82.41)\n","Epoch: [75][180/391]\tTime  0.090 ( 0.091)\tLoss 1.8942e+00 (1.9289e+00)\tAcc@1  74.22 ( 56.83)\tAcc@5  90.62 ( 82.75)\n","Epoch: [75][210/391]\tTime  0.090 ( 0.091)\tLoss 7.2676e-01 (1.9447e+00)\tAcc@1  79.69 ( 55.68)\tAcc@5  96.88 ( 82.12)\n","Epoch: [75][240/391]\tTime  0.090 ( 0.091)\tLoss 2.2877e+00 (1.9581e+00)\tAcc@1  53.91 ( 55.26)\tAcc@5  80.47 ( 81.81)\n","Epoch: [75][270/391]\tTime  0.091 ( 0.091)\tLoss 1.3761e+00 (1.9570e+00)\tAcc@1  77.34 ( 55.12)\tAcc@5  94.53 ( 81.50)\n","Epoch: [75][300/391]\tTime  0.090 ( 0.091)\tLoss 2.6798e+00 (1.9544e+00)\tAcc@1  22.66 ( 55.47)\tAcc@5  59.38 ( 81.53)\n","Epoch: [75][330/391]\tTime  0.090 ( 0.091)\tLoss 2.3886e+00 (1.9648e+00)\tAcc@1  30.47 ( 55.16)\tAcc@5  65.62 ( 81.43)\n","Epoch: [75][360/391]\tTime  0.092 ( 0.091)\tLoss 2.3526e+00 (1.9666e+00)\tAcc@1  23.44 ( 54.99)\tAcc@5  65.62 ( 81.30)\n","Epoch: [75][390/391]\tTime  0.082 ( 0.090)\tLoss 2.1111e+00 (1.9734e+00)\tAcc@1  67.50 ( 55.06)\tAcc@5  91.25 ( 81.42)\n","==> Train Accuracy: Acc@1 55.062 || Acc@5 81.424\n","==> Test Accuracy:  Acc@1 71.590 || Acc@5 92.700\n","==> 37.79 seconds to train this epoch\n","\n","\n","----- epoch: 76, lr: 0.020000000000000004 -----\n","Epoch: [76][  0/391]\tTime  0.204 ( 0.204)\tLoss 1.9910e+00 (1.9910e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5  91.41 ( 91.41)\n","Epoch: [76][ 30/391]\tTime  0.090 ( 0.093)\tLoss 7.0552e-01 (1.9106e+00)\tAcc@1  81.25 ( 54.54)\tAcc@5  96.88 ( 81.98)\n","Epoch: [76][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.4055e+00 (1.8627e+00)\tAcc@1  15.62 ( 57.56)\tAcc@5  60.16 ( 84.49)\n","Epoch: [76][ 90/391]\tTime  0.091 ( 0.091)\tLoss 1.4528e+00 (1.8830e+00)\tAcc@1  73.44 ( 57.81)\tAcc@5  94.53 ( 84.57)\n","Epoch: [76][120/391]\tTime  0.090 ( 0.091)\tLoss 2.4241e+00 (1.8686e+00)\tAcc@1  51.56 ( 59.06)\tAcc@5  78.12 ( 85.25)\n","Epoch: [76][150/391]\tTime  0.090 ( 0.091)\tLoss 1.8469e+00 (1.8891e+00)\tAcc@1   1.56 ( 58.80)\tAcc@5  16.41 ( 84.60)\n","Epoch: [76][180/391]\tTime  0.090 ( 0.091)\tLoss 1.9745e+00 (1.9161e+00)\tAcc@1  63.28 ( 57.63)\tAcc@5  90.62 ( 84.13)\n","Epoch: [76][210/391]\tTime  0.091 ( 0.091)\tLoss 1.2517e+00 (1.9258e+00)\tAcc@1  78.12 ( 57.59)\tAcc@5  94.53 ( 84.11)\n","Epoch: [76][240/391]\tTime  0.090 ( 0.091)\tLoss 9.5581e-01 (1.9292e+00)\tAcc@1  85.16 ( 57.41)\tAcc@5  97.66 ( 83.88)\n","Epoch: [76][270/391]\tTime  0.090 ( 0.091)\tLoss 2.4608e+00 (1.9450e+00)\tAcc@1  25.00 ( 56.58)\tAcc@5  69.53 ( 83.28)\n","Epoch: [76][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4564e+00 (1.9453e+00)\tAcc@1  80.47 ( 57.16)\tAcc@5  96.09 ( 83.68)\n","Epoch: [76][330/391]\tTime  0.091 ( 0.091)\tLoss 2.3191e+00 (1.9493e+00)\tAcc@1  45.31 ( 57.10)\tAcc@5  81.25 ( 83.42)\n","Epoch: [76][360/391]\tTime  0.091 ( 0.091)\tLoss 1.0539e+00 (1.9495e+00)\tAcc@1  75.78 ( 56.61)\tAcc@5  96.09 ( 82.91)\n","Epoch: [76][390/391]\tTime  0.082 ( 0.090)\tLoss 2.2810e+00 (1.9480e+00)\tAcc@1  55.00 ( 56.71)\tAcc@5  85.00 ( 82.91)\n","==> Train Accuracy: Acc@1 56.710 || Acc@5 82.912\n","==> Test Accuracy:  Acc@1 70.840 || Acc@5 92.580\n","==> 37.82 seconds to train this epoch\n","\n","\n","----- epoch: 77, lr: 0.020000000000000004 -----\n","Epoch: [77][  0/391]\tTime  0.215 ( 0.215)\tLoss 2.3245e+00 (2.3245e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  84.38 ( 84.38)\n","Epoch: [77][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.2822e+00 (1.7835e+00)\tAcc@1  45.31 ( 66.89)\tAcc@5  81.25 ( 89.34)\n","Epoch: [77][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.8153e+00 (1.8456e+00)\tAcc@1  67.19 ( 61.40)\tAcc@5  92.97 ( 85.16)\n","Epoch: [77][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.4214e+00 (1.8723e+00)\tAcc@1  41.41 ( 60.30)\tAcc@5  78.91 ( 85.00)\n","Epoch: [77][120/391]\tTime  0.092 ( 0.091)\tLoss 2.2779e+00 (1.8988e+00)\tAcc@1  26.56 ( 57.33)\tAcc@5  67.19 ( 82.56)\n","Epoch: [77][150/391]\tTime  0.090 ( 0.091)\tLoss 1.8395e+00 (1.9087e+00)\tAcc@1  66.41 ( 57.82)\tAcc@5  87.50 ( 82.96)\n","Epoch: [77][180/391]\tTime  0.089 ( 0.091)\tLoss 1.6205e+00 (1.9238e+00)\tAcc@1  75.78 ( 57.64)\tAcc@5  91.41 ( 83.22)\n","Epoch: [77][210/391]\tTime  0.091 ( 0.091)\tLoss 2.0734e+00 (1.9445e+00)\tAcc@1  64.06 ( 57.35)\tAcc@5  87.50 ( 83.05)\n","Epoch: [77][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7805e+00 (1.9607e+00)\tAcc@1  77.34 ( 56.52)\tAcc@5  91.41 ( 82.48)\n","Epoch: [77][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9455e+00 (1.9697e+00)\tAcc@1  64.84 ( 56.47)\tAcc@5  92.97 ( 82.27)\n","Epoch: [77][300/391]\tTime  0.090 ( 0.091)\tLoss 2.2721e+00 (1.9642e+00)\tAcc@1  48.44 ( 56.51)\tAcc@5  81.25 ( 82.27)\n","Epoch: [77][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5507e+00 (1.9534e+00)\tAcc@1  75.00 ( 56.74)\tAcc@5  90.62 ( 82.42)\n","Epoch: [77][360/391]\tTime  0.090 ( 0.091)\tLoss 2.2432e+00 (1.9612e+00)\tAcc@1  49.22 ( 56.45)\tAcc@5  82.03 ( 82.10)\n","Epoch: [77][390/391]\tTime  0.081 ( 0.091)\tLoss 1.9696e+00 (1.9719e+00)\tAcc@1  68.75 ( 56.19)\tAcc@5  92.50 ( 82.00)\n","==> Train Accuracy: Acc@1 56.192 || Acc@5 82.004\n","==> Test Accuracy:  Acc@1 72.610 || Acc@5 92.960\n","==> 37.84 seconds to train this epoch\n","\n","\n","----- epoch: 78, lr: 0.020000000000000004 -----\n","Epoch: [78][  0/391]\tTime  0.203 ( 0.203)\tLoss 2.6676e+00 (2.6676e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  66.41 ( 66.41)\n","Epoch: [78][ 30/391]\tTime  0.090 ( 0.093)\tLoss 1.6661e+00 (1.7618e+00)\tAcc@1  76.56 ( 57.41)\tAcc@5  94.53 ( 82.33)\n","Epoch: [78][ 60/391]\tTime  0.087 ( 0.092)\tLoss 2.1623e+00 (1.7612e+00)\tAcc@1  28.12 ( 58.68)\tAcc@5  71.88 ( 83.21)\n","Epoch: [78][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.5795e+00 (1.8005e+00)\tAcc@1  78.12 ( 59.73)\tAcc@5  95.31 ( 84.30)\n","Epoch: [78][120/391]\tTime  0.091 ( 0.091)\tLoss 1.0696e+00 (1.8559e+00)\tAcc@1  79.69 ( 57.60)\tAcc@5  98.44 ( 83.01)\n","Epoch: [78][150/391]\tTime  0.090 ( 0.091)\tLoss 2.1440e+00 (1.8449e+00)\tAcc@1  60.94 ( 58.20)\tAcc@5  88.28 ( 83.81)\n","Epoch: [78][180/391]\tTime  0.090 ( 0.091)\tLoss 2.3013e+00 (1.8571e+00)\tAcc@1  61.72 ( 58.05)\tAcc@5  88.28 ( 84.09)\n","Epoch: [78][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2707e+00 (1.8708e+00)\tAcc@1  41.41 ( 57.56)\tAcc@5  77.34 ( 83.52)\n","Epoch: [78][240/391]\tTime  0.088 ( 0.091)\tLoss 2.7256e+00 (1.8784e+00)\tAcc@1  32.81 ( 57.54)\tAcc@5  65.62 ( 83.41)\n","Epoch: [78][270/391]\tTime  0.090 ( 0.091)\tLoss 2.4434e+00 (1.8882e+00)\tAcc@1  40.62 ( 57.51)\tAcc@5  69.53 ( 83.38)\n","Epoch: [78][300/391]\tTime  0.090 ( 0.091)\tLoss 2.0138e+00 (1.9011e+00)\tAcc@1  67.19 ( 57.34)\tAcc@5  87.50 ( 83.14)\n","Epoch: [78][330/391]\tTime  0.090 ( 0.091)\tLoss 2.1753e+00 (1.9137e+00)\tAcc@1  50.78 ( 57.20)\tAcc@5  85.94 ( 83.05)\n","Epoch: [78][360/391]\tTime  0.088 ( 0.091)\tLoss 2.0265e+00 (1.9197e+00)\tAcc@1  65.62 ( 57.45)\tAcc@5  85.16 ( 83.31)\n","Epoch: [78][390/391]\tTime  0.082 ( 0.090)\tLoss 2.2081e+00 (1.9300e+00)\tAcc@1  63.75 ( 57.38)\tAcc@5  88.75 ( 83.31)\n","==> Train Accuracy: Acc@1 57.378 || Acc@5 83.312\n","==> Test Accuracy:  Acc@1 72.890 || Acc@5 92.490\n","==> 37.79 seconds to train this epoch\n","\n","\n","----- epoch: 79, lr: 0.020000000000000004 -----\n","Epoch: [79][  0/391]\tTime  0.212 ( 0.212)\tLoss 2.0677e+00 (2.0677e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  89.06 ( 89.06)\n","Epoch: [79][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.8408e+00 (2.0143e+00)\tAcc@1  70.31 ( 53.02)\tAcc@5  96.88 ( 81.02)\n","Epoch: [79][ 60/391]\tTime  0.089 ( 0.092)\tLoss 2.4415e+00 (1.9442e+00)\tAcc@1  35.94 ( 56.94)\tAcc@5  74.22 ( 83.66)\n","Epoch: [79][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.5909e+00 (1.9163e+00)\tAcc@1  16.41 ( 58.52)\tAcc@5  57.81 ( 84.54)\n","Epoch: [79][120/391]\tTime  0.090 ( 0.091)\tLoss 2.2719e+00 (1.9468e+00)\tAcc@1  10.16 ( 58.01)\tAcc@5  46.09 ( 84.20)\n","Epoch: [79][150/391]\tTime  0.090 ( 0.091)\tLoss 1.9413e+00 (1.9267e+00)\tAcc@1  66.41 ( 58.85)\tAcc@5  89.84 ( 84.36)\n","Epoch: [79][180/391]\tTime  0.090 ( 0.091)\tLoss 1.4993e+00 (1.9446e+00)\tAcc@1  75.00 ( 57.80)\tAcc@5  93.75 ( 83.81)\n","Epoch: [79][210/391]\tTime  0.090 ( 0.091)\tLoss 2.4585e+00 (1.9450e+00)\tAcc@1  42.19 ( 57.84)\tAcc@5  75.00 ( 84.11)\n","Epoch: [79][240/391]\tTime  0.090 ( 0.091)\tLoss 2.2696e+00 (1.9522e+00)\tAcc@1  17.97 ( 57.44)\tAcc@5  66.41 ( 84.00)\n","Epoch: [79][270/391]\tTime  0.090 ( 0.091)\tLoss 2.2086e+00 (1.9471e+00)\tAcc@1  64.06 ( 57.78)\tAcc@5  85.16 ( 83.94)\n","Epoch: [79][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9875e+00 (1.9503e+00)\tAcc@1  66.41 ( 57.34)\tAcc@5  91.41 ( 83.41)\n","Epoch: [79][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5817e+00 (1.9562e+00)\tAcc@1  71.09 ( 56.86)\tAcc@5  94.53 ( 82.97)\n","Epoch: [79][360/391]\tTime  0.090 ( 0.091)\tLoss 2.3983e+00 (1.9567e+00)\tAcc@1  14.06 ( 56.72)\tAcc@5  60.94 ( 82.91)\n","Epoch: [79][390/391]\tTime  0.081 ( 0.091)\tLoss 1.5954e+00 (1.9470e+00)\tAcc@1  76.25 ( 57.22)\tAcc@5  97.50 ( 83.17)\n","==> Train Accuracy: Acc@1 57.220 || Acc@5 83.172\n","==> Test Accuracy:  Acc@1 70.280 || Acc@5 92.240\n","==> 37.82 seconds to train this epoch\n","\n","\n","----- epoch: 80, lr: 0.020000000000000004 -----\n","Epoch: [80][  0/391]\tTime  0.200 ( 0.200)\tLoss 2.4848e+00 (2.4848e+00)\tAcc@1   8.59 (  8.59)\tAcc@5  42.19 ( 42.19)\n","Epoch: [80][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.3030e+00 (1.9609e+00)\tAcc@1  47.66 ( 54.13)\tAcc@5  81.25 ( 82.18)\n","Epoch: [80][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.3300e+00 (1.8770e+00)\tAcc@1  42.19 ( 58.90)\tAcc@5  77.34 ( 85.16)\n","Epoch: [80][ 90/391]\tTime  0.087 ( 0.091)\tLoss 2.1862e+00 (1.8846e+00)\tAcc@1  59.38 ( 58.99)\tAcc@5  89.84 ( 84.92)\n","Epoch: [80][120/391]\tTime  0.092 ( 0.091)\tLoss 1.9955e+00 (1.9072e+00)\tAcc@1  69.53 ( 58.03)\tAcc@5  94.53 ( 84.31)\n","Epoch: [80][150/391]\tTime  0.090 ( 0.091)\tLoss 2.0539e+00 (1.9215e+00)\tAcc@1  66.41 ( 57.11)\tAcc@5  82.81 ( 83.50)\n","Epoch: [80][180/391]\tTime  0.090 ( 0.091)\tLoss 2.0041e+00 (1.9163e+00)\tAcc@1  65.62 ( 57.80)\tAcc@5  86.72 ( 83.79)\n","Epoch: [80][210/391]\tTime  0.090 ( 0.091)\tLoss 8.1514e-01 (1.9413e+00)\tAcc@1  79.69 ( 56.30)\tAcc@5  96.09 ( 82.81)\n","Epoch: [80][240/391]\tTime  0.091 ( 0.091)\tLoss 1.0140e+00 (1.9460e+00)\tAcc@1  85.16 ( 56.52)\tAcc@5  96.88 ( 82.91)\n","Epoch: [80][270/391]\tTime  0.090 ( 0.091)\tLoss 1.8664e+00 (1.9435e+00)\tAcc@1  77.34 ( 56.31)\tAcc@5  93.75 ( 82.69)\n","Epoch: [80][300/391]\tTime  0.090 ( 0.091)\tLoss 2.5460e+00 (1.9497e+00)\tAcc@1  21.09 ( 55.96)\tAcc@5  54.69 ( 82.32)\n","Epoch: [80][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6395e+00 (1.9503e+00)\tAcc@1  81.25 ( 55.64)\tAcc@5  96.88 ( 82.05)\n","Epoch: [80][360/391]\tTime  0.090 ( 0.091)\tLoss 2.4156e+00 (1.9465e+00)\tAcc@1  25.00 ( 55.76)\tAcc@5  60.16 ( 81.98)\n","Epoch: [80][390/391]\tTime  0.081 ( 0.091)\tLoss 1.7860e+00 (1.9499e+00)\tAcc@1  72.50 ( 55.72)\tAcc@5  90.00 ( 81.95)\n","==> Train Accuracy: Acc@1 55.720 || Acc@5 81.952\n","==> Test Accuracy:  Acc@1 71.480 || Acc@5 92.490\n","==> 37.83 seconds to train this epoch\n","\n","\n","----- epoch: 81, lr: 0.020000000000000004 -----\n","Epoch: [81][  0/391]\tTime  0.204 ( 0.204)\tLoss 1.8850e+00 (1.8850e+00)\tAcc@1  72.66 ( 72.66)\tAcc@5  91.41 ( 91.41)\n","Epoch: [81][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.6008e+00 (1.9212e+00)\tAcc@1   7.03 ( 57.89)\tAcc@5  42.19 ( 83.92)\n","Epoch: [81][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.0277e+00 (1.7788e+00)\tAcc@1  66.41 ( 64.29)\tAcc@5  92.19 ( 87.62)\n","Epoch: [81][ 90/391]\tTime  0.090 ( 0.091)\tLoss 2.0355e+00 (1.8517e+00)\tAcc@1  61.72 ( 61.86)\tAcc@5  89.84 ( 85.95)\n","Epoch: [81][120/391]\tTime  0.090 ( 0.091)\tLoss 2.1543e+00 (1.8774e+00)\tAcc@1  60.94 ( 59.93)\tAcc@5  82.81 ( 84.97)\n","Epoch: [81][150/391]\tTime  0.093 ( 0.091)\tLoss 2.4519e+00 (1.9026e+00)\tAcc@1  28.12 ( 59.17)\tAcc@5  73.44 ( 84.54)\n","Epoch: [81][180/391]\tTime  0.090 ( 0.091)\tLoss 2.2485e+00 (1.9328e+00)\tAcc@1  62.50 ( 58.05)\tAcc@5  89.06 ( 83.71)\n","Epoch: [81][210/391]\tTime  0.090 ( 0.091)\tLoss 2.5243e+00 (1.9416e+00)\tAcc@1  25.00 ( 57.78)\tAcc@5  63.28 ( 83.39)\n","Epoch: [81][240/391]\tTime  0.090 ( 0.091)\tLoss 2.4101e+00 (1.9573e+00)\tAcc@1  28.12 ( 57.25)\tAcc@5  66.41 ( 83.12)\n","Epoch: [81][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3673e+00 (1.9629e+00)\tAcc@1  76.56 ( 57.26)\tAcc@5  96.88 ( 83.16)\n","Epoch: [81][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8651e+00 (1.9546e+00)\tAcc@1  71.88 ( 57.37)\tAcc@5  93.75 ( 83.30)\n","Epoch: [81][330/391]\tTime  0.090 ( 0.091)\tLoss 2.5089e+00 (1.9601e+00)\tAcc@1  39.06 ( 57.22)\tAcc@5  71.88 ( 83.18)\n","Epoch: [81][360/391]\tTime  0.090 ( 0.091)\tLoss 2.0786e+00 (1.9530e+00)\tAcc@1  65.62 ( 57.53)\tAcc@5  87.50 ( 83.45)\n","Epoch: [81][390/391]\tTime  0.082 ( 0.091)\tLoss 1.8505e+00 (1.9541e+00)\tAcc@1  71.25 ( 57.55)\tAcc@5  95.00 ( 83.39)\n","==> Train Accuracy: Acc@1 57.550 || Acc@5 83.394\n","==> Test Accuracy:  Acc@1 71.080 || Acc@5 91.840\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 82, lr: 0.020000000000000004 -----\n","Epoch: [82][  0/391]\tTime  0.181 ( 0.181)\tLoss 1.8735e+00 (1.8735e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  91.41 ( 91.41)\n","Epoch: [82][ 30/391]\tTime  0.090 ( 0.093)\tLoss 1.5387e+00 (1.8839e+00)\tAcc@1  77.34 ( 60.33)\tAcc@5  95.31 ( 85.13)\n","Epoch: [82][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.3374e+00 (1.8867e+00)\tAcc@1  36.72 ( 59.58)\tAcc@5  76.56 ( 85.12)\n","Epoch: [82][ 90/391]\tTime  0.090 ( 0.091)\tLoss 9.4128e-01 (1.8550e+00)\tAcc@1  78.91 ( 61.16)\tAcc@5  97.66 ( 85.91)\n","Epoch: [82][120/391]\tTime  0.090 ( 0.091)\tLoss 1.8312e+00 (1.8726e+00)\tAcc@1   3.12 ( 59.96)\tAcc@5  16.41 ( 84.61)\n","Epoch: [82][150/391]\tTime  0.090 ( 0.091)\tLoss 1.1398e+00 (1.8543e+00)\tAcc@1  79.69 ( 60.16)\tAcc@5  94.53 ( 84.73)\n","Epoch: [82][180/391]\tTime  0.090 ( 0.091)\tLoss 7.5495e-01 (1.8451e+00)\tAcc@1  84.38 ( 60.07)\tAcc@5  96.88 ( 84.88)\n","Epoch: [82][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2646e+00 (1.8695e+00)\tAcc@1  59.38 ( 59.25)\tAcc@5  86.72 ( 84.26)\n","Epoch: [82][240/391]\tTime  0.092 ( 0.091)\tLoss 2.4383e+00 (1.8675e+00)\tAcc@1  50.78 ( 59.02)\tAcc@5  76.56 ( 83.89)\n","Epoch: [82][270/391]\tTime  0.090 ( 0.091)\tLoss 2.3429e+00 (1.8841e+00)\tAcc@1  32.81 ( 58.43)\tAcc@5  76.56 ( 83.65)\n","Epoch: [82][300/391]\tTime  0.090 ( 0.091)\tLoss 9.4098e-01 (1.8924e+00)\tAcc@1  82.81 ( 58.44)\tAcc@5  96.09 ( 83.74)\n","Epoch: [82][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2963e+00 (1.8864e+00)\tAcc@1  81.25 ( 58.75)\tAcc@5  96.09 ( 83.94)\n","Epoch: [82][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7756e+00 (1.8945e+00)\tAcc@1  71.88 ( 58.96)\tAcc@5  92.19 ( 84.21)\n","Epoch: [82][390/391]\tTime  0.081 ( 0.090)\tLoss 2.4802e+00 (1.8968e+00)\tAcc@1  28.75 ( 58.88)\tAcc@5  62.50 ( 84.16)\n","==> Train Accuracy: Acc@1 58.878 || Acc@5 84.162\n","==> Test Accuracy:  Acc@1 70.760 || Acc@5 92.170\n","==> 37.80 seconds to train this epoch\n","\n","\n","----- epoch: 83, lr: 0.020000000000000004 -----\n","Epoch: [83][  0/391]\tTime  0.209 ( 0.209)\tLoss 1.9239e+00 (1.9239e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  95.31 ( 95.31)\n","Epoch: [83][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.3240e+00 (1.8327e+00)\tAcc@1  46.88 ( 64.44)\tAcc@5  84.38 ( 88.21)\n","Epoch: [83][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.2641e+00 (1.9497e+00)\tAcc@1  53.91 ( 57.68)\tAcc@5  81.25 ( 84.55)\n","Epoch: [83][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3117e+00 (1.9696e+00)\tAcc@1  78.12 ( 55.90)\tAcc@5  94.53 ( 82.96)\n","Epoch: [83][120/391]\tTime  0.091 ( 0.091)\tLoss 2.2542e+00 (1.9366e+00)\tAcc@1  37.50 ( 57.50)\tAcc@5  75.78 ( 83.91)\n","Epoch: [83][150/391]\tTime  0.090 ( 0.091)\tLoss 2.3752e+00 (1.9201e+00)\tAcc@1  50.00 ( 58.02)\tAcc@5  82.03 ( 84.36)\n","Epoch: [83][180/391]\tTime  0.090 ( 0.091)\tLoss 2.4004e+00 (1.9266e+00)\tAcc@1  33.59 ( 57.71)\tAcc@5  70.31 ( 84.19)\n","Epoch: [83][210/391]\tTime  0.090 ( 0.091)\tLoss 1.7619e+00 (1.9427e+00)\tAcc@1  72.66 ( 57.45)\tAcc@5  92.97 ( 84.14)\n","Epoch: [83][240/391]\tTime  0.090 ( 0.091)\tLoss 1.9235e+00 (1.9406e+00)\tAcc@1  68.75 ( 57.60)\tAcc@5  89.06 ( 84.15)\n","Epoch: [83][270/391]\tTime  0.091 ( 0.091)\tLoss 1.4493e+00 (1.9222e+00)\tAcc@1  79.69 ( 58.49)\tAcc@5  95.31 ( 84.62)\n","Epoch: [83][300/391]\tTime  0.090 ( 0.091)\tLoss 8.3634e-01 (1.9259e+00)\tAcc@1  85.16 ( 58.11)\tAcc@5  97.66 ( 84.33)\n","Epoch: [83][330/391]\tTime  0.090 ( 0.091)\tLoss 2.0187e+00 (1.9102e+00)\tAcc@1  60.94 ( 58.56)\tAcc@5  86.72 ( 84.60)\n","Epoch: [83][360/391]\tTime  0.091 ( 0.091)\tLoss 2.4401e+00 (1.9130e+00)\tAcc@1  21.88 ( 58.02)\tAcc@5  58.59 ( 84.21)\n","Epoch: [83][390/391]\tTime  0.082 ( 0.091)\tLoss 2.0974e+00 (1.9169e+00)\tAcc@1  61.25 ( 57.86)\tAcc@5  91.25 ( 84.13)\n","==> Train Accuracy: Acc@1 57.860 || Acc@5 84.130\n","==> Test Accuracy:  Acc@1 70.940 || Acc@5 92.470\n","==> 37.84 seconds to train this epoch\n","\n","\n","----- epoch: 84, lr: 0.020000000000000004 -----\n","Epoch: [84][  0/391]\tTime  0.190 ( 0.190)\tLoss 1.5751e+00 (1.5751e+00)\tAcc@1  77.34 ( 77.34)\tAcc@5  97.66 ( 97.66)\n","Epoch: [84][ 30/391]\tTime  0.090 ( 0.093)\tLoss 2.4439e+00 (1.8267e+00)\tAcc@1  33.59 ( 59.30)\tAcc@5  78.12 ( 84.25)\n","Epoch: [84][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.2621e+00 (1.8204e+00)\tAcc@1  46.88 ( 54.83)\tAcc@5  77.34 ( 78.47)\n","Epoch: [84][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.9382e+00 (1.8380e+00)\tAcc@1  68.75 ( 55.16)\tAcc@5  89.06 ( 79.60)\n","Epoch: [84][120/391]\tTime  0.090 ( 0.091)\tLoss 9.6714e-01 (1.8515e+00)\tAcc@1  82.81 ( 56.06)\tAcc@5  96.88 ( 80.37)\n","Epoch: [84][150/391]\tTime  0.090 ( 0.091)\tLoss 1.1172e+00 (1.8671e+00)\tAcc@1  82.81 ( 55.95)\tAcc@5  96.88 ( 80.90)\n","Epoch: [84][180/391]\tTime  0.090 ( 0.091)\tLoss 2.4176e+00 (1.8643e+00)\tAcc@1  15.62 ( 56.86)\tAcc@5  59.38 ( 81.70)\n","Epoch: [84][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8071e+00 (1.9011e+00)\tAcc@1  68.75 ( 55.32)\tAcc@5  89.06 ( 80.92)\n","Epoch: [84][240/391]\tTime  0.090 ( 0.091)\tLoss 2.4272e+00 (1.9259e+00)\tAcc@1  22.66 ( 54.69)\tAcc@5  64.84 ( 80.76)\n","Epoch: [84][270/391]\tTime  0.090 ( 0.091)\tLoss 1.8573e+00 (1.9161e+00)\tAcc@1  70.31 ( 55.54)\tAcc@5  92.19 ( 81.45)\n","Epoch: [84][300/391]\tTime  0.088 ( 0.091)\tLoss 1.4689e+00 (1.9002e+00)\tAcc@1  78.91 ( 56.14)\tAcc@5  94.53 ( 81.82)\n","Epoch: [84][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5720e+00 (1.9142e+00)\tAcc@1  78.91 ( 55.94)\tAcc@5  97.66 ( 81.70)\n","Epoch: [84][360/391]\tTime  0.090 ( 0.091)\tLoss 2.3176e+00 (1.9331e+00)\tAcc@1  53.91 ( 55.15)\tAcc@5  82.03 ( 81.20)\n","Epoch: [84][390/391]\tTime  0.082 ( 0.090)\tLoss 1.6781e+00 (1.9313e+00)\tAcc@1  78.75 ( 55.10)\tAcc@5  93.75 ( 81.13)\n","==> Train Accuracy: Acc@1 55.100 || Acc@5 81.126\n","==> Test Accuracy:  Acc@1 73.390 || Acc@5 93.170\n","==> 37.82 seconds to train this epoch\n","\n","\n","----- epoch: 85, lr: 0.020000000000000004 -----\n","Epoch: [85][  0/391]\tTime  0.195 ( 0.195)\tLoss 1.9640e+00 (1.9640e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  92.19 ( 92.19)\n","Epoch: [85][ 30/391]\tTime  0.090 ( 0.093)\tLoss 9.4921e-01 (1.8584e+00)\tAcc@1  87.50 ( 59.05)\tAcc@5  97.66 ( 83.97)\n","Epoch: [85][ 60/391]\tTime  0.089 ( 0.092)\tLoss 1.6521e+00 (1.9306e+00)\tAcc@1  78.91 ( 57.03)\tAcc@5  95.31 ( 83.21)\n","Epoch: [85][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.5273e+00 (1.8782e+00)\tAcc@1  78.12 ( 58.17)\tAcc@5  96.09 ( 83.14)\n","Epoch: [85][120/391]\tTime  0.090 ( 0.091)\tLoss 2.2199e+00 (1.9295e+00)\tAcc@1  55.47 ( 55.87)\tAcc@5  84.38 ( 81.97)\n","Epoch: [85][150/391]\tTime  0.090 ( 0.091)\tLoss 2.2786e+00 (1.9298e+00)\tAcc@1  52.34 ( 55.73)\tAcc@5  88.28 ( 81.87)\n","Epoch: [85][180/391]\tTime  0.090 ( 0.091)\tLoss 2.1482e+00 (1.9294e+00)\tAcc@1  61.72 ( 55.92)\tAcc@5  86.72 ( 82.15)\n","Epoch: [85][210/391]\tTime  0.087 ( 0.091)\tLoss 2.3196e+00 (1.9170e+00)\tAcc@1   5.47 ( 56.44)\tAcc@5  33.59 ( 82.45)\n","Epoch: [85][240/391]\tTime  0.090 ( 0.091)\tLoss 5.1085e-01 (1.9236e+00)\tAcc@1  85.16 ( 56.81)\tAcc@5  99.22 ( 82.75)\n","Epoch: [85][270/391]\tTime  0.090 ( 0.091)\tLoss 1.4684e+00 (1.9126e+00)\tAcc@1  73.44 ( 56.96)\tAcc@5  92.97 ( 82.85)\n","Epoch: [85][300/391]\tTime  0.090 ( 0.091)\tLoss 2.4979e+00 (1.9141e+00)\tAcc@1  32.81 ( 57.40)\tAcc@5  70.31 ( 83.14)\n","Epoch: [85][330/391]\tTime  0.089 ( 0.091)\tLoss 1.4785e+00 (1.9196e+00)\tAcc@1  81.25 ( 57.19)\tAcc@5  96.88 ( 83.05)\n","Epoch: [85][360/391]\tTime  0.090 ( 0.091)\tLoss 2.1456e+00 (1.9242e+00)\tAcc@1  60.16 ( 57.13)\tAcc@5  91.41 ( 83.18)\n","Epoch: [85][390/391]\tTime  0.082 ( 0.090)\tLoss 1.1190e+00 (1.9236e+00)\tAcc@1  85.00 ( 57.26)\tAcc@5  96.25 ( 83.18)\n","==> Train Accuracy: Acc@1 57.260 || Acc@5 83.180\n","==> Test Accuracy:  Acc@1 71.790 || Acc@5 92.550\n","==> 37.80 seconds to train this epoch\n","\n","\n","----- epoch: 86, lr: 0.020000000000000004 -----\n","Epoch: [86][  0/391]\tTime  0.213 ( 0.213)\tLoss 9.1495e-01 (9.1495e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n","Epoch: [86][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.9711e+00 (1.8663e+00)\tAcc@1  69.53 ( 62.07)\tAcc@5  88.28 ( 87.17)\n","Epoch: [86][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.1265e+00 (1.9493e+00)\tAcc@1  85.16 ( 58.06)\tAcc@5  97.66 ( 84.80)\n","Epoch: [86][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.2497e+00 (1.9740e+00)\tAcc@1   4.69 ( 56.24)\tAcc@5  32.81 ( 82.91)\n","Epoch: [86][120/391]\tTime  0.090 ( 0.091)\tLoss 2.1856e+00 (1.9785e+00)\tAcc@1  50.78 ( 56.97)\tAcc@5  80.47 ( 83.07)\n","Epoch: [86][150/391]\tTime  0.090 ( 0.091)\tLoss 5.9441e-01 (1.9249e+00)\tAcc@1  82.03 ( 57.94)\tAcc@5  97.66 ( 83.70)\n","Epoch: [86][180/391]\tTime  0.094 ( 0.091)\tLoss 6.6535e-01 (1.8923e+00)\tAcc@1  82.81 ( 58.37)\tAcc@5  96.88 ( 83.74)\n","Epoch: [86][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8395e+00 (1.8977e+00)\tAcc@1  67.97 ( 58.28)\tAcc@5  86.72 ( 83.73)\n","Epoch: [86][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5280e+00 (1.9005e+00)\tAcc@1  78.12 ( 58.43)\tAcc@5  94.53 ( 83.92)\n","Epoch: [86][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6503e+00 (1.9026e+00)\tAcc@1  80.47 ( 58.47)\tAcc@5  95.31 ( 84.05)\n","Epoch: [86][300/391]\tTime  0.090 ( 0.091)\tLoss 1.5693e+00 (1.9120e+00)\tAcc@1  75.00 ( 57.97)\tAcc@5  93.75 ( 83.71)\n","Epoch: [86][330/391]\tTime  0.089 ( 0.091)\tLoss 1.6011e+00 (1.9272e+00)\tAcc@1  70.31 ( 57.22)\tAcc@5  93.75 ( 83.32)\n","Epoch: [86][360/391]\tTime  0.091 ( 0.091)\tLoss 2.1560e+00 (1.9241e+00)\tAcc@1  60.94 ( 57.32)\tAcc@5  85.94 ( 83.41)\n","Epoch: [86][390/391]\tTime  0.081 ( 0.091)\tLoss 2.4656e+00 (1.9192e+00)\tAcc@1  11.25 ( 57.57)\tAcc@5  46.25 ( 83.60)\n","==> Train Accuracy: Acc@1 57.570 || Acc@5 83.596\n","==> Test Accuracy:  Acc@1 71.150 || Acc@5 92.100\n","==> 37.84 seconds to train this epoch\n","\n","\n","----- epoch: 87, lr: 0.020000000000000004 -----\n","Epoch: [87][  0/391]\tTime  0.219 ( 0.219)\tLoss 2.3193e+00 (2.3193e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5  77.34 ( 77.34)\n","Epoch: [87][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.0816e+00 (1.9232e+00)\tAcc@1  66.41 ( 54.16)\tAcc@5  89.84 ( 81.83)\n","Epoch: [87][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.3543e+00 (1.8611e+00)\tAcc@1  15.62 ( 56.69)\tAcc@5  63.28 ( 83.63)\n","Epoch: [87][ 90/391]\tTime  0.089 ( 0.092)\tLoss 2.3045e+00 (1.8789e+00)\tAcc@1  11.72 ( 54.82)\tAcc@5  56.25 ( 81.76)\n","Epoch: [87][120/391]\tTime  0.093 ( 0.091)\tLoss 1.9714e+00 (1.8972e+00)\tAcc@1  70.31 ( 55.33)\tAcc@5  88.28 ( 82.19)\n","Epoch: [87][150/391]\tTime  0.090 ( 0.091)\tLoss 1.4258e+00 (1.9102e+00)\tAcc@1  81.25 ( 55.81)\tAcc@5  96.09 ( 82.38)\n","Epoch: [87][180/391]\tTime  0.090 ( 0.091)\tLoss 2.4906e+00 (1.8754e+00)\tAcc@1  32.03 ( 57.25)\tAcc@5  65.62 ( 83.14)\n","Epoch: [87][210/391]\tTime  0.094 ( 0.091)\tLoss 2.2468e+00 (1.8941e+00)\tAcc@1  49.22 ( 57.23)\tAcc@5  76.56 ( 83.21)\n","Epoch: [87][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1322e+00 (1.8980e+00)\tAcc@1  79.69 ( 56.66)\tAcc@5  96.88 ( 82.77)\n","Epoch: [87][270/391]\tTime  0.091 ( 0.091)\tLoss 1.7063e+00 (1.8875e+00)\tAcc@1  74.22 ( 57.12)\tAcc@5  93.75 ( 82.88)\n","Epoch: [87][300/391]\tTime  0.092 ( 0.091)\tLoss 2.6670e+00 (1.8827e+00)\tAcc@1  25.78 ( 57.48)\tAcc@5  64.84 ( 83.15)\n","Epoch: [87][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5502e+00 (1.8820e+00)\tAcc@1  78.91 ( 57.05)\tAcc@5  96.88 ( 82.73)\n","Epoch: [87][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8287e+00 (1.8941e+00)\tAcc@1  68.75 ( 57.01)\tAcc@5  93.75 ( 82.71)\n","Epoch: [87][390/391]\tTime  0.086 ( 0.091)\tLoss 2.2683e+00 (1.8899e+00)\tAcc@1  46.25 ( 57.31)\tAcc@5  80.00 ( 82.88)\n","==> Train Accuracy: Acc@1 57.308 || Acc@5 82.884\n","==> Test Accuracy:  Acc@1 73.090 || Acc@5 93.280\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 88, lr: 0.020000000000000004 -----\n","Epoch: [88][  0/391]\tTime  0.202 ( 0.202)\tLoss 5.9593e-01 (5.9593e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  98.44 ( 98.44)\n","Epoch: [88][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.5616e+00 (1.9458e+00)\tAcc@1  85.94 ( 53.38)\tAcc@5  96.09 ( 79.46)\n","Epoch: [88][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.1984e+00 (1.9319e+00)\tAcc@1  39.06 ( 55.85)\tAcc@5  84.38 ( 82.22)\n","Epoch: [88][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.9554e+00 (1.9521e+00)\tAcc@1  60.94 ( 56.77)\tAcc@5  88.28 ( 83.14)\n","Epoch: [88][120/391]\tTime  0.090 ( 0.091)\tLoss 1.1450e+00 (1.9062e+00)\tAcc@1  82.03 ( 57.89)\tAcc@5  96.88 ( 83.61)\n","Epoch: [88][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3006e+00 (1.8815e+00)\tAcc@1  78.91 ( 58.39)\tAcc@5  95.31 ( 83.92)\n","Epoch: [88][180/391]\tTime  0.091 ( 0.091)\tLoss 1.7602e+00 (1.9029e+00)\tAcc@1  67.97 ( 57.58)\tAcc@5  91.41 ( 83.54)\n","Epoch: [88][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2943e+00 (1.9145e+00)\tAcc@1  39.06 ( 57.55)\tAcc@5  78.91 ( 83.58)\n","Epoch: [88][240/391]\tTime  0.090 ( 0.091)\tLoss 2.2853e+00 (1.9096e+00)\tAcc@1  48.44 ( 57.73)\tAcc@5  78.12 ( 83.77)\n","Epoch: [88][270/391]\tTime  0.090 ( 0.091)\tLoss 2.1552e+00 (1.8941e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  86.72 ( 84.37)\n","Epoch: [88][300/391]\tTime  0.090 ( 0.091)\tLoss 2.4380e+00 (1.8950e+00)\tAcc@1  12.50 ( 58.68)\tAcc@5  50.00 ( 84.44)\n","Epoch: [88][330/391]\tTime  0.095 ( 0.091)\tLoss 2.2242e+00 (1.8973e+00)\tAcc@1  60.16 ( 58.82)\tAcc@5  84.38 ( 84.45)\n","Epoch: [88][360/391]\tTime  0.090 ( 0.091)\tLoss 2.3097e+00 (1.8963e+00)\tAcc@1   3.91 ( 58.62)\tAcc@5  35.16 ( 84.31)\n","Epoch: [88][390/391]\tTime  0.082 ( 0.091)\tLoss 2.1991e+00 (1.8934e+00)\tAcc@1  66.25 ( 58.76)\tAcc@5  88.75 ( 84.28)\n","==> Train Accuracy: Acc@1 58.760 || Acc@5 84.284\n","==> Test Accuracy:  Acc@1 72.630 || Acc@5 93.110\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 89, lr: 0.020000000000000004 -----\n","Epoch: [89][  0/391]\tTime  0.206 ( 0.206)\tLoss 1.8070e+00 (1.8070e+00)\tAcc@1  74.22 ( 74.22)\tAcc@5  90.62 ( 90.62)\n","Epoch: [89][ 30/391]\tTime  0.091 ( 0.094)\tLoss 2.2064e+00 (1.9232e+00)\tAcc@1   1.56 ( 53.73)\tAcc@5  24.22 ( 79.08)\n","Epoch: [89][ 60/391]\tTime  0.090 ( 0.092)\tLoss 2.1972e+00 (1.9818e+00)\tAcc@1  53.91 ( 53.01)\tAcc@5  85.16 ( 80.06)\n","Epoch: [89][ 90/391]\tTime  0.094 ( 0.091)\tLoss 1.3907e+00 (1.9416e+00)\tAcc@1  85.16 ( 56.66)\tAcc@5  97.66 ( 82.02)\n","Epoch: [89][120/391]\tTime  0.090 ( 0.091)\tLoss 2.0615e+00 (1.9360e+00)\tAcc@1  64.06 ( 56.55)\tAcc@5  89.84 ( 81.34)\n","Epoch: [89][150/391]\tTime  0.090 ( 0.091)\tLoss 2.2201e+00 (1.9316e+00)\tAcc@1  50.00 ( 57.05)\tAcc@5  82.03 ( 81.70)\n","Epoch: [89][180/391]\tTime  0.091 ( 0.091)\tLoss 1.7623e+00 (1.9166e+00)\tAcc@1   0.78 ( 55.87)\tAcc@5   8.59 ( 80.64)\n","Epoch: [89][210/391]\tTime  0.090 ( 0.091)\tLoss 2.5067e+00 (1.9285e+00)\tAcc@1   3.91 ( 55.59)\tAcc@5  25.78 ( 80.64)\n","Epoch: [89][240/391]\tTime  0.090 ( 0.091)\tLoss 7.8942e-01 (1.9097e+00)\tAcc@1  78.91 ( 56.38)\tAcc@5  96.88 ( 81.22)\n","Epoch: [89][270/391]\tTime  0.091 ( 0.091)\tLoss 2.2675e+00 (1.8927e+00)\tAcc@1  52.34 ( 56.86)\tAcc@5  82.81 ( 81.88)\n","Epoch: [89][300/391]\tTime  0.089 ( 0.091)\tLoss 2.5275e+00 (1.8889e+00)\tAcc@1  33.59 ( 57.39)\tAcc@5  70.31 ( 82.37)\n","Epoch: [89][330/391]\tTime  0.090 ( 0.091)\tLoss 2.2111e+00 (1.8854e+00)\tAcc@1  57.03 ( 57.77)\tAcc@5  85.94 ( 82.79)\n","Epoch: [89][360/391]\tTime  0.091 ( 0.091)\tLoss 2.2046e+00 (1.8906e+00)\tAcc@1  60.94 ( 57.24)\tAcc@5  88.28 ( 82.35)\n","Epoch: [89][390/391]\tTime  0.082 ( 0.090)\tLoss 2.4479e+00 (1.8941e+00)\tAcc@1   5.00 ( 57.23)\tAcc@5  31.25 ( 82.39)\n","==> Train Accuracy: Acc@1 57.232 || Acc@5 82.394\n","==> Test Accuracy:  Acc@1 72.860 || Acc@5 93.100\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 90, lr: 0.004000000000000001 -----\n","Epoch: [90][  0/391]\tTime  0.197 ( 0.197)\tLoss 2.3738e+00 (2.3738e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  78.91 ( 78.91)\n","Epoch: [90][ 30/391]\tTime  0.094 ( 0.094)\tLoss 2.1827e+00 (1.7674e+00)\tAcc@1  10.94 ( 61.64)\tAcc@5  51.56 ( 86.11)\n","Epoch: [90][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.0895e+00 (1.6301e+00)\tAcc@1  81.25 ( 68.66)\tAcc@5  95.31 ( 89.93)\n","Epoch: [90][ 90/391]\tTime  0.091 ( 0.091)\tLoss 1.7597e+00 (1.6035e+00)\tAcc@1  77.34 ( 67.31)\tAcc@5  94.53 ( 88.35)\n","Epoch: [90][120/391]\tTime  0.090 ( 0.091)\tLoss 2.0921e+00 (1.6630e+00)\tAcc@1  56.25 ( 64.95)\tAcc@5  83.59 ( 87.40)\n","Epoch: [90][150/391]\tTime  0.090 ( 0.091)\tLoss 1.9418e+00 (1.6587e+00)\tAcc@1  57.81 ( 64.85)\tAcc@5  90.62 ( 87.53)\n","Epoch: [90][180/391]\tTime  0.091 ( 0.091)\tLoss 2.1330e+00 (1.6903e+00)\tAcc@1  55.47 ( 62.67)\tAcc@5  82.81 ( 86.25)\n","Epoch: [90][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8109e+00 (1.6870e+00)\tAcc@1  68.75 ( 63.19)\tAcc@5  89.84 ( 86.71)\n","Epoch: [90][240/391]\tTime  0.090 ( 0.091)\tLoss 2.2196e+00 (1.6806e+00)\tAcc@1  18.75 ( 63.83)\tAcc@5  64.06 ( 87.07)\n","Epoch: [90][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0615e+00 (1.6888e+00)\tAcc@1  60.94 ( 63.42)\tAcc@5  84.38 ( 86.93)\n","Epoch: [90][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4914e+00 (1.6947e+00)\tAcc@1  83.59 ( 63.17)\tAcc@5  98.44 ( 86.77)\n","Epoch: [90][330/391]\tTime  0.091 ( 0.091)\tLoss 1.7987e+00 (1.6998e+00)\tAcc@1   5.47 ( 62.42)\tAcc@5  49.22 ( 86.57)\n","Epoch: [90][360/391]\tTime  0.091 ( 0.091)\tLoss 4.6650e-01 (1.6868e+00)\tAcc@1  88.28 ( 62.61)\tAcc@5  98.44 ( 86.59)\n","Epoch: [90][390/391]\tTime  0.082 ( 0.091)\tLoss 2.1975e+00 (1.6869e+00)\tAcc@1  36.25 ( 62.52)\tAcc@5  75.00 ( 86.52)\n","==> Train Accuracy: Acc@1 62.522 || Acc@5 86.516\n","==> Test Accuracy:  Acc@1 79.010 || Acc@5 95.190\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 91, lr: 0.004000000000000001 -----\n","Epoch: [91][  0/391]\tTime  0.225 ( 0.225)\tLoss 1.6173e+00 (1.6173e+00)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.09 ( 96.09)\n","Epoch: [91][ 30/391]\tTime  0.095 ( 0.094)\tLoss 1.9982e+00 (1.4971e+00)\tAcc@1  35.16 ( 69.43)\tAcc@5  75.78 ( 91.00)\n","Epoch: [91][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.3229e+00 (1.5869e+00)\tAcc@1  89.84 ( 66.52)\tAcc@5  99.22 ( 89.16)\n","Epoch: [91][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.0937e+00 (1.6346e+00)\tAcc@1  32.81 ( 64.36)\tAcc@5  76.56 ( 87.86)\n","Epoch: [91][120/391]\tTime  0.090 ( 0.091)\tLoss 1.7844e+00 (1.6789e+00)\tAcc@1   0.78 ( 61.14)\tAcc@5  32.03 ( 85.49)\n","Epoch: [91][150/391]\tTime  0.090 ( 0.091)\tLoss 1.9464e+00 (1.6612e+00)\tAcc@1  42.97 ( 63.00)\tAcc@5  85.16 ( 86.80)\n","Epoch: [91][180/391]\tTime  0.091 ( 0.091)\tLoss 1.9074e+00 (1.6652e+00)\tAcc@1  71.88 ( 63.63)\tAcc@5  89.84 ( 87.46)\n","Epoch: [91][210/391]\tTime  0.090 ( 0.091)\tLoss 1.7344e+00 (1.6661e+00)\tAcc@1  77.34 ( 63.04)\tAcc@5  92.97 ( 87.11)\n","Epoch: [91][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5559e+00 (1.6475e+00)\tAcc@1  79.69 ( 63.79)\tAcc@5  99.22 ( 87.53)\n","Epoch: [91][270/391]\tTime  0.091 ( 0.091)\tLoss 8.6418e-01 (1.6390e+00)\tAcc@1  87.50 ( 63.40)\tAcc@5  98.44 ( 87.13)\n","Epoch: [91][300/391]\tTime  0.088 ( 0.091)\tLoss 1.8467e+00 (1.6419e+00)\tAcc@1  69.53 ( 64.00)\tAcc@5  93.75 ( 87.46)\n","Epoch: [91][330/391]\tTime  0.090 ( 0.091)\tLoss 1.8227e+00 (1.6459e+00)\tAcc@1  70.31 ( 63.80)\tAcc@5  90.62 ( 87.31)\n","Epoch: [91][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6971e+00 (1.6424e+00)\tAcc@1  80.47 ( 63.97)\tAcc@5  93.75 ( 87.39)\n","Epoch: [91][390/391]\tTime  0.082 ( 0.091)\tLoss 2.1086e+00 (1.6346e+00)\tAcc@1  43.75 ( 64.39)\tAcc@5  81.25 ( 87.72)\n","==> Train Accuracy: Acc@1 64.390 || Acc@5 87.718\n","==> Test Accuracy:  Acc@1 79.230 || Acc@5 95.220\n","==> 38.04 seconds to train this epoch\n","\n","\n","----- epoch: 92, lr: 0.004000000000000001 -----\n","Epoch: [92][  0/391]\tTime  0.215 ( 0.215)\tLoss 5.3782e-01 (5.3782e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  96.09 ( 96.09)\n","Epoch: [92][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.8964e+00 (1.5679e+00)\tAcc@1  40.62 ( 63.71)\tAcc@5  83.59 ( 88.36)\n","Epoch: [92][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.9949e+00 (1.5566e+00)\tAcc@1  60.16 ( 65.82)\tAcc@5  89.06 ( 88.10)\n","Epoch: [92][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.0776e-01 (1.4951e+00)\tAcc@1  89.84 ( 67.94)\tAcc@5  99.22 ( 89.28)\n","Epoch: [92][120/391]\tTime  0.097 ( 0.091)\tLoss 7.3633e-01 (1.5294e+00)\tAcc@1  88.28 ( 66.83)\tAcc@5  97.66 ( 89.11)\n","Epoch: [92][150/391]\tTime  0.090 ( 0.091)\tLoss 1.6636e+00 (1.5492e+00)\tAcc@1  78.91 ( 65.92)\tAcc@5  92.19 ( 88.75)\n","Epoch: [92][180/391]\tTime  0.089 ( 0.091)\tLoss 1.4783e+00 (1.5462e+00)\tAcc@1  82.81 ( 66.54)\tAcc@5  98.44 ( 89.09)\n","Epoch: [92][210/391]\tTime  0.094 ( 0.091)\tLoss 6.7460e-01 (1.5522e+00)\tAcc@1  89.84 ( 66.44)\tAcc@5  99.22 ( 89.09)\n","Epoch: [92][240/391]\tTime  0.090 ( 0.091)\tLoss 1.6480e+00 (1.5436e+00)\tAcc@1  78.12 ( 66.29)\tAcc@5  95.31 ( 88.98)\n","Epoch: [92][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6779e+00 (1.5516e+00)\tAcc@1  75.00 ( 66.41)\tAcc@5  91.41 ( 89.14)\n","Epoch: [92][300/391]\tTime  0.093 ( 0.091)\tLoss 1.3744e+00 (1.5625e+00)\tAcc@1  87.50 ( 66.40)\tAcc@5  94.53 ( 89.04)\n","Epoch: [92][330/391]\tTime  0.089 ( 0.091)\tLoss 2.2532e+00 (1.5516e+00)\tAcc@1  48.44 ( 66.49)\tAcc@5  86.72 ( 88.83)\n","Epoch: [92][360/391]\tTime  0.089 ( 0.091)\tLoss 1.0972e+00 (1.5525e+00)\tAcc@1  89.06 ( 66.24)\tAcc@5 100.00 ( 88.69)\n","Epoch: [92][390/391]\tTime  0.085 ( 0.091)\tLoss 1.5653e+00 (1.5504e+00)\tAcc@1  80.00 ( 66.27)\tAcc@5  92.50 ( 88.60)\n","==> Train Accuracy: Acc@1 66.270 || Acc@5 88.600\n","==> Test Accuracy:  Acc@1 79.220 || Acc@5 95.280\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 93, lr: 0.004000000000000001 -----\n","Epoch: [93][  0/391]\tTime  0.196 ( 0.196)\tLoss 1.2732e+00 (1.2732e+00)\tAcc@1  89.84 ( 89.84)\tAcc@5  96.88 ( 96.88)\n","Epoch: [93][ 30/391]\tTime  0.092 ( 0.093)\tLoss 1.1986e+00 (1.5644e+00)\tAcc@1  92.19 ( 68.95)\tAcc@5  99.22 ( 90.78)\n","Epoch: [93][ 60/391]\tTime  0.090 ( 0.092)\tLoss 9.6206e-01 (1.5480e+00)\tAcc@1  91.41 ( 67.24)\tAcc@5 100.00 ( 90.54)\n","Epoch: [93][ 90/391]\tTime  0.092 ( 0.091)\tLoss 1.1806e+00 (1.5739e+00)\tAcc@1  85.16 ( 66.66)\tAcc@5  98.44 ( 90.55)\n","Epoch: [93][120/391]\tTime  0.089 ( 0.091)\tLoss 1.7703e+00 (1.5780e+00)\tAcc@1  75.00 ( 66.54)\tAcc@5  92.97 ( 90.24)\n","Epoch: [93][150/391]\tTime  0.090 ( 0.091)\tLoss 1.4243e+00 (1.5877e+00)\tAcc@1  82.81 ( 65.68)\tAcc@5  96.88 ( 89.57)\n","Epoch: [93][180/391]\tTime  0.090 ( 0.091)\tLoss 1.7953e+00 (1.5962e+00)\tAcc@1  67.97 ( 65.09)\tAcc@5  93.75 ( 89.30)\n","Epoch: [93][210/391]\tTime  0.091 ( 0.091)\tLoss 1.9544e+00 (1.5769e+00)\tAcc@1  57.81 ( 65.62)\tAcc@5  87.50 ( 89.49)\n","Epoch: [93][240/391]\tTime  0.093 ( 0.091)\tLoss 1.5370e+00 (1.5925e+00)\tAcc@1  80.47 ( 65.28)\tAcc@5  96.88 ( 89.14)\n","Epoch: [93][270/391]\tTime  0.090 ( 0.091)\tLoss 1.9760e+00 (1.6052e+00)\tAcc@1  62.50 ( 64.45)\tAcc@5  87.50 ( 88.75)\n","Epoch: [93][300/391]\tTime  0.090 ( 0.091)\tLoss 2.3386e+00 (1.6122e+00)\tAcc@1  22.66 ( 63.93)\tAcc@5  71.09 ( 88.53)\n","Epoch: [93][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8081e+00 (1.6034e+00)\tAcc@1  67.97 ( 63.69)\tAcc@5  94.53 ( 88.13)\n","Epoch: [93][360/391]\tTime  0.090 ( 0.091)\tLoss 1.3873e+00 (1.5988e+00)\tAcc@1  86.72 ( 63.85)\tAcc@5  96.88 ( 87.93)\n","Epoch: [93][390/391]\tTime  0.082 ( 0.091)\tLoss 2.0007e+00 (1.5891e+00)\tAcc@1  60.00 ( 64.23)\tAcc@5  86.25 ( 88.09)\n","==> Train Accuracy: Acc@1 64.228 || Acc@5 88.094\n","==> Test Accuracy:  Acc@1 79.780 || Acc@5 95.330\n","==> 37.83 seconds to train this epoch\n","\n","\n","----- epoch: 94, lr: 0.004000000000000001 -----\n","Epoch: [94][  0/391]\tTime  0.208 ( 0.208)\tLoss 1.8732e+00 (1.8732e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  91.41 ( 91.41)\n","Epoch: [94][ 30/391]\tTime  0.090 ( 0.094)\tLoss 7.4472e-01 (1.5056e+00)\tAcc@1  89.06 ( 64.59)\tAcc@5  99.22 ( 86.92)\n","Epoch: [94][ 60/391]\tTime  0.090 ( 0.093)\tLoss 6.8508e-01 (1.6181e+00)\tAcc@1  95.31 ( 60.85)\tAcc@5 100.00 ( 86.51)\n","Epoch: [94][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.2911e+00 (1.5797e+00)\tAcc@1  11.72 ( 61.26)\tAcc@5  52.34 ( 85.52)\n","Epoch: [94][120/391]\tTime  0.099 ( 0.092)\tLoss 1.4572e+00 (1.5554e+00)\tAcc@1  85.94 ( 64.44)\tAcc@5  96.88 ( 87.24)\n","Epoch: [94][150/391]\tTime  0.091 ( 0.091)\tLoss 1.5843e+00 (1.5662e+00)\tAcc@1   2.34 ( 64.27)\tAcc@5  45.31 ( 87.28)\n","Epoch: [94][180/391]\tTime  0.090 ( 0.091)\tLoss 2.8125e-01 (1.5340e+00)\tAcc@1  92.19 ( 65.25)\tAcc@5  99.22 ( 87.95)\n","Epoch: [94][210/391]\tTime  0.090 ( 0.091)\tLoss 1.6186e+00 (1.5494e+00)\tAcc@1  73.44 ( 64.32)\tAcc@5  96.09 ( 87.45)\n","Epoch: [94][240/391]\tTime  0.091 ( 0.091)\tLoss 1.8651e+00 (1.5487e+00)\tAcc@1  14.06 ( 63.92)\tAcc@5  64.06 ( 87.17)\n","Epoch: [94][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0514e+00 (1.5338e+00)\tAcc@1  40.62 ( 64.86)\tAcc@5  78.12 ( 87.72)\n","Epoch: [94][300/391]\tTime  0.090 ( 0.091)\tLoss 1.5520e+00 (1.5323e+00)\tAcc@1  82.03 ( 65.28)\tAcc@5  96.09 ( 87.95)\n","Epoch: [94][330/391]\tTime  0.097 ( 0.091)\tLoss 1.8128e+00 (1.5274e+00)\tAcc@1  13.28 ( 65.42)\tAcc@5  67.97 ( 88.08)\n","Epoch: [94][360/391]\tTime  0.091 ( 0.091)\tLoss 1.9454e+00 (1.5188e+00)\tAcc@1  58.59 ( 66.22)\tAcc@5  84.38 ( 88.51)\n","Epoch: [94][390/391]\tTime  0.081 ( 0.091)\tLoss 1.8057e+00 (1.5061e+00)\tAcc@1  52.50 ( 66.63)\tAcc@5  87.50 ( 88.67)\n","==> Train Accuracy: Acc@1 66.626 || Acc@5 88.670\n","==> Test Accuracy:  Acc@1 79.450 || Acc@5 95.250\n","==> 38.01 seconds to train this epoch\n","\n","\n","----- epoch: 95, lr: 0.004000000000000001 -----\n","Epoch: [95][  0/391]\tTime  0.250 ( 0.250)\tLoss 1.6178e+00 (1.6178e+00)\tAcc@1  78.12 ( 78.12)\tAcc@5  96.09 ( 96.09)\n","Epoch: [95][ 30/391]\tTime  0.090 ( 0.095)\tLoss 2.0701e+00 (1.5434e+00)\tAcc@1  24.22 ( 74.75)\tAcc@5  74.22 ( 93.15)\n","Epoch: [95][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.7756e+00 (1.5212e+00)\tAcc@1  68.75 ( 69.99)\tAcc@5  89.06 ( 91.18)\n","Epoch: [95][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2206e+00 (1.4616e+00)\tAcc@1  86.72 ( 71.29)\tAcc@5  99.22 ( 91.45)\n","Epoch: [95][120/391]\tTime  0.090 ( 0.092)\tLoss 1.9002e+00 (1.4605e+00)\tAcc@1  19.53 ( 70.62)\tAcc@5  76.56 ( 91.33)\n","Epoch: [95][150/391]\tTime  0.090 ( 0.091)\tLoss 1.8274e+00 (1.4673e+00)\tAcc@1  68.75 ( 70.31)\tAcc@5  89.84 ( 91.32)\n","Epoch: [95][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6874e+00 (1.4984e+00)\tAcc@1  65.62 ( 68.53)\tAcc@5  95.31 ( 90.42)\n","Epoch: [95][210/391]\tTime  0.093 ( 0.091)\tLoss 1.8404e+00 (1.5277e+00)\tAcc@1  64.06 ( 66.60)\tAcc@5  92.19 ( 89.63)\n","Epoch: [95][240/391]\tTime  0.090 ( 0.091)\tLoss 1.9329e+00 (1.5387e+00)\tAcc@1  10.94 ( 65.78)\tAcc@5  62.50 ( 89.25)\n","Epoch: [95][270/391]\tTime  0.085 ( 0.091)\tLoss 1.6286e+00 (1.5384e+00)\tAcc@1  75.00 ( 66.59)\tAcc@5  96.09 ( 89.60)\n","Epoch: [95][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9074e+00 (1.5354e+00)\tAcc@1   8.59 ( 66.61)\tAcc@5  50.00 ( 89.55)\n","Epoch: [95][330/391]\tTime  0.091 ( 0.091)\tLoss 1.4258e+00 (1.5457e+00)\tAcc@1  83.59 ( 66.28)\tAcc@5  96.88 ( 89.41)\n","Epoch: [95][360/391]\tTime  0.091 ( 0.091)\tLoss 1.0124e+00 (1.5414e+00)\tAcc@1  89.84 ( 66.51)\tAcc@5  99.22 ( 89.35)\n","Epoch: [95][390/391]\tTime  0.083 ( 0.091)\tLoss 1.9432e+00 (1.5357e+00)\tAcc@1  52.50 ( 66.70)\tAcc@5  87.50 ( 89.43)\n","==> Train Accuracy: Acc@1 66.700 || Acc@5 89.430\n","==> Test Accuracy:  Acc@1 79.460 || Acc@5 95.140\n","==> 37.92 seconds to train this epoch\n","\n","\n","----- epoch: 96, lr: 0.004000000000000001 -----\n","Epoch: [96][  0/391]\tTime  0.194 ( 0.194)\tLoss 1.9871e+00 (1.9871e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  85.94 ( 85.94)\n","Epoch: [96][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.9715e+00 (1.4594e+00)\tAcc@1  43.75 ( 70.09)\tAcc@5  82.81 ( 91.13)\n","Epoch: [96][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.8462e+00 (1.4638e+00)\tAcc@1  65.62 ( 69.40)\tAcc@5  92.19 ( 90.36)\n","Epoch: [96][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.9181e+00 (1.5355e+00)\tAcc@1  37.50 ( 65.26)\tAcc@5  76.56 ( 88.40)\n","Epoch: [96][120/391]\tTime  0.091 ( 0.091)\tLoss 1.4893e+00 (1.5156e+00)\tAcc@1  84.38 ( 67.50)\tAcc@5  97.66 ( 89.65)\n","Epoch: [96][150/391]\tTime  0.090 ( 0.091)\tLoss 5.3440e-01 (1.5082e+00)\tAcc@1  90.62 ( 67.78)\tAcc@5 100.00 ( 89.79)\n","Epoch: [96][180/391]\tTime  0.091 ( 0.091)\tLoss 1.5247e+00 (1.5161e+00)\tAcc@1  76.56 ( 68.22)\tAcc@5  94.53 ( 90.04)\n","Epoch: [96][210/391]\tTime  0.090 ( 0.091)\tLoss 1.2422e+00 (1.5135e+00)\tAcc@1  85.94 ( 67.82)\tAcc@5  98.44 ( 89.81)\n","Epoch: [96][240/391]\tTime  0.090 ( 0.091)\tLoss 1.8187e+00 (1.5087e+00)\tAcc@1  66.41 ( 67.87)\tAcc@5  92.97 ( 89.75)\n","Epoch: [96][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3381e+00 (1.5182e+00)\tAcc@1  86.72 ( 67.69)\tAcc@5 100.00 ( 89.83)\n","Epoch: [96][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6915e+00 (1.5188e+00)\tAcc@1  76.56 ( 67.36)\tAcc@5  93.75 ( 89.64)\n","Epoch: [96][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9654e+00 (1.5190e+00)\tAcc@1  62.50 ( 67.24)\tAcc@5  85.94 ( 89.53)\n","Epoch: [96][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5516e+00 (1.5172e+00)\tAcc@1  79.69 ( 67.56)\tAcc@5  95.31 ( 89.61)\n","Epoch: [96][390/391]\tTime  0.082 ( 0.091)\tLoss 1.3843e+00 (1.5196e+00)\tAcc@1  80.00 ( 66.74)\tAcc@5  98.75 ( 88.93)\n","==> Train Accuracy: Acc@1 66.740 || Acc@5 88.930\n","==> Test Accuracy:  Acc@1 79.560 || Acc@5 95.250\n","==> 37.84 seconds to train this epoch\n","\n","\n","----- epoch: 97, lr: 0.004000000000000001 -----\n","Epoch: [97][  0/391]\tTime  0.192 ( 0.192)\tLoss 1.8839e+00 (1.8839e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  79.69 ( 79.69)\n","Epoch: [97][ 30/391]\tTime  0.089 ( 0.093)\tLoss 1.6437e+00 (1.5330e+00)\tAcc@1  42.97 ( 64.84)\tAcc@5  89.84 ( 88.31)\n","Epoch: [97][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.5055e+00 (1.4789e+00)\tAcc@1  81.25 ( 67.82)\tAcc@5  97.66 ( 89.57)\n","Epoch: [97][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.8137e+00 (1.5047e+00)\tAcc@1  51.56 ( 66.10)\tAcc@5  85.94 ( 88.83)\n","Epoch: [97][120/391]\tTime  0.090 ( 0.091)\tLoss 3.3698e-01 (1.4936e+00)\tAcc@1  92.19 ( 67.94)\tAcc@5  99.22 ( 89.86)\n","Epoch: [97][150/391]\tTime  0.091 ( 0.091)\tLoss 1.1060e+00 (1.4838e+00)\tAcc@1  89.06 ( 68.28)\tAcc@5  99.22 ( 90.14)\n","Epoch: [97][180/391]\tTime  0.091 ( 0.091)\tLoss 6.4019e-01 (1.4546e+00)\tAcc@1  94.53 ( 69.49)\tAcc@5  98.44 ( 90.77)\n","Epoch: [97][210/391]\tTime  0.090 ( 0.091)\tLoss 1.6722e+00 (1.4725e+00)\tAcc@1  67.19 ( 68.45)\tAcc@5  89.06 ( 90.47)\n","Epoch: [97][240/391]\tTime  0.090 ( 0.091)\tLoss 9.9190e-01 (1.4767e+00)\tAcc@1  94.53 ( 68.71)\tAcc@5 100.00 ( 90.69)\n","Epoch: [97][270/391]\tTime  0.089 ( 0.091)\tLoss 1.7238e+00 (1.5009e+00)\tAcc@1  60.94 ( 68.01)\tAcc@5  91.41 ( 90.54)\n","Epoch: [97][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9306e+00 (1.5025e+00)\tAcc@1  43.75 ( 68.06)\tAcc@5  82.81 ( 90.52)\n","Epoch: [97][330/391]\tTime  0.091 ( 0.091)\tLoss 1.9049e+00 (1.4989e+00)\tAcc@1  64.06 ( 68.41)\tAcc@5  91.41 ( 90.71)\n","Epoch: [97][360/391]\tTime  0.093 ( 0.091)\tLoss 1.6090e+00 (1.4961e+00)\tAcc@1  81.25 ( 68.64)\tAcc@5  92.19 ( 90.76)\n","Epoch: [97][390/391]\tTime  0.081 ( 0.091)\tLoss 2.2551e+00 (1.4932e+00)\tAcc@1  15.00 ( 68.60)\tAcc@5  70.00 ( 90.73)\n","==> Train Accuracy: Acc@1 68.602 || Acc@5 90.726\n","==> Test Accuracy:  Acc@1 79.520 || Acc@5 95.340\n","==> 37.84 seconds to train this epoch\n","\n","\n","----- epoch: 98, lr: 0.004000000000000001 -----\n","Epoch: [98][  0/391]\tTime  0.186 ( 0.186)\tLoss 9.5454e-01 (9.5454e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n","Epoch: [98][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.9768e+00 (1.5360e+00)\tAcc@1  17.19 ( 65.83)\tAcc@5  74.22 ( 90.47)\n","Epoch: [98][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.4190e+00 (1.5266e+00)\tAcc@1  83.59 ( 66.57)\tAcc@5  96.88 ( 89.93)\n","Epoch: [98][ 90/391]\tTime  0.091 ( 0.091)\tLoss 1.6416e+00 (1.5084e+00)\tAcc@1  71.09 ( 67.61)\tAcc@5  93.75 ( 90.30)\n","Epoch: [98][120/391]\tTime  0.090 ( 0.091)\tLoss 1.7623e+00 (1.5016e+00)\tAcc@1  70.31 ( 67.15)\tAcc@5  92.97 ( 89.86)\n","Epoch: [98][150/391]\tTime  0.090 ( 0.091)\tLoss 1.5723e+00 (1.4508e+00)\tAcc@1  80.47 ( 68.45)\tAcc@5  95.31 ( 90.12)\n","Epoch: [98][180/391]\tTime  0.091 ( 0.091)\tLoss 1.9585e+00 (1.4675e+00)\tAcc@1  51.56 ( 67.85)\tAcc@5  82.03 ( 90.03)\n","Epoch: [98][210/391]\tTime  0.090 ( 0.091)\tLoss 1.1880e+00 (1.4789e+00)\tAcc@1  93.75 ( 67.77)\tAcc@5  99.22 ( 90.10)\n","Epoch: [98][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5892e+00 (1.4829e+00)\tAcc@1  84.38 ( 67.56)\tAcc@5  95.31 ( 90.11)\n","Epoch: [98][270/391]\tTime  0.090 ( 0.091)\tLoss 1.5760e+00 (1.4967e+00)\tAcc@1  27.34 ( 67.01)\tAcc@5  84.38 ( 89.94)\n","Epoch: [98][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7336e+00 (1.4877e+00)\tAcc@1  54.69 ( 67.40)\tAcc@5  89.84 ( 90.16)\n","Epoch: [98][330/391]\tTime  0.090 ( 0.091)\tLoss 8.6413e-01 (1.4812e+00)\tAcc@1  90.62 ( 67.31)\tAcc@5  98.44 ( 89.85)\n","Epoch: [98][360/391]\tTime  0.091 ( 0.091)\tLoss 1.7025e+00 (1.4909e+00)\tAcc@1   6.25 ( 67.05)\tAcc@5  30.47 ( 89.65)\n","Epoch: [98][390/391]\tTime  0.082 ( 0.091)\tLoss 1.8941e+00 (1.4922e+00)\tAcc@1   2.50 ( 66.55)\tAcc@5  13.75 ( 89.16)\n","==> Train Accuracy: Acc@1 66.552 || Acc@5 89.156\n","==> Test Accuracy:  Acc@1 78.900 || Acc@5 95.130\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 99, lr: 0.004000000000000001 -----\n","Epoch: [99][  0/391]\tTime  0.192 ( 0.192)\tLoss 6.5278e-01 (6.5278e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n","Epoch: [99][ 30/391]\tTime  0.092 ( 0.093)\tLoss 1.4917e+00 (1.4045e+00)\tAcc@1  85.16 ( 73.97)\tAcc@5  95.31 ( 93.40)\n","Epoch: [99][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.0786e+00 (1.4887e+00)\tAcc@1  90.62 ( 69.63)\tAcc@5  97.66 ( 91.10)\n","Epoch: [99][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.3063e+00 (1.4750e+00)\tAcc@1  89.84 ( 70.59)\tAcc@5  99.22 ( 91.82)\n","Epoch: [99][120/391]\tTime  0.090 ( 0.091)\tLoss 1.5633e+00 (1.4940e+00)\tAcc@1  71.09 ( 68.70)\tAcc@5  96.09 ( 90.56)\n","Epoch: [99][150/391]\tTime  0.090 ( 0.091)\tLoss 2.1455e+00 (1.4798e+00)\tAcc@1  42.19 ( 68.83)\tAcc@5  81.25 ( 90.53)\n","Epoch: [99][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6212e+00 (1.4653e+00)\tAcc@1  84.38 ( 69.68)\tAcc@5  96.09 ( 90.91)\n","Epoch: [99][210/391]\tTime  0.090 ( 0.091)\tLoss 1.9580e+00 (1.4696e+00)\tAcc@1  56.25 ( 69.01)\tAcc@5  82.03 ( 90.71)\n","Epoch: [99][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7442e+00 (1.4681e+00)\tAcc@1  75.00 ( 69.35)\tAcc@5  96.09 ( 90.85)\n","Epoch: [99][270/391]\tTime  0.090 ( 0.091)\tLoss 1.8206e+00 (1.4708e+00)\tAcc@1  57.03 ( 69.51)\tAcc@5  87.50 ( 90.94)\n","Epoch: [99][300/391]\tTime  0.086 ( 0.091)\tLoss 1.4603e+00 (1.4654e+00)\tAcc@1  86.72 ( 69.72)\tAcc@5  96.09 ( 91.06)\n","Epoch: [99][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9371e+00 (1.4793e+00)\tAcc@1  30.47 ( 68.78)\tAcc@5  75.00 ( 90.60)\n","Epoch: [99][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1969e+00 (1.4822e+00)\tAcc@1  89.84 ( 68.70)\tAcc@5  96.09 ( 90.55)\n","Epoch: [99][390/391]\tTime  0.081 ( 0.091)\tLoss 3.7701e-01 (1.4871e+00)\tAcc@1  88.75 ( 67.96)\tAcc@5 100.00 ( 90.36)\n","==> Train Accuracy: Acc@1 67.960 || Acc@5 90.358\n","==> Test Accuracy:  Acc@1 79.240 || Acc@5 95.210\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 100, lr: 0.004000000000000001 -----\n","Epoch: [100][  0/391]\tTime  0.204 ( 0.204)\tLoss 1.5850e+00 (1.5850e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5  96.88 ( 96.88)\n","Epoch: [100][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.6920e+00 (1.3201e+00)\tAcc@1  71.88 ( 75.25)\tAcc@5  92.97 ( 94.73)\n","Epoch: [100][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.8227e+00 (1.4256e+00)\tAcc@1  57.03 ( 70.57)\tAcc@5  89.84 ( 92.80)\n","Epoch: [100][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.4344e+00 (1.4123e+00)\tAcc@1  83.59 ( 71.12)\tAcc@5  97.66 ( 92.51)\n","Epoch: [100][120/391]\tTime  0.092 ( 0.091)\tLoss 7.2479e-01 (1.4433e+00)\tAcc@1  92.19 ( 68.91)\tAcc@5  99.22 ( 90.86)\n","Epoch: [100][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7314e+00 (1.4389e+00)\tAcc@1  69.53 ( 68.81)\tAcc@5  92.97 ( 90.68)\n","Epoch: [100][180/391]\tTime  0.090 ( 0.091)\tLoss 9.2420e-01 (1.4466e+00)\tAcc@1  94.53 ( 69.29)\tAcc@5  98.44 ( 91.08)\n","Epoch: [100][210/391]\tTime  0.089 ( 0.091)\tLoss 2.0536e+00 (1.4567e+00)\tAcc@1  25.78 ( 68.87)\tAcc@5  77.34 ( 90.84)\n","Epoch: [100][240/391]\tTime  0.090 ( 0.091)\tLoss 1.4365e+00 (1.4539e+00)\tAcc@1  87.50 ( 68.30)\tAcc@5  98.44 ( 90.39)\n","Epoch: [100][270/391]\tTime  0.090 ( 0.091)\tLoss 1.8291e+00 (1.4579e+00)\tAcc@1  43.75 ( 67.91)\tAcc@5  89.06 ( 90.16)\n","Epoch: [100][300/391]\tTime  0.091 ( 0.091)\tLoss 4.5426e-01 (1.4582e+00)\tAcc@1  94.53 ( 67.56)\tAcc@5 100.00 ( 89.77)\n","Epoch: [100][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5442e+00 (1.4658e+00)\tAcc@1  82.03 ( 67.42)\tAcc@5  96.09 ( 89.74)\n","Epoch: [100][360/391]\tTime  0.088 ( 0.091)\tLoss 1.7617e+00 (1.4713e+00)\tAcc@1  30.47 ( 66.62)\tAcc@5  78.91 ( 89.30)\n","Epoch: [100][390/391]\tTime  0.082 ( 0.091)\tLoss 1.6398e+00 (1.4791e+00)\tAcc@1  80.00 ( 66.05)\tAcc@5  90.00 ( 88.99)\n","==> Train Accuracy: Acc@1 66.048 || Acc@5 88.992\n","==> Test Accuracy:  Acc@1 79.650 || Acc@5 95.290\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 101, lr: 0.004000000000000001 -----\n","Epoch: [101][  0/391]\tTime  0.212 ( 0.212)\tLoss 1.4416e+00 (1.4416e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  95.31 ( 95.31)\n","Epoch: [101][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.6618e+00 (1.5619e+00)\tAcc@1  66.41 ( 54.86)\tAcc@5  92.97 ( 81.55)\n","Epoch: [101][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.5842e+00 (1.5044e+00)\tAcc@1  78.12 ( 61.40)\tAcc@5  96.88 ( 85.09)\n","Epoch: [101][ 90/391]\tTime  0.085 ( 0.092)\tLoss 1.7778e+00 (1.4946e+00)\tAcc@1  75.00 ( 63.28)\tAcc@5  91.41 ( 86.63)\n","Epoch: [101][120/391]\tTime  0.090 ( 0.091)\tLoss 1.8000e+00 (1.4658e+00)\tAcc@1  61.72 ( 65.99)\tAcc@5  92.19 ( 88.32)\n","Epoch: [101][150/391]\tTime  0.091 ( 0.091)\tLoss 1.3204e+00 (1.4517e+00)\tAcc@1  86.72 ( 66.28)\tAcc@5  96.09 ( 88.25)\n","Epoch: [101][180/391]\tTime  0.090 ( 0.091)\tLoss 1.9976e+00 (1.4566e+00)\tAcc@1  21.09 ( 66.30)\tAcc@5  60.94 ( 88.63)\n","Epoch: [101][210/391]\tTime  0.090 ( 0.091)\tLoss 7.9145e-01 (1.4670e+00)\tAcc@1  92.19 ( 66.28)\tAcc@5 100.00 ( 88.78)\n","Epoch: [101][240/391]\tTime  0.090 ( 0.091)\tLoss 9.9078e-01 (1.4575e+00)\tAcc@1  91.41 ( 66.57)\tAcc@5 100.00 ( 88.78)\n","Epoch: [101][270/391]\tTime  0.090 ( 0.091)\tLoss 1.7164e+00 (1.4711e+00)\tAcc@1  67.19 ( 67.14)\tAcc@5  94.53 ( 89.25)\n","Epoch: [101][300/391]\tTime  0.091 ( 0.091)\tLoss 7.8214e-01 (1.4700e+00)\tAcc@1  89.84 ( 66.75)\tAcc@5  98.44 ( 89.11)\n","Epoch: [101][330/391]\tTime  0.091 ( 0.091)\tLoss 1.1478e+00 (1.4713e+00)\tAcc@1  94.53 ( 66.68)\tAcc@5  99.22 ( 89.15)\n","Epoch: [101][360/391]\tTime  0.091 ( 0.091)\tLoss 1.4318e+00 (1.4738e+00)\tAcc@1  87.50 ( 67.06)\tAcc@5  97.66 ( 89.38)\n","Epoch: [101][390/391]\tTime  0.081 ( 0.091)\tLoss 8.3198e-01 (1.4695e+00)\tAcc@1  90.00 ( 67.16)\tAcc@5 100.00 ( 89.31)\n","==> Train Accuracy: Acc@1 67.164 || Acc@5 89.308\n","==> Test Accuracy:  Acc@1 79.460 || Acc@5 95.330\n","==> 38.04 seconds to train this epoch\n","\n","\n","----- epoch: 102, lr: 0.004000000000000001 -----\n","Epoch: [102][  0/391]\tTime  0.212 ( 0.212)\tLoss 2.1194e+00 (2.1194e+00)\tAcc@1   6.25 (  6.25)\tAcc@5  32.81 ( 32.81)\n","Epoch: [102][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.8201e+00 (1.3951e+00)\tAcc@1  55.47 ( 73.49)\tAcc@5  86.72 ( 91.89)\n","Epoch: [102][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.7038e+00 (1.4452e+00)\tAcc@1  69.53 ( 71.03)\tAcc@5  89.06 ( 91.03)\n","Epoch: [102][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.8411e+00 (1.3931e+00)\tAcc@1  50.00 ( 71.31)\tAcc@5  86.72 ( 91.55)\n","Epoch: [102][120/391]\tTime  0.091 ( 0.091)\tLoss 8.2834e-01 (1.4204e+00)\tAcc@1  95.31 ( 70.85)\tAcc@5  99.22 ( 91.71)\n","Epoch: [102][150/391]\tTime  0.090 ( 0.091)\tLoss 1.5968e+00 (1.4070e+00)\tAcc@1  72.66 ( 71.46)\tAcc@5  96.09 ( 91.93)\n","Epoch: [102][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6580e+00 (1.4249e+00)\tAcc@1  67.19 ( 69.72)\tAcc@5  92.97 ( 91.27)\n","Epoch: [102][210/391]\tTime  0.090 ( 0.091)\tLoss 1.9428e+00 (1.4353e+00)\tAcc@1  43.75 ( 68.69)\tAcc@5  85.94 ( 90.58)\n","Epoch: [102][240/391]\tTime  0.091 ( 0.091)\tLoss 2.0147e+00 (1.4444e+00)\tAcc@1  14.84 ( 68.45)\tAcc@5  68.75 ( 90.63)\n","Epoch: [102][270/391]\tTime  0.090 ( 0.091)\tLoss 1.0850e+00 (1.4442e+00)\tAcc@1  95.31 ( 68.55)\tAcc@5  99.22 ( 90.67)\n","Epoch: [102][300/391]\tTime  0.090 ( 0.091)\tLoss 2.0061e+00 (1.4453e+00)\tAcc@1  14.06 ( 68.75)\tAcc@5  57.03 ( 90.66)\n","Epoch: [102][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9949e+00 (1.4445e+00)\tAcc@1   7.03 ( 69.00)\tAcc@5  47.66 ( 90.72)\n","Epoch: [102][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8665e+00 (1.4454e+00)\tAcc@1  56.25 ( 68.45)\tAcc@5  88.28 ( 90.42)\n","Epoch: [102][390/391]\tTime  0.081 ( 0.091)\tLoss 1.4334e+00 (1.4501e+00)\tAcc@1  81.25 ( 67.95)\tAcc@5  98.75 ( 90.25)\n","==> Train Accuracy: Acc@1 67.954 || Acc@5 90.254\n","==> Test Accuracy:  Acc@1 78.960 || Acc@5 95.090\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 103, lr: 0.004000000000000001 -----\n","Epoch: [103][  0/391]\tTime  0.205 ( 0.205)\tLoss 1.4340e+00 (1.4340e+00)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n","Epoch: [103][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.2979e+00 (1.4251e+00)\tAcc@1  89.84 ( 68.37)\tAcc@5  96.88 ( 90.80)\n","Epoch: [103][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.7388e+00 (1.4352e+00)\tAcc@1  58.59 ( 68.07)\tAcc@5  93.75 ( 91.03)\n","Epoch: [103][ 90/391]\tTime  0.091 ( 0.092)\tLoss 5.6288e-01 (1.4512e+00)\tAcc@1  90.62 ( 67.71)\tAcc@5  99.22 ( 90.92)\n","Epoch: [103][120/391]\tTime  0.090 ( 0.091)\tLoss 1.3104e+00 (1.4397e+00)\tAcc@1  90.62 ( 67.43)\tAcc@5  96.09 ( 90.06)\n","Epoch: [103][150/391]\tTime  0.090 ( 0.091)\tLoss 1.9316e+00 (1.4517e+00)\tAcc@1  17.19 ( 67.96)\tAcc@5  67.97 ( 90.43)\n","Epoch: [103][180/391]\tTime  0.090 ( 0.091)\tLoss 1.1297e+00 (1.4565e+00)\tAcc@1  87.50 ( 67.50)\tAcc@5  96.88 ( 90.11)\n","Epoch: [103][210/391]\tTime  0.092 ( 0.091)\tLoss 1.8487e+00 (1.4389e+00)\tAcc@1   3.12 ( 68.26)\tAcc@5  39.84 ( 90.30)\n","Epoch: [103][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5614e+00 (1.4400e+00)\tAcc@1  77.34 ( 67.13)\tAcc@5  95.31 ( 89.58)\n","Epoch: [103][270/391]\tTime  0.090 ( 0.091)\tLoss 3.7105e-01 (1.4396e+00)\tAcc@1  94.53 ( 67.12)\tAcc@5  99.22 ( 89.56)\n","Epoch: [103][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4928e+00 (1.4377e+00)\tAcc@1  78.91 ( 67.58)\tAcc@5  95.31 ( 89.70)\n","Epoch: [103][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8402e+00 (1.4352e+00)\tAcc@1  46.09 ( 67.59)\tAcc@5  86.72 ( 89.68)\n","Epoch: [103][360/391]\tTime  0.091 ( 0.091)\tLoss 2.0492e+00 (1.4355e+00)\tAcc@1  32.81 ( 67.87)\tAcc@5  79.69 ( 89.83)\n","Epoch: [103][390/391]\tTime  0.082 ( 0.091)\tLoss 1.1797e+00 (1.4431e+00)\tAcc@1  87.50 ( 67.62)\tAcc@5  98.75 ( 89.81)\n","==> Train Accuracy: Acc@1 67.616 || Acc@5 89.812\n","==> Test Accuracy:  Acc@1 79.570 || Acc@5 95.440\n","==> 37.90 seconds to train this epoch\n","\n","\n","----- epoch: 104, lr: 0.004000000000000001 -----\n","Epoch: [104][  0/391]\tTime  0.211 ( 0.211)\tLoss 1.8209e+00 (1.8209e+00)\tAcc@1  33.59 ( 33.59)\tAcc@5  81.25 ( 81.25)\n","Epoch: [104][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.6351e+00 (1.4784e+00)\tAcc@1  74.22 ( 67.82)\tAcc@5  95.31 ( 88.61)\n","Epoch: [104][ 60/391]\tTime  0.091 ( 0.092)\tLoss 3.4644e-01 (1.4879e+00)\tAcc@1  96.09 ( 65.33)\tAcc@5  99.22 ( 87.59)\n","Epoch: [104][ 90/391]\tTime  0.090 ( 0.092)\tLoss 8.8299e-01 (1.5174e+00)\tAcc@1  95.31 ( 63.06)\tAcc@5 100.00 ( 87.10)\n","Epoch: [104][120/391]\tTime  0.090 ( 0.091)\tLoss 3.7447e-01 (1.4970e+00)\tAcc@1  95.31 ( 64.17)\tAcc@5  99.22 ( 87.69)\n","Epoch: [104][150/391]\tTime  0.090 ( 0.091)\tLoss 8.6332e-01 (1.4846e+00)\tAcc@1  90.62 ( 64.46)\tAcc@5 100.00 ( 87.54)\n","Epoch: [104][180/391]\tTime  0.090 ( 0.091)\tLoss 1.5670e+00 (1.4748e+00)\tAcc@1  80.47 ( 65.95)\tAcc@5  95.31 ( 88.59)\n","Epoch: [104][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6996e+00 (1.4555e+00)\tAcc@1  62.50 ( 66.94)\tAcc@5  95.31 ( 88.97)\n","Epoch: [104][240/391]\tTime  0.092 ( 0.091)\tLoss 7.0809e-01 (1.4627e+00)\tAcc@1  93.75 ( 67.20)\tAcc@5  99.22 ( 89.21)\n","Epoch: [104][270/391]\tTime  0.090 ( 0.091)\tLoss 4.8189e-01 (1.4713e+00)\tAcc@1  93.75 ( 66.16)\tAcc@5  99.22 ( 88.79)\n","Epoch: [104][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6244e+00 (1.4596e+00)\tAcc@1  61.72 ( 66.96)\tAcc@5  94.53 ( 89.11)\n","Epoch: [104][330/391]\tTime  0.090 ( 0.091)\tLoss 8.3670e-01 (1.4535e+00)\tAcc@1  87.50 ( 67.52)\tAcc@5  99.22 ( 89.40)\n","Epoch: [104][360/391]\tTime  0.091 ( 0.091)\tLoss 1.6189e+00 (1.4366e+00)\tAcc@1  80.47 ( 67.38)\tAcc@5  97.66 ( 89.32)\n","Epoch: [104][390/391]\tTime  0.087 ( 0.091)\tLoss 1.6811e+00 (1.4358e+00)\tAcc@1  66.25 ( 67.75)\tAcc@5  91.25 ( 89.43)\n","==> Train Accuracy: Acc@1 67.752 || Acc@5 89.428\n","==> Test Accuracy:  Acc@1 79.220 || Acc@5 95.220\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 105, lr: 0.004000000000000001 -----\n","Epoch: [105][  0/391]\tTime  0.208 ( 0.208)\tLoss 1.6304e+00 (1.6304e+00)\tAcc@1  78.12 ( 78.12)\tAcc@5  94.53 ( 94.53)\n","Epoch: [105][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.0145e+00 (1.2812e+00)\tAcc@1  92.19 ( 72.18)\tAcc@5  99.22 ( 90.10)\n","Epoch: [105][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.4129e+00 (1.3916e+00)\tAcc@1  85.16 ( 65.57)\tAcc@5  95.31 ( 87.09)\n","Epoch: [105][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.1972e+00 (1.3646e+00)\tAcc@1  90.62 ( 67.92)\tAcc@5  97.66 ( 88.74)\n","Epoch: [105][120/391]\tTime  0.091 ( 0.091)\tLoss 8.4056e-01 (1.3683e+00)\tAcc@1  93.75 ( 69.21)\tAcc@5 100.00 ( 89.81)\n","Epoch: [105][150/391]\tTime  0.090 ( 0.091)\tLoss 1.6335e+00 (1.4038e+00)\tAcc@1  73.44 ( 65.79)\tAcc@5  96.09 ( 88.37)\n","Epoch: [105][180/391]\tTime  0.092 ( 0.091)\tLoss 1.8918e+00 (1.4035e+00)\tAcc@1   9.38 ( 66.28)\tAcc@5  55.47 ( 88.19)\n","Epoch: [105][210/391]\tTime  0.091 ( 0.091)\tLoss 1.8212e+00 (1.4209e+00)\tAcc@1  65.62 ( 66.44)\tAcc@5  90.62 ( 88.57)\n","Epoch: [105][240/391]\tTime  0.092 ( 0.091)\tLoss 1.1665e+00 (1.4120e+00)\tAcc@1  92.97 ( 66.96)\tAcc@5  98.44 ( 88.81)\n","Epoch: [105][270/391]\tTime  0.091 ( 0.091)\tLoss 2.1120e+00 (1.4196e+00)\tAcc@1  11.72 ( 66.61)\tAcc@5  53.12 ( 88.63)\n","Epoch: [105][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6628e+00 (1.4276e+00)\tAcc@1  42.97 ( 66.50)\tAcc@5  82.81 ( 88.46)\n","Epoch: [105][330/391]\tTime  0.093 ( 0.091)\tLoss 1.0708e+00 (1.4259e+00)\tAcc@1  90.62 ( 66.61)\tAcc@5  98.44 ( 88.48)\n","Epoch: [105][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6458e+00 (1.4379e+00)\tAcc@1  40.62 ( 66.40)\tAcc@5  89.84 ( 88.68)\n","Epoch: [105][390/391]\tTime  0.082 ( 0.091)\tLoss 4.5219e-01 (1.4340e+00)\tAcc@1  92.50 ( 66.68)\tAcc@5  98.75 ( 88.80)\n","==> Train Accuracy: Acc@1 66.678 || Acc@5 88.804\n","==> Test Accuracy:  Acc@1 78.880 || Acc@5 94.930\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 106, lr: 0.004000000000000001 -----\n","Epoch: [106][  0/391]\tTime  0.202 ( 0.202)\tLoss 1.9285e+00 (1.9285e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  85.16 ( 85.16)\n","Epoch: [106][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.2967e+00 (1.4481e+00)\tAcc@1  89.84 ( 72.88)\tAcc@5 100.00 ( 92.57)\n","Epoch: [106][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.0143e+00 (1.4498e+00)\tAcc@1  20.31 ( 70.50)\tAcc@5  73.44 ( 90.79)\n","Epoch: [106][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.6674e+00 (1.4826e+00)\tAcc@1  68.75 ( 65.90)\tAcc@5  89.84 ( 89.09)\n","Epoch: [106][120/391]\tTime  0.090 ( 0.091)\tLoss 2.0246e+00 (1.5150e+00)\tAcc@1  35.16 ( 64.70)\tAcc@5  82.03 ( 88.55)\n","Epoch: [106][150/391]\tTime  0.087 ( 0.091)\tLoss 1.1740e+00 (1.5008e+00)\tAcc@1  89.84 ( 65.12)\tAcc@5  98.44 ( 88.70)\n","Epoch: [106][180/391]\tTime  0.092 ( 0.091)\tLoss 1.7618e+00 (1.4717e+00)\tAcc@1  64.84 ( 66.73)\tAcc@5  90.62 ( 89.38)\n","Epoch: [106][210/391]\tTime  0.090 ( 0.091)\tLoss 1.1563e+00 (1.4604e+00)\tAcc@1  89.84 ( 67.49)\tAcc@5 100.00 ( 89.65)\n","Epoch: [106][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1836e+00 (1.4724e+00)\tAcc@1  89.84 ( 66.93)\tAcc@5  96.88 ( 89.53)\n","Epoch: [106][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3238e+00 (1.4740e+00)\tAcc@1  91.41 ( 66.92)\tAcc@5  99.22 ( 89.49)\n","Epoch: [106][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6492e+00 (1.4714e+00)\tAcc@1  75.78 ( 67.03)\tAcc@5  97.66 ( 89.71)\n","Epoch: [106][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2169e+00 (1.4749e+00)\tAcc@1  89.84 ( 66.88)\tAcc@5 100.00 ( 89.75)\n","Epoch: [106][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5333e+00 (1.4753e+00)\tAcc@1  75.00 ( 66.41)\tAcc@5  96.88 ( 89.45)\n","Epoch: [106][390/391]\tTime  0.082 ( 0.091)\tLoss 9.0713e-01 (1.4762e+00)\tAcc@1  81.25 ( 66.29)\tAcc@5 100.00 ( 89.33)\n","==> Train Accuracy: Acc@1 66.286 || Acc@5 89.334\n","==> Test Accuracy:  Acc@1 79.360 || Acc@5 95.370\n","==> 37.88 seconds to train this epoch\n","\n","\n","----- epoch: 107, lr: 0.004000000000000001 -----\n","Epoch: [107][  0/391]\tTime  0.202 ( 0.202)\tLoss 1.7887e+00 (1.7887e+00)\tAcc@1  38.28 ( 38.28)\tAcc@5  79.69 ( 79.69)\n","Epoch: [107][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.9872e+00 (1.4520e+00)\tAcc@1  21.09 ( 69.10)\tAcc@5  64.84 ( 90.78)\n","Epoch: [107][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.9841e+00 (1.4464e+00)\tAcc@1  57.81 ( 69.06)\tAcc@5  88.28 ( 90.00)\n","Epoch: [107][ 90/391]\tTime  0.090 ( 0.092)\tLoss 8.4967e-01 (1.4199e+00)\tAcc@1  92.19 ( 69.31)\tAcc@5  99.22 ( 89.72)\n","Epoch: [107][120/391]\tTime  0.093 ( 0.091)\tLoss 2.0095e+00 (1.4188e+00)\tAcc@1  11.72 ( 68.56)\tAcc@5  63.28 ( 89.55)\n","Epoch: [107][150/391]\tTime  0.088 ( 0.091)\tLoss 1.6663e+00 (1.4353e+00)\tAcc@1  77.34 ( 67.50)\tAcc@5  94.53 ( 89.31)\n","Epoch: [107][180/391]\tTime  0.091 ( 0.091)\tLoss 1.4192e+00 (1.4352e+00)\tAcc@1  84.38 ( 67.49)\tAcc@5  96.88 ( 89.58)\n","Epoch: [107][210/391]\tTime  0.093 ( 0.091)\tLoss 2.0914e-01 (1.4426e+00)\tAcc@1  96.88 ( 67.47)\tAcc@5  99.22 ( 89.55)\n","Epoch: [107][240/391]\tTime  0.090 ( 0.091)\tLoss 1.8415e+00 (1.4367e+00)\tAcc@1   2.34 ( 67.53)\tAcc@5  32.03 ( 89.47)\n","Epoch: [107][270/391]\tTime  0.091 ( 0.091)\tLoss 9.0679e-01 (1.4454e+00)\tAcc@1  91.41 ( 66.46)\tAcc@5  99.22 ( 89.13)\n","Epoch: [107][300/391]\tTime  0.091 ( 0.091)\tLoss 1.3423e+00 (1.4433e+00)\tAcc@1  86.72 ( 66.75)\tAcc@5  96.88 ( 89.21)\n","Epoch: [107][330/391]\tTime  0.089 ( 0.091)\tLoss 2.6238e-01 (1.4401e+00)\tAcc@1  93.75 ( 67.03)\tAcc@5  99.22 ( 89.31)\n","Epoch: [107][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6332e+00 (1.4410e+00)\tAcc@1  59.38 ( 67.45)\tAcc@5  92.97 ( 89.59)\n","Epoch: [107][390/391]\tTime  0.082 ( 0.091)\tLoss 1.9132e+00 (1.4519e+00)\tAcc@1  63.75 ( 67.25)\tAcc@5  87.50 ( 89.56)\n","==> Train Accuracy: Acc@1 67.252 || Acc@5 89.556\n","==> Test Accuracy:  Acc@1 78.550 || Acc@5 95.110\n","==> 37.90 seconds to train this epoch\n","\n","\n","----- epoch: 108, lr: 0.004000000000000001 -----\n","Epoch: [108][  0/391]\tTime  0.197 ( 0.197)\tLoss 1.4979e+00 (1.4979e+00)\tAcc@1  82.03 ( 82.03)\tAcc@5  95.31 ( 95.31)\n","Epoch: [108][ 30/391]\tTime  0.091 ( 0.093)\tLoss 1.2733e+00 (1.2647e+00)\tAcc@1  90.62 ( 74.09)\tAcc@5  96.88 ( 91.51)\n","Epoch: [108][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.5560e+00 (1.2703e+00)\tAcc@1  65.62 ( 73.12)\tAcc@5  93.75 ( 92.09)\n","Epoch: [108][ 90/391]\tTime  0.090 ( 0.092)\tLoss 5.4352e-01 (1.3338e+00)\tAcc@1  95.31 ( 71.10)\tAcc@5  98.44 ( 91.53)\n","Epoch: [108][120/391]\tTime  0.091 ( 0.091)\tLoss 1.2428e+00 (1.3381e+00)\tAcc@1  84.38 ( 71.91)\tAcc@5  97.66 ( 91.90)\n","Epoch: [108][150/391]\tTime  0.092 ( 0.091)\tLoss 2.0216e+00 (1.3835e+00)\tAcc@1  34.38 ( 70.78)\tAcc@5  80.47 ( 91.66)\n","Epoch: [108][180/391]\tTime  0.091 ( 0.091)\tLoss 1.6432e+00 (1.3894e+00)\tAcc@1  74.22 ( 70.52)\tAcc@5  92.97 ( 91.51)\n","Epoch: [108][210/391]\tTime  0.090 ( 0.091)\tLoss 4.6830e-01 (1.3963e+00)\tAcc@1  92.19 ( 70.29)\tAcc@5  98.44 ( 91.43)\n","Epoch: [108][240/391]\tTime  0.091 ( 0.091)\tLoss 9.7323e-01 (1.4004e+00)\tAcc@1  89.06 ( 69.99)\tAcc@5 100.00 ( 91.46)\n","Epoch: [108][270/391]\tTime  0.090 ( 0.091)\tLoss 1.2912e+00 (1.3975e+00)\tAcc@1  92.97 ( 70.49)\tAcc@5  97.66 ( 91.63)\n","Epoch: [108][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8146e+00 (1.3977e+00)\tAcc@1  73.44 ( 70.81)\tAcc@5  92.97 ( 91.67)\n","Epoch: [108][330/391]\tTime  0.085 ( 0.091)\tLoss 1.6336e+00 (1.3964e+00)\tAcc@1  76.56 ( 70.59)\tAcc@5  96.88 ( 91.58)\n","Epoch: [108][360/391]\tTime  0.090 ( 0.091)\tLoss 2.0365e-01 (1.3829e+00)\tAcc@1  94.53 ( 70.86)\tAcc@5  99.22 ( 91.74)\n","Epoch: [108][390/391]\tTime  0.081 ( 0.091)\tLoss 1.7297e+00 (1.3920e+00)\tAcc@1  57.50 ( 70.47)\tAcc@5  83.75 ( 91.58)\n","==> Train Accuracy: Acc@1 70.474 || Acc@5 91.584\n","==> Test Accuracy:  Acc@1 78.980 || Acc@5 95.140\n","==> 37.86 seconds to train this epoch\n","\n","\n","----- epoch: 109, lr: 0.004000000000000001 -----\n","Epoch: [109][  0/391]\tTime  0.190 ( 0.190)\tLoss 1.8447e+00 (1.8447e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.16 ( 85.16)\n","Epoch: [109][ 30/391]\tTime  0.090 ( 0.093)\tLoss 1.3516e+00 (1.4423e+00)\tAcc@1  80.47 ( 66.53)\tAcc@5  96.09 ( 90.30)\n","Epoch: [109][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.4931e+00 (1.4819e+00)\tAcc@1  82.81 ( 66.09)\tAcc@5  96.88 ( 90.46)\n","Epoch: [109][ 90/391]\tTime  0.091 ( 0.091)\tLoss 6.9148e-01 (1.5034e+00)\tAcc@1  95.31 ( 65.73)\tAcc@5  99.22 ( 90.56)\n","Epoch: [109][120/391]\tTime  0.090 ( 0.091)\tLoss 1.1000e+00 (1.5106e+00)\tAcc@1  96.09 ( 65.95)\tAcc@5  99.22 ( 90.95)\n","Epoch: [109][150/391]\tTime  0.090 ( 0.091)\tLoss 9.5421e-01 (1.4895e+00)\tAcc@1  95.31 ( 65.44)\tAcc@5  98.44 ( 90.20)\n","Epoch: [109][180/391]\tTime  0.090 ( 0.091)\tLoss 1.5761e+00 (1.4611e+00)\tAcc@1  78.91 ( 67.43)\tAcc@5  97.66 ( 90.62)\n","Epoch: [109][210/391]\tTime  0.091 ( 0.091)\tLoss 1.4322e+00 (1.4470e+00)\tAcc@1  83.59 ( 68.44)\tAcc@5  96.88 ( 90.94)\n","Epoch: [109][240/391]\tTime  0.090 ( 0.091)\tLoss 1.8987e+00 (1.4450e+00)\tAcc@1  29.69 ( 68.64)\tAcc@5  78.12 ( 91.15)\n","Epoch: [109][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6272e+00 (1.4319e+00)\tAcc@1  57.81 ( 69.17)\tAcc@5  92.97 ( 91.34)\n","Epoch: [109][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4284e+00 (1.4267e+00)\tAcc@1  86.72 ( 68.78)\tAcc@5  99.22 ( 91.11)\n","Epoch: [109][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6188e+00 (1.4264e+00)\tAcc@1  78.91 ( 69.26)\tAcc@5  95.31 ( 91.17)\n","Epoch: [109][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5282e+00 (1.4264e+00)\tAcc@1   4.69 ( 69.19)\tAcc@5  36.72 ( 91.03)\n","Epoch: [109][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7348e+00 (1.4313e+00)\tAcc@1  60.00 ( 69.06)\tAcc@5  91.25 ( 90.97)\n","==> Train Accuracy: Acc@1 69.056 || Acc@5 90.966\n","==> Test Accuracy:  Acc@1 78.950 || Acc@5 95.270\n","==> 37.82 seconds to train this epoch\n","\n","\n","----- epoch: 110, lr: 0.004000000000000001 -----\n","Epoch: [110][  0/391]\tTime  0.209 ( 0.209)\tLoss 1.0923e+00 (1.0923e+00)\tAcc@1  91.41 ( 91.41)\tAcc@5  97.66 ( 97.66)\n","Epoch: [110][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.5948e+00 (1.4951e+00)\tAcc@1  79.69 ( 62.65)\tAcc@5  96.09 ( 88.03)\n","Epoch: [110][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.4250e+00 (1.4325e+00)\tAcc@1  78.12 ( 66.82)\tAcc@5  96.88 ( 90.33)\n","Epoch: [110][ 90/391]\tTime  0.091 ( 0.091)\tLoss 1.6707e+00 (1.4590e+00)\tAcc@1  46.88 ( 65.65)\tAcc@5  87.50 ( 89.99)\n","Epoch: [110][120/391]\tTime  0.089 ( 0.091)\tLoss 1.9261e+00 (1.4801e+00)\tAcc@1  32.81 ( 64.68)\tAcc@5  82.81 ( 89.82)\n","Epoch: [110][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7073e+00 (1.4686e+00)\tAcc@1  60.16 ( 65.29)\tAcc@5  90.62 ( 89.69)\n","Epoch: [110][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6694e+00 (1.4675e+00)\tAcc@1  71.09 ( 65.38)\tAcc@5  92.97 ( 89.76)\n","Epoch: [110][210/391]\tTime  0.094 ( 0.091)\tLoss 1.5063e+00 (1.4843e+00)\tAcc@1  83.59 ( 64.37)\tAcc@5  96.09 ( 89.31)\n","Epoch: [110][240/391]\tTime  0.090 ( 0.091)\tLoss 1.4187e+00 (1.4686e+00)\tAcc@1  83.59 ( 64.83)\tAcc@5  96.09 ( 89.31)\n","Epoch: [110][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6654e+00 (1.4683e+00)\tAcc@1  49.22 ( 64.81)\tAcc@5  88.28 ( 89.25)\n","Epoch: [110][300/391]\tTime  0.093 ( 0.091)\tLoss 1.6840e+00 (1.4593e+00)\tAcc@1  59.38 ( 65.85)\tAcc@5  92.97 ( 89.68)\n","Epoch: [110][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2199e+00 (1.4463e+00)\tAcc@1  84.38 ( 66.20)\tAcc@5  97.66 ( 89.77)\n","Epoch: [110][360/391]\tTime  0.087 ( 0.091)\tLoss 1.8963e+00 (1.4316e+00)\tAcc@1  21.09 ( 67.00)\tAcc@5  67.97 ( 90.13)\n","Epoch: [110][390/391]\tTime  0.082 ( 0.091)\tLoss 9.9163e-01 (1.4326e+00)\tAcc@1  93.75 ( 67.24)\tAcc@5  98.75 ( 90.27)\n","==> Train Accuracy: Acc@1 67.242 || Acc@5 90.270\n","==> Test Accuracy:  Acc@1 78.980 || Acc@5 94.970\n","==> 37.82 seconds to train this epoch\n","\n","\n","----- epoch: 111, lr: 0.004000000000000001 -----\n","Epoch: [111][  0/391]\tTime  0.202 ( 0.202)\tLoss 6.9764e-01 (6.9764e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n","Epoch: [111][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.1417e+00 (1.4784e+00)\tAcc@1  94.53 ( 61.44)\tAcc@5  99.22 ( 86.54)\n","Epoch: [111][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.4869e+00 (1.3997e+00)\tAcc@1  82.81 ( 66.46)\tAcc@5  96.88 ( 89.33)\n","Epoch: [111][ 90/391]\tTime  0.090 ( 0.091)\tLoss 8.6449e-01 (1.4238e+00)\tAcc@1  92.97 ( 65.80)\tAcc@5  99.22 ( 89.30)\n","Epoch: [111][120/391]\tTime  0.090 ( 0.091)\tLoss 1.8248e+00 (1.3990e+00)\tAcc@1  21.09 ( 67.04)\tAcc@5  71.88 ( 89.73)\n","Epoch: [111][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2227e+00 (1.4072e+00)\tAcc@1  92.19 ( 67.49)\tAcc@5  99.22 ( 90.09)\n","Epoch: [111][180/391]\tTime  0.090 ( 0.091)\tLoss 8.1821e-01 (1.3948e+00)\tAcc@1  96.88 ( 68.53)\tAcc@5  99.22 ( 90.58)\n","Epoch: [111][210/391]\tTime  0.090 ( 0.091)\tLoss 7.2031e-01 (1.4013e+00)\tAcc@1  90.62 ( 67.63)\tAcc@5  99.22 ( 90.14)\n","Epoch: [111][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7368e+00 (1.4081e+00)\tAcc@1  17.97 ( 67.87)\tAcc@5  69.53 ( 90.45)\n","Epoch: [111][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6335e+00 (1.4010e+00)\tAcc@1   6.25 ( 67.45)\tAcc@5  37.50 ( 89.88)\n","Epoch: [111][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8554e+00 (1.3999e+00)\tAcc@1  56.25 ( 67.49)\tAcc@5  83.59 ( 89.65)\n","Epoch: [111][330/391]\tTime  0.090 ( 0.091)\tLoss 2.0758e+00 (1.3999e+00)\tAcc@1  21.09 ( 67.44)\tAcc@5  71.09 ( 89.66)\n","Epoch: [111][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7774e+00 (1.3935e+00)\tAcc@1  29.69 ( 67.67)\tAcc@5  78.12 ( 89.71)\n","Epoch: [111][390/391]\tTime  0.081 ( 0.090)\tLoss 1.6130e+00 (1.3956e+00)\tAcc@1  81.25 ( 67.93)\tAcc@5  97.50 ( 89.95)\n","==> Train Accuracy: Acc@1 67.926 || Acc@5 89.954\n","==> Test Accuracy:  Acc@1 78.630 || Acc@5 95.000\n","==> 37.81 seconds to train this epoch\n","\n","\n","----- epoch: 112, lr: 0.004000000000000001 -----\n","Epoch: [112][  0/391]\tTime  0.190 ( 0.190)\tLoss 1.6087e+00 (1.6087e+00)\tAcc@1  78.12 ( 78.12)\tAcc@5  95.31 ( 95.31)\n","Epoch: [112][ 30/391]\tTime  0.091 ( 0.093)\tLoss 1.2846e+00 (1.5387e+00)\tAcc@1  89.84 ( 60.66)\tAcc@5 100.00 ( 88.79)\n","Epoch: [112][ 60/391]\tTime  0.090 ( 0.092)\tLoss 4.5103e-01 (1.4090e+00)\tAcc@1  94.53 ( 64.32)\tAcc@5 100.00 ( 88.70)\n","Epoch: [112][ 90/391]\tTime  0.090 ( 0.091)\tLoss 9.6041e-01 (1.4458e+00)\tAcc@1  95.31 ( 61.38)\tAcc@5 100.00 ( 87.12)\n","Epoch: [112][120/391]\tTime  0.090 ( 0.091)\tLoss 1.8003e+00 (1.3728e+00)\tAcc@1  59.38 ( 64.89)\tAcc@5  85.94 ( 88.70)\n","Epoch: [112][150/391]\tTime  0.090 ( 0.091)\tLoss 2.9805e-01 (1.3917e+00)\tAcc@1  93.75 ( 63.73)\tAcc@5  99.22 ( 88.06)\n","Epoch: [112][180/391]\tTime  0.090 ( 0.091)\tLoss 8.5748e-01 (1.4086e+00)\tAcc@1  94.53 ( 63.89)\tAcc@5  99.22 ( 88.33)\n","Epoch: [112][210/391]\tTime  0.090 ( 0.091)\tLoss 6.7918e-01 (1.4107e+00)\tAcc@1  93.75 ( 64.55)\tAcc@5  99.22 ( 88.64)\n","Epoch: [112][240/391]\tTime  0.090 ( 0.091)\tLoss 2.9475e-01 (1.4078e+00)\tAcc@1  96.88 ( 65.71)\tAcc@5 100.00 ( 89.03)\n","Epoch: [112][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8280e+00 (1.3961e+00)\tAcc@1   7.03 ( 66.19)\tAcc@5  56.25 ( 89.21)\n","Epoch: [112][300/391]\tTime  0.090 ( 0.091)\tLoss 9.8669e-01 (1.4051e+00)\tAcc@1  92.19 ( 66.43)\tAcc@5  98.44 ( 89.38)\n","Epoch: [112][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5823e+00 (1.4106e+00)\tAcc@1  73.44 ( 66.18)\tAcc@5  96.09 ( 89.29)\n","Epoch: [112][360/391]\tTime  0.091 ( 0.091)\tLoss 3.1272e-01 (1.4076e+00)\tAcc@1  92.97 ( 66.78)\tAcc@5  99.22 ( 89.54)\n","Epoch: [112][390/391]\tTime  0.084 ( 0.091)\tLoss 1.4432e+00 (1.4091e+00)\tAcc@1  86.25 ( 66.72)\tAcc@5  97.50 ( 89.58)\n","==> Train Accuracy: Acc@1 66.720 || Acc@5 89.578\n","==> Test Accuracy:  Acc@1 78.800 || Acc@5 94.980\n","==> 37.85 seconds to train this epoch\n","\n","\n","----- epoch: 113, lr: 0.004000000000000001 -----\n","Epoch: [113][  0/391]\tTime  0.192 ( 0.192)\tLoss 1.1660e+00 (1.1660e+00)\tAcc@1  90.62 ( 90.62)\tAcc@5  98.44 ( 98.44)\n","Epoch: [113][ 30/391]\tTime  0.090 ( 0.093)\tLoss 1.1889e+00 (1.4176e+00)\tAcc@1  88.28 ( 73.16)\tAcc@5  97.66 ( 92.84)\n","Epoch: [113][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.5519e+00 (1.4488e+00)\tAcc@1  82.03 ( 69.47)\tAcc@5  96.88 ( 91.65)\n","Epoch: [113][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.4396e+00 (1.3796e+00)\tAcc@1  74.22 ( 72.23)\tAcc@5  96.09 ( 92.59)\n","Epoch: [113][120/391]\tTime  0.090 ( 0.091)\tLoss 1.1752e+00 (1.3992e+00)\tAcc@1  86.72 ( 71.08)\tAcc@5  98.44 ( 92.01)\n","Epoch: [113][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7984e+00 (1.3839e+00)\tAcc@1  71.09 ( 70.28)\tAcc@5  89.06 ( 90.97)\n","Epoch: [113][180/391]\tTime  0.090 ( 0.091)\tLoss 8.3387e-01 (1.3854e+00)\tAcc@1  92.97 ( 70.38)\tAcc@5  99.22 ( 91.07)\n","Epoch: [113][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8863e+00 (1.3967e+00)\tAcc@1  22.66 ( 69.68)\tAcc@5  80.47 ( 90.90)\n","Epoch: [113][240/391]\tTime  0.092 ( 0.091)\tLoss 1.7913e+00 (1.3970e+00)\tAcc@1  16.41 ( 69.55)\tAcc@5  66.41 ( 91.10)\n","Epoch: [113][270/391]\tTime  0.091 ( 0.091)\tLoss 1.0498e+00 (1.3814e+00)\tAcc@1  93.75 ( 70.16)\tAcc@5  98.44 ( 91.17)\n","Epoch: [113][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8893e+00 (1.3957e+00)\tAcc@1  46.88 ( 69.26)\tAcc@5  82.81 ( 90.77)\n","Epoch: [113][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9707e+00 (1.4049e+00)\tAcc@1  50.00 ( 68.84)\tAcc@5  82.03 ( 90.47)\n","Epoch: [113][360/391]\tTime  0.090 ( 0.091)\tLoss 8.3199e-01 (1.4062e+00)\tAcc@1  95.31 ( 68.85)\tAcc@5  99.22 ( 90.51)\n","Epoch: [113][390/391]\tTime  0.081 ( 0.091)\tLoss 1.6987e+00 (1.4065e+00)\tAcc@1  78.75 ( 68.99)\tAcc@5  95.00 ( 90.56)\n","==> Train Accuracy: Acc@1 68.988 || Acc@5 90.558\n","==> Test Accuracy:  Acc@1 79.050 || Acc@5 95.050\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 114, lr: 0.004000000000000001 -----\n","Epoch: [114][  0/391]\tTime  0.220 ( 0.220)\tLoss 1.9971e+00 (1.9971e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  60.16 ( 60.16)\n","Epoch: [114][ 30/391]\tTime  0.090 ( 0.094)\tLoss 2.1249e+00 (1.3329e+00)\tAcc@1  17.19 ( 69.35)\tAcc@5  68.75 ( 90.10)\n","Epoch: [114][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.7104e+00 (1.3794e+00)\tAcc@1  57.81 ( 66.89)\tAcc@5  90.62 ( 89.13)\n","Epoch: [114][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.1229e+00 (1.3466e+00)\tAcc@1  88.28 ( 69.99)\tAcc@5  95.31 ( 90.77)\n","Epoch: [114][120/391]\tTime  0.092 ( 0.091)\tLoss 1.0641e+00 (1.3859e+00)\tAcc@1  92.97 ( 67.78)\tAcc@5  99.22 ( 89.75)\n","Epoch: [114][150/391]\tTime  0.090 ( 0.091)\tLoss 1.1306e+00 (1.3896e+00)\tAcc@1  92.97 ( 68.81)\tAcc@5  99.22 ( 90.54)\n","Epoch: [114][180/391]\tTime  0.090 ( 0.091)\tLoss 4.1220e-01 (1.4054e+00)\tAcc@1  92.97 ( 68.71)\tAcc@5  99.22 ( 90.72)\n","Epoch: [114][210/391]\tTime  0.091 ( 0.091)\tLoss 1.1179e+00 (1.4213e+00)\tAcc@1   2.34 ( 67.41)\tAcc@5   5.47 ( 89.62)\n","Epoch: [114][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7090e+00 (1.4211e+00)\tAcc@1  61.72 ( 67.39)\tAcc@5  90.62 ( 89.64)\n","Epoch: [114][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6359e+00 (1.4258e+00)\tAcc@1  71.88 ( 67.91)\tAcc@5  94.53 ( 90.10)\n","Epoch: [114][300/391]\tTime  0.090 ( 0.091)\tLoss 1.7209e+00 (1.4229e+00)\tAcc@1  52.34 ( 68.14)\tAcc@5  93.75 ( 90.39)\n","Epoch: [114][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5669e+00 (1.4267e+00)\tAcc@1   1.56 ( 67.45)\tAcc@5  42.19 ( 89.87)\n","Epoch: [114][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1146e+00 (1.4277e+00)\tAcc@1  89.06 ( 67.58)\tAcc@5  97.66 ( 89.97)\n","Epoch: [114][390/391]\tTime  0.082 ( 0.091)\tLoss 1.6866e+00 (1.4265e+00)\tAcc@1  76.25 ( 67.50)\tAcc@5  95.00 ( 90.03)\n","==> Train Accuracy: Acc@1 67.502 || Acc@5 90.026\n","==> Test Accuracy:  Acc@1 78.150 || Acc@5 94.720\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 115, lr: 0.004000000000000001 -----\n","Epoch: [115][  0/391]\tTime  0.208 ( 0.208)\tLoss 1.5337e+00 (1.5337e+00)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.88 ( 96.88)\n","Epoch: [115][ 30/391]\tTime  0.090 ( 0.094)\tLoss 9.7649e-01 (1.4318e+00)\tAcc@1  93.75 ( 70.29)\tAcc@5 100.00 ( 90.17)\n","Epoch: [115][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.9731e+00 (1.4318e+00)\tAcc@1  57.03 ( 68.63)\tAcc@5  89.06 ( 90.60)\n","Epoch: [115][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.1186e+00 (1.4064e+00)\tAcc@1  89.84 ( 69.36)\tAcc@5  99.22 ( 90.92)\n","Epoch: [115][120/391]\tTime  0.091 ( 0.091)\tLoss 7.1372e-01 (1.4067e+00)\tAcc@1  97.66 ( 70.19)\tAcc@5  99.22 ( 91.24)\n","Epoch: [115][150/391]\tTime  0.091 ( 0.091)\tLoss 3.6166e-01 (1.4014e+00)\tAcc@1  93.75 ( 71.06)\tAcc@5  99.22 ( 91.59)\n","Epoch: [115][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6972e+00 (1.4214e+00)\tAcc@1  67.97 ( 70.85)\tAcc@5  93.75 ( 91.72)\n","Epoch: [115][210/391]\tTime  0.090 ( 0.091)\tLoss 1.4899e+00 (1.4336e+00)\tAcc@1  82.81 ( 69.88)\tAcc@5  96.09 ( 91.26)\n","Epoch: [115][240/391]\tTime  0.091 ( 0.091)\tLoss 1.6848e+00 (1.4340e+00)\tAcc@1  64.84 ( 68.78)\tAcc@5  90.62 ( 90.46)\n","Epoch: [115][270/391]\tTime  0.092 ( 0.091)\tLoss 8.2437e-01 (1.4201e+00)\tAcc@1  92.97 ( 69.07)\tAcc@5  98.44 ( 90.50)\n","Epoch: [115][300/391]\tTime  0.090 ( 0.091)\tLoss 1.7476e+00 (1.4258e+00)\tAcc@1  40.62 ( 68.26)\tAcc@5  85.94 ( 90.01)\n","Epoch: [115][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6243e+00 (1.4258e+00)\tAcc@1   1.56 ( 68.48)\tAcc@5  35.16 ( 90.05)\n","Epoch: [115][360/391]\tTime  0.091 ( 0.091)\tLoss 1.9347e+00 (1.4262e+00)\tAcc@1  20.31 ( 68.22)\tAcc@5  71.88 ( 90.13)\n","Epoch: [115][390/391]\tTime  0.081 ( 0.091)\tLoss 2.7249e-01 (1.4176e+00)\tAcc@1  96.25 ( 68.30)\tAcc@5  97.50 ( 90.12)\n","==> Train Accuracy: Acc@1 68.300 || Acc@5 90.120\n","==> Test Accuracy:  Acc@1 77.960 || Acc@5 94.700\n","==> 37.98 seconds to train this epoch\n","\n","\n","----- epoch: 116, lr: 0.004000000000000001 -----\n","Epoch: [116][  0/391]\tTime  0.193 ( 0.193)\tLoss 1.3124e+00 (1.3124e+00)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n","Epoch: [116][ 30/391]\tTime  0.090 ( 0.093)\tLoss 6.9345e-01 (1.3631e+00)\tAcc@1  94.53 ( 66.94)\tAcc@5  98.44 ( 91.38)\n","Epoch: [116][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.4112e+00 (1.3911e+00)\tAcc@1  84.38 ( 65.20)\tAcc@5  97.66 ( 89.64)\n","Epoch: [116][ 90/391]\tTime  0.091 ( 0.091)\tLoss 1.6455e+00 (1.3921e+00)\tAcc@1  76.56 ( 66.69)\tAcc@5  93.75 ( 90.16)\n","Epoch: [116][120/391]\tTime  0.093 ( 0.091)\tLoss 6.1064e-01 (1.3881e+00)\tAcc@1  93.75 ( 66.97)\tAcc@5  98.44 ( 89.80)\n","Epoch: [116][150/391]\tTime  0.091 ( 0.091)\tLoss 1.4135e+00 (1.4040e+00)\tAcc@1  90.62 ( 67.25)\tAcc@5  98.44 ( 90.44)\n","Epoch: [116][180/391]\tTime  0.091 ( 0.091)\tLoss 1.1744e+00 (1.4130e+00)\tAcc@1  89.84 ( 66.88)\tAcc@5  98.44 ( 90.19)\n","Epoch: [116][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6269e+00 (1.4209e+00)\tAcc@1  69.53 ( 66.54)\tAcc@5  94.53 ( 89.84)\n","Epoch: [116][240/391]\tTime  0.090 ( 0.091)\tLoss 1.9665e+00 (1.4126e+00)\tAcc@1  13.28 ( 66.87)\tAcc@5  54.69 ( 89.85)\n","Epoch: [116][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6318e+00 (1.4189e+00)\tAcc@1  18.75 ( 66.55)\tAcc@5  72.66 ( 89.75)\n","Epoch: [116][300/391]\tTime  0.091 ( 0.091)\tLoss 1.3383e+00 (1.4124e+00)\tAcc@1  81.25 ( 66.93)\tAcc@5  96.88 ( 89.72)\n","Epoch: [116][330/391]\tTime  0.091 ( 0.091)\tLoss 1.6921e+00 (1.4154e+00)\tAcc@1  45.31 ( 66.86)\tAcc@5  90.62 ( 89.76)\n","Epoch: [116][360/391]\tTime  0.090 ( 0.091)\tLoss 4.3464e-01 (1.4254e+00)\tAcc@1  95.31 ( 66.63)\tAcc@5  99.22 ( 89.77)\n","Epoch: [116][390/391]\tTime  0.081 ( 0.091)\tLoss 7.3524e-01 (1.4241e+00)\tAcc@1  92.50 ( 67.12)\tAcc@5 100.00 ( 89.93)\n","==> Train Accuracy: Acc@1 67.118 || Acc@5 89.934\n","==> Test Accuracy:  Acc@1 78.880 || Acc@5 94.930\n","==> 37.88 seconds to train this epoch\n","\n","\n","----- epoch: 117, lr: 0.004000000000000001 -----\n","Epoch: [117][  0/391]\tTime  0.194 ( 0.194)\tLoss 1.3654e+00 (1.3654e+00)\tAcc@1  79.69 ( 79.69)\tAcc@5  98.44 ( 98.44)\n","Epoch: [117][ 30/391]\tTime  0.092 ( 0.093)\tLoss 1.3084e+00 (1.3738e+00)\tAcc@1  89.06 ( 73.89)\tAcc@5  97.66 ( 92.01)\n","Epoch: [117][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.3837e+00 (1.3853e+00)\tAcc@1  85.94 ( 68.69)\tAcc@5  96.88 ( 89.64)\n","Epoch: [117][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.0530e+00 (1.3744e+00)\tAcc@1  91.41 ( 67.96)\tAcc@5  98.44 ( 89.53)\n","Epoch: [117][120/391]\tTime  0.090 ( 0.091)\tLoss 1.7804e+00 (1.3772e+00)\tAcc@1  60.94 ( 67.25)\tAcc@5  88.28 ( 88.69)\n","Epoch: [117][150/391]\tTime  0.091 ( 0.091)\tLoss 1.8584e+00 (1.3836e+00)\tAcc@1  65.62 ( 66.90)\tAcc@5  91.41 ( 88.72)\n","Epoch: [117][180/391]\tTime  0.091 ( 0.091)\tLoss 1.3382e+00 (1.4040e+00)\tAcc@1  91.41 ( 66.33)\tAcc@5  98.44 ( 88.75)\n","Epoch: [117][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8113e+00 (1.4264e+00)\tAcc@1  37.50 ( 66.34)\tAcc@5  85.16 ( 88.90)\n","Epoch: [117][240/391]\tTime  0.089 ( 0.091)\tLoss 1.6600e+00 (1.4168e+00)\tAcc@1  52.34 ( 67.26)\tAcc@5  90.62 ( 89.46)\n","Epoch: [117][270/391]\tTime  0.091 ( 0.091)\tLoss 1.5217e+00 (1.4025e+00)\tAcc@1  73.44 ( 68.03)\tAcc@5  94.53 ( 89.91)\n","Epoch: [117][300/391]\tTime  0.090 ( 0.091)\tLoss 1.3394e+00 (1.4033e+00)\tAcc@1  89.06 ( 67.85)\tAcc@5  99.22 ( 89.84)\n","Epoch: [117][330/391]\tTime  0.086 ( 0.091)\tLoss 1.4149e+00 (1.4038e+00)\tAcc@1  87.50 ( 68.21)\tAcc@5  98.44 ( 90.15)\n","Epoch: [117][360/391]\tTime  0.090 ( 0.091)\tLoss 1.9865e+00 (1.4082e+00)\tAcc@1  38.28 ( 67.90)\tAcc@5  80.47 ( 90.07)\n","Epoch: [117][390/391]\tTime  0.081 ( 0.091)\tLoss 1.8713e+00 (1.4103e+00)\tAcc@1  17.50 ( 67.77)\tAcc@5  70.00 ( 90.02)\n","==> Train Accuracy: Acc@1 67.766 || Acc@5 90.024\n","==> Test Accuracy:  Acc@1 78.240 || Acc@5 94.730\n","==> 37.86 seconds to train this epoch\n","\n","\n","----- epoch: 118, lr: 0.004000000000000001 -----\n","Epoch: [118][  0/391]\tTime  0.207 ( 0.207)\tLoss 1.2078e+00 (1.2078e+00)\tAcc@1  89.84 ( 89.84)\tAcc@5  98.44 ( 98.44)\n","Epoch: [118][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.5548e+00 (1.2323e+00)\tAcc@1  83.59 ( 80.70)\tAcc@5  94.53 ( 95.69)\n","Epoch: [118][ 60/391]\tTime  0.092 ( 0.092)\tLoss 1.1481e+00 (1.3294e+00)\tAcc@1  92.19 ( 70.98)\tAcc@5  99.22 ( 90.80)\n","Epoch: [118][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2885e+00 (1.3202e+00)\tAcc@1  89.84 ( 72.41)\tAcc@5  99.22 ( 91.72)\n","Epoch: [118][120/391]\tTime  0.090 ( 0.091)\tLoss 1.0227e+00 (1.3420e+00)\tAcc@1  96.09 ( 72.68)\tAcc@5  97.66 ( 92.33)\n","Epoch: [118][150/391]\tTime  0.090 ( 0.091)\tLoss 3.2924e-01 (1.3550e+00)\tAcc@1  97.66 ( 70.84)\tAcc@5 100.00 ( 91.35)\n","Epoch: [118][180/391]\tTime  0.092 ( 0.091)\tLoss 1.7663e+00 (1.3686e+00)\tAcc@1  35.94 ( 70.36)\tAcc@5  79.69 ( 91.31)\n","Epoch: [118][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5639e+00 (1.3673e+00)\tAcc@1  59.38 ( 70.73)\tAcc@5  94.53 ( 91.57)\n","Epoch: [118][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5312e+00 (1.3776e+00)\tAcc@1  83.59 ( 70.50)\tAcc@5  96.88 ( 91.64)\n","Epoch: [118][270/391]\tTime  0.085 ( 0.091)\tLoss 2.2926e-01 (1.3733e+00)\tAcc@1  98.44 ( 70.64)\tAcc@5 100.00 ( 91.59)\n","Epoch: [118][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8942e+00 (1.3869e+00)\tAcc@1   8.59 ( 69.68)\tAcc@5  42.97 ( 91.07)\n","Epoch: [118][330/391]\tTime  0.093 ( 0.091)\tLoss 1.4499e+00 (1.3803e+00)\tAcc@1   2.34 ( 69.82)\tAcc@5  32.81 ( 91.12)\n","Epoch: [118][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7281e+00 (1.3819e+00)\tAcc@1  45.31 ( 69.95)\tAcc@5  85.16 ( 91.14)\n","Epoch: [118][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7274e+00 (1.3866e+00)\tAcc@1  70.00 ( 69.89)\tAcc@5  90.00 ( 91.19)\n","==> Train Accuracy: Acc@1 69.890 || Acc@5 91.186\n","==> Test Accuracy:  Acc@1 78.340 || Acc@5 94.790\n","==> 37.88 seconds to train this epoch\n","\n","\n","----- epoch: 119, lr: 0.004000000000000001 -----\n","Epoch: [119][  0/391]\tTime  0.196 ( 0.196)\tLoss 1.3663e+00 (1.3663e+00)\tAcc@1  90.62 ( 90.62)\tAcc@5  99.22 ( 99.22)\n","Epoch: [119][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.7589e+00 (1.3358e+00)\tAcc@1  51.56 ( 76.16)\tAcc@5  88.28 ( 93.80)\n","Epoch: [119][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.8086e+00 (1.2846e+00)\tAcc@1  39.06 ( 75.96)\tAcc@5  82.03 ( 93.55)\n","Epoch: [119][ 90/391]\tTime  0.091 ( 0.091)\tLoss 2.2456e+00 (1.3076e+00)\tAcc@1  26.56 ( 72.47)\tAcc@5  70.31 ( 91.90)\n","Epoch: [119][120/391]\tTime  0.093 ( 0.091)\tLoss 1.4905e+00 (1.3304e+00)\tAcc@1   3.91 ( 68.52)\tAcc@5  46.88 ( 89.92)\n","Epoch: [119][150/391]\tTime  0.091 ( 0.091)\tLoss 1.8405e+00 (1.3377e+00)\tAcc@1  28.91 ( 68.77)\tAcc@5  78.91 ( 90.33)\n","Epoch: [119][180/391]\tTime  0.091 ( 0.091)\tLoss 4.8726e-01 (1.3367e+00)\tAcc@1  97.66 ( 68.43)\tAcc@5 100.00 ( 90.28)\n","Epoch: [119][210/391]\tTime  0.090 ( 0.091)\tLoss 8.6078e-01 (1.3423e+00)\tAcc@1  94.53 ( 69.21)\tAcc@5  98.44 ( 90.66)\n","Epoch: [119][240/391]\tTime  0.090 ( 0.091)\tLoss 8.0538e-01 (1.3457e+00)\tAcc@1  94.53 ( 68.60)\tAcc@5  99.22 ( 90.48)\n","Epoch: [119][270/391]\tTime  0.090 ( 0.091)\tLoss 1.2070e+00 (1.3540e+00)\tAcc@1  92.19 ( 69.01)\tAcc@5  99.22 ( 90.56)\n","Epoch: [119][300/391]\tTime  0.091 ( 0.091)\tLoss 9.8971e-01 (1.3583e+00)\tAcc@1  92.97 ( 69.48)\tAcc@5  99.22 ( 90.74)\n","Epoch: [119][330/391]\tTime  0.090 ( 0.091)\tLoss 9.1445e-01 (1.3591e+00)\tAcc@1  95.31 ( 69.54)\tAcc@5 100.00 ( 90.75)\n","Epoch: [119][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6691e+00 (1.3658e+00)\tAcc@1  53.91 ( 69.61)\tAcc@5  93.75 ( 90.91)\n","Epoch: [119][390/391]\tTime  0.082 ( 0.091)\tLoss 1.3426e+00 (1.3698e+00)\tAcc@1  90.00 ( 69.92)\tAcc@5  95.00 ( 91.07)\n","==> Train Accuracy: Acc@1 69.916 || Acc@5 91.074\n","==> Test Accuracy:  Acc@1 77.960 || Acc@5 94.660\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 120, lr: 0.0008000000000000003 -----\n","Epoch: [120][  0/391]\tTime  0.208 ( 0.208)\tLoss 1.5954e+00 (1.5954e+00)\tAcc@1  78.12 ( 78.12)\tAcc@5  96.09 ( 96.09)\n","Epoch: [120][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.2984e+00 (1.2942e+00)\tAcc@1  85.16 ( 74.72)\tAcc@5  99.22 ( 94.48)\n","Epoch: [120][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.9715e+00 (1.3789e+00)\tAcc@1  27.34 ( 69.56)\tAcc@5  69.53 ( 91.19)\n","Epoch: [120][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.1036e+00 (1.3708e+00)\tAcc@1  91.41 ( 67.96)\tAcc@5  97.66 ( 89.73)\n","Epoch: [120][120/391]\tTime  0.091 ( 0.091)\tLoss 1.5428e+00 (1.3571e+00)\tAcc@1  75.78 ( 69.83)\tAcc@5  93.75 ( 90.62)\n","Epoch: [120][150/391]\tTime  0.091 ( 0.091)\tLoss 1.7605e+00 (1.3320e+00)\tAcc@1  67.97 ( 70.78)\tAcc@5  90.62 ( 91.07)\n","Epoch: [120][180/391]\tTime  0.090 ( 0.091)\tLoss 1.4119e+00 (1.3421e+00)\tAcc@1  83.59 ( 70.78)\tAcc@5  96.88 ( 91.57)\n","Epoch: [120][210/391]\tTime  0.090 ( 0.091)\tLoss 1.3273e+00 (1.3466e+00)\tAcc@1  76.56 ( 71.05)\tAcc@5  98.44 ( 91.66)\n","Epoch: [120][240/391]\tTime  0.091 ( 0.091)\tLoss 1.3461e+00 (1.3456e+00)\tAcc@1  87.50 ( 70.38)\tAcc@5  94.53 ( 91.46)\n","Epoch: [120][270/391]\tTime  0.090 ( 0.091)\tLoss 1.1268e+00 (1.3526e+00)\tAcc@1  95.31 ( 70.04)\tAcc@5  99.22 ( 91.48)\n","Epoch: [120][300/391]\tTime  0.090 ( 0.091)\tLoss 1.1722e+00 (1.3477e+00)\tAcc@1  92.97 ( 70.11)\tAcc@5 100.00 ( 91.38)\n","Epoch: [120][330/391]\tTime  0.087 ( 0.091)\tLoss 1.4846e+00 (1.3367e+00)\tAcc@1  81.25 ( 70.83)\tAcc@5  94.53 ( 91.67)\n","Epoch: [120][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7766e+00 (1.3251e+00)\tAcc@1  40.62 ( 71.11)\tAcc@5  82.81 ( 91.82)\n","Epoch: [120][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2643e+00 (1.3165e+00)\tAcc@1  90.00 ( 71.47)\tAcc@5 100.00 ( 91.87)\n","==> Train Accuracy: Acc@1 71.474 || Acc@5 91.874\n","==> Test Accuracy:  Acc@1 80.210 || Acc@5 95.310\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 121, lr: 0.0008000000000000003 -----\n","Epoch: [121][  0/391]\tTime  0.228 ( 0.228)\tLoss 1.7471e+00 (1.7471e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  91.41 ( 91.41)\n","Epoch: [121][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.6383e+00 (1.3703e+00)\tAcc@1  45.31 ( 67.77)\tAcc@5  88.28 ( 92.82)\n","Epoch: [121][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.3119e+00 (1.3711e+00)\tAcc@1  90.62 ( 67.33)\tAcc@5  97.66 ( 90.55)\n","Epoch: [121][ 90/391]\tTime  0.092 ( 0.092)\tLoss 1.2806e+00 (1.3066e+00)\tAcc@1  94.53 ( 71.27)\tAcc@5  99.22 ( 91.34)\n","Epoch: [121][120/391]\tTime  0.102 ( 0.092)\tLoss 1.5265e+00 (1.2732e+00)\tAcc@1  80.47 ( 73.04)\tAcc@5  96.09 ( 92.11)\n","Epoch: [121][150/391]\tTime  0.090 ( 0.091)\tLoss 7.7497e-01 (1.2795e+00)\tAcc@1  99.22 ( 73.20)\tAcc@5 100.00 ( 92.16)\n","Epoch: [121][180/391]\tTime  0.091 ( 0.091)\tLoss 1.4383e+00 (1.2711e+00)\tAcc@1  83.59 ( 73.61)\tAcc@5  98.44 ( 92.68)\n","Epoch: [121][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6285e+00 (1.2738e+00)\tAcc@1  56.25 ( 73.22)\tAcc@5  89.06 ( 92.72)\n","Epoch: [121][240/391]\tTime  0.090 ( 0.091)\tLoss 7.9466e-01 (1.2715e+00)\tAcc@1  93.75 ( 73.50)\tAcc@5  97.66 ( 92.59)\n","Epoch: [121][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6258e+00 (1.2752e+00)\tAcc@1  70.31 ( 72.54)\tAcc@5  92.19 ( 92.05)\n","Epoch: [121][300/391]\tTime  0.090 ( 0.091)\tLoss 1.7312e+00 (1.2797e+00)\tAcc@1   3.91 ( 71.97)\tAcc@5  45.31 ( 91.86)\n","Epoch: [121][330/391]\tTime  0.090 ( 0.091)\tLoss 8.4200e-01 (1.2776e+00)\tAcc@1  95.31 ( 72.17)\tAcc@5  99.22 ( 92.04)\n","Epoch: [121][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4480e+00 (1.2802e+00)\tAcc@1  53.91 ( 71.73)\tAcc@5  91.41 ( 91.67)\n","Epoch: [121][390/391]\tTime  0.082 ( 0.091)\tLoss 1.4041e+00 (1.2747e+00)\tAcc@1  87.50 ( 71.96)\tAcc@5  97.50 ( 91.67)\n","==> Train Accuracy: Acc@1 71.958 || Acc@5 91.668\n","==> Test Accuracy:  Acc@1 80.420 || Acc@5 95.320\n","==> 38.00 seconds to train this epoch\n","\n","\n","----- epoch: 122, lr: 0.0008000000000000003 -----\n","Epoch: [122][  0/391]\tTime  0.190 ( 0.190)\tLoss 8.9656e-01 (8.9656e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  98.44 ( 98.44)\n","Epoch: [122][ 30/391]\tTime  0.090 ( 0.093)\tLoss 1.4226e+00 (1.2162e+00)\tAcc@1  84.38 ( 81.05)\tAcc@5  98.44 ( 95.44)\n","Epoch: [122][ 60/391]\tTime  0.086 ( 0.092)\tLoss 1.6567e+00 (1.3329e+00)\tAcc@1  46.09 ( 72.12)\tAcc@5  89.06 ( 93.12)\n","Epoch: [122][ 90/391]\tTime  0.089 ( 0.091)\tLoss 1.4190e+00 (1.3016e+00)\tAcc@1  82.81 ( 74.75)\tAcc@5  96.09 ( 94.01)\n","Epoch: [122][120/391]\tTime  0.107 ( 0.091)\tLoss 1.3832e+00 (1.3024e+00)\tAcc@1  78.12 ( 74.16)\tAcc@5  97.66 ( 93.70)\n","Epoch: [122][150/391]\tTime  0.091 ( 0.091)\tLoss 4.6677e-01 (1.2907e+00)\tAcc@1  97.66 ( 73.77)\tAcc@5  98.44 ( 92.94)\n","Epoch: [122][180/391]\tTime  0.092 ( 0.091)\tLoss 1.0845e+00 (1.2994e+00)\tAcc@1  92.19 ( 72.59)\tAcc@5  97.66 ( 92.49)\n","Epoch: [122][210/391]\tTime  0.086 ( 0.091)\tLoss 1.8013e+00 (1.2876e+00)\tAcc@1  15.62 ( 72.36)\tAcc@5  75.00 ( 92.46)\n","Epoch: [122][240/391]\tTime  0.091 ( 0.091)\tLoss 1.0710e+00 (1.2925e+00)\tAcc@1  94.53 ( 71.98)\tAcc@5 100.00 ( 92.44)\n","Epoch: [122][270/391]\tTime  0.090 ( 0.091)\tLoss 5.6124e-01 (1.2903e+00)\tAcc@1  97.66 ( 71.86)\tAcc@5 100.00 ( 92.42)\n","Epoch: [122][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7188e+00 (1.2936e+00)\tAcc@1  49.22 ( 71.17)\tAcc@5  90.62 ( 92.16)\n","Epoch: [122][330/391]\tTime  0.090 ( 0.091)\tLoss 7.3304e-01 (1.2868e+00)\tAcc@1  96.09 ( 71.37)\tAcc@5  99.22 ( 92.06)\n","Epoch: [122][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1331e+00 (1.2871e+00)\tAcc@1  93.75 ( 71.44)\tAcc@5  98.44 ( 91.95)\n","Epoch: [122][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5210e+00 (1.3009e+00)\tAcc@1  33.75 ( 71.14)\tAcc@5  86.25 ( 92.00)\n","==> Train Accuracy: Acc@1 71.140 || Acc@5 91.998\n","==> Test Accuracy:  Acc@1 80.400 || Acc@5 95.360\n","==> 37.92 seconds to train this epoch\n","\n","\n","----- epoch: 123, lr: 0.0008000000000000003 -----\n","Epoch: [123][  0/391]\tTime  0.208 ( 0.208)\tLoss 1.7809e+00 (1.7809e+00)\tAcc@1   6.25 (  6.25)\tAcc@5  55.47 ( 55.47)\n","Epoch: [123][ 30/391]\tTime  0.093 ( 0.094)\tLoss 1.3887e+00 (1.3155e+00)\tAcc@1  83.59 ( 71.70)\tAcc@5  96.09 ( 92.29)\n","Epoch: [123][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.5983e+00 (1.2965e+00)\tAcc@1  48.44 ( 68.29)\tAcc@5  91.41 ( 90.60)\n","Epoch: [123][ 90/391]\tTime  0.087 ( 0.092)\tLoss 3.7737e-01 (1.2622e+00)\tAcc@1  99.22 ( 69.21)\tAcc@5 100.00 ( 90.66)\n","Epoch: [123][120/391]\tTime  0.090 ( 0.091)\tLoss 1.5207e+00 (1.2808e+00)\tAcc@1  23.44 ( 68.90)\tAcc@5  79.69 ( 90.77)\n","Epoch: [123][150/391]\tTime  0.091 ( 0.091)\tLoss 1.8790e+00 (1.2836e+00)\tAcc@1  42.97 ( 70.13)\tAcc@5  85.94 ( 91.34)\n","Epoch: [123][180/391]\tTime  0.092 ( 0.091)\tLoss 1.1742e+00 (1.2884e+00)\tAcc@1  85.94 ( 70.08)\tAcc@5  97.66 ( 91.26)\n","Epoch: [123][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5946e+00 (1.2764e+00)\tAcc@1  57.03 ( 70.85)\tAcc@5  87.50 ( 91.54)\n","Epoch: [123][240/391]\tTime  0.090 ( 0.091)\tLoss 1.2918e+00 (1.2688e+00)\tAcc@1  91.41 ( 71.76)\tAcc@5  98.44 ( 91.86)\n","Epoch: [123][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6458e+00 (1.2727e+00)\tAcc@1  42.97 ( 72.24)\tAcc@5  88.28 ( 92.07)\n","Epoch: [123][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4109e+00 (1.2747e+00)\tAcc@1  72.66 ( 72.14)\tAcc@5  95.31 ( 92.09)\n","Epoch: [123][330/391]\tTime  0.091 ( 0.091)\tLoss 7.3764e-01 (1.2676e+00)\tAcc@1  96.88 ( 72.23)\tAcc@5 100.00 ( 92.21)\n","Epoch: [123][360/391]\tTime  0.091 ( 0.091)\tLoss 1.3126e+00 (1.2793e+00)\tAcc@1  86.72 ( 71.65)\tAcc@5  97.66 ( 92.15)\n","Epoch: [123][390/391]\tTime  0.083 ( 0.091)\tLoss 1.4273e+00 (1.2767e+00)\tAcc@1  83.75 ( 71.91)\tAcc@5  97.50 ( 92.18)\n","==> Train Accuracy: Acc@1 71.914 || Acc@5 92.180\n","==> Test Accuracy:  Acc@1 80.160 || Acc@5 95.360\n","==> 37.90 seconds to train this epoch\n","\n","\n","----- epoch: 124, lr: 0.0008000000000000003 -----\n","Epoch: [124][  0/391]\tTime  0.201 ( 0.201)\tLoss 1.1450e-01 (1.1450e-01)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n","Epoch: [124][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.6173e+00 (1.1590e+00)\tAcc@1  45.31 ( 71.35)\tAcc@5  89.84 ( 90.30)\n","Epoch: [124][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.4743e+00 (1.1990e+00)\tAcc@1  72.66 ( 72.41)\tAcc@5  97.66 ( 91.01)\n","Epoch: [124][ 90/391]\tTime  0.085 ( 0.091)\tLoss 1.4703e+00 (1.1859e+00)\tAcc@1  73.44 ( 73.90)\tAcc@5  94.53 ( 92.29)\n","Epoch: [124][120/391]\tTime  0.090 ( 0.091)\tLoss 8.7675e-01 (1.2216e+00)\tAcc@1  93.75 ( 73.53)\tAcc@5  97.66 ( 92.24)\n","Epoch: [124][150/391]\tTime  0.090 ( 0.091)\tLoss 1.1140e-01 (1.2195e+00)\tAcc@1  97.66 ( 74.14)\tAcc@5  99.22 ( 92.58)\n","Epoch: [124][180/391]\tTime  0.090 ( 0.091)\tLoss 9.7102e-01 (1.2383e+00)\tAcc@1  95.31 ( 73.47)\tAcc@5 100.00 ( 92.26)\n","Epoch: [124][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6364e+00 (1.2464e+00)\tAcc@1  42.97 ( 72.43)\tAcc@5  88.28 ( 92.01)\n","Epoch: [124][240/391]\tTime  0.091 ( 0.091)\tLoss 1.1593e+00 (1.2358e+00)\tAcc@1  91.41 ( 73.10)\tAcc@5  97.66 ( 92.37)\n","Epoch: [124][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3474e+00 (1.2496e+00)\tAcc@1  81.25 ( 72.82)\tAcc@5  96.09 ( 92.37)\n","Epoch: [124][300/391]\tTime  0.091 ( 0.091)\tLoss 1.3491e+00 (1.2503e+00)\tAcc@1  89.06 ( 73.30)\tAcc@5  97.66 ( 92.56)\n","Epoch: [124][330/391]\tTime  0.091 ( 0.091)\tLoss 1.1993e+00 (1.2451e+00)\tAcc@1  90.62 ( 73.70)\tAcc@5  97.66 ( 92.79)\n","Epoch: [124][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8356e+00 (1.2471e+00)\tAcc@1  40.62 ( 73.41)\tAcc@5  82.03 ( 92.80)\n","Epoch: [124][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5567e+00 (1.2353e+00)\tAcc@1  63.75 ( 73.53)\tAcc@5  93.75 ( 92.74)\n","==> Train Accuracy: Acc@1 73.532 || Acc@5 92.742\n","==> Test Accuracy:  Acc@1 80.150 || Acc@5 95.370\n","==> 37.97 seconds to train this epoch\n","\n","\n","----- epoch: 125, lr: 0.0008000000000000003 -----\n","Epoch: [125][  0/391]\tTime  0.196 ( 0.196)\tLoss 1.9175e+00 (1.9175e+00)\tAcc@1  32.03 ( 32.03)\tAcc@5  79.69 ( 79.69)\n","Epoch: [125][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.2301e+00 (1.2861e+00)\tAcc@1  92.97 ( 78.02)\tAcc@5  99.22 ( 94.33)\n","Epoch: [125][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.8603e-01 (1.2712e+00)\tAcc@1  96.88 ( 74.54)\tAcc@5  99.22 ( 92.75)\n","Epoch: [125][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.4440e+00 (1.2486e+00)\tAcc@1  75.00 ( 74.67)\tAcc@5  96.09 ( 92.87)\n","Epoch: [125][120/391]\tTime  0.090 ( 0.091)\tLoss 1.5013e+00 (1.2614e+00)\tAcc@1  79.69 ( 72.95)\tAcc@5  93.75 ( 92.81)\n","Epoch: [125][150/391]\tTime  0.090 ( 0.091)\tLoss 1.0191e+00 (1.2392e+00)\tAcc@1  96.09 ( 73.70)\tAcc@5 100.00 ( 92.99)\n","Epoch: [125][180/391]\tTime  0.091 ( 0.091)\tLoss 1.3660e+00 (1.2445e+00)\tAcc@1  82.03 ( 74.66)\tAcc@5  98.44 ( 93.23)\n","Epoch: [125][210/391]\tTime  0.090 ( 0.091)\tLoss 5.9891e-01 (1.2553e+00)\tAcc@1  96.88 ( 74.87)\tAcc@5 100.00 ( 93.36)\n","Epoch: [125][240/391]\tTime  0.090 ( 0.091)\tLoss 8.8874e-01 (1.2582e+00)\tAcc@1  96.09 ( 74.29)\tAcc@5  99.22 ( 93.34)\n","Epoch: [125][270/391]\tTime  0.091 ( 0.091)\tLoss 1.2862e+00 (1.2551e+00)\tAcc@1  91.41 ( 73.96)\tAcc@5  96.88 ( 93.32)\n","Epoch: [125][300/391]\tTime  0.091 ( 0.091)\tLoss 1.3470e+00 (1.2535e+00)\tAcc@1  82.03 ( 73.71)\tAcc@5  99.22 ( 93.24)\n","Epoch: [125][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2638e+00 (1.2465e+00)\tAcc@1  94.53 ( 73.98)\tAcc@5  99.22 ( 93.18)\n","Epoch: [125][360/391]\tTime  0.090 ( 0.091)\tLoss 1.0760e+00 (1.2472e+00)\tAcc@1  96.09 ( 73.62)\tAcc@5  98.44 ( 93.00)\n","Epoch: [125][390/391]\tTime  0.081 ( 0.091)\tLoss 5.7966e-01 (1.2412e+00)\tAcc@1 100.00 ( 74.07)\tAcc@5 100.00 ( 93.20)\n","==> Train Accuracy: Acc@1 74.066 || Acc@5 93.200\n","==> Test Accuracy:  Acc@1 80.350 || Acc@5 95.470\n","==> 37.89 seconds to train this epoch\n","\n","\n","----- epoch: 126, lr: 0.0008000000000000003 -----\n","Epoch: [126][  0/391]\tTime  0.210 ( 0.210)\tLoss 2.0468e+00 (2.0468e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  73.44 ( 73.44)\n","Epoch: [126][ 30/391]\tTime  0.092 ( 0.094)\tLoss 1.1751e+00 (1.1572e+00)\tAcc@1  92.19 ( 83.19)\tAcc@5  99.22 ( 95.94)\n","Epoch: [126][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.6307e+00 (1.2235e+00)\tAcc@1  58.59 ( 77.72)\tAcc@5  89.06 ( 94.19)\n","Epoch: [126][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3891e+00 (1.2842e+00)\tAcc@1  61.72 ( 73.30)\tAcc@5  95.31 ( 93.18)\n","Epoch: [126][120/391]\tTime  0.090 ( 0.091)\tLoss 6.8347e-01 (1.2828e+00)\tAcc@1  96.09 ( 73.03)\tAcc@5 100.00 ( 93.24)\n","Epoch: [126][150/391]\tTime  0.091 ( 0.091)\tLoss 6.6220e-01 (1.2905e+00)\tAcc@1  97.66 ( 71.69)\tAcc@5 100.00 ( 92.64)\n","Epoch: [126][180/391]\tTime  0.090 ( 0.091)\tLoss 1.7820e+00 (1.2883e+00)\tAcc@1  15.62 ( 71.62)\tAcc@5  71.09 ( 92.67)\n","Epoch: [126][210/391]\tTime  0.090 ( 0.091)\tLoss 1.7100e+00 (1.2865e+00)\tAcc@1  56.25 ( 71.43)\tAcc@5  85.94 ( 92.77)\n","Epoch: [126][240/391]\tTime  0.090 ( 0.091)\tLoss 1.3399e+00 (1.2822e+00)\tAcc@1  85.94 ( 71.28)\tAcc@5  99.22 ( 92.47)\n","Epoch: [126][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6599e+00 (1.2988e+00)\tAcc@1  50.00 ( 70.58)\tAcc@5  89.06 ( 92.31)\n","Epoch: [126][300/391]\tTime  0.090 ( 0.091)\tLoss 1.2090e+00 (1.2898e+00)\tAcc@1  92.97 ( 70.60)\tAcc@5  98.44 ( 92.14)\n","Epoch: [126][330/391]\tTime  0.090 ( 0.091)\tLoss 1.1457e-01 (1.2803e+00)\tAcc@1  98.44 ( 71.24)\tAcc@5 100.00 ( 92.46)\n","Epoch: [126][360/391]\tTime  0.090 ( 0.091)\tLoss 1.3317e+00 (1.2840e+00)\tAcc@1  85.94 ( 70.81)\tAcc@5  96.09 ( 92.06)\n","Epoch: [126][390/391]\tTime  0.082 ( 0.091)\tLoss 1.6331e+00 (1.2902e+00)\tAcc@1  13.75 ( 70.47)\tAcc@5  66.25 ( 91.88)\n","==> Train Accuracy: Acc@1 70.470 || Acc@5 91.884\n","==> Test Accuracy:  Acc@1 80.400 || Acc@5 95.350\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 127, lr: 0.0008000000000000003 -----\n","Epoch: [127][  0/391]\tTime  0.208 ( 0.208)\tLoss 1.0515e+00 (1.0515e+00)\tAcc@1  92.19 ( 92.19)\tAcc@5  98.44 ( 98.44)\n","Epoch: [127][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.4925e+00 (1.2632e+00)\tAcc@1  63.28 ( 69.78)\tAcc@5  94.53 ( 93.60)\n","Epoch: [127][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.5772e+00 (1.2537e+00)\tAcc@1  16.41 ( 70.50)\tAcc@5  71.88 ( 93.63)\n","Epoch: [127][ 90/391]\tTime  0.092 ( 0.092)\tLoss 1.4190e+00 (1.2372e+00)\tAcc@1  40.62 ( 71.69)\tAcc@5  89.84 ( 93.29)\n","Epoch: [127][120/391]\tTime  0.091 ( 0.091)\tLoss 9.2200e-01 (1.2021e+00)\tAcc@1  93.75 ( 73.39)\tAcc@5  98.44 ( 93.56)\n","Epoch: [127][150/391]\tTime  0.089 ( 0.091)\tLoss 1.5193e+00 (1.1968e+00)\tAcc@1  38.28 ( 74.19)\tAcc@5  88.28 ( 93.72)\n","Epoch: [127][180/391]\tTime  0.090 ( 0.091)\tLoss 1.7810e+00 (1.2158e+00)\tAcc@1  50.00 ( 72.68)\tAcc@5  86.72 ( 93.23)\n","Epoch: [127][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5299e+00 (1.2197e+00)\tAcc@1   5.47 ( 72.49)\tAcc@5  58.59 ( 93.01)\n","Epoch: [127][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1855e+00 (1.2234e+00)\tAcc@1  90.62 ( 72.79)\tAcc@5  98.44 ( 92.98)\n","Epoch: [127][270/391]\tTime  0.090 ( 0.091)\tLoss 9.7226e-01 (1.2275e+00)\tAcc@1  96.88 ( 73.12)\tAcc@5  99.22 ( 93.02)\n","Epoch: [127][300/391]\tTime  0.090 ( 0.091)\tLoss 5.0792e-01 (1.2266e+00)\tAcc@1  99.22 ( 73.18)\tAcc@5 100.00 ( 93.10)\n","Epoch: [127][330/391]\tTime  0.090 ( 0.091)\tLoss 1.7607e+00 (1.2352e+00)\tAcc@1  62.50 ( 73.04)\tAcc@5  89.06 ( 93.16)\n","Epoch: [127][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4262e+00 (1.2284e+00)\tAcc@1  73.44 ( 73.42)\tAcc@5  93.75 ( 93.20)\n","Epoch: [127][390/391]\tTime  0.083 ( 0.091)\tLoss 9.8130e-01 (1.2311e+00)\tAcc@1  93.75 ( 73.52)\tAcc@5  98.75 ( 93.30)\n","==> Train Accuracy: Acc@1 73.522 || Acc@5 93.302\n","==> Test Accuracy:  Acc@1 80.490 || Acc@5 95.360\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 128, lr: 0.0008000000000000003 -----\n","Epoch: [128][  0/391]\tTime  0.209 ( 0.209)\tLoss 9.4318e-02 (9.4318e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n","Epoch: [128][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.3304e+00 (1.2626e+00)\tAcc@1  88.28 ( 73.34)\tAcc@5  98.44 ( 92.54)\n","Epoch: [128][ 60/391]\tTime  0.085 ( 0.092)\tLoss 1.5215e+00 (1.2889e+00)\tAcc@1  74.22 ( 70.68)\tAcc@5  92.97 ( 91.00)\n","Epoch: [128][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.5736e+00 (1.2562e+00)\tAcc@1  68.75 ( 72.28)\tAcc@5  96.09 ( 91.93)\n","Epoch: [128][120/391]\tTime  0.090 ( 0.091)\tLoss 8.8987e-01 (1.2071e+00)\tAcc@1  93.75 ( 74.21)\tAcc@5  97.66 ( 92.67)\n","Epoch: [128][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2189e+00 (1.2147e+00)\tAcc@1  92.97 ( 74.35)\tAcc@5  96.88 ( 92.37)\n","Epoch: [128][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2779e+00 (1.2022e+00)\tAcc@1  83.59 ( 74.96)\tAcc@5 100.00 ( 92.84)\n","Epoch: [128][210/391]\tTime  0.091 ( 0.091)\tLoss 1.3792e+00 (1.2095e+00)\tAcc@1  67.19 ( 74.71)\tAcc@5  94.53 ( 92.88)\n","Epoch: [128][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5026e+00 (1.2207e+00)\tAcc@1  71.09 ( 73.05)\tAcc@5  93.75 ( 92.00)\n","Epoch: [128][270/391]\tTime  0.090 ( 0.091)\tLoss 1.1809e+00 (1.2154e+00)\tAcc@1  90.62 ( 73.41)\tAcc@5  99.22 ( 92.18)\n","Epoch: [128][300/391]\tTime  0.090 ( 0.091)\tLoss 1.0234e+00 (1.2217e+00)\tAcc@1  92.97 ( 72.91)\tAcc@5  99.22 ( 92.14)\n","Epoch: [128][330/391]\tTime  0.090 ( 0.091)\tLoss 5.8828e-01 (1.2218e+00)\tAcc@1  96.88 ( 72.97)\tAcc@5 100.00 ( 92.20)\n","Epoch: [128][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4790e+00 (1.2198e+00)\tAcc@1  74.22 ( 73.17)\tAcc@5  95.31 ( 92.37)\n","Epoch: [128][390/391]\tTime  0.082 ( 0.091)\tLoss 9.9816e-01 (1.2185e+00)\tAcc@1  98.75 ( 73.44)\tAcc@5 100.00 ( 92.48)\n","==> Train Accuracy: Acc@1 73.438 || Acc@5 92.478\n","==> Test Accuracy:  Acc@1 80.210 || Acc@5 95.340\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 129, lr: 0.0008000000000000003 -----\n","Epoch: [129][  0/391]\tTime  0.214 ( 0.214)\tLoss 1.4406e+00 (1.4406e+00)\tAcc@1  85.94 ( 85.94)\tAcc@5  97.66 ( 97.66)\n","Epoch: [129][ 30/391]\tTime  0.093 ( 0.094)\tLoss 1.6453e+00 (1.2472e+00)\tAcc@1  15.62 ( 70.72)\tAcc@5  68.75 ( 92.24)\n","Epoch: [129][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.3214e+00 (1.2614e+00)\tAcc@1  89.06 ( 69.25)\tAcc@5  97.66 ( 91.85)\n","Epoch: [129][ 90/391]\tTime  0.091 ( 0.092)\tLoss 8.1362e-01 (1.2343e+00)\tAcc@1  95.31 ( 71.37)\tAcc@5  99.22 ( 92.45)\n","Epoch: [129][120/391]\tTime  0.090 ( 0.091)\tLoss 1.4550e+00 (1.2113e+00)\tAcc@1   2.34 ( 72.11)\tAcc@5  47.66 ( 92.08)\n","Epoch: [129][150/391]\tTime  0.091 ( 0.091)\tLoss 1.3385e+00 (1.2155e+00)\tAcc@1  71.88 ( 73.22)\tAcc@5  96.88 ( 92.78)\n","Epoch: [129][180/391]\tTime  0.091 ( 0.091)\tLoss 1.4416e+00 (1.2423e+00)\tAcc@1  72.66 ( 70.80)\tAcc@5  96.09 ( 91.47)\n","Epoch: [129][210/391]\tTime  0.090 ( 0.091)\tLoss 1.3032e+00 (1.2528e+00)\tAcc@1  85.94 ( 70.36)\tAcc@5  96.88 ( 91.32)\n","Epoch: [129][240/391]\tTime  0.092 ( 0.091)\tLoss 9.8258e-01 (1.2577e+00)\tAcc@1  93.75 ( 70.43)\tAcc@5 100.00 ( 91.52)\n","Epoch: [129][270/391]\tTime  0.090 ( 0.091)\tLoss 1.0812e+00 (1.2635e+00)\tAcc@1  91.41 ( 69.98)\tAcc@5  98.44 ( 91.44)\n","Epoch: [129][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6638e+00 (1.2592e+00)\tAcc@1  14.06 ( 70.21)\tAcc@5  74.22 ( 91.54)\n","Epoch: [129][330/391]\tTime  0.090 ( 0.091)\tLoss 1.4399e+00 (1.2560e+00)\tAcc@1  82.81 ( 70.78)\tAcc@5  98.44 ( 91.82)\n","Epoch: [129][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5298e+00 (1.2539e+00)\tAcc@1  23.44 ( 71.38)\tAcc@5  83.59 ( 92.09)\n","Epoch: [129][390/391]\tTime  0.081 ( 0.091)\tLoss 6.9386e-01 (1.2448e+00)\tAcc@1  98.75 ( 71.70)\tAcc@5 100.00 ( 92.18)\n","==> Train Accuracy: Acc@1 71.702 || Acc@5 92.184\n","==> Test Accuracy:  Acc@1 80.270 || Acc@5 95.440\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 130, lr: 0.0008000000000000003 -----\n","Epoch: [130][  0/391]\tTime  0.212 ( 0.212)\tLoss 7.0371e-01 (7.0371e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n","Epoch: [130][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.0128e+00 (1.1690e+00)\tAcc@1  95.31 ( 77.17)\tAcc@5 100.00 ( 93.65)\n","Epoch: [130][ 60/391]\tTime  0.090 ( 0.092)\tLoss 8.7139e-01 (1.2277e+00)\tAcc@1  95.31 ( 72.61)\tAcc@5 100.00 ( 92.53)\n","Epoch: [130][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.4226e+00 (1.2861e+00)\tAcc@1  79.69 ( 69.40)\tAcc@5  97.66 ( 91.85)\n","Epoch: [130][120/391]\tTime  0.091 ( 0.091)\tLoss 1.2962e+00 (1.2707e+00)\tAcc@1  86.72 ( 71.51)\tAcc@5  96.88 ( 92.60)\n","Epoch: [130][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2657e+00 (1.2669e+00)\tAcc@1  89.06 ( 72.60)\tAcc@5 100.00 ( 93.08)\n","Epoch: [130][180/391]\tTime  0.090 ( 0.091)\tLoss 1.3831e+00 (1.2516e+00)\tAcc@1  75.00 ( 73.36)\tAcc@5  96.09 ( 93.12)\n","Epoch: [130][210/391]\tTime  0.089 ( 0.091)\tLoss 1.4650e+00 (1.2446e+00)\tAcc@1  71.88 ( 73.52)\tAcc@5  96.09 ( 93.07)\n","Epoch: [130][240/391]\tTime  0.091 ( 0.091)\tLoss 3.8362e-01 (1.2511e+00)\tAcc@1  99.22 ( 72.90)\tAcc@5 100.00 ( 93.05)\n","Epoch: [130][270/391]\tTime  0.090 ( 0.091)\tLoss 1.4471e+00 (1.2627e+00)\tAcc@1  58.59 ( 72.26)\tAcc@5  97.66 ( 92.93)\n","Epoch: [130][300/391]\tTime  0.091 ( 0.091)\tLoss 1.1876e+00 (1.2712e+00)\tAcc@1  94.53 ( 71.96)\tAcc@5 100.00 ( 92.88)\n","Epoch: [130][330/391]\tTime  0.091 ( 0.091)\tLoss 5.8887e-01 (1.2620e+00)\tAcc@1  98.44 ( 72.43)\tAcc@5 100.00 ( 93.03)\n","Epoch: [130][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5209e+00 (1.2612e+00)\tAcc@1  37.50 ( 72.43)\tAcc@5  88.28 ( 93.00)\n","Epoch: [130][390/391]\tTime  0.081 ( 0.091)\tLoss 1.6548e+00 (1.2604e+00)\tAcc@1  62.50 ( 72.45)\tAcc@5  92.50 ( 93.02)\n","==> Train Accuracy: Acc@1 72.446 || Acc@5 93.024\n","==> Test Accuracy:  Acc@1 80.580 || Acc@5 95.370\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 131, lr: 0.0008000000000000003 -----\n","Epoch: [131][  0/391]\tTime  0.228 ( 0.228)\tLoss 1.6239e+00 (1.6239e+00)\tAcc@1  17.19 ( 17.19)\tAcc@5  73.44 ( 73.44)\n","Epoch: [131][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.6582e+00 (1.3575e+00)\tAcc@1   5.47 ( 56.45)\tAcc@5  63.28 ( 85.23)\n","Epoch: [131][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.1549e+00 (1.2930e+00)\tAcc@1  93.75 ( 63.04)\tAcc@5  98.44 ( 88.29)\n","Epoch: [131][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.0722e-01 (1.2479e+00)\tAcc@1  96.09 ( 66.88)\tAcc@5 100.00 ( 90.11)\n","Epoch: [131][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2247e+00 (1.2496e+00)\tAcc@1  89.06 ( 68.34)\tAcc@5  99.22 ( 90.86)\n","Epoch: [131][150/391]\tTime  0.090 ( 0.091)\tLoss 1.0815e+00 (1.2559e+00)\tAcc@1  93.75 ( 68.99)\tAcc@5  97.66 ( 91.20)\n","Epoch: [131][180/391]\tTime  0.090 ( 0.091)\tLoss 1.4241e+00 (1.2636e+00)\tAcc@1  76.56 ( 67.71)\tAcc@5  96.88 ( 90.50)\n","Epoch: [131][210/391]\tTime  0.090 ( 0.091)\tLoss 7.5659e-01 (1.2466e+00)\tAcc@1  96.09 ( 69.62)\tAcc@5 100.00 ( 91.21)\n","Epoch: [131][240/391]\tTime  0.090 ( 0.091)\tLoss 1.6470e+00 (1.2331e+00)\tAcc@1  77.34 ( 70.81)\tAcc@5  95.31 ( 91.77)\n","Epoch: [131][270/391]\tTime  0.091 ( 0.091)\tLoss 1.7001e+00 (1.2472e+00)\tAcc@1  22.66 ( 70.60)\tAcc@5  75.78 ( 91.65)\n","Epoch: [131][300/391]\tTime  0.090 ( 0.091)\tLoss 1.1136e+00 (1.2462e+00)\tAcc@1  96.88 ( 71.08)\tAcc@5  98.44 ( 91.81)\n","Epoch: [131][330/391]\tTime  0.093 ( 0.091)\tLoss 1.5521e+00 (1.2424e+00)\tAcc@1  55.47 ( 70.73)\tAcc@5  92.19 ( 91.70)\n","Epoch: [131][360/391]\tTime  0.089 ( 0.091)\tLoss 1.0661e+00 (1.2329e+00)\tAcc@1  93.75 ( 71.46)\tAcc@5  99.22 ( 92.01)\n","Epoch: [131][390/391]\tTime  0.081 ( 0.091)\tLoss 1.5834e+00 (1.2296e+00)\tAcc@1  35.00 ( 71.90)\tAcc@5  90.00 ( 92.27)\n","==> Train Accuracy: Acc@1 71.898 || Acc@5 92.266\n","==> Test Accuracy:  Acc@1 80.460 || Acc@5 95.630\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 132, lr: 0.0008000000000000003 -----\n","Epoch: [132][  0/391]\tTime  0.209 ( 0.209)\tLoss 1.5027e+00 (1.5027e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  60.94 ( 60.94)\n","Epoch: [132][ 30/391]\tTime  0.090 ( 0.094)\tLoss 8.4571e-01 (1.2403e+00)\tAcc@1  96.09 ( 63.86)\tAcc@5  99.22 ( 87.22)\n","Epoch: [132][ 60/391]\tTime  0.091 ( 0.092)\tLoss 6.7499e-01 (1.2589e+00)\tAcc@1  96.09 ( 65.93)\tAcc@5  99.22 ( 87.87)\n","Epoch: [132][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3283e+00 (1.2446e+00)\tAcc@1  82.03 ( 68.94)\tAcc@5  96.09 ( 90.14)\n","Epoch: [132][120/391]\tTime  0.090 ( 0.091)\tLoss 1.1203e+00 (1.2502e+00)\tAcc@1  94.53 ( 68.00)\tAcc@5 100.00 ( 90.20)\n","Epoch: [132][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3746e+00 (1.2624e+00)\tAcc@1  69.53 ( 68.00)\tAcc@5  96.88 ( 90.40)\n","Epoch: [132][180/391]\tTime  0.092 ( 0.091)\tLoss 1.3902e+00 (1.2803e+00)\tAcc@1  74.22 ( 67.92)\tAcc@5  96.88 ( 90.39)\n","Epoch: [132][210/391]\tTime  0.090 ( 0.091)\tLoss 7.2983e-01 (1.2739e+00)\tAcc@1  97.66 ( 69.42)\tAcc@5 100.00 ( 91.20)\n","Epoch: [132][240/391]\tTime  0.090 ( 0.091)\tLoss 1.4020e+00 (1.2829e+00)\tAcc@1  87.50 ( 69.84)\tAcc@5  99.22 ( 91.58)\n","Epoch: [132][270/391]\tTime  0.091 ( 0.091)\tLoss 1.7468e+00 (1.2870e+00)\tAcc@1  28.12 ( 70.54)\tAcc@5  82.81 ( 92.02)\n","Epoch: [132][300/391]\tTime  0.089 ( 0.091)\tLoss 1.2636e+00 (1.2872e+00)\tAcc@1  88.28 ( 69.97)\tAcc@5  98.44 ( 91.80)\n","Epoch: [132][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6066e+00 (1.2917e+00)\tAcc@1  70.31 ( 69.28)\tAcc@5  93.75 ( 91.47)\n","Epoch: [132][360/391]\tTime  0.086 ( 0.091)\tLoss 1.1576e+00 (1.2857e+00)\tAcc@1  92.19 ( 69.39)\tAcc@5  98.44 ( 91.45)\n","Epoch: [132][390/391]\tTime  0.082 ( 0.091)\tLoss 1.4734e+00 (1.2801e+00)\tAcc@1  81.25 ( 70.23)\tAcc@5  93.75 ( 91.82)\n","==> Train Accuracy: Acc@1 70.232 || Acc@5 91.818\n","==> Test Accuracy:  Acc@1 80.440 || Acc@5 95.460\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 133, lr: 0.0008000000000000003 -----\n","Epoch: [133][  0/391]\tTime  0.193 ( 0.193)\tLoss 1.4669e+00 (1.4669e+00)\tAcc@1  82.03 ( 82.03)\tAcc@5  99.22 ( 99.22)\n","Epoch: [133][ 30/391]\tTime  0.093 ( 0.093)\tLoss 1.3240e+00 (1.1185e+00)\tAcc@1  82.03 ( 80.87)\tAcc@5  96.88 ( 96.90)\n","Epoch: [133][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.5904e+00 (1.1727e+00)\tAcc@1  67.97 ( 76.36)\tAcc@5  93.75 ( 94.90)\n","Epoch: [133][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.5356e+00 (1.2017e+00)\tAcc@1  48.44 ( 73.53)\tAcc@5  91.41 ( 94.01)\n","Epoch: [133][120/391]\tTime  0.091 ( 0.091)\tLoss 1.1267e+00 (1.2091e+00)\tAcc@1  94.53 ( 74.46)\tAcc@5  98.44 ( 94.09)\n","Epoch: [133][150/391]\tTime  0.090 ( 0.091)\tLoss 1.4092e+00 (1.1907e+00)\tAcc@1  87.50 ( 76.86)\tAcc@5  94.53 ( 94.78)\n","Epoch: [133][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2942e+00 (1.2173e+00)\tAcc@1  85.94 ( 75.73)\tAcc@5  99.22 ( 94.43)\n","Epoch: [133][210/391]\tTime  0.090 ( 0.091)\tLoss 7.8199e-01 (1.2129e+00)\tAcc@1  96.88 ( 75.24)\tAcc@5  99.22 ( 94.20)\n","Epoch: [133][240/391]\tTime  0.090 ( 0.091)\tLoss 1.4897e+00 (1.2260e+00)\tAcc@1  69.53 ( 74.79)\tAcc@5  96.09 ( 93.87)\n","Epoch: [133][270/391]\tTime  0.090 ( 0.091)\tLoss 1.5524e+00 (1.2117e+00)\tAcc@1  24.22 ( 75.37)\tAcc@5  85.94 ( 94.08)\n","Epoch: [133][300/391]\tTime  0.091 ( 0.091)\tLoss 1.6083e+00 (1.2152e+00)\tAcc@1  12.50 ( 75.20)\tAcc@5  73.44 ( 94.09)\n","Epoch: [133][330/391]\tTime  0.090 ( 0.091)\tLoss 1.4095e+00 (1.2170e+00)\tAcc@1   0.00 ( 74.85)\tAcc@5  42.97 ( 94.00)\n","Epoch: [133][360/391]\tTime  0.090 ( 0.091)\tLoss 9.2589e-01 (1.2265e+00)\tAcc@1  96.88 ( 74.20)\tAcc@5 100.00 ( 93.74)\n","Epoch: [133][390/391]\tTime  0.079 ( 0.091)\tLoss 1.2403e+00 (1.2215e+00)\tAcc@1  88.75 ( 74.42)\tAcc@5 100.00 ( 93.81)\n","==> Train Accuracy: Acc@1 74.422 || Acc@5 93.812\n","==> Test Accuracy:  Acc@1 80.180 || Acc@5 95.450\n","==> 37.92 seconds to train this epoch\n","\n","\n","----- epoch: 134, lr: 0.0008000000000000003 -----\n","Epoch: [134][  0/391]\tTime  0.195 ( 0.195)\tLoss 1.3266e+00 (1.3266e+00)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n","Epoch: [134][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.0462e+00 (1.3077e+00)\tAcc@1  96.88 ( 73.66)\tAcc@5  99.22 ( 94.51)\n","Epoch: [134][ 60/391]\tTime  0.085 ( 0.092)\tLoss 1.6693e+00 (1.2975e+00)\tAcc@1  40.62 ( 71.45)\tAcc@5  89.84 ( 93.34)\n","Epoch: [134][ 90/391]\tTime  0.090 ( 0.091)\tLoss 1.6567e+00 (1.2651e+00)\tAcc@1  28.91 ( 72.74)\tAcc@5  79.69 ( 93.76)\n","Epoch: [134][120/391]\tTime  0.090 ( 0.091)\tLoss 1.9823e+00 (1.2691e+00)\tAcc@1  28.91 ( 73.74)\tAcc@5  78.12 ( 93.89)\n","Epoch: [134][150/391]\tTime  0.091 ( 0.091)\tLoss 1.5319e+00 (1.2413e+00)\tAcc@1  11.72 ( 72.09)\tAcc@5  69.53 ( 92.72)\n","Epoch: [134][180/391]\tTime  0.090 ( 0.091)\tLoss 1.5775e+00 (1.2302e+00)\tAcc@1  70.31 ( 72.84)\tAcc@5  97.66 ( 93.12)\n","Epoch: [134][210/391]\tTime  0.090 ( 0.091)\tLoss 9.9740e-01 (1.2300e+00)\tAcc@1  97.66 ( 72.56)\tAcc@5 100.00 ( 92.72)\n","Epoch: [134][240/391]\tTime  0.090 ( 0.091)\tLoss 1.3560e+00 (1.2415e+00)\tAcc@1  63.28 ( 70.79)\tAcc@5  93.75 ( 92.25)\n","Epoch: [134][270/391]\tTime  0.091 ( 0.091)\tLoss 9.8625e-01 (1.2386e+00)\tAcc@1  92.97 ( 71.08)\tAcc@5 100.00 ( 92.43)\n","Epoch: [134][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6143e+00 (1.2414e+00)\tAcc@1  26.56 ( 71.23)\tAcc@5  84.38 ( 92.54)\n","Epoch: [134][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6108e+00 (1.2362e+00)\tAcc@1  47.66 ( 71.78)\tAcc@5  85.94 ( 92.76)\n","Epoch: [134][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4178e+00 (1.2346e+00)\tAcc@1  71.09 ( 71.36)\tAcc@5  95.31 ( 92.61)\n","Epoch: [134][390/391]\tTime  0.081 ( 0.091)\tLoss 1.4018e+00 (1.2377e+00)\tAcc@1  76.25 ( 71.60)\tAcc@5  97.50 ( 92.78)\n","==> Train Accuracy: Acc@1 71.596 || Acc@5 92.780\n","==> Test Accuracy:  Acc@1 79.790 || Acc@5 95.390\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 135, lr: 0.0008000000000000003 -----\n","Epoch: [135][  0/391]\tTime  0.205 ( 0.205)\tLoss 1.2073e+00 (1.2073e+00)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [135][ 30/391]\tTime  0.090 ( 0.094)\tLoss 9.8804e-01 (1.2522e+00)\tAcc@1  96.09 ( 74.70)\tAcc@5  99.22 ( 92.11)\n","Epoch: [135][ 60/391]\tTime  0.090 ( 0.092)\tLoss 9.3708e-01 (1.2262e+00)\tAcc@1  96.88 ( 77.50)\tAcc@5  99.22 ( 94.06)\n","Epoch: [135][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.0349e+00 (1.2386e+00)\tAcc@1  96.09 ( 75.13)\tAcc@5 100.00 ( 93.56)\n","Epoch: [135][120/391]\tTime  0.091 ( 0.091)\tLoss 1.7126e+00 (1.2216e+00)\tAcc@1  33.59 ( 73.36)\tAcc@5  78.12 ( 92.70)\n","Epoch: [135][150/391]\tTime  0.090 ( 0.091)\tLoss 1.4339e+00 (1.2312e+00)\tAcc@1  67.19 ( 73.50)\tAcc@5  93.75 ( 93.04)\n","Epoch: [135][180/391]\tTime  0.092 ( 0.091)\tLoss 7.0540e-01 (1.2490e+00)\tAcc@1  99.22 ( 73.20)\tAcc@5 100.00 ( 93.17)\n","Epoch: [135][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5445e+00 (1.2483e+00)\tAcc@1   5.47 ( 73.31)\tAcc@5  52.34 ( 93.30)\n","Epoch: [135][240/391]\tTime  0.091 ( 0.091)\tLoss 1.0280e+00 (1.2316e+00)\tAcc@1  96.09 ( 73.63)\tAcc@5 100.00 ( 93.35)\n","Epoch: [135][270/391]\tTime  0.090 ( 0.091)\tLoss 1.5786e+00 (1.2344e+00)\tAcc@1  48.44 ( 73.06)\tAcc@5  90.62 ( 92.90)\n","Epoch: [135][300/391]\tTime  0.087 ( 0.091)\tLoss 1.4186e+00 (1.2436e+00)\tAcc@1  54.69 ( 72.53)\tAcc@5  92.97 ( 92.82)\n","Epoch: [135][330/391]\tTime  0.088 ( 0.091)\tLoss 1.6948e+00 (1.2544e+00)\tAcc@1  57.81 ( 71.61)\tAcc@5  88.28 ( 92.48)\n","Epoch: [135][360/391]\tTime  0.090 ( 0.091)\tLoss 4.6258e-01 (1.2591e+00)\tAcc@1  96.88 ( 71.10)\tAcc@5  99.22 ( 92.09)\n","Epoch: [135][390/391]\tTime  0.082 ( 0.091)\tLoss 1.6411e+00 (1.2559e+00)\tAcc@1  12.50 ( 71.55)\tAcc@5  63.75 ( 92.22)\n","==> Train Accuracy: Acc@1 71.554 || Acc@5 92.216\n","==> Test Accuracy:  Acc@1 80.300 || Acc@5 95.280\n","==> 37.90 seconds to train this epoch\n","\n","\n","----- epoch: 136, lr: 0.0008000000000000003 -----\n","Epoch: [136][  0/391]\tTime  0.226 ( 0.226)\tLoss 1.2686e+00 (1.2686e+00)\tAcc@1  78.12 ( 78.12)\tAcc@5  98.44 ( 98.44)\n","Epoch: [136][ 30/391]\tTime  0.090 ( 0.094)\tLoss 7.2788e-01 (1.2454e+00)\tAcc@1 100.00 ( 71.47)\tAcc@5 100.00 ( 92.77)\n","Epoch: [136][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.5559e+00 (1.2816e+00)\tAcc@1  77.34 ( 70.84)\tAcc@5  92.97 ( 92.14)\n","Epoch: [136][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.3590e+00 (1.2879e+00)\tAcc@1  28.12 ( 69.45)\tAcc@5  85.16 ( 91.36)\n","Epoch: [136][120/391]\tTime  0.091 ( 0.091)\tLoss 7.9009e-01 (1.2524e+00)\tAcc@1  98.44 ( 71.78)\tAcc@5 100.00 ( 92.43)\n","Epoch: [136][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2194e+00 (1.2515e+00)\tAcc@1  90.62 ( 71.80)\tAcc@5 100.00 ( 92.42)\n","Epoch: [136][180/391]\tTime  0.091 ( 0.091)\tLoss 1.7348e+00 (1.2616e+00)\tAcc@1  62.50 ( 72.44)\tAcc@5  89.06 ( 92.89)\n","Epoch: [136][210/391]\tTime  0.090 ( 0.091)\tLoss 8.5840e-01 (1.2533e+00)\tAcc@1  96.88 ( 73.05)\tAcc@5 100.00 ( 93.18)\n","Epoch: [136][240/391]\tTime  0.090 ( 0.091)\tLoss 1.4798e+00 (1.2510e+00)\tAcc@1  78.12 ( 73.60)\tAcc@5  94.53 ( 93.50)\n","Epoch: [136][270/391]\tTime  0.089 ( 0.091)\tLoss 1.2845e+00 (1.2462e+00)\tAcc@1  83.59 ( 74.18)\tAcc@5  99.22 ( 93.73)\n","Epoch: [136][300/391]\tTime  0.087 ( 0.091)\tLoss 1.5054e+00 (1.2336e+00)\tAcc@1  63.28 ( 74.63)\tAcc@5  96.88 ( 93.91)\n","Epoch: [136][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6062e+00 (1.2335e+00)\tAcc@1  28.91 ( 74.48)\tAcc@5  84.38 ( 93.90)\n","Epoch: [136][360/391]\tTime  0.091 ( 0.091)\tLoss 1.2618e+00 (1.2290e+00)\tAcc@1  83.59 ( 74.38)\tAcc@5  99.22 ( 93.80)\n","Epoch: [136][390/391]\tTime  0.081 ( 0.091)\tLoss 1.3371e+00 (1.2280e+00)\tAcc@1  66.25 ( 73.81)\tAcc@5 100.00 ( 93.46)\n","==> Train Accuracy: Acc@1 73.814 || Acc@5 93.462\n","==> Test Accuracy:  Acc@1 80.390 || Acc@5 95.380\n","==> 37.88 seconds to train this epoch\n","\n","\n","----- epoch: 137, lr: 0.0008000000000000003 -----\n","Epoch: [137][  0/391]\tTime  0.204 ( 0.204)\tLoss 1.1164e+00 (1.1164e+00)\tAcc@1  90.62 ( 90.62)\tAcc@5  98.44 ( 98.44)\n","Epoch: [137][ 30/391]\tTime  0.090 ( 0.094)\tLoss 3.4575e-01 (1.2182e+00)\tAcc@1  97.66 ( 72.05)\tAcc@5 100.00 ( 92.19)\n","Epoch: [137][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.4946e+00 (1.2780e+00)\tAcc@1  60.94 ( 72.86)\tAcc@5  95.31 ( 93.60)\n","Epoch: [137][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.5382e+00 (1.2689e+00)\tAcc@1  72.66 ( 72.18)\tAcc@5  92.19 ( 92.89)\n","Epoch: [137][120/391]\tTime  0.090 ( 0.091)\tLoss 1.5770e+00 (1.2608e+00)\tAcc@1   4.69 ( 71.92)\tAcc@5  64.84 ( 92.90)\n","Epoch: [137][150/391]\tTime  0.090 ( 0.091)\tLoss 1.4976e+00 (1.2444e+00)\tAcc@1  82.03 ( 72.35)\tAcc@5  95.31 ( 93.13)\n","Epoch: [137][180/391]\tTime  0.090 ( 0.091)\tLoss 1.5661e+00 (1.2542e+00)\tAcc@1  46.09 ( 71.84)\tAcc@5  87.50 ( 92.81)\n","Epoch: [137][210/391]\tTime  0.091 ( 0.091)\tLoss 4.0752e-01 (1.2450e+00)\tAcc@1  99.22 ( 71.81)\tAcc@5 100.00 ( 92.63)\n","Epoch: [137][240/391]\tTime  0.091 ( 0.091)\tLoss 9.8549e-01 (1.2499e+00)\tAcc@1  96.09 ( 71.74)\tAcc@5  99.22 ( 92.70)\n","Epoch: [137][270/391]\tTime  0.090 ( 0.091)\tLoss 1.4657e+00 (1.2412e+00)\tAcc@1  64.84 ( 71.75)\tAcc@5  90.62 ( 92.78)\n","Epoch: [137][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4349e+00 (1.2422e+00)\tAcc@1  78.91 ( 71.95)\tAcc@5  94.53 ( 92.88)\n","Epoch: [137][330/391]\tTime  0.091 ( 0.091)\tLoss 1.2316e+00 (1.2326e+00)\tAcc@1  91.41 ( 72.66)\tAcc@5 100.00 ( 93.12)\n","Epoch: [137][360/391]\tTime  0.092 ( 0.091)\tLoss 8.0328e-01 (1.2402e+00)\tAcc@1  96.88 ( 72.38)\tAcc@5 100.00 ( 93.01)\n","Epoch: [137][390/391]\tTime  0.078 ( 0.091)\tLoss 1.5740e+00 (1.2414e+00)\tAcc@1  37.50 ( 72.31)\tAcc@5  83.75 ( 93.07)\n","==> Train Accuracy: Acc@1 72.314 || Acc@5 93.066\n","==> Test Accuracy:  Acc@1 79.980 || Acc@5 95.520\n","==> 37.91 seconds to train this epoch\n","\n","\n","----- epoch: 138, lr: 0.0008000000000000003 -----\n","Epoch: [138][  0/391]\tTime  0.205 ( 0.205)\tLoss 1.3189e+00 (1.3189e+00)\tAcc@1  89.06 ( 89.06)\tAcc@5  98.44 ( 98.44)\n","Epoch: [138][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.0379e+00 (1.2231e+00)\tAcc@1  94.53 ( 73.79)\tAcc@5 100.00 ( 94.53)\n","Epoch: [138][ 60/391]\tTime  0.091 ( 0.092)\tLoss 2.2097e-01 (1.1925e+00)\tAcc@1  99.22 ( 72.17)\tAcc@5 100.00 ( 93.43)\n","Epoch: [138][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.9228e-01 (1.2146e+00)\tAcc@1  99.22 ( 73.11)\tAcc@5 100.00 ( 93.63)\n","Epoch: [138][120/391]\tTime  0.090 ( 0.091)\tLoss 1.5798e+00 (1.1761e+00)\tAcc@1  44.53 ( 74.63)\tAcc@5  86.72 ( 93.92)\n","Epoch: [138][150/391]\tTime  0.090 ( 0.091)\tLoss 8.6035e-01 (1.1680e+00)\tAcc@1  96.88 ( 75.19)\tAcc@5  98.44 ( 93.76)\n","Epoch: [138][180/391]\tTime  0.091 ( 0.091)\tLoss 1.3347e+00 (1.1824e+00)\tAcc@1  88.28 ( 74.94)\tAcc@5  96.09 ( 93.85)\n","Epoch: [138][210/391]\tTime  0.090 ( 0.091)\tLoss 1.2863e+00 (1.1784e+00)\tAcc@1  91.41 ( 74.73)\tAcc@5  98.44 ( 93.75)\n","Epoch: [138][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5215e+00 (1.1739e+00)\tAcc@1  63.28 ( 74.82)\tAcc@5  92.19 ( 93.56)\n","Epoch: [138][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3076e+00 (1.1733e+00)\tAcc@1  84.38 ( 74.74)\tAcc@5  99.22 ( 93.38)\n","Epoch: [138][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6756e+00 (1.1939e+00)\tAcc@1  29.69 ( 73.69)\tAcc@5  85.94 ( 93.08)\n","Epoch: [138][330/391]\tTime  0.091 ( 0.091)\tLoss 1.4958e+00 (1.1981e+00)\tAcc@1  79.69 ( 73.92)\tAcc@5  96.88 ( 93.22)\n","Epoch: [138][360/391]\tTime  0.090 ( 0.091)\tLoss 1.2934e+00 (1.1936e+00)\tAcc@1  53.91 ( 74.05)\tAcc@5  96.09 ( 93.33)\n","Epoch: [138][390/391]\tTime  0.081 ( 0.091)\tLoss 1.1960e+00 (1.1955e+00)\tAcc@1  91.25 ( 73.83)\tAcc@5 100.00 ( 93.30)\n","==> Train Accuracy: Acc@1 73.826 || Acc@5 93.304\n","==> Test Accuracy:  Acc@1 80.280 || Acc@5 95.490\n","==> 37.88 seconds to train this epoch\n","\n","\n","----- epoch: 139, lr: 0.0008000000000000003 -----\n","Epoch: [139][  0/391]\tTime  0.202 ( 0.202)\tLoss 1.3607e+00 (1.3607e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  95.31 ( 95.31)\n","Epoch: [139][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.4311e+00 (1.1727e+00)\tAcc@1   7.03 ( 78.48)\tAcc@5  70.31 ( 94.30)\n","Epoch: [139][ 60/391]\tTime  0.092 ( 0.092)\tLoss 1.1866e+00 (1.2089e+00)\tAcc@1  82.81 ( 73.54)\tAcc@5  97.66 ( 92.56)\n","Epoch: [139][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.0058e+00 (1.2101e+00)\tAcc@1  92.97 ( 74.18)\tAcc@5  98.44 ( 92.90)\n","Epoch: [139][120/391]\tTime  0.091 ( 0.091)\tLoss 3.1611e-01 (1.1957e+00)\tAcc@1  98.44 ( 74.07)\tAcc@5 100.00 ( 93.10)\n","Epoch: [139][150/391]\tTime  0.091 ( 0.091)\tLoss 9.0708e-01 (1.2064e+00)\tAcc@1  95.31 ( 74.83)\tAcc@5  98.44 ( 93.57)\n","Epoch: [139][180/391]\tTime  0.090 ( 0.091)\tLoss 3.5694e-01 (1.2067e+00)\tAcc@1 100.00 ( 72.92)\tAcc@5 100.00 ( 92.66)\n","Epoch: [139][210/391]\tTime  0.090 ( 0.091)\tLoss 6.2344e-01 (1.1893e+00)\tAcc@1  96.88 ( 73.79)\tAcc@5 100.00 ( 92.85)\n","Epoch: [139][240/391]\tTime  0.091 ( 0.091)\tLoss 6.7491e-01 (1.1966e+00)\tAcc@1  96.88 ( 73.37)\tAcc@5  99.22 ( 92.75)\n","Epoch: [139][270/391]\tTime  0.090 ( 0.091)\tLoss 1.5621e+00 (1.2033e+00)\tAcc@1  72.66 ( 73.60)\tAcc@5  91.41 ( 92.89)\n","Epoch: [139][300/391]\tTime  0.091 ( 0.091)\tLoss 2.1787e-01 (1.2118e+00)\tAcc@1  99.22 ( 73.47)\tAcc@5 100.00 ( 93.03)\n","Epoch: [139][330/391]\tTime  0.093 ( 0.091)\tLoss 1.7077e+00 (1.2146e+00)\tAcc@1  28.12 ( 73.65)\tAcc@5  78.12 ( 93.16)\n","Epoch: [139][360/391]\tTime  0.090 ( 0.091)\tLoss 6.1621e-01 (1.2128e+00)\tAcc@1  97.66 ( 74.05)\tAcc@5 100.00 ( 93.32)\n","Epoch: [139][390/391]\tTime  0.082 ( 0.091)\tLoss 1.1373e+00 (1.2075e+00)\tAcc@1  92.50 ( 74.27)\tAcc@5  98.75 ( 93.22)\n","==> Train Accuracy: Acc@1 74.266 || Acc@5 93.224\n","==> Test Accuracy:  Acc@1 80.040 || Acc@5 95.600\n","==> 37.95 seconds to train this epoch\n","\n","\n","----- epoch: 140, lr: 0.0008000000000000003 -----\n","Epoch: [140][  0/391]\tTime  0.216 ( 0.216)\tLoss 1.3224e+00 (1.3224e+00)\tAcc@1  85.94 ( 85.94)\tAcc@5  96.09 ( 96.09)\n","Epoch: [140][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.1928e+00 (1.2945e+00)\tAcc@1  92.19 ( 70.67)\tAcc@5  99.22 ( 92.49)\n","Epoch: [140][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.3650e+00 (1.3002e+00)\tAcc@1  75.00 ( 69.12)\tAcc@5  96.09 ( 92.10)\n","Epoch: [140][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.4104e+00 (1.2881e+00)\tAcc@1  68.75 ( 71.44)\tAcc@5  96.88 ( 92.69)\n","Epoch: [140][120/391]\tTime  0.090 ( 0.091)\tLoss 2.5772e-01 (1.2810e+00)\tAcc@1  97.66 ( 72.86)\tAcc@5  99.22 ( 93.23)\n","Epoch: [140][150/391]\tTime  0.091 ( 0.091)\tLoss 1.7120e+00 (1.2678e+00)\tAcc@1   9.38 ( 72.53)\tAcc@5  64.06 ( 93.01)\n","Epoch: [140][180/391]\tTime  0.090 ( 0.091)\tLoss 1.0949e+00 (1.2266e+00)\tAcc@1  95.31 ( 74.22)\tAcc@5  99.22 ( 93.31)\n","Epoch: [140][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5290e+00 (1.2189e+00)\tAcc@1   7.81 ( 74.77)\tAcc@5  53.91 ( 93.54)\n","Epoch: [140][240/391]\tTime  0.090 ( 0.091)\tLoss 1.2515e+00 (1.2088e+00)\tAcc@1  90.62 ( 75.30)\tAcc@5  98.44 ( 93.83)\n","Epoch: [140][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3769e+00 (1.2151e+00)\tAcc@1  83.59 ( 74.48)\tAcc@5  97.66 ( 93.55)\n","Epoch: [140][300/391]\tTime  0.090 ( 0.091)\tLoss 8.5590e-01 (1.2164e+00)\tAcc@1  94.53 ( 75.16)\tAcc@5 100.00 ( 93.86)\n","Epoch: [140][330/391]\tTime  0.090 ( 0.091)\tLoss 1.0759e+00 (1.2119e+00)\tAcc@1  92.19 ( 74.76)\tAcc@5  98.44 ( 93.64)\n","Epoch: [140][360/391]\tTime  0.089 ( 0.091)\tLoss 1.3098e+00 (1.2041e+00)\tAcc@1  89.84 ( 74.70)\tAcc@5  98.44 ( 93.48)\n","Epoch: [140][390/391]\tTime  0.081 ( 0.091)\tLoss 1.1044e+00 (1.2065e+00)\tAcc@1  95.00 ( 74.54)\tAcc@5 100.00 ( 93.48)\n","==> Train Accuracy: Acc@1 74.538 || Acc@5 93.476\n","==> Test Accuracy:  Acc@1 79.980 || Acc@5 95.390\n","==> 37.92 seconds to train this epoch\n","\n","\n","----- epoch: 141, lr: 0.0008000000000000003 -----\n","Epoch: [141][  0/391]\tTime  0.205 ( 0.205)\tLoss 1.4330e+00 (1.4330e+00)\tAcc@1  75.00 ( 75.00)\tAcc@5  94.53 ( 94.53)\n","Epoch: [141][ 30/391]\tTime  0.090 ( 0.094)\tLoss 6.2195e-01 (1.1942e+00)\tAcc@1  95.31 ( 79.03)\tAcc@5  99.22 ( 95.64)\n","Epoch: [141][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.2335e+00 (1.1706e+00)\tAcc@1  89.06 ( 77.14)\tAcc@5  97.66 ( 93.85)\n","Epoch: [141][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.2941e+00 (1.2044e+00)\tAcc@1  92.19 ( 76.43)\tAcc@5  99.22 ( 94.46)\n","Epoch: [141][120/391]\tTime  0.090 ( 0.091)\tLoss 1.4695e+00 (1.2215e+00)\tAcc@1  74.22 ( 75.09)\tAcc@5  96.88 ( 94.01)\n","Epoch: [141][150/391]\tTime  0.090 ( 0.091)\tLoss 1.5153e+00 (1.2184e+00)\tAcc@1  45.31 ( 74.69)\tAcc@5  94.53 ( 94.08)\n","Epoch: [141][180/391]\tTime  0.090 ( 0.091)\tLoss 7.6847e-01 (1.2217e+00)\tAcc@1  97.66 ( 74.99)\tAcc@5  99.22 ( 94.29)\n","Epoch: [141][210/391]\tTime  0.087 ( 0.091)\tLoss 1.5159e+00 (1.2316e+00)\tAcc@1  78.12 ( 73.02)\tAcc@5  94.53 ( 93.68)\n","Epoch: [141][240/391]\tTime  0.090 ( 0.091)\tLoss 7.1853e-01 (1.2093e+00)\tAcc@1  97.66 ( 74.45)\tAcc@5  99.22 ( 94.14)\n","Epoch: [141][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6233e+00 (1.2089e+00)\tAcc@1  10.94 ( 73.39)\tAcc@5  77.34 ( 93.69)\n","Epoch: [141][300/391]\tTime  0.091 ( 0.091)\tLoss 1.5059e+00 (1.2087e+00)\tAcc@1  63.28 ( 72.65)\tAcc@5  93.75 ( 93.48)\n","Epoch: [141][330/391]\tTime  0.090 ( 0.091)\tLoss 4.0990e-01 (1.2024e+00)\tAcc@1  96.88 ( 73.20)\tAcc@5 100.00 ( 93.46)\n","Epoch: [141][360/391]\tTime  0.090 ( 0.091)\tLoss 1.3571e+00 (1.2023e+00)\tAcc@1  81.25 ( 73.42)\tAcc@5  96.09 ( 93.59)\n","Epoch: [141][390/391]\tTime  0.082 ( 0.091)\tLoss 1.3837e+00 (1.1990e+00)\tAcc@1  82.50 ( 73.54)\tAcc@5  98.75 ( 93.64)\n","==> Train Accuracy: Acc@1 73.542 || Acc@5 93.638\n","==> Test Accuracy:  Acc@1 80.330 || Acc@5 95.490\n","==> 37.95 seconds to train this epoch\n","\n","\n","----- epoch: 142, lr: 0.0008000000000000003 -----\n","Epoch: [142][  0/391]\tTime  0.201 ( 0.201)\tLoss 1.5741e+00 (1.5741e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  79.69 ( 79.69)\n","Epoch: [142][ 30/391]\tTime  0.092 ( 0.094)\tLoss 1.1239e+00 (1.1792e+00)\tAcc@1  93.75 ( 77.60)\tAcc@5  99.22 ( 95.61)\n","Epoch: [142][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.1594e+00 (1.1884e+00)\tAcc@1  96.09 ( 77.11)\tAcc@5  98.44 ( 94.74)\n","Epoch: [142][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2773e+00 (1.1859e+00)\tAcc@1  89.06 ( 77.24)\tAcc@5  97.66 ( 94.69)\n","Epoch: [142][120/391]\tTime  0.091 ( 0.091)\tLoss 1.6432e+00 (1.2060e+00)\tAcc@1  15.62 ( 76.22)\tAcc@5  73.44 ( 94.54)\n","Epoch: [142][150/391]\tTime  0.091 ( 0.091)\tLoss 1.3631e+00 (1.1918e+00)\tAcc@1  88.28 ( 75.62)\tAcc@5  96.09 ( 93.69)\n","Epoch: [142][180/391]\tTime  0.093 ( 0.091)\tLoss 1.3419e+00 (1.1930e+00)\tAcc@1  58.59 ( 74.34)\tAcc@5  95.31 ( 92.87)\n","Epoch: [142][210/391]\tTime  0.090 ( 0.091)\tLoss 4.5098e-01 (1.2031e+00)\tAcc@1  96.09 ( 73.52)\tAcc@5  99.22 ( 92.31)\n","Epoch: [142][240/391]\tTime  0.091 ( 0.091)\tLoss 4.3481e-01 (1.1996e+00)\tAcc@1  97.66 ( 73.70)\tAcc@5 100.00 ( 92.54)\n","Epoch: [142][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3996e+00 (1.1844e+00)\tAcc@1  86.72 ( 73.99)\tAcc@5  97.66 ( 92.46)\n","Epoch: [142][300/391]\tTime  0.090 ( 0.091)\tLoss 7.6812e-01 (1.1757e+00)\tAcc@1  97.66 ( 74.14)\tAcc@5 100.00 ( 92.42)\n","Epoch: [142][330/391]\tTime  0.090 ( 0.091)\tLoss 7.2782e-01 (1.1882e+00)\tAcc@1  98.44 ( 73.65)\tAcc@5  99.22 ( 92.27)\n","Epoch: [142][360/391]\tTime  0.091 ( 0.091)\tLoss 1.3780e+00 (1.1977e+00)\tAcc@1  80.47 ( 73.08)\tAcc@5  96.09 ( 92.14)\n","Epoch: [142][390/391]\tTime  0.081 ( 0.091)\tLoss 1.7060e+00 (1.1979e+00)\tAcc@1  56.25 ( 72.88)\tAcc@5  93.75 ( 92.07)\n","==> Train Accuracy: Acc@1 72.876 || Acc@5 92.074\n","==> Test Accuracy:  Acc@1 79.660 || Acc@5 95.380\n","==> 37.90 seconds to train this epoch\n","\n","\n","----- epoch: 143, lr: 0.0008000000000000003 -----\n","Epoch: [143][  0/391]\tTime  0.222 ( 0.222)\tLoss 5.6898e-01 (5.6898e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n","Epoch: [143][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.2736e+00 (1.1545e+00)\tAcc@1  85.16 ( 76.84)\tAcc@5  99.22 ( 94.30)\n","Epoch: [143][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.5268e+00 (1.1762e+00)\tAcc@1  73.44 ( 77.73)\tAcc@5  93.75 ( 94.83)\n","Epoch: [143][ 90/391]\tTime  0.092 ( 0.092)\tLoss 1.5008e+00 (1.1763e+00)\tAcc@1  60.16 ( 77.68)\tAcc@5  96.09 ( 95.17)\n","Epoch: [143][120/391]\tTime  0.091 ( 0.091)\tLoss 8.5070e-01 (1.1624e+00)\tAcc@1  95.31 ( 77.43)\tAcc@5  99.22 ( 95.03)\n","Epoch: [143][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7040e+00 (1.1520e+00)\tAcc@1  11.72 ( 77.09)\tAcc@5  66.41 ( 94.97)\n","Epoch: [143][180/391]\tTime  0.090 ( 0.091)\tLoss 1.3071e+00 (1.1496e+00)\tAcc@1  92.19 ( 77.87)\tAcc@5  96.88 ( 95.22)\n","Epoch: [143][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6768e+00 (1.1566e+00)\tAcc@1  29.69 ( 76.34)\tAcc@5  78.91 ( 94.56)\n","Epoch: [143][240/391]\tTime  0.088 ( 0.091)\tLoss 1.4555e+00 (1.1556e+00)\tAcc@1  67.19 ( 75.98)\tAcc@5  94.53 ( 94.38)\n","Epoch: [143][270/391]\tTime  0.092 ( 0.091)\tLoss 1.8503e+00 (1.1560e+00)\tAcc@1  39.06 ( 76.39)\tAcc@5  87.50 ( 94.59)\n","Epoch: [143][300/391]\tTime  0.090 ( 0.091)\tLoss 1.0329e+00 (1.1601e+00)\tAcc@1  95.31 ( 76.56)\tAcc@5  98.44 ( 94.57)\n","Epoch: [143][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5299e+00 (1.1575e+00)\tAcc@1  41.41 ( 77.30)\tAcc@5  88.28 ( 94.86)\n","Epoch: [143][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6378e+00 (1.1642e+00)\tAcc@1  44.53 ( 77.00)\tAcc@5  86.72 ( 94.87)\n","Epoch: [143][390/391]\tTime  0.082 ( 0.091)\tLoss 9.1123e-01 (1.1611e+00)\tAcc@1  95.00 ( 77.16)\tAcc@5  98.75 ( 94.91)\n","==> Train Accuracy: Acc@1 77.158 || Acc@5 94.906\n","==> Test Accuracy:  Acc@1 80.380 || Acc@5 95.700\n","==> 37.95 seconds to train this epoch\n","\n","\n","----- epoch: 144, lr: 0.0008000000000000003 -----\n","Epoch: [144][  0/391]\tTime  0.198 ( 0.198)\tLoss 1.8506e+00 (1.8506e+00)\tAcc@1   8.59 (  8.59)\tAcc@5  58.59 ( 58.59)\n","Epoch: [144][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.2561e+00 (1.3246e+00)\tAcc@1  92.97 ( 67.21)\tAcc@5  97.66 ( 89.89)\n","Epoch: [144][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.5522e+00 (1.2430e+00)\tAcc@1   9.38 ( 71.50)\tAcc@5  69.53 ( 91.79)\n","Epoch: [144][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.0446e+00 (1.2349e+00)\tAcc@1  97.66 ( 70.62)\tAcc@5  99.22 ( 91.02)\n","Epoch: [144][120/391]\tTime  0.090 ( 0.091)\tLoss 3.6016e-01 (1.2161e+00)\tAcc@1 100.00 ( 71.97)\tAcc@5 100.00 ( 92.01)\n","Epoch: [144][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3619e+00 (1.2330e+00)\tAcc@1  74.22 ( 69.65)\tAcc@5  98.44 ( 91.61)\n","Epoch: [144][180/391]\tTime  0.091 ( 0.091)\tLoss 1.0333e+00 (1.2028e+00)\tAcc@1  92.97 ( 71.43)\tAcc@5  99.22 ( 92.11)\n","Epoch: [144][210/391]\tTime  0.088 ( 0.091)\tLoss 1.3411e+00 (1.2050e+00)\tAcc@1  77.34 ( 72.55)\tAcc@5  98.44 ( 92.57)\n","Epoch: [144][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5413e+00 (1.2228e+00)\tAcc@1  71.88 ( 71.52)\tAcc@5  95.31 ( 92.33)\n","Epoch: [144][270/391]\tTime  0.093 ( 0.091)\tLoss 1.6518e+00 (1.2277e+00)\tAcc@1  36.72 ( 71.51)\tAcc@5  84.38 ( 92.32)\n","Epoch: [144][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4807e+00 (1.2223e+00)\tAcc@1  75.00 ( 71.71)\tAcc@5  94.53 ( 92.24)\n","Epoch: [144][330/391]\tTime  0.091 ( 0.091)\tLoss 1.3214e+00 (1.2143e+00)\tAcc@1  69.53 ( 72.40)\tAcc@5  95.31 ( 92.51)\n","Epoch: [144][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5641e+00 (1.2111e+00)\tAcc@1  40.62 ( 72.52)\tAcc@5  86.72 ( 92.60)\n","Epoch: [144][390/391]\tTime  0.082 ( 0.091)\tLoss 1.4884e+00 (1.2222e+00)\tAcc@1  80.00 ( 72.07)\tAcc@5  96.25 ( 92.63)\n","==> Train Accuracy: Acc@1 72.068 || Acc@5 92.628\n","==> Test Accuracy:  Acc@1 80.020 || Acc@5 95.400\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 145, lr: 0.0008000000000000003 -----\n","Epoch: [145][  0/391]\tTime  0.199 ( 0.199)\tLoss 1.6066e+00 (1.6066e+00)\tAcc@1  20.31 ( 20.31)\tAcc@5  77.34 ( 77.34)\n","Epoch: [145][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.1329e+00 (1.1804e+00)\tAcc@1  94.53 ( 74.40)\tAcc@5 100.00 ( 94.91)\n","Epoch: [145][ 60/391]\tTime  0.090 ( 0.092)\tLoss 1.0007e+00 (1.2352e+00)\tAcc@1  94.53 ( 72.21)\tAcc@5 100.00 ( 94.22)\n","Epoch: [145][ 90/391]\tTime  0.090 ( 0.092)\tLoss 8.0395e-01 (1.1589e+00)\tAcc@1  96.88 ( 74.54)\tAcc@5 100.00 ( 94.02)\n","Epoch: [145][120/391]\tTime  0.090 ( 0.091)\tLoss 8.9635e-01 (1.1515e+00)\tAcc@1  96.09 ( 75.21)\tAcc@5 100.00 ( 93.60)\n","Epoch: [145][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2753e+00 (1.1596e+00)\tAcc@1  85.94 ( 74.49)\tAcc@5  97.66 ( 93.36)\n","Epoch: [145][180/391]\tTime  0.091 ( 0.091)\tLoss 7.5797e-01 (1.1596e+00)\tAcc@1  98.44 ( 73.91)\tAcc@5 100.00 ( 92.97)\n","Epoch: [145][210/391]\tTime  0.091 ( 0.091)\tLoss 1.5732e+00 (1.1623e+00)\tAcc@1  21.88 ( 73.39)\tAcc@5  86.72 ( 92.78)\n","Epoch: [145][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5345e+00 (1.1554e+00)\tAcc@1  85.94 ( 74.74)\tAcc@5  96.09 ( 93.02)\n","Epoch: [145][270/391]\tTime  0.090 ( 0.091)\tLoss 9.2824e-01 (1.1494e+00)\tAcc@1  94.53 ( 75.45)\tAcc@5  99.22 ( 93.40)\n","Epoch: [145][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7885e+00 (1.1595e+00)\tAcc@1  21.09 ( 75.06)\tAcc@5  82.03 ( 93.19)\n","Epoch: [145][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6056e+00 (1.1637e+00)\tAcc@1  14.84 ( 74.93)\tAcc@5  69.53 ( 92.99)\n","Epoch: [145][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4354e+00 (1.1695e+00)\tAcc@1  79.69 ( 75.10)\tAcc@5  93.75 ( 93.13)\n","Epoch: [145][390/391]\tTime  0.082 ( 0.091)\tLoss 1.3409e+00 (1.1711e+00)\tAcc@1  82.50 ( 74.87)\tAcc@5  96.25 ( 93.04)\n","==> Train Accuracy: Acc@1 74.870 || Acc@5 93.042\n","==> Test Accuracy:  Acc@1 80.400 || Acc@5 95.570\n","==> 37.87 seconds to train this epoch\n","\n","\n","----- epoch: 146, lr: 0.0008000000000000003 -----\n","Epoch: [146][  0/391]\tTime  0.198 ( 0.198)\tLoss 1.5636e+00 (1.5636e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  89.06 ( 89.06)\n","Epoch: [146][ 30/391]\tTime  0.091 ( 0.094)\tLoss 1.3211e+00 (1.3145e+00)\tAcc@1  82.81 ( 66.03)\tAcc@5  98.44 ( 92.39)\n","Epoch: [146][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.1460e+00 (1.2213e+00)\tAcc@1  93.75 ( 69.97)\tAcc@5  99.22 ( 93.17)\n","Epoch: [146][ 90/391]\tTime  0.090 ( 0.092)\tLoss 9.7449e-01 (1.1842e+00)\tAcc@1  95.31 ( 72.48)\tAcc@5 100.00 ( 93.29)\n","Epoch: [146][120/391]\tTime  0.095 ( 0.091)\tLoss 1.3739e+00 (1.1745e+00)\tAcc@1  77.34 ( 74.21)\tAcc@5  96.88 ( 94.01)\n","Epoch: [146][150/391]\tTime  0.091 ( 0.091)\tLoss 1.4769e+00 (1.1796e+00)\tAcc@1  78.91 ( 75.01)\tAcc@5  94.53 ( 94.26)\n","Epoch: [146][180/391]\tTime  0.090 ( 0.091)\tLoss 1.4601e+00 (1.2050e+00)\tAcc@1  78.12 ( 74.09)\tAcc@5  97.66 ( 94.08)\n","Epoch: [146][210/391]\tTime  0.091 ( 0.091)\tLoss 1.3512e+00 (1.2034e+00)\tAcc@1  82.03 ( 74.62)\tAcc@5  97.66 ( 94.07)\n","Epoch: [146][240/391]\tTime  0.090 ( 0.091)\tLoss 6.0926e-01 (1.2044e+00)\tAcc@1  98.44 ( 74.00)\tAcc@5  99.22 ( 93.73)\n","Epoch: [146][270/391]\tTime  0.090 ( 0.091)\tLoss 1.4296e+00 (1.2134e+00)\tAcc@1  68.75 ( 73.87)\tAcc@5  91.41 ( 93.78)\n","Epoch: [146][300/391]\tTime  0.095 ( 0.091)\tLoss 1.0194e+00 (1.2154e+00)\tAcc@1  96.09 ( 73.48)\tAcc@5 100.00 ( 93.43)\n","Epoch: [146][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5360e+00 (1.2142e+00)\tAcc@1  60.94 ( 72.62)\tAcc@5  93.75 ( 93.03)\n","Epoch: [146][360/391]\tTime  0.090 ( 0.091)\tLoss 1.5979e+00 (1.2049e+00)\tAcc@1  28.91 ( 72.51)\tAcc@5  83.59 ( 92.93)\n","Epoch: [146][390/391]\tTime  0.081 ( 0.091)\tLoss 1.8119e-01 (1.2101e+00)\tAcc@1 100.00 ( 71.99)\tAcc@5 100.00 ( 92.83)\n","==> Train Accuracy: Acc@1 71.988 || Acc@5 92.826\n","==> Test Accuracy:  Acc@1 80.350 || Acc@5 95.400\n","==> 37.93 seconds to train this epoch\n","\n","\n","----- epoch: 147, lr: 0.0008000000000000003 -----\n","Epoch: [147][  0/391]\tTime  0.199 ( 0.199)\tLoss 1.0109e+00 (1.0109e+00)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n","Epoch: [147][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.5662e+00 (1.2791e+00)\tAcc@1  10.16 ( 65.68)\tAcc@5  74.22 ( 90.57)\n","Epoch: [147][ 60/391]\tTime  0.092 ( 0.092)\tLoss 6.6122e-01 (1.2533e+00)\tAcc@1  97.66 ( 65.66)\tAcc@5  99.22 ( 89.86)\n","Epoch: [147][ 90/391]\tTime  0.092 ( 0.092)\tLoss 1.4610e+00 (1.2415e+00)\tAcc@1  61.72 ( 69.96)\tAcc@5  95.31 ( 91.76)\n","Epoch: [147][120/391]\tTime  0.091 ( 0.091)\tLoss 1.4390e+00 (1.2470e+00)\tAcc@1  77.34 ( 69.25)\tAcc@5  94.53 ( 91.74)\n","Epoch: [147][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7349e+00 (1.2312e+00)\tAcc@1   8.59 ( 68.75)\tAcc@5  65.62 ( 91.65)\n","Epoch: [147][180/391]\tTime  0.091 ( 0.091)\tLoss 1.1228e+00 (1.2217e+00)\tAcc@1  93.75 ( 70.03)\tAcc@5  98.44 ( 92.02)\n","Epoch: [147][210/391]\tTime  0.091 ( 0.091)\tLoss 1.8431e+00 (1.2352e+00)\tAcc@1  36.72 ( 69.74)\tAcc@5  85.16 ( 92.09)\n","Epoch: [147][240/391]\tTime  0.091 ( 0.091)\tLoss 7.0207e-01 (1.2188e+00)\tAcc@1  99.22 ( 70.86)\tAcc@5 100.00 ( 92.47)\n","Epoch: [147][270/391]\tTime  0.091 ( 0.091)\tLoss 1.3872e+00 (1.2092e+00)\tAcc@1  67.19 ( 71.33)\tAcc@5  96.09 ( 92.60)\n","Epoch: [147][300/391]\tTime  0.093 ( 0.091)\tLoss 1.1806e+00 (1.2013e+00)\tAcc@1  94.53 ( 72.41)\tAcc@5  99.22 ( 92.90)\n","Epoch: [147][330/391]\tTime  0.089 ( 0.091)\tLoss 1.7345e+00 (1.2000e+00)\tAcc@1  39.06 ( 72.33)\tAcc@5  84.38 ( 92.97)\n","Epoch: [147][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1827e+00 (1.2031e+00)\tAcc@1  88.28 ( 72.46)\tAcc@5  97.66 ( 93.03)\n","Epoch: [147][390/391]\tTime  0.082 ( 0.091)\tLoss 1.2377e+00 (1.2063e+00)\tAcc@1  78.75 ( 71.92)\tAcc@5  98.75 ( 92.76)\n","==> Train Accuracy: Acc@1 71.922 || Acc@5 92.762\n","==> Test Accuracy:  Acc@1 80.210 || Acc@5 95.440\n","==> 37.94 seconds to train this epoch\n","\n","\n","----- epoch: 148, lr: 0.0008000000000000003 -----\n","Epoch: [148][  0/391]\tTime  0.224 ( 0.224)\tLoss 1.7429e+00 (1.7429e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  82.81 ( 82.81)\n","Epoch: [148][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.3998e+00 (1.2554e+00)\tAcc@1  71.09 ( 65.98)\tAcc@5  96.88 ( 91.15)\n","Epoch: [148][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.3476e+00 (1.2101e+00)\tAcc@1  82.81 ( 70.33)\tAcc@5  96.88 ( 92.96)\n","Epoch: [148][ 90/391]\tTime  0.089 ( 0.092)\tLoss 1.1207e+00 (1.2235e+00)\tAcc@1  93.75 ( 70.22)\tAcc@5  97.66 ( 92.99)\n","Epoch: [148][120/391]\tTime  0.091 ( 0.092)\tLoss 1.3644e+00 (1.2283e+00)\tAcc@1  83.59 ( 71.67)\tAcc@5  97.66 ( 93.50)\n","Epoch: [148][150/391]\tTime  0.091 ( 0.091)\tLoss 1.0780e+00 (1.2149e+00)\tAcc@1  97.66 ( 72.67)\tAcc@5 100.00 ( 93.93)\n","Epoch: [148][180/391]\tTime  0.090 ( 0.091)\tLoss 1.8005e+00 (1.2115e+00)\tAcc@1   2.34 ( 71.96)\tAcc@5  14.06 ( 93.15)\n","Epoch: [148][210/391]\tTime  0.090 ( 0.091)\tLoss 8.9155e-01 (1.1957e+00)\tAcc@1  96.09 ( 73.02)\tAcc@5  99.22 ( 93.58)\n","Epoch: [148][240/391]\tTime  0.091 ( 0.091)\tLoss 1.3890e+00 (1.1954e+00)\tAcc@1  82.03 ( 72.74)\tAcc@5  96.88 ( 93.15)\n","Epoch: [148][270/391]\tTime  0.091 ( 0.091)\tLoss 1.3852e+00 (1.1866e+00)\tAcc@1  82.81 ( 73.04)\tAcc@5  97.66 ( 92.98)\n","Epoch: [148][300/391]\tTime  0.090 ( 0.091)\tLoss 1.2694e+00 (1.1878e+00)\tAcc@1  89.06 ( 73.78)\tAcc@5  98.44 ( 93.27)\n","Epoch: [148][330/391]\tTime  0.090 ( 0.091)\tLoss 1.1679e+00 (1.1905e+00)\tAcc@1  92.19 ( 73.57)\tAcc@5  98.44 ( 93.26)\n","Epoch: [148][360/391]\tTime  0.091 ( 0.091)\tLoss 1.3871e+00 (1.2003e+00)\tAcc@1  74.22 ( 72.88)\tAcc@5  97.66 ( 93.04)\n","Epoch: [148][390/391]\tTime  0.082 ( 0.091)\tLoss 1.1620e+00 (1.2068e+00)\tAcc@1  97.50 ( 72.64)\tAcc@5 100.00 ( 93.00)\n","==> Train Accuracy: Acc@1 72.636 || Acc@5 93.004\n","==> Test Accuracy:  Acc@1 80.130 || Acc@5 95.320\n","==> 37.99 seconds to train this epoch\n","\n","\n","----- epoch: 149, lr: 0.0008000000000000003 -----\n","Epoch: [149][  0/391]\tTime  0.213 ( 0.213)\tLoss 1.2269e+00 (1.2269e+00)\tAcc@1  85.94 ( 85.94)\tAcc@5  97.66 ( 97.66)\n","Epoch: [149][ 30/391]\tTime  0.090 ( 0.094)\tLoss 1.3033e+00 (1.2397e+00)\tAcc@1  82.03 ( 69.08)\tAcc@5  96.88 ( 90.90)\n","Epoch: [149][ 60/391]\tTime  0.091 ( 0.092)\tLoss 1.3464e+00 (1.2433e+00)\tAcc@1  77.34 ( 69.11)\tAcc@5  97.66 ( 91.93)\n","Epoch: [149][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.0608e+00 (1.2305e+00)\tAcc@1  95.31 ( 73.20)\tAcc@5  99.22 ( 93.40)\n","Epoch: [149][120/391]\tTime  0.090 ( 0.091)\tLoss 1.1859e+00 (1.2288e+00)\tAcc@1  95.31 ( 75.15)\tAcc@5  99.22 ( 94.14)\n","Epoch: [149][150/391]\tTime  0.090 ( 0.091)\tLoss 1.5026e+00 (1.2179e+00)\tAcc@1  75.00 ( 75.53)\tAcc@5  94.53 ( 94.00)\n","Epoch: [149][180/391]\tTime  0.087 ( 0.091)\tLoss 1.3258e+00 (1.2041e+00)\tAcc@1  83.59 ( 75.98)\tAcc@5  98.44 ( 94.21)\n","Epoch: [149][210/391]\tTime  0.091 ( 0.091)\tLoss 1.1178e+00 (1.2138e+00)\tAcc@1  92.19 ( 75.37)\tAcc@5  99.22 ( 94.04)\n","Epoch: [149][240/391]\tTime  0.091 ( 0.091)\tLoss 1.3065e+00 (1.2163e+00)\tAcc@1  78.91 ( 75.39)\tAcc@5  97.66 ( 94.07)\n","Epoch: [149][270/391]\tTime  0.090 ( 0.091)\tLoss 2.5741e-01 (1.2147e+00)\tAcc@1  96.88 ( 75.50)\tAcc@5 100.00 ( 94.09)\n","Epoch: [149][300/391]\tTime  0.090 ( 0.091)\tLoss 1.2798e+00 (1.2044e+00)\tAcc@1  86.72 ( 76.08)\tAcc@5  99.22 ( 94.21)\n","Epoch: [149][330/391]\tTime  0.091 ( 0.091)\tLoss 1.3848e+00 (1.2090e+00)\tAcc@1  64.06 ( 75.15)\tAcc@5  95.31 ( 93.90)\n","Epoch: [149][360/391]\tTime  0.090 ( 0.091)\tLoss 9.7570e-01 (1.2034e+00)\tAcc@1  98.44 ( 75.83)\tAcc@5 100.00 ( 94.15)\n","Epoch: [149][390/391]\tTime  0.085 ( 0.091)\tLoss 1.1627e+00 (1.2142e+00)\tAcc@1  97.50 ( 74.95)\tAcc@5 100.00 ( 93.96)\n","==> Train Accuracy: Acc@1 74.952 || Acc@5 93.958\n","==> Test Accuracy:  Acc@1 79.950 || Acc@5 95.380\n","==> 37.93 seconds to train this epoch\n","\n","Best Top-1 Accuracy: 80.58\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F0QNn0DkibF-"},"source":[""],"execution_count":null,"outputs":[]}]}